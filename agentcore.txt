Table of Contents
What is Amazon Bedrock AgentCore?............................................................................................
Services...........................................................................................................................................................
Amazon Bedrock AgentCore Runtime................................................................................................
Amazon Bedrock AgentCore Identity..................................................................................................
Amazon Bedrock AgentCore Memory.................................................................................................
Amazon Bedrock AgentCore Code Interpreter..................................................................................
Amazon Bedrock AgentCore Browser.................................................................................................
Amazon Bedrock AgentCore Gateway................................................................................................
Amazon Bedrock AgentCore Observability........................................................................................
Common use cases for Amazon Bedrock AgentCore............................................................................
Are you a first-time Amazon Bedrock AgentCore user?.......................................................................
Learn more about AgentCore....................................................................................................................
Pricing for Amazon Bedrock AgentCore..................................................................................................
AWS Regions..................................................................................................................................................
Get started with AgentCore............................................................................................................
Prerequisites..................................................................................................................................................
Install the AgentCore starter toolkit...................................................................................................
Step 1: Create the agent............................................................................................................................
Step 2: Configure and deploy the agent.................................................................................................
Configure the agent...............................................................................................................................
Deploy to AgentCore..............................................................................................................................
Step 3: Monitor the deployment............................................................................................................
Step 4: Test Memory and Code Interpreter..........................................................................................
Test short-term memory.....................................................................................................................
Test long-term memory â€“ cross-session persistence.....................................................................
Test Code Interpreter...........................................................................................................................
Step 5: View traces and logs...................................................................................................................
Access the Amazon CloudWatch dashboard...................................................................................
View AgentCore Runtime logs...........................................................................................................
Clean up.......................................................................................................................................................
Troubleshooting..........................................................................................................................................
Summary......................................................................................................................................................
Understand the available interfaces for using AgentCore..........................................................
Amazon Bedrock AgentCore starter toolkit.........................................................................................
AgentCore Python SDK.............................................................................................................................
Amazon Bedrock AgentCore MCP server..............................................................................................
AWS SDK......................................................................................................................................................
Amazon Bedrock AgentCore console.....................................................................................................
AWS Command Line Interface................................................................................................................
AgentCore Runtime: Host agent or tools.....................................................................................
How it works...............................................................................................................................................
Key components....................................................................................................................................
Authentication and security...............................................................................................................
Additional features...............................................................................................................................
Implementation overview...................................................................................................................
Understanding the AgentCore Runtime service contract.............................................................
IAM Permissions for AgentCore Runtime..............................................................................................
Use Amazon Bedrock AgentCore.......................................................................................................
Use the starter toolkit.........................................................................................................................
Execution role for running an agent in AgentCore Runtime.......................................................
Get started with AgentCore Runtime....................................................................................................
Get started with starter toolkit.........................................................................................................
Get started without the starter toolkit............................................................................................
Use any agent framework........................................................................................................................
Strands Agents......................................................................................................................................
LangGraph..............................................................................................................................................
Google ADK............................................................................................................................................
OpenAI Agents SDK..............................................................................................................................
Microsoft AutoGen................................................................................................................................
CrewAI.....................................................................................................................................................
Use any foundation model......................................................................................................................
Amazon Bedrock...................................................................................................................................
Open AI...................................................................................................................................................
Gemini.....................................................................................................................................................
Deploy MCP servers...................................................................................................................................
How Amazon Bedrock AgentCore supports MCP...........................................................................
Prerequisites...........................................................................................................................................
Step 1: Create your MCP server........................................................................................................
Step 2: Test your MCP server locally................................................................................................
Step 3: Deploy your MCP server to AWS.........................................................................................
Step 4: Invoke your deployed MCP server.......................................................................................
Appendix.................................................................................................................................................
Deploy A2A servers....................................................................................................................................
How Amazon Bedrock AgentCore supports A2A...........................................................................
Using A2A with AgentCore Runtime................................................................................................
Appendix.................................................................................................................................................
Use isolated sessions for agents.............................................................................................................
Understanding ephemeral context....................................................................................................
Extended conversations and multi-step workflows.......................................................................
AgentCore Runtime session lifecycle................................................................................................
How to use sessions.............................................................................................................................
Configure lifecycle settings................................................................................................................
Stop a running session........................................................................................................................
Handle asynchronous and long running agents................................................................................
Key concepts........................................................................................................................................
Implementing asynchronous tasks.................................................................................................
Complete example.............................................................................................................................
Stream agent responses.........................................................................................................................
Pass custom headers...............................................................................................................................
Step 1: Create your agent................................................................................................................
Step 2: Deploy your agent...............................................................................................................
Step 3: Invoke your agent with custom headers.........................................................................
agent..................................................................................................................................................... Step 4: (Optional) Pass the JWT token used for OAuth based inbound access to your
Authenticate and authorize with Inbound Auth and Outbound Auth..........................................
JWT inbound authorization and OAuth outbound access sample............................................
Prerequisites........................................................................................................................................
Step 1: Prepare your agent..............................................................................................................
Step 2: Set up AWS Cognito user pool and add a user..............................................................
Step 3: Deploy your agent...............................................................................................................
Step 4: Use bearer token to invoke your agent...........................................................................
Step 5: Set up your agent to access tools using OAuth.............................................................
Step 6: (Optional) Propagate a JWT token to AgentCore Runtime..........................................
Troubleshooting..................................................................................................................................
AgentCore Runtime versioning and endpoints..................................................................................
How endpoints reference versions..................................................................................................
Versioning scenarios...........................................................................................................................
Endpoint lifecycle states...................................................................................................................
Listing AgentCore Runtime versions and endpoints...................................................................
Invoke an agent..........................................................................................................................................
Invoke streaming agents...................................................................................................................
Invoke multi-modal agents..............................................................................................................
Session management.........................................................................................................................
Error handling.....................................................................................................................................
Best practices......................................................................................................................................
Observe agents........................................................................................................................................
Troubleshoot.............................................................................................................................................
My agent invocations fail with 504 Gateway Timeout errors....................................................
My Docker build fails with "403 Forbidden" when pulling Python base images....................
I get "Unknown service: 'bedrock-agent-core-runtime'" error when using boto3..................
Runtime................................................................................................................................................ I get "AccessDeniedException" when trying to create an Amazon Bedrock AgentCore
My Docker build fails with "exec /bin/sh: exec format error"....................................................
Runtime?............................................................................................................................................... What are the requirements for Docker containers used with Amazon Bedrock AgentCore
My long-running tool gets interrupted after 15 minutes..........................................................
resources?............................................................................................................................................. How do I access the runtimeSessionId in my agent code for tagging or grouping
I have RuntimeClientError (403) issues..........................................................................................
I have missing or empty CloudWatch Logs...................................................................................
I have payload format issues...........................................................................................................
I need help understanding HTTP error codes..............................................................................
I need recommendations for testing my agent...........................................................................
I need help debugging container issues........................................................................................
I need help troubleshooting MCP protocol agents.....................................................................
Best practices.........................................................................................................................................
AgentCore Memory: Add memory to your agent......................................................................
Memory types...........................................................................................................................................
Memory key benefits..............................................................................................................................
Common use cases of memory............................................................................................................
How it works.............................................................................................................................................
Memory terminology.........................................................................................................................
Memory types.....................................................................................................................................
Memory strategies..............................................................................................................................
Get started with AgentCore Memory..................................................................................................
Prerequisites........................................................................................................................................
Step 1: Create an AgentCore Memory...........................................................................................
Step 2: Write events to memory.....................................................................................................
Step 3: Retrieve records from long term memory......................................................................
Cleanup.................................................................................................................................................
Next steps............................................................................................................................................
Create an AgentCore Memory...............................................................................................................
Encrypt your Amazon Bedrock AgentCore Memory....................................................................
Use short-term memory.........................................................................................................................
Create an event...................................................................................................................................
Get an event........................................................................................................................................
List events............................................................................................................................................
Delete an event...................................................................................................................................
Use long-term memory..........................................................................................................................
Enable long-term memory...............................................................................................................
Specify memory organization..........................................................................................................
Configure built-in strategies............................................................................................................
Configure built-in with overrides strategies.................................................................................
Save and retrieve insights................................................................................................................
Retrieve memory records..................................................................................................................
List memory records..........................................................................................................................
Delete memory records.....................................................................................................................
AgentCore Memory examples...............................................................................................................
Customer support AI agent..............................................................................................................
Integrate with LangChain or LangGraph.......................................................................................
AWS SDK..............................................................................................................................................
Amazon Bedrock AgentCore SDK....................................................................................................
Strands Agents SDK...........................................................................................................................
Amazon Bedrock capacity for built-in with overrides strategies....................................................
Observability.............................................................................................................................................
Best practices..............................................................................................................................................
Encrypting your memory..................................................................................................................
Memory poisoning or prompt injection.........................................................................................
Least-privilege principle....................................................................................................................
AgentCore Gateway: Securely connect to tools and resources.................................................
Key benefits..............................................................................................................................................
Key capabilities.........................................................................................................................................
Get started with AgentCore Gateway.................................................................................................
Prerequisites........................................................................................................................................
Step 1: Setup and install..................................................................................................................
Step 2: Create gateway setup script..............................................................................................
Step 3: Run the setup.......................................................................................................................
Step 4: Use the gateway with an agent........................................................................................
What you've built...............................................................................................................................
Troubleshooting..................................................................................................................................
Quick validation..................................................................................................................................
Cleanup.................................................................................................................................................
Next steps............................................................................................................................................
Core concepts...........................................................................................................................................
Key concepts........................................................................................................................................
Tool types.............................................................................................................................................
Supported gateway targets...................................................................................................................
Lambda functions...............................................................................................................................
OpenAPI schemas...............................................................................................................................
Smithy models....................................................................................................................................
MCP servers targets...........................................................................................................................
Integration provider templates.......................................................................................................
Understand gateway tool naming..................................................................................................
Prerequisites..............................................................................................................................................
Set up dependencies and credentials............................................................................................
Set up permissions.............................................................................................................................
Set up inbound authorization..........................................................................................................
Set up outbound authorization.......................................................................................................
Set up a gateway.....................................................................................................................................
Gateway workflow..............................................................................................................................
Create a gateway................................................................................................................................
Add targets to a gateway.................................................................................................................
Use a gateway..........................................................................................................................................
List gateway tools..............................................................................................................................
Call a gateway tool............................................................................................................................
Search for a gateway tool................................................................................................................
Connect an agent...............................................................................................................................
Debug and assess your gateway..........................................................................................................
Turn on debugging messages..........................................................................................................
Use the MCP Inspector......................................................................................................................
Logging Gateway API calls with CloudTrail..................................................................................
Advanced topics.......................................................................................................................................
Customize your gateway's encryption...........................................................................................
Custom domain names.....................................................................................................................
Performance optimization................................................................................................................
AgentCore Identity: Provide identity management for agent applications.............................
Overview....................................................................................................................................................
Features................................................................................................................................................
Terminology.........................................................................................................................................
Example use cases..............................................................................................................................
Get started with AgentCore Identity...................................................................................................
Primary getting started tutorial......................................................................................................
OAuth2 integration getting started tutorial.................................................................................
Common prerequisites......................................................................................................................
Build your first agent........................................................................................................................
Google Drive integration..................................................................................................................
Using the console....................................................................................................................................
Configure an OAuth client................................................................................................................
Configure an API key.........................................................................................................................
Manage agent identities.........................................................................................................................
Understanding identities...................................................................................................................
Agent identity directory....................................................................................................................
Create identities..................................................................................................................................
Manage credential providers.................................................................................................................
Supported authentication patterns................................................................................................
Configure credential provider..........................................................................................................
Obtain credentials..............................................................................................................................
Provider setup..........................................................................................................................................
Amazon Cognito.................................................................................................................................
Auth0 by Okta....................................................................................................................................
Atlassian................................................................................................................................................
CyberArk...............................................................................................................................................
Dropbox................................................................................................................................................
Facebook...............................................................................................................................................
FusionAuth...........................................................................................................................................
GitHub...................................................................................................................................................
Google...................................................................................................................................................
HubSpot................................................................................................................................................
LinkedIn................................................................................................................................................
Microsoft...............................................................................................................................................
Notion...................................................................................................................................................
Okta.......................................................................................................................................................
OneLogin..............................................................................................................................................
PingOne................................................................................................................................................
Reddit....................................................................................................................................................
Salesforce.............................................................................................................................................
Slack......................................................................................................................................................
Spotify...................................................................................................................................................
Twitch....................................................................................................................................................
X.............................................................................................................................................................
Yandex...................................................................................................................................................
Zoom.....................................................................................................................................................
Data protection........................................................................................................................................
Data encryption..................................................................................................................................
Set customer managed key policy..................................................................................................
Configure with API operations or an AWS SDK...........................................................................
Identity resource tagging.......................................................................................................................
Benefits of tagging AgentCore Identity resources.......................................................................
Resource architecture........................................................................................................................
Tagging support matrix.....................................................................................................................
AgentCore Built-in Tools: Interact with your applications using built-in tools.......................
Built-in Tools Overview..........................................................................................................................
Security and Access Control.............................................................................................................
Key components.................................................................................................................................
Integrating built-in tools with Agents...........................................................................................
AgentCore Code Interpreter: Execute code and analyze data........................................................
Overview...............................................................................................................................................
Why use Code Interpreter in agent development.......................................................................
Best practices......................................................................................................................................
Pre-installed libraries.........................................................................................................................
Get started with AgentCore Code Interpreter..............................................................................
Run code from agents.......................................................................................................................
Write files to a session......................................................................................................................
Using Terminal Commands with an execution role.....................................................................
Resource and session management................................................................................................
API Reference Examples....................................................................................................................
Observability........................................................................................................................................
AgentCore Browser: interact with web applications........................................................................
Overview...............................................................................................................................................
Why use remote browsers for agent development?...................................................................
Security Features................................................................................................................................
How it works.......................................................................................................................................
Use cases..............................................................................................................................................
Get started with AgentCore Browser.............................................................................................
Using AgentCore Browser with other libraries.............................................................................
Resource and session management................................................................................................
Rendering live view using DCV client.............................................................................................
Observability and session replay....................................................................................................
Troubleshoot built-in tools....................................................................................................................
Browser tool issues............................................................................................................................
Code Interpreter issues.....................................................................................................................
AgentCore Observability: Observe your agents and resources................................................
Get started with AgentCore Observability.........................................................................................
Prerequisites...........................................................................................................................................
Step 1: Enable transaction search on CloudWatch......................................................................
Step 2: Enable observability for Amazon Bedrock AgentCore Runtime hosted agents........
Step 3: Enable observability for non-Amazon Bedrock AgentCore-hosted agents...............
Step 4: Observe your agent with GenAI observability on Amazon CloudWatch....................
Best practices.........................................................................................................................................
Add observability to your agents.........................................................................................................
Enabling AgentCore observability...................................................................................................
Enabling observability in agent code for AgentCore-hosted agents.......................................
Enabling observability for agents hosted outside of AgentCore..............................................
identity resources............................................................................................................................... Enabling observability for AgentCore runtime, memory, gateway, built-in tools, and
Enhanced AgentCore runtime observability with custom headers..........................................
Enhanced AgentCore built-in tools observability with custom headers..................................
Enhanced AgentCore identity observability with custom headers...........................................
Observability best practices.............................................................................................................
Using other observability platforms..............................................................................................
Observability concepts...........................................................................................................................
Sessions.................................................................................................................................................
Traces....................................................................................................................................................
Agent Spans.........................................................................................................................................
Relationship.........................................................................................................................................
AgentCore generated observability data............................................................................................
Runtime observability data..............................................................................................................
Memory observability data..............................................................................................................
Gateway observability data..............................................................................................................
Built-in tools observability data......................................................................................................
Identity observability data...............................................................................................................
View metrics for your agents................................................................................................................
View data using generative AI observability in Amazon CloudWatch.....................................
View other data in CloudWatch......................................................................................................
AgentCore MCP Server: Vibe coding with your coding assistant..............................................
Prerequisites..............................................................................................................................................
Install required dependencies..........................................................................................................
Step 1: Install the MCP server..............................................................................................................
Add MCP server configuration.........................................................................................................
Verify MCP server installation.........................................................................................................
Step 2: Transform an existing agent for AgentCore runtime.........................................................
Transform your agent code..............................................................................................................
Transformation procedure................................................................................................................
Step 3: Deploy your agent to AgentCore runtime............................................................................
Deploy using the AgentCore CLI.....................................................................................................
Verify deployment..............................................................................................................................
Step 4: Test your deployed agent........................................................................................................
Invoke the agent.................................................................................................................................
Next steps..................................................................................................................................................
Security........................................................................................................................................
Data protection........................................................................................................................................
Data encryption..................................................................................................................................
VPC and AWS PrivateLink.................................................................................................................
Cross-region inference in AgentCore Memory.............................................................................
Identity and access management.........................................................................................................
Audience...............................................................................................................................................
Authenticating with identities.........................................................................................................
Managing access using policies.......................................................................................................
How Amazon Bedrock AgentCore works with IAM......................................................................
Identity-based policy examples.......................................................................................................
AWS managed policies......................................................................................................................
Service-linked roles............................................................................................................................
Credentials Management..................................................................................................................
Troubleshooting..................................................................................................................................
Compliance validation............................................................................................................................
Resilience...................................................................................................................................................
Cross-service confused deputy prevention.........................................................................................
Tagging resources........................................................................................................................
Tagging overview.....................................................................................................................................
Resources that support tagging...........................................................................................................
Tag restrictions.........................................................................................................................................
Working with tags...................................................................................................................................
Adding tags..........................................................................................................................................
Managing tags.....................................................................................................................................
Deleting tags.......................................................................................................................................
Quotas..........................................................................................................................................
AgentCore Runtime Service Quotas....................................................................................................
Resource allocation limits.................................................................................................................
Invocation limits.................................................................................................................................
Throttling limits..................................................................................................................................
Lifetime session lifecycle parameters............................................................................................
AgentCore Memory Service Quotas.....................................................................................................
AgentCore Identity Service Quotas......................................................................................................
AgentCore Gateway Service Quotas....................................................................................................
Endpoints..............................................................................................................................................
Service quotas.....................................................................................................................................
AgentCore Browser Service Quotas.....................................................................................................
Browser Invocation Limits.................................................................................................................
AgentCore Code Interpreter Service Quotas......................................................................................
Code Interpreter Invocation Limits.................................................................................................
Document history........................................................................................................................
What is Amazon Bedrock AgentCore?............................................................................................
Amazon Bedrock AgentCore enables you to deploy and operate highly effective agents securely, at
scale using any framework and model. With Amazon Bedrock AgentCore, developers can accelerate
AI agents into production with the scale, reliability, and security, critical to real-world deployment.
AgentCore provides tools and capabilities to make agents more effective and capable, purpose-
built infrastructure to securely scale agents, and controls to operate trustworthy agents. Amazon
Bedrock AgentCore services are composable and work with popular open-source frameworks and
any model, so you donâ€™t have to choose between open-source flexibility and enterprise-grade
security and reliability.

Services in Amazon Bedrock AgentCore
Amazon Bedrock AgentCore includes the following modular Services that you can use together or
independently:

Amazon Bedrock AgentCore Runtime................................................................................................
AgentCore Runtime is a secure, serverless runtime purpose-built for deploying and scaling dynamic
AI agents and tools using any open-source framework including LangGraph, CrewAI, and Strands
Agents, any protocol, and any model. Runtime was built to work for agentic workloads with
industry-leading extended runtime support, fast cold starts, true session isolation, built-in identity,
and support for multi-modal payloads. Developers can focus on innovation while Amazon Bedrock
AgentCore Runtime handles infrastructure and securityâ€”accelerating time-to-market

Amazon Bedrock AgentCore Identity..................................................................................................
AgentCore Identity provides a secure, scalable agent identity and access management capability
accelerating AI agent development. It is compatible with existing identity providers, eliminating
needs for user migration or rebuilding authentication flows. AgentCore Identity's helps to minimize
consent fatigue with a secure token vault and allows you to build streamlined AI agent experiences.
Just-enough access and secure permission delegation allow agents to securely access AWS
resources and third-party tools and services.

Amazon Bedrock AgentCore Memory.................................................................................................
AgentCore Memory makes it easy for developers to build context aware agents by eliminating
complex memory infrastructure management while providing full control over what the AI agent

Services 1

remembers. Memory provides industry-leading accuracy along with support for both short-term
memory for multi-turn conversations and long-term memory that can be shared across agents and
sessions.

Amazon Bedrock AgentCore Code Interpreter..................................................................................
AgentCore Code Interpreter tool enables agents to securely execute code in isolated sandbox
environments. It offers advanced configuration support and seamless integration with popular
frameworks. Developers can build powerful agents for complex workflows and data analysis while
meeting enterprise security requirements.

Amazon Bedrock AgentCore Browser.................................................................................................
AgentCore Browser tool provides a fast, secure, cloud-based browser runtime to enable AI
agents to interact with websites at scale. It provides enterprise-grade security, comprehensive
observability features, and automatically scalesâ€” all without infrastructure management
overhead.

Amazon Bedrock AgentCore Gateway................................................................................................
Amazon Bedrock AgentCore Gateway provides a secure way for agents to discover and use
tools along with easy transformation of APIs, Lambda functions, and existing services into
agent-compatible tools. Gateway eliminates weeks of custom code development, infrastructure
provisioning, and security implementation so developers can focus on building innovative agent
applications.

Amazon Bedrock AgentCore Observability........................................................................................
AgentCore Observability helps developers trace, debug, and monitor agent performance in
production through unified operational dashboards. With support for OpenTelemetry compatible
telemetry and detailed visualizations of each step of the agent workflow, AgentCore enables
developers to easily gain visibility into agent behavior and maintain quality standards at scale.

Common use cases for Amazon Bedrock AgentCore............................................................................
Equip agents with built-in tools and capabilities
Amazon Bedrock AgentCore Code Interpreter 2

Leverage built-in tools (browser automation and code interpretation) in your agent. Enable
agents to seamlessly integrate with internal and external tools and resources. Create agents that
can remember interactions with your agent users.
Deploy securely at scale
Securely deploy and scale dynamic AI agents and tools, regardless of framework, protocol, or
model choice without managing any underlying resources with seamless agent identity and
access management.
Test and monitor agents
Gain deep operational insights with real-time visibility into agents' usage and operational
metrics such as token usage, latency, session duration, and error rates.
Are you a first-time Amazon Bedrock AgentCore user?.......................................................................
If you are a first-time user of Amazon Bedrock AgentCore, we recommend that you begin by
reading the following sections:

Get started with Amazon Bedrock AgentCore
Understand the available interfaces for using AgentCore..........................................................
Host agent or tools with Amazon Bedrock AgentCore Runtime
Add memory to your Amazon Bedrock AgentCore agent
Use Amazon Bedrock AgentCore built-in tools to interact with your applications
Amazon Bedrock AgentCore Gateway: Securely connect tools and other resources to your
Gateway
For code examples, see https://github.com/awslabs/amazon-bedrock-agentcore-samples/.

Learn more about AgentCore....................................................................................................................
Watch this video to learn more about AgentCore:

Are you a first-time Amazon Bedrock AgentCore user? 3

Pricing for Amazon Bedrock AgentCore..................................................................................................
AgentCore offers flexible, consumption-based pricing with no upfront commitments or minimum
fees. For more information, see AgentCore pricing.

AgentCore may use and store your content to improve your service experience or performance.
Such improvements would be for your use of AgentCore and not for other customers.

AWS Regions..................................................................................................................................................
Amazon Bedrock AgentCore is supported in the following AWS Regions:

US East (N. Virginia)
US East (Ohio)
US West (Oregon)
Asia Pacific (Sydney)
Asia Pacific (Mumbai)
Asia Pacific (Tokyo)
Asia Pacific (Singapore)
Europe (Ireland)
Europe (Frankfurt)
Pricing for Amazon Bedrock AgentCore 4

Get started with Amazon Bedrock AgentCore
Build and deploy a production-ready AI agent in minutes with runtime hosting, memory, secure
code execution, and observability. This guide shows you how to use AgentCore Runtime, Memory,
Code Interpreter, and Observability features.

For AgentCore Gateway and Identity features, see the Gateway quickstart and Identity quickstart.

Topics

Prerequisites
Step 1: Create the agent
Step 2: Configure and deploy the agent
Step 3: Monitor the deployment
Step 4: Test Memory and Code Interpreter
Step 5: View traces and logs
Clean up
Troubleshooting
Summary
Prerequisites..................................................................................................................................................
Before you start, make sure you have:

AWS permissions. AWS root users or users with privileged roles (such as the
AdministratorAccess role) can skip this step. Others need to attach the starter toolkit policy and
AmazonBedrockAgentCoreFullAccess managed policy.
AWS CLI version 2.0 or later. Configure the AWS CLI using aws configure. For more
information, see the AWS Command Line Interface User Guide for Version 2.
Amazon Bedrock model access to Claude 3.7 Sonnet. To enable model access, go to the AWS
Management Console, choose Amazon Bedrock, choose Model access , and enable Claude 3.
Sonnet in your AWS Region. For information about using a different model with Strands Agents,
see the Model Providers section in the Strands Agents SDK documentation.
Python 3.10 or newer
AgentCore starter toolkit. For installation instructions, see the following section.
Prerequisites 5

AWS Region consistency
Make sure you're using the same AWS Region for:
The default Region you selected when you ran aws configure.
The Region where you've enabled Amazon Bedrock model access.
All resources created during the agent deployment will use this Region.
Install the AgentCore starter toolkit...................................................................................................
Install the AgentCore starter toolkit:

# Create virtual environment
python -m venv .venv
source .venv/bin/activate # On Windows: .venv\Scripts\activate
# Install required packages (version 0.1.21 or later)
pip install "bedrock-agentcore-starter-toolkit>=0.1.21" strands-agents boto
Step 1: Create the agent............................................................................................................................
Create agentcore_starter_strands.py:

"""
Strands Agent sample with AgentCore
"""
import os
from strands import Agent, tool
from bedrock_agentcore.memory.integrations.strands.config import AgentCoreMemoryConfig,
RetrievalConfig
from bedrock_agentcore.memory.integrations.strands.session_manager import
AgentCoreMemorySessionManager
from bedrock_agentcore.tools.code_interpreter_client import CodeInterpreter
from bedrock_agentcore.runtime import BedrockAgentCoreApp
app = BedrockAgentCoreApp()
MEMORY_ID = os.getenv("BEDROCK_AGENTCORE_MEMORY_ID")
Install the AgentCore starter toolkit 6

REGION = os.getenv("AWS_REGION")
MODEL_ID = "us.anthropic.claude-3-7-sonnet-20250219-v1:0"
ci_sessions = {}
current_session = None
@tool
def calculate(code: str) -> str:
"""Execute Python code for calculations or analysis."""
session_id = current_session or 'default'
if session_id not in ci_sessions:
ci_sessions[session_id] = {
'client': CodeInterpreter(REGION),
'session_id': None
}
ci = ci_sessions[session_id]
if not ci['session_id']:
ci['session_id'] = ci['client'].start(
name=f"session_{session_id[:30]}",
session_timeout_seconds=1800
)
result = ci['client'].invoke("executeCode", {
"code": code,
"language": "python"
})
for event in result.get("stream", []):
if stdout := event.get("result", {}).get("structuredContent",
{}).get("stdout"):
return stdout
return "Executed"
@app.entrypoint
def invoke(payload, context):
global current_session
if not MEMORY_ID:
return {"error": "Memory not configured"}
actor_id = context.headers.get('X-Amzn-Bedrock-AgentCore-Runtime-Custom-Actor-Id',
'user') if hasattr(context, 'headers') else 'user'
Step 1: Create the agent 7

session_id = getattr(context, 'session_id', 'default')
current_session = session_id
memory_config = AgentCoreMemoryConfig(
memory_id=MEMORY_ID,
session_id=session_id,
actor_id=actor_id,
retrieval_config={
f"/users/{actor_id}/facts": RetrievalConfig(top_k=3, relevance_score=0.5),
f"/users/{actor_id}/preferences": RetrievalConfig(top_k=3,
relevance_score=0.5)
}
)
agent = Agent(
model=MODEL_ID,
session_manager=AgentCoreMemorySessionManager(memory_config, REGION),
system_prompt="You are a helpful assistant. Use tools when appropriate.",
tools=[calculate]
)
result = agent(payload.get("prompt", ""))
return {"response": result.message.get('content', [{}])[0].get('text',
str(result))}
if __name__ == "__main__":
app.run()
Create requirements.txt:

strands-agents
bedrock-agentcore
Step 2: Configure and deploy the agent.................................................................................................
In this step, you'll use the AgentCore CLI to configure and deploy your agent.

Configure the agent...............................................................................................................................
Configure the agent with memory and execution settings:

Step 2: Configure and deploy the agent 8

For this tutorial : When prompted for the execution role, press Enter to auto-create a new role with
all required permissions for the Runtime, Memory, Code Interpreter, and Observability features.
When prompted for long-term memory, type yes.

agentcore configure -e agentcore_starter_strands.py
#Interactive prompts you'll see:
# 1. Execution Role: Press Enter to auto-create or provide existing role ARN/name
# 2. ECR Repository: Press Enter to auto-create or provide existing ECR URI
# 3. Requirements File: Confirm the detected requirements.txt file or specify a
different path
# 4. OAuth Configuration: Configure OAuth authorizer? (yes/no) - Type `no` for this
tutorial
# 5. Request Header Allowlist: Configure request header allowlist? (yes/no) - Type `no`
for this tutorial
# 6. Memory Configuration:
# - If existing memories found: Choose from list or press Enter to create new
# - If creating new: Enable long-term memory extraction? (yes/no) - Type `yes` for
this tutorial
# - Note: Short-term memory is always enabled by default
Note
If the memory configuration prompts do not appear during agentcore configure, refer
to the Troubleshooting section ( Memory configuration not appearing ) for instructions on
how to check whether the correct toolkit version is installed.
Deploy to AgentCore..............................................................................................................................
Launch your agent to the AgentCore runtime environment:

agentcore launch
# This performs:
# 1. Memory resource provisioning (STM + LTM strategies)
# 2. Docker container build with dependencies
# 3. ECR repository push
# 4. AgentCore Runtime deployment with X-Ray tracing enabled
# 5. CloudWatch Transaction Search configuration (automatic)
Deploy to AgentCore 9

# 6. Endpoint activation with trace collection
Expected output:

# Memory created: bedrock_agentcore_memory_ci_agent_memory-abc123
Observability is enabled, configuring Transaction Search...
# Transaction Search configured: resource_policy, trace_destination, indexing_rule
# GenAI Observability Dashboard:
https://console.aws.amazon.com/cloudwatch/home?region=us-west-2#gen-ai-
observability/agent-core
# Container deployed to Bedrock AgentCore
Agent ARN: arn:aws:bedrock-agentcore:us-west-2:123456789:runtime/starter_agent-xyz
If the deployment encounters errors or behaves unexpectedly, check your configuration:

cat .bedrock_agentcore.yaml # Review deployed configuration
agentcore status # Verify resource provisioning status
Step 3: Monitor the deployment............................................................................................................
Check the agent's deployment status:

agentcore status
# Shows:
# Memory ID: bedrock_agentcore_memory_ci_agent_memory-abc123
# Memory Status: CREATING (if still provisioning)
# Memory Type: STM+LTM (provisioning...) (if creating with LTM)
# Memory Type: STM+LTM (3 strategies) (when active with strategies)
# Memory Type: STM only (if configured without LTM)
# Observability: Enabled
Note
Memory may take around 2-5 minutes to activate.
Step 4: Test Memory and Code Interpreter..........................................................................................
In this section, you'll test your agent's memory capabilities and code execution features.

Step 3: Monitor the deployment 10

Test short-term memory.....................................................................................................................
Test short-term memory within a single session:

# Store information (session IDs must be 33+ characters)
agentcore invoke '{"prompt": "Remember that my favorite agent platform is AgentCore"}'
# If invoked too early (memory still provisioning), you'll see:
# "Memory is still provisioning (current status: CREATING).
# Long-term memory extraction takes 60-180 seconds to activate.
#
# Please wait and check status with:
# agentcore status"
# Retrieve within same session
agentcore invoke '{"prompt": "What is my favorite agent platform?"}'
# Expected response:
# "Your favorite agent platform is AgentCore."
Test long-term memory â€“ cross-session persistence.....................................................................
Long-term memory (LTM) lets information persist across different sessions. This requires waiting
for long-term memory to be extracted before starting a new session.

Test long-term memory by starting a session:

# Session 1: Store facts
agentcore invoke '{"prompt": "My email is user@example.com and I am an AgentCore
user"}'
After invoking the agent, AgentCore runs in the background to perform an extraction. Wait for the
extraction to finish. This typically takes 10-30 seconds. If you do not see any facts, wait a few more
seconds.

Start another session:

sleep 20
# Session 2: Different runtime session retrieves the facts extracted from initial
session
SESSION_ID=$(python -c "import uuid; print(uuid.uuid4())")
Test short-term memory 11

agentcore invoke '{"prompt": "Tell me about myself?"}' --session-id $SESSION_ID
# Expected response:
# "Your email address is user@example.com."
# "You appear to be a user of AgentCore, which seems to be your favorite agent
platform."
Test Code Interpreter...........................................................................................................................
Test AgentCore Code Interpreter:

# Store data
agentcore invoke '{"prompt": "My dataset has values: 23, 45, 67, 89, 12, 34, 56."}'
# Create visualization
agentcore invoke '{"prompt": "Create a text-based bar chart visualization showing the
distribution of values in my dataset with proper labels"}'
# Expected: Agent generates matplotlib code to create a bar chart
Step 5: View traces and logs...................................................................................................................
In this section, you'll use observability features to monitor your agent's performance.

Access the Amazon CloudWatch dashboard...................................................................................
Navigate to the GenAI Observability dashboard to view end-to-end request traces including agent
execution tracking, memory retrieval operations, code interpreter executions, agent reasoning
steps, and latency breakdown by component. The dashboard provides a service map view
showing agent runtime connections to Memory and Code Interpreter services with request flow
visualization and latency metrics, as well as detailed X-Ray traces for debugging and performance
analysis.

# Get the dashboard URL from status
agentcore status
# Navigate to the URL shown, or go directly to:
# https://console.aws.amazon.com/cloudwatch/home?region=us-west-2#gen-ai-observability/
agent-core
# Note: Replace the Region
Test Code Interpreter 12

View AgentCore Runtime logs...........................................................................................................
Access detailed AgentCore Runtime logs for debugging and monitoring:

# The correct log paths are shown in the invoke or status output
agentcore status
# You'll see log paths like:
# aws logs tail /aws/bedrock-agentcore/runtimes/AGENT_ID-DEFAULT --log-stream-name-
prefix "YYYY/MM/DD/[runtime-logs]" --follow
# Copy this command from the output to view logs
# For example:
aws logs tail /aws/bedrock-agentcore/runtimes/AGENT_ID-DEFAULT --log-stream-name-prefix
"YYYY/MM/DD/[runtime-logs]" --follow
# For recent logs, use the --since option as shown in the output:
aws logs tail /aws/bedrock-agentcore/runtimes/AGENT_ID-DEFAULT --log-stream-name-prefix
"YYYY/MM/DD/[runtime-logs]" --since 1h
Clean up.......................................................................................................................................................
Remove all resources created during this tutorial:

agentcore destroy
# Removes:
# - AgentCore Runtime endpoint and agent
# - AgentCore Memory resources (short- and long-term memory)
# - Amazon ECR repository and images
# - IAM roles (if auto-created)
# - CloudWatch log groups (optional)
Troubleshooting..........................................................................................................................................
This section describes common issues and solutions when using the AgentCore starter toolkit.

Memory configuration not appearing

Memory option not showing during agentcore configure

View AgentCore Runtime logs 13

This issue typically occurs when using an outdated version of the AgentCore starter toolkit. Make
sure you have version 0.1.21 or later installed:

# Step 1: Verify current state
which python # Should show .venv/bin/python
which agentcore # Currently showing global path
# Step 2: Deactivate and reactivate venv to reset PATH
deactivate
source .venv/bin/activate
# Step 3: Check if that fixed it
which agentcore
# If NOW showing .venv/bin/agentcore -> RESOLVED, skip to Step 7
# If STILL showing global path -> continue to Step 4
# Step 4: Force local venv to take precedence in PATH
export PATH="$(pwd)/.venv/bin:$PATH"
# Step 5: Check again
which agentcore
# If NOW showing .venv/bin/agentcore -> RESOLVED, skip to Step 7
# If STILL showing global path -> continue to Step 6
# Step 6: Reinstall in local venv with forced precedence
pip install --force-reinstall --no-cache-dir "bedrock-agentcore-starter-
toolkit>=0.1.21"
# Step 7: Final verification
which agentcore # Must show: /path/to/your-project/.venv/bin/agentcore
pip show bedrock-agentcore-starter-toolkit # Verify version >= 0.1.21
agentcore --version # Double check it's working
# Step 8: Try configure again
agentcore configure -e agentcore_starter_strands.py
#If Step 6 still doesn't work, the nuclear option:
cd ..
mkdir fresh-agentcore-project && cd fresh-agentcore-project
python3 -m venv .venv
source .venv/bin/activate
pip install --no-cache-dir "bedrock-agentcore-starter-toolkit>=0.1.21" strands-agents
boto3
Troubleshooting 14

# Copy your agent code here, then reconfigure
Additional checks

Make sure you're running agentcore configure from within the activated virtual
environment.
If you're using an IDE (VSCode, PyCharm), restart the IDE after reinstalling.
Verify no system-wide agentcore installation conflicts: pip list | grep bedrock-
agentcore.
AWS Region misconfiguration

If you need to change your AWS Region configuration:

Clean up resources in the incorrect Region:
agentcore destroy
# This removes:
# - AgentCore Runtime endpoint and agent
# - AgentCore Memory resources (short- and long-term memory)
# - Amazon ECR repository and images
# - IAM roles (if auto-created)
# - CloudWatch log groups (optional)
Verify your AWS CLI is configured for the correct Region:
aws configure get region
# Or reconfigure for the correct region:
aws configure set region your-desired-region
Make sure Amazon Bedrock model access is enabled in the target Region. To check, go to
the AWS Management Console, choose the Amazon Bedrock service, and then choose Model
access )
Copy your agent code and requirements.txt to the new folder, then return to Step 2:
Configure and deploy the agent and complete the steps.
Troubleshooting 15

Memory issues

"Memory status is not active" error

Run agentcore status to check the memory status.
If the status is showing provisioning, wait 2-3 minutes.
Retry after the status shows Memory Type: STM+LTM (3 strategies).
Cross-session memory not working

Verify that long-term memory is active (not "provisioning")
Wait 15-30 seconds after storing facts for extraction
Check extraction logs for completion
Observability issues

No traces appearing

Verify observability was enabled during agentcore configure
Check IAM permissions include CloudWatch and X-Ray access
Wait 30-60 seconds for traces to appear in CloudWatch
Traces are viewable at: AWS Management Console â†’ CloudWatch â†’ Service Map or X-Ray â†’
Traces
Missing memory logs

Check log group exists: /aws/vendedlogs/bedrock-agentcore/memory/
APPLICATION_LOGS/ memory-id
Verify that the IAM role has CloudWatch Logs permissions
Summary......................................................................................................................................................
You've deployed a production agent with:

AgentCore Runtime for managed container orchestration.
Summary 16

AgentCore Memory with short-term memory for immediate context and long-term memory for
cross-session persistence.
AgentCore Code Interpreter for secure Python execution with data visualization capabilities.
AWS X-Ray Tracing automatically configured for distributed tracing.
CloudWatch integration for logs and metrics with Transaction Search enabled.
All services are automatically instrumented with X-Ray tracing, providing complete visibility into
agent behavior, memory operations, and tool executions through the CloudWatch dashboard.

Summary 17

Understand the available interfaces for using Amazon
Bedrock AgentCore
Amazon Bedrock AgentCore supports various interfaces for developing and deploying your agent
code. The simplest approach is to use the AgentCore Python SDK to create your agent code and use
the AgentCore starter toolkit to deploy your agent.

The AgentCore starter toolkit and AgentCore Python SDK don't support all AgentCore operations
that the AWS SDK supplies. If they don't support a specific AgentCore operation, use the AWS SDK.

Topics

Amazon Bedrock AgentCore starter toolkit
AgentCore Python SDK
Amazon Bedrock AgentCore MCP server
AWS SDK
Amazon Bedrock AgentCore console
AWS Command Line Interface
Amazon Bedrock AgentCore starter toolkit.........................................................................................
The AgentCore starter toolkit provides CLI tools and higher-level abstractions for:

Deployment : Containerize and deploy agents to AWS infrastructure
Import Agent : Migrate existing Bedrock Agents to AgentCore with framework conversion
Gateway Integration : Transform existing APIs into agent tools
Configuration Management : Manage environment and deployment settings
Observability : Monitor agents in production environments
The getting started instructions in this guide use the AgentCore starter toolkit.

AgentCore Python SDK.............................................................................................................................
The AgentCore Python SDK provides Python primitives for agent development with built-in
support for:

Amazon Bedrock AgentCore starter toolkit 18

Runtime : Lightweight wrapper over the AgentCore operations in the AWS SDK that lets you easily
write Python code for an agent.
Memory : Persistent storage for conversation history and agent context
Tools : Built-in clients for code interpretation and browser automation
Identity : Secure authentication and access management
The AgentCore Python SDK supports multiple frameworks, such as Strands Agents and LangGraph.
If you are using other AWS services, you'll need to use the AWS SDK to integrate those services into
your agent, alongside your AgentCore Python SDK code.

Amazon Bedrock AgentCore MCP server..............................................................................................
The AgentCore Model Context Protocol (MCP) server helps you transform, deploy, and test
AgentCore-compatible agents directly from your preferred development environment. With built-
in support for runtime integration, gateway connectivity, and agent lifecycle management, the
MCP server simplifies moving from local development to production deployment on AgentCore
services.

The MCP server works with popular MCP clients including Kiro, Cursor, Claude Code, and Amazon Q
CLI, providing conversational commands to automate complex agent development workflows.

For more information, see Amazon Bedrock AgentCore MCP Server: Vibe coding with your coding
assistant.

AWS SDK......................................................................................................................................................
You can use the AWS SDK to achieve the same results as the AgentCore Python SDK, as well as
other tasks that the AgentCore Python SDK doesn't support. You'll need to use the AWS SDK to
interact with other AWS services such as AWS Lambda and Amazon S3. You'll also need to the AWS
SDK if you aren't using Python as your coding language.

To configure and deploy an agent, you use the AgentCore control plane API. For example, you can
create an AgentCore Runtime or create an AgentCore Memory.

At runtime, you use the AgentCore data plane API for tasks such as adding a memory event to an
AgentCore Memory. The client code that calls your agent uses the InvokeAgentRuntime data
plane operation to invoke an agent that you have hosted in an AgentCore Runtime.

Amazon Bedrock AgentCore MCP server 19

Amazon Bedrock AgentCore console.....................................................................................................
You can use the AgentCore console to create and manage the AgentCore services that your
agent code uses. You can get code snippets that show to call an agent hosted in an AgentCore
Runtime. You can also test your agent in the agent sandbox. Open the console at https://
console.aws.amazon.com/bedrock-agentcore/home#.

AWS Command Line Interface................................................................................................................
You can use the AWS CLI with the AgentCore services that you use. Use control plane api to create
and manage services. For example you can create an AgentCore Memory or update the endpoint
for an AgentCore Runtime. You can also perform runtime actions with the data plane API, which
can be useful for testing an agent.

Amazon Bedrock AgentCore console 20

Host agent or tools with Amazon Bedrock AgentCore
Runtime
Amazon Bedrock AgentCore Runtime provides a secure, serverless and purpose-built hosting
environment for deploying and running AI agents or tools. It offers the following benefits:

Framework agnostic

AgentCore Runtime lets you transform any local agent code to cloud-native deployments
with a few lines of code no matter the underlying framework. Works seamlessly with popular
frameworks like LangGraph, Strands, and CrewAI. You can also leverage it with custom agents
that don't use a specific framework.
Model flexibility

AgentCore Runtime works with any Large Language Model, such as models offered by Amazon
Bedrock, Anthropic Claude, Google Gemini, and OpenAI.
Protocol support

AgentCore Runtime lets agents communicate with other agents and tools via Model Context
Protocol (MCP).
Extended execution time

AgentCore Runtime supports both real-time interactions and long-running workloads up to 8
hours, enabling complex agent reasoning and asynchronous workloads that may involve multi-
agent collaboration or extended problem-solving sessions.
Enhanced payload handling

AgentCore Runtime can process 100MB payloads enabling seamless processing of multiple
modalities (text, images, audio, video), with rich media content or large datasets.
Session isolation

In AgentCore Runtime, each user session runs in a dedicated microVM with isolated CPU,
memory, and filesystem resources. This helps create complete separation between user
sessions, safeguarding stateful agent reasoning processes and helps prevent cross-session
data contamination. After session completion, the entire microVM is terminated and memory
is sanitized, delivering deterministic security even when working with non-deterministic AI
processes.
21
Consumption-based pricing model

Runtime implements consumption-based pricing that charges only for resources actually
consumed. Unlike allocation-based models that require pre-selecting resources, Runtime
dynamically provisions what's needed without requiring right-sizing. The service aligns CPU
billing with actual active processing - typically eliminating charges during I/O wait periods
when agents are primarily waiting for LLM responses - while continuously maintaining your
session state.
Built-in authentication

AgentCore Runtime, powered by AgentCore Identity, assigns distinct identities to AI agents and
seamlessly integrates with your corporate identity provider such as Okta, Microsoft Entra ID,
or Amazon Cognito, enabling your end users to authenticate into only the agents they have
access to. In addition, Runtime lets outbound authentication flows to securely access third-party
services like Slack, Zoom, and GitHub - whether operating on behalf of users or autonomously
(using either OAuth or API keys).
Agent-specific observability

AgentCore Runtime provides specialized built-in tracing that captures agent reasoning steps,
tool invocations, and model interactions, providing clear visibility into agent decision-making
processes, a critical capability for debugging and auditing AI agent behaviors.
Unified set of agent-specific capabilities

AgentCore Runtime is delivered through a single, comprehensive SDK that provides streamlined
access to the complete AgentCore capabilities including Memory, Tools, and Gateway.
This integrated approach eliminates the integration work typically required when building
equivalent agent infrastructure from disparate components.
Topics

How it works
IAM Permissions for AgentCore Runtime
Get started with AgentCore Runtime
Use any agent framework
Use any foundation model
Deploy MCP servers in AgentCore Runtime
22
Deploy A2A servers in AgentCore Runtime
Use isolated sessions for agents
Handle asynchronous and long running agents with Amazon Bedrock AgentCore Runtime
Stream agent responses
Pass custom headers to Amazon Bedrock AgentCore Runtime
Authenticate and authorize with Inbound Auth and Outbound Auth
AgentCore Runtime versioning and endpoints
Invoke an AgentCore Runtime agent
Observe agents in Amazon Bedrock AgentCore Runtime
Troubleshoot AgentCore Runtime
How it works...............................................................................................................................................
The AgentCore Runtime handles scaling, session management, security isolation, and infrastructure
management, allowing you to focus on building intelligent agent experiences rather than
operational complexity. By leveraging the features and capabilities described here, you can build,
deploy, and manage sophisticated AI agents that deliver value to your users while helping to
maintain enterprise-grade security and reliability.

Topics

Key components
Authentication and security
Additional features
Implementation overview
Understanding the AgentCore Runtime service contract
Key components....................................................................................................................................
AgentCore Runtime

An AgentCore Runtime is the foundational component that hosts your AI agent or tool code. It
represents a containerized application that processes user inputs, maintains context, and executes
actions using AI capabilities. When you create an agent, you define its behavior, capabilities, and

How it works 23

the tools it can access. For example, a customer support agent might answer product questions,
process returns, and escalate complex issues to human representatives.

You can build and deploy agents to AgentCore Runtime using the AgentCore Python SDK or
directly through AWS SDKs. With the AgentCore Python SDK, you can define your agent using
popular frameworks like LangGraph, CrewAI, or Strands Agents. The SDK handles infrastructure
complexities, allowing you to focus on the agent's logic and capabilities.

Each AgentCore Runtime:

Has a unique identity
Is versioned to support controlled deployment and updates
Versions

Each AgentCore Runtime maintains immutable versions that capture a complete snapshot of the
configuration at a specific point in time:

When you create an AgentCore Runtime, Version 1 (V1) is automatically created
Each update to configuration (container image, protocol settings, network settings) creates a
new version
Each version contains all necessary configuration needed for execution
This versioning system provides reliable deployment history and rollback capabilities.

Endpoints

Endpoints provide addressable access points to specific versions of your AgentCore Runtime. Each
endpoint:

Has a unique ARN for invocation
References a specific version of your Agent Runtime
Provides stable access to your agent even as you update implementations
Key endpoint details:

The "DEFAULT" endpoint is automatically created when you call CreateAgentRuntime and points
to the latest version
Key components 24

When you update your AgentCore Runtime, a new version is created but the DEFAULT endpoint
automatically updates to reference it
You can create custom endpoints with the CreateAgentRuntimeEndpoint operation for different
environments (dev, test, prod)
When a user makes a request to an endpoint, the request is resolved to the specific agent version
referenced by that endpoint
Endpoints have distinct lifecycle states:

CREATING - Initial state during endpoint creation
CREATE_FAILED - Indicates creation failure due to permissions or other issues
READY - Endpoint is operational and accepting requests
UPDATING - Endpoint is being modified to reference a new version
UPDATE_FAILED - Indicates update operation failure
You can update endpoints without downtime, allowing for seamless version transitions and
rollbacks.

Sessions

Sessions represent individual interaction contexts between users and your AgentCore Runtime.
Each session:

Is identified by a unique runtimeSessionId provided by your application, or by the Runtime
itself in the first invocation if the runtimeSessionId is left empty
Runs in a dedicated microVM with completely isolated CPU, memory, and filesystem resources
Preserves context across multiple interactions within the same conversation
Can persist for up to 8 hours of total runtime
Session states include:

Active - Currently processing a request or executing background tasks
Idle - Not processing any requests but maintaining context while waiting for next interaction
Terminated - Session ended due to inactivity (15 minutes), reaching maximum lifetime (8 hours),
or being deemed unhealthy
Key components 25

Important session characteristics:

After session termination, the entire microVM is terminated and memory is sanitized
A subsequent request with the same runtimeSessionId after termination will create a new
execution environment
Session isolation prevents cross-session data contamination and ensures security
Session state is ephemeral and should not be used for long-term durability (use AgentCore
Memory for context durability)
This complete isolation between sessions is crucial for enterprise security, particularly when dealing
with non-deterministic AI processes.

Authentication and security...............................................................................................................
Inbound authentication

Inbound Auth, powered by AgentCore Identity, controls who can access and invoke your agents or
tools in AgentCore Runtime.

Authentication methods

AWS IAM (SigV4): Uses AWS credentials for identity verification
OAuth 2.0 : Integrates with external identity providers
OAuth configuration options

Discovery URL : Your identity provider's OpenID Connect discovery endpoint
Allowed Audiences : List of valid audience values your tokens should contain
Allowed Clients : List of client identifiers that can access this agent
Authentication flow

1.End users authenticate with your identity provider (Amazon Cognito, Okta, Microsoft Entra ID)

2.Your client application receives a bearer token after successful authentication

3.The client passes this token in the authorization header when invoking the agent

4.AgentCore Runtime validates the token with the authorization server

Authentication and security 26

5.If valid, the request is processed; if invalid, it's rejected

This ensures only authenticated users with proper authorization can access your agents.

Outbound authentication

Outbound Auth, powered by Amazon Bedrock AgentCore Identity, lets your agents hosted on
AgentCore Runtime securely access third-party services:

Authentication methods

OAuth : For services supporting OAuth flows
API Keys : For services using key-based authentication
Authentication modes

User-delegated : Acting on behalf of the end user with their credentials
Autonomous : Acting independently with service-level credentials
Supported services

Enterprise systems such as Slack, Zoom, and GitHub)
AWS services
Custom APIs and data sources
AgentCore Identity manages these credentials securely, preventing credential exposure in your
agent code or logs.

Additional features...............................................................................................................................
Asynchronous processing

AgentCore Runtime supports long-running workloads through:

Background task handling for operations that exceed request/response cycles
Automatic status tracking via the /ping endpoint
Additional features 27

Support for operations up to 8 hours in duration
Streaming responses

Agents can stream partial results as they become available rather than waiting for complete
processing. This lets you provide a more responsive user experience, especially for operations that
generate large amounts of content or take significant time to complete.

Protocol support

Runtime supports multiple communication protocols:

HTTP for simple request/response patterns
Model Context Protocol (MCP) for standardized agent-tool interactions
Implementation overview...................................................................................................................
Here's how to get started with the AgentCore Runtime:

Prepare your agent or tool code

Define your agent logic using any AI framework or custom code
Add the required HTTP endpoints using the AgentCore SDK or custom implementation
Package dependencies in a requirements.txt file
Deploy your agent or tool

Build and push a container image to Amazon ECR directly or via the AgentCore SDK
Create an AgentCore Runtime using the container image
The initial version (V1) and DEFAULT endpoint are created automatically
Invoke your agent or tool

Generate a unique session ID for each user conversation
Call the InvokeAgentRuntime operation with your agent's ARN and session ID
Pass user input in the request payload
Implementation overview 28

Manage and observe sessions, and make updates

Use the same session ID for follow-up interactions to maintain context
Review logs, traces, and observability metrics
Deploy updates by modifying your AgentCore Runtime (creates new versions)
Control rollout by updating endpoints to point to new versions
Understanding the AgentCore Runtime service contract.............................................................
The AgentCore Runtime service contract defines the standardized communication protocol that
your agent application must implement to integrate with the Amazon Bedrock agent hosting
infrastructure. This contract ensures seamless communication between your custom agent code
and AWS's managed hosting environment.

Topics

Supported protocols
HTTP protocol contract
MCP protocol contract
Supported protocols

The AgentCore Runtime service contract supports two communication protocols:

HTTP Protocol : Direct REST API endpoints for traditional request/response patterns
MCP Protocol : Model Context Protocol for tools and agent servers
HTTP protocol contract

Container requirements

Your agent must be deployed as a containerized application meeting these specifications:

Host : 0.0.0.0
Port : 8080 - Standard port for HTTP-based agent communication
Platform : ARM64 container - Required for compatibility with the AgentCore Runtime
environment
Understanding the AgentCore Runtime service contract 29

Path requirements

/invocations - POST

This is the primary agent interaction endpoint with JSON input and JSON/SSE output.

Purpose

Receives incoming requests from users or applications and processes them through your agent's
business logic

Use cases

The /invocations endpoint serves several key purposes:

Direct user interactions and conversations
API integrations with external systems
Batch processing of multiple requests
Real-time streaming responses for long-running operations
Example Request format

Content-Type: application/json
{
"prompt": "What's the weather today?"
}
Response formats

Your agent can respond using either of the following formats depending on the use case:

JSON response (non-streaming)

Purpose

Provides complete responses for requests that can be processed quickly

Use cases

JSON responses are ideal for:

Understanding the AgentCore Runtime service contract 30

Simple question-answering scenarios
Deterministic computations
Quick data lookups
Status confirmations
Example JSON response format

Content-Type: application/json
{
"response": "Your agent's response here",
"status": "success"
}
SSE response (streaming)

Server-sent events (SSE) let you deliver real-time streaming responses. For more information, see
the Server-sent events specification.

Purpose

Enables incremental response delivery for long-running operations and improved user experience

Use cases

SSE responses are ideal for:

Real-time conversational experiences
Progressive content generation
Long-running computations with intermediate results
Live data feeds and updates
Example SSE response format

Content-Type: text/event-stream
data: {"event": "partial response 1"}
data: {"event": "partial response 2"}
Understanding the AgentCore Runtime service contract 31

data: {"event": "final response"}
/ping - GET

Purpose

Verifies that your agent is operational and ready to handle requests

Use cases

The /ping endpoint serves several key purposes:

Service monitoring to detect and remediate issues
Automated recovery through AWS's managed infrastructure
Response format

Returns a status code indicating your agent's health:

Content-Type : application/json
HTTP Status Code : 200 for healthy, appropriate error codes for unhealthy states
If your agent needs to process background tasks, you can indicate it with the /ping status. If the
ping status is HealthyBusy, the runtime session is considered active.

Example Ping response format

{
"status": "<status_value>",
"time_of_last_update": <unix_timestamp>
}
status

Healthy - System is ready to accept new work
HealthyBusy - System is operational but currently busy with async tasks
time_of_last_update

Used to determine how long the system has been in its current state
Understanding the AgentCore Runtime service contract 32

MCP protocol contract

Protocol implementation requirements

Your MCP server must implement these specific protocol requirements:

Transport : Stateless streamable-http only - Ensures compatibility with AWS's session
management and load balancing
Session Management : Platform automatically adds Mcp-Session-Id header for session
isolation, servers must support stateless operation so as to not reject platform generated Mcp-
Session-Id header
Container requirements

Your MCP server must be deployed as a containerized application meeting these specifications:

Host : 0.0.0.0
Port : 8000 - Standard port for MCP server communication (different from HTTP protocol)
Platform : ARM64 container - Required for compatibility with AWS Amazon Bedrock AgentCore
runtime environment
Path requirements

/mcp - POST

Purpose

Receives MCP RPC messages and processes them through your agent's tool capabilities, complete
pass-through of InvokeAgentRuntime API payload with standard MCP RPC messages

Response format

JSON-RPC based request/response format, supporting both application/json and text/
event-stream as response content-types

Use cases

The /mcp endpoint serves several key purposes:

Tool invocation and management
Understanding the AgentCore Runtime service contract 33

Agent capability discovery
Resource access and manipulation
Multi-step agent workflows
IAM Permissions for AgentCore Runtime..............................................................................................
The following are IAM permissions you need to create an agent in an AgentCore Runtime and the
execution role permissions that an agent needs to run in an AgentCore Runtime

Topics

Use Amazon Bedrock AgentCore
Use the starter toolkit
Execution role for running an agent in AgentCore Runtime
Use Amazon Bedrock AgentCore.......................................................................................................
To use Amazon Bedrock AgentCore, you can attach the BedrockAgentCoreFullAccess AWS managed
policy to your IAM user or IAM. role. This AWS managed policy grants broad permissions. We
recommend creating a custom policy with only the permissions your application requires by
copying the relevant statements and restricting the resources to your specific use case. To use the
starter toolkit, you need additional permissions.

Use the starter toolkit.........................................................................................................................
To use the Amazon Bedrock AgentCore starter toolkit, attach the following IAM policy to your IAM
user or role. To change IAM permissions, see Change permissions for an IAM user.

JSON

{
"Version":"2012-10-17",
"Statement": [
{
"Sid": "IAMRoleManagement",
"Effect": "Allow",
"Action": [
"iam:CreateRole",
IAM Permissions for AgentCore Runtime 34

"iam:DeleteRole",
"iam:GetRole",
"iam:PutRolePolicy",
"iam:DeleteRolePolicy",
"iam:AttachRolePolicy",
"iam:DetachRolePolicy",
"iam:TagRole",
"iam:ListRolePolicies",
"iam:ListAttachedRolePolicies"
],
"Resource": [
"arn:aws:iam::*:role/*BedrockAgentCore*",
"arn:aws:iam::*:role/service-role/*BedrockAgentCore*"
]
},
{
"Sid": "CodeBuildProjectAccess",
"Effect": "Allow",
"Action": [
"codebuild:StartBuild",
"codebuild:BatchGetBuilds",
"codebuild:ListBuildsForProject",
"codebuild:CreateProject",
"codebuild:UpdateProject",
"codebuild:BatchGetProjects"
],
"Resource": [
"arn:aws:codebuild:*:*:project/bedrock-agentcore-*",
"arn:aws:codebuild:*:*:build/bedrock-agentcore-*"
]
},
{
"Sid": "CodeBuildListAccess",
"Effect": "Allow",
"Action": [
"codebuild:ListProjects"
],
"Resource": "*"
},
{
"Sid": "IAMPassRoleAccess",
"Effect": "Allow",
"Action": [
"iam:PassRole"
Use the starter toolkit 35

],
"Resource": [
"arn:aws:iam::*:role/AmazonBedrockAgentCore*",
"arn:aws:iam::*:role/service-role/AmazonBedrockAgentCore*"
]
},
{
"Sid": "CloudWatchLogsAccess",
"Effect": "Allow",
"Action": [
"logs:GetLogEvents",
"logs:DescribeLogGroups",
"logs:DescribeLogStreams"
],
"Resource": [
"arn:aws:logs:*:*:log-group:/aws/bedrock-agentcore/*",
"arn:aws:logs:*:*:log-group:/aws/codebuild/*"
]
},
{
"Sid": "S3Access",
"Effect": "Allow",
"Action": [
"s3:GetObject",
"s3:PutObject",
"s3:ListBucket",
"s3:CreateBucket",
"s3:PutLifecycleConfiguration"
],
"Resource": [
"arn:aws:s3:::bedrock-agentcore-*",
"arn:aws:s3:::bedrock-agentcore-*/*"
]
},
{
"Sid": "ECRRepositoryAccess",
"Effect": "Allow",
"Action": [
"ecr:CreateRepository",
"ecr:DescribeRepositories",
"ecr:GetRepositoryPolicy",
"ecr:InitiateLayerUpload",
"ecr:CompleteLayerUpload",
"ecr:PutImage",
Use the starter toolkit 36

"ecr:UploadLayerPart",
"ecr:BatchCheckLayerAvailability",
"ecr:GetDownloadUrlForLayer",
"ecr:BatchGetImage",
"ecr:ListImages",
"ecr:TagResource"
],
"Resource": [
"arn:aws:ecr:*:*:repository/bedrock-agentcore-*"
]
},
{
"Sid": "ECRAuthorizationAccess",
"Effect": "Allow",
"Action": [
"ecr:GetAuthorizationToken"
],
"Resource": "*"
}
]
}
Execution role for running an agent in AgentCore Runtime.......................................................
To run agent or tool in AgentCore Runtime you need an AWS Identity and Access Management
execution role. For information about creating an IAM role, see IAM role creation.

AgentCore Runtime execution role

The AgentCore Runtime execution role is an IAM role that AgentCore Runtime assumes to run an
agent. Replace the following:

us-east-1 with the AWS Region that you are using
123456789012 with your AWS account ID
agentName with the name of your agent. You'll need to decide the agent name before creating
the role and AgentCore Runtime.
Execution role for running an agent in AgentCore Runtime 37

JSON
{
"Version":"2012-10-17",
"Statement": [
{
"Sid": "ECRImageAccess",
"Effect": "Allow",
"Action": [
"ecr:BatchGetImage",
"ecr:GetDownloadUrlForLayer"
],
"Resource": [
"arn:aws:ecr: us-east-1 : 123456789012 :repository/*"
]
},
{
"Effect": "Allow",
"Action": [
"logs:DescribeLogStreams",
"logs:CreateLogGroup"
],
"Resource": [
"arn:aws:logs: us-east-1 : 123456789012 :log-group:/aws/bedrock-
agentcore/runtimes/*"
]
},
{
"Effect": "Allow",
"Action": [
"logs:DescribeLogGroups"
],
"Resource": [
"arn:aws:logs: us-east-1 : 123456789012 :log-group:*"
]
},
{
"Effect": "Allow",
"Action": [
"logs:CreateLogStream",
"logs:PutLogEvents"
],
"Resource": [
Execution role for running an agent in AgentCore Runtime 38

"arn:aws:logs: us-east-1 : 123456789012 :log-group:/aws/bedrock-
agentcore/runtimes/*:log-stream:*"
]
},
{
"Sid": "ECRTokenAccess",
"Effect": "Allow",
"Action": [
"ecr:GetAuthorizationToken"
],
"Resource": "*"
},
{
"Effect": "Allow",
"Action": [
"xray:PutTraceSegments",
"xray:PutTelemetryRecords",
"xray:GetSamplingRules",
"xray:GetSamplingTargets"
],
"Resource": [ "*" ]
},
{
"Effect": "Allow",
"Resource": "*",
"Action": "cloudwatch:PutMetricData",
"Condition": {
"StringEquals": {
"cloudwatch:namespace": "bedrock-agentcore"
}
}
},
{
"Sid": "GetAgentAccessToken",
"Effect": "Allow",
"Action": [
"bedrock-agentcore:GetWorkloadAccessToken",
"bedrock-agentcore:GetWorkloadAccessTokenForJWT",
"bedrock-agentcore:GetWorkloadAccessTokenForUserId"
],
"Resource": [
"arn:aws:bedrock-agentcore: us-east-1 : 123456789012 :workload-
identity-directory/default",
Execution role for running an agent in AgentCore Runtime 39

"arn:aws:bedrock-agentcore: us-east-1 : 123456789012 :workload-
identity-directory/default/workload-identity/ agentName -*"
]
},
{"Sid": "BedrockModelInvocation",
"Effect": "Allow",
"Action": [
"bedrock:InvokeModel",
"bedrock:InvokeModelWithResponseStream"
],
"Resource": [
"arn:aws:bedrock:*::foundation-model/*",
"arn:aws:bedrock: us-east-1 : 123456789012 :*"
]
}
]
}
AgentCore Runtime trust policy

The trust relationship for the AgentCore Runtime execution role should allow AgentCore Runtime
to assume the role:

Replace the following:

us-east-1 with the AWS Region that you are using
123456789012 with your AWS account ID
JSON
{
"Version":"2012-10-17",
"Statement": [
{
"Sid": "AssumeRolePolicy",
"Effect": "Allow",
"Principal": {
"Service": "bedrock-agentcore.amazonaws.com"
},
"Action": "sts:AssumeRole",
Execution role for running an agent in AgentCore Runtime 40

"Condition": {
"StringEquals": {
"aws:SourceAccount": " 123456789012 "
},
"ArnLike": {
"aws:SourceArn": "arn:aws:bedrock-agentcore: us-
east-1 : 123456789012 :*"
}
}
}
]
}
Get started with AgentCore Runtime....................................................................................................
You can use the following tutorials to get started with Amazon Bedrock AgentCore Runtime.

The Amazon Bedrock AgentCore Starter Toolkit is a Command Line Interface (CLI) that simplifies
the infrastructure setup for containerizing and deploying an agent to an AgentCore Runtime.

Topics

Get started with the Amazon Bedrock AgentCore starter toolkit
Get started without the starter toolkit
Get started with the Amazon Bedrock AgentCore starter toolkit
This tutorial shows you how to use the Amazon Bedrock AgentCore starter toolkit to deploy an
agent to an Amazon Bedrock AgentCore Runtime.

The starter toolkit is a Command Line Interface (CLI) toolkit that you can use to deploy AI agents
to an Amazon Bedrock AgentCore Runtime. You can use the toolkit with popular Python agent
frameworks, such as LangGraph or Strands Agents. This tutorial uses Strands Agents.

Topics

Prerequisites
Step 1: Set up project and install dependencies
Step 2: Create your agent
Get started with AgentCore Runtime 41

Step 3: Test locally
Step 4: Configure your agent
Step 5: Enable observability for your agent
Step 6: Deploy to Amazon Bedrock AgentCore Runtime
Step 7: Test your deployed agent
Step 8: Invoke your agent programmatically
Step 9: Clean up
Find your resources
Common issues and solutions
Advanced options (Optional)
Prerequisites...........................................................................................................................................
Before you start, make sure you have:

AWS Account with credentials configured. To configure your AWS credentials, see Configuration
and credential file settings in the AWS CLI.
Python 3.10+ installed
Boto3 installed
AWS Permissions : To create and deploy an agent with the starter toolkit, you must have
appropriate permissions. For information, see Use the starter toolkit.
Model access : Anthropic Claude Sonnet 4.0 enabled in the Amazon Bedrock console. For
information about using a different model with the Strands Agents see the Model Providers
section in the Strands Agents SDK documentation.
Step 1: Set up project and install dependencies

Create a project folder and install the required packages:

mkdir agentcore-runtime-quickstart
cd agentcore-runtime-quickstart
python3 -m venv .venv
source .venv/bin/activate
Get started with starter toolkit 42

Note
On Microsoft Windows, use: .venv\Scripts\activate
Upgrade pip to the latest version:

pip install --upgrade pip
Install the following required packages:

bedrock-agentcore - The Amazon Bedrock AgentCore SDK for building AI agents
strands-agents - The Strands Agents SDK
bedrock-agentcore-starter-toolkit - The Amazon Bedrock AgentCore starter toolkit
pip install bedrock-agentcore strands-agents bedrock-agentcore-starter-toolkit
Verify installation:

agentcore --help
Step 2: Create your agent

Create a source file for your agent code named my_agent.py. Add the following code:

from bedrock_agentcore import BedrockAgentCoreApp
from strands import Agent
app = BedrockAgentCoreApp()
agent = Agent()
@app.entrypoint
def invoke(payload):
"""Your AI agent function"""
user_message = payload.get("prompt", "Hello! How can I help you today?")
result = agent(user_message)
return {"result": result.message}
Get started with starter toolkit 43

if __name__ == "__main__":
app.run()
Create requirements.txt and add the following:

bedrock-agentcore
strands-agents
Step 3: Test locally

Make sure port 8080 is free before starting. See Port 8080 in use (local only) in Common issues and
solutions.

Open a terminal window and start your agent with the following command:

python my_agent.py
Test your agent by opening another terminal window and enter the following command:

curl -X POST http://localhost:8080/invocations \
-H "Content-Type: application/json" \
-d '{"prompt": "Hello!"}'
Success: You should see a response like {"result": "Hello! I'm here to help..."}. In
the terminal window that's running the agent, enter Ctrl+C to stop the agent.

Step 4: Configure your agent

Configure and deploy your agent to AWS using the starter toolkit. The toolkit automatically creates
the IAM execution role, container image, and Amazon Elastic Container Registry repository needed
to host the agent in an AgentCore Runtime. By default the toolkit hosts the agent in an AgentCore
Runtime that is in the us-west-2 AWS Region.

Configure the agent using the default values:

agentcore configure -e my_agent.py
The e or -entrypoint flag specifies the entrypoint file for your agent (the Python file
containing your agent code)
Get started with starter toolkit 44

This command creates configuration for deployment to AWS
Accept the default values unless you have specific requirements
The configuration information is stored in a hidden file named .bedrock_agentcore.yaml
(Optional) Use a different AWS Region

By default, the starter toolkit deploys to the us-west-2 AWS Region. To use a different Region:

agentcore configure -e my_agent.py -r us-east-1
Step 5: Enable observability for your agent

Amazon Bedrock AgentCore Observability helps you trace, debug, and monitor agents that you
host in Amazon Bedrock AgentCore Runtime. First enable CloudWatch Transaction Search by
following the instructions at Enabling Amazon Bedrock AgentCore runtime observability. To
observe your agent, see View observability data for your Amazon Bedrock AgentCore agents.

Step 6: Deploy to Amazon Bedrock AgentCore Runtime

Host your agent in AgentCore Runtime:

agentcore launch
This command:

Builds your container using AWS CodeBuild (no Docker required locally)
Creates necessary AWS resources (ECR repository, IAM roles, etc.)
Deploys your agent to Amazon Bedrock AgentCore Runtime
Configures CloudWatch logging
In the output from agentcore launch note the following:

The Amazon Resource Name (ARN) of the agent. You need it to invoke the agent with the
InvokeAgentRuntime operation.
The location of the logs in Amazon CloudWatch Logs
Get started with starter toolkit 45

If the deployment fails check for common issues. For other deployment options, see Deployment
modes.

Step 7: Test your deployed agent

Test your deployed agent:

agentcore invoke '{"prompt": "tell me a joke"}'
If you see a joke in the response, your agent is now running in an Amazon Bedrock AgentCore
Runtime and can be invoked. If not, check for common issues.

Step 8: Invoke your agent programmatically

You can invoke the agent using the AWS SDK InvokeAgentRuntime operation. To call
InvokeAgentRuntime, you need the ARN of the agent that you noted in Step 6: Deploy to
Amazon Bedrock AgentCore Runtime. You can also get the ARN from the bedrock_agentcore:
section of the .bedrock_agentcore.yaml (hidden) file that the toolkit creates. Use the
following boto3 (AWS SDK) code to invoke your agent. Replace Agent ARN with the ARN of your
agent. Make sure that you have bedrock-agentcore:InvokeAgentRuntime permissions.
Create a file named invoke_agent.py and add the following code:

import json
import uuid
import boto3
agent_arn = " Agent ARN "
prompt = "Tell me a joke"
# Initialize the Amazon Bedrock AgentCore client
agent_core_client = boto3.client('bedrock-agentcore')
# Prepare the payload
payload = json.dumps({"prompt": prompt}).encode()
# Invoke the agent
response = agent_core_client.invoke_agent_runtime(
agentRuntimeArn=agent_arn,
runtimeSessionId=str(uuid.uuid4()),
payload=payload,
qualifier="DEFAULT"
Get started with starter toolkit 46

)
content = []
for chunk in response.get("response", []):
content.append(chunk.decode('utf-8'))
print(json.loads(''.join(content)))
Open a terminal window and run the code with the following command:

python invoke_agent.py
If successful, you should see a joke in the response. If the call fails, check the logs that you noted in
Step 6: Deploy to Amazon Bedrock AgentCore Runtime.

Note
If you plan on integrating your agent with OAuth, you can't use the AWS SDK to call
InvokeAgentRuntime. Instead, make a HTTPS request to InvokeAgentRuntime. For
more information, see the section called â€œAuthenticate and authorize with Inbound Auth
and Outbound Authâ€.
Step 9: Clean up

If you no longer want to host the agent in the AgentCore Runtime, use the destroy commnand to
delete the AWS resources that the starter toolit created for you.

agentcore destroy
Find your resources

After deployment, view your resources in the AWS Console:

Resource locations

Resource Location
Agent Logs CloudWatch â†’ Log groups â†’ /aws/bedrock-agentcore/
runtimes/{agent-id}-DEFAULT
Get started with starter toolkit 47

Resource Location
Container Images ECR â†’ Repositories â†’ bedrock-agentcore-{agent-na
me}
Build Logs CodeBuild â†’ Build history
IAM Role IAM â†’ Roles â†’ Search for "BedrockAgentCore"
Common issues and solutions

Common issues and solutions when getting started with the Amazon Bedrock AgentCore starter
toolkit. For more troubleshooting information, see Troubleshoot Amazon Bedrock AgentCore
Runtime.

Permission denied errors

Verify your AWS credentials and permissions:
Verify AWS credentials: aws sts get-caller-identity
Check you have the required policies attached
Review caller permissions policy for detailed requirements
Docker not found warnings

You can ignore this warning:
Ignore this! Default deployment uses CodeBuild (no Docker needed)
Only install Docker/Finch/Podman if you want to use --local or --local-build flags
Model access denied

Enable model access in the Bedrock console:
Enable Anthropic Claude 4.0 in the Bedrock console
Make sure you're in the correct AWS Region (us-west-2 by default)
CodeBuild build error

Check build logs and permissions:
Check CodeBuild project logs in AWS console
Verify your caller permissions include CodeBuild access
Get started with starter toolkit 48

Port 8080 in use (local only)

Find and stop processes that are using port 8080:
Use lsof -ti:8080 to get a list of process using port 8080.
Use kill -9 PID to stop the process. Replace PID with the process ID.
Region mismatch

Verify the AWS Region with aws configure get region and make sure resources are in
same Region
Advanced options (Optional)

The starter toolkit has advanced configuration options for different deployment modes and
custom IAM roles. For more information, see Runtime commands for the starter toolkit.

Deployment modes

Choose the right deployment approach for your needs:

Default: CodeBuild + Cloud Runtime (RECOMMENDED)

Suitable for production, managed environments, teams without Docker:
agentcore launch # Uses CodeBuild (no Docker needed)
Local Development

Suitable for development, rapid iteration, debugging:
agentcore launch --local # Build and run locally (requires Docker/Finch/Podman)
Hybrid: Local Build + Cloud Runtime

Suitable for teams with Docker expertise needing build customization:
agentcore launch --local-build # Build locally, deploy to cloud (requires Docker/
Finch/Podman)
Get started with starter toolkit 49

Note
Docker is only required for â€”local and â€”local-build modes. The default mode uses
AWS CodeBuild.
Custom execution role

Use an existing IAM role:

agentcore configure -e my_agent.py --execution-role arn:aws:iam::111122223333:role/
MyRole
Why ARM64?

Amazon Bedrock AgentCore Runtime requires ARM64 containers (AWS Graviton). The toolkit
handles this automatically:

Default (CodeBuild) : Builds ARM64 containers in the cloud - no Docker needed
Local with Docker : Only containers built on ARM64 machines will work when deployed to
agentcore runtime
Get started without the starter toolkit............................................................................................
You can create a AgentCore Runtime agent without the starter toolkit. Instead you can use a
combination of command line tools to configure and deploy your agent to an AgentCore Runtime.

This tutorial shows how to deploy a custom agent without using the starter toollkit. A custom
agent is an agent built without using the AgentCore Python SDK. In this tutorial, the custom agent
is built using FastAPI and Docker. The custom agent follows the AgentCore Runtime requirements,
meaning the agent must expose /invocations POST and /ping GET endpoints and be packaged
in a Docker container. Amazon Bedrock AgentCore requires ARM64 architecture for all deployed
agents.

Note
You can also use this approach for agents that you build with the AgentCore Python SDK.
Get started without the starter toolkit 50

Quick start setup

Enable observability for your agent

Amazon Bedrock AgentCore Observability helps you trace, debug, and monitor agents that you
host in AgentCore Runtime. To observe an agent, first enable CloudWatch Transaction Search by
following the instructions at Enabling AgentCore observability.

Install uv

For this example, we'll use the uv package manager, though you can use any Python utility or
package manager. To install uv on macOS:

curl -LsSf https://astral.sh/uv/install.sh | sh
For installation instructions on other platforms, refer to the uv documentation.

Create your agent project

Setting up your project

Create and navigate to your project directory:
mkdir my-custom-agent && cd my-custom-agent
Initialize the project with Python 3.11:
uv init --python 3.11
Add the required dependencies (uv automatically creates a .venv):
uv add fastapi 'uvicorn[standard]' pydantic httpx strands-agents
Agent contract requirements

Your custom agent must fulfill these core requirements:

/invocations Endpoint : POST endpoint for agent interactions (REQUIRED)
/ping Endpoint : GET endpoint for health checks (REQUIRED)
Docker Container : ARM64 containerized deployment package
Get started without the starter toolkit 51

Project structure

Note: For convenience, the example below uses FastAPI Server as the Web server framework for
handling requests.

Your project should have the following structure:

my-custom-agent/
### agent.py # FastAPI application
### Dockerfile # ARM64 container configuration
### pyproject.toml # Created by uv init
### uv.lock # Created automatically by uv
Complete strands agent example

Create agent.py in your project root with the following content:

Example agent.py

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Dict, Any
from datetime import datetime
from strands import Agent
app = FastAPI(title="Strands Agent Server", version="1.0.0")
# Initialize Strands agent
strands_agent = Agent()
class InvocationRequest(BaseModel):
input: Dict[str, Any]
class InvocationResponse(BaseModel):
output: Dict[str, Any]
@app.post("/invocations", response_model=InvocationResponse)
async def invoke_agent(request: InvocationRequest):
try:
user_message = request.input.get("prompt", "")
if not user_message:
raise HTTPException(
Get started without the starter toolkit 52

status_code=400,
detail="No prompt found in input. Please provide a 'prompt' key in the
input."
)
result = strands_agent(user_message)
response = {
"message": result.message,
"timestamp": datetime.utcnow().isoformat()
}
return InvocationResponse(output=response)
except Exception as e:
raise HTTPException(status_code=500, detail=f"Agent processing failed:
{str(e)}")
@app.get("/ping")
async def ping():
return {"status": "healthy"}
if __name__ == "__main__":
import uvicorn
uvicorn.run(app, host="0.0.0.0", port=8080)
This implementation:

Creates a FastAPI application with the required endpoints
Initializes a Strands agent for processing user messages
Implements the /invocations POST endpoint for agent interactions
Implements the /ping GET endpoint for health checks
Configures the server to run on host 0.0.0.0 and port 8080
Test locally

Testing your agent

Run the application:
uv run uvicorn agent:app --host 0.0.0.0 --port 8080
Get started without the starter toolkit 53

Test the /ping endpoint (in another terminal):
curl http://localhost:8080/ping
Test the /invocations endpoint:
curl -X POST http://localhost:8080/invocations \
-H "Content-Type: application/json" \
-d '{
"input": {"prompt": "What is artificial intelligence?"}
}'
Create dockerfile

Create Dockerfile in your project root with the following content:

Example Dockerfile

# Use uv's ARM64 Python base image
FROM --platform=linux/arm64 ghcr.io/astral-sh/uv:python3.11-bookworm-slim
WORKDIR /app
# Copy uv files
COPY pyproject.toml uv.lock ./
# Install dependencies (including strands-agents)
RUN uv sync --frozen --no-cache
# Copy agent file
COPY agent.py ./
# Expose port
EXPOSE 8080
# Run application
CMD ["uv", "run", "uvicorn", "agent:app", "--host", "0.0.0.0", "--port", "8080"]
This Dockerfile:

Uses an ARM64 Python base image (required by Amazon Bedrock AgentCore)
Get started without the starter toolkit 54

Sets up the working directory
Copies the dependency files and installs dependencies
Copies the agent code
Exposes port 8080
Configures the command to run the application
Build and deploy ARM64 image

Setup docker buildx

Docker buildx lets you build images for different architectures. Set it up with:

docker buildx create --use
Build for ARM64 and test locally

Building and testing your image

Build the image locally for testing:
docker buildx build --platform linux/arm64 -t my-agent:arm64 --load.
Test locally with credentials (Strands agents need AWS credentials):
docker run --platform linux/arm64 -p 8080:8080 \
-e AWS_ACCESS_KEY_ID="$AWS_ACCESS_KEY_ID" \
-e AWS_SECRET_ACCESS_KEY="$AWS_SECRET_ACCESS_KEY" \
-e AWS_SESSION_TOKEN="$AWS_SESSION_TOKEN" \
-e AWS_REGION="$AWS_REGION" \
my-agent:arm64
Create ECR repository and deploy

Deploying to ECR

Create an ECR repository:
aws ecr create-repository --repository-name my-strands-agent --region us-west-2
Get started without the starter toolkit 55

Log in to ECR:
aws ecr get-login-password --region us-west-2 | docker login --username AWS --
password-stdin account-id .dkr.ecr.us-west-2.amazonaws.com
Build and push to ECR:
docker buildx build --platform linux/arm64 -t account-id .dkr.ecr.us-
west-2.amazonaws.com/my-strands-agent:latest --push.
Verify the image was pushed:
aws ecr describe-images --repository-name my-strands-agent --region us-west-2
Deploy agent runtime

Create a file named deploy_agent.py with the following content:

Example deploy_agent.py

import boto3
client = boto3.client('bedrock-agentcore-control', region_name='us-west-2')
response = client.create_agent_runtime(
agentRuntimeName='strands_agent',
agentRuntimeArtifact={
'containerConfiguration': {
'containerUri': ' account-id .dkr.ecr.us-west-2.amazonaws.com/my-strands-
agent:latest'
}
},
networkConfiguration={"networkMode": "PUBLIC"},
roleArn='arn:aws:iam:: account-id :role/AgentRuntimeRole'
)
print(f"Agent Runtime created successfully!")
print(f"Agent Runtime ARN: {response['agentRuntimeArn']}")
print(f"Status: {response['status']}")
Run the script to deploy your agent:

Get started without the starter toolkit 56

uv run deploy_agent.py
This script uses the create_agent_runtime operation to deploy your agent to Amazon Bedrock
AgentCore. Make sure to replace account-id with your actual AWS account ID and ensure the
IAM role has the necessary permissions. For more information, see IAM Permissions for AgentCore
Runtime.

Invoke your agent

Create a file named invoke_agent.py with the following content:

Example invoke_agent.py

import boto3
import json
agent_core_client = boto3.client('bedrock-agentcore', region_name='us-west-2')
payload = json.dumps({
"input": {"prompt": "Explain machine learning in simple terms"}
})
response = agent_core_client.invoke_agent_runtime(
agentRuntimeArn='arn:aws:bedrock-agentcore:us-west-2: account-id :runtime/
myStrandsAgent- suffix ',
runtimeSessionId='dfmeoagmreaklgmrkleafremoigrmtesogmtrskhmtkrlshmt', # Must be
33+ chars
payload=payload,
qualifier="DEFAULT"
)
response_body = response['response'].read()
response_data = json.loads(response_body)
print("Agent Response:", response_data)
Run the script to invoke your agent:

uv run invoke_agent.py
This script uses the InvokeAgentRuntime AWS SDK operation to send a request to your deployed
agent. Make sure to replace account-id and agentArn with your actual values.

Get started without the starter toolkit 57

If you plan on integrating your agent with OAuth, you can't use the AWS SDK to call
InvokeAgentRuntime. Instead, make a HTTPS request to InvokeAgentRuntime. For more
information, see Authenticate and authorize with Inbound Auth and Outbound Auth.

Expected response format

When you invoke your agent, you'll receive a response like this:

Example Sample response

{
"output": {
"message": {
"role": "assistant",
"content": [
{
"text": "# Artificial Intelligence in Simple Terms\n\nArtificial Intelligence
(AI) is technology that allows computers to do tasks that normally need human
intelligence. Think of it as teaching machines to:\n\n- Learn from information (like
how you learn from experience)\n- Make decisions based on what they've learned\n-
Recognize patterns (like identifying faces in photos)\n- Understand language (like
when I respond to your questions)\n\nInstead of following specific step-by-step
instructions for every situation, AI systems can adapt to new information and improve
over time.\n\nExamples you might use every day include voice assistants like Siri,
recommendation systems on streaming services, and email spam filters that learn which
messages are unwanted."
}
]
},
"timestamp": "2025-07-13T01:48:06.740668"
}
}
Amazon Bedrock AgentCore requirements summary

Platform : Must be linux/arm64
Endpoints : /invocations POST and /ping GET are mandatory
ECR : Images must be deployed to ECR
Port : Application runs on port 8080
Strands Integration : Uses Strands Agent for AI processing
Credentials : Strands agents require AWS credentials for operation
Get started without the starter toolkit 58

Conclusion

In this guide, you've learned how to:

Set up a development environment for building custom agents
Create a FastAPI application that implements the required endpoints
Containerize your agent for ARM64 architecture
Test your agent locally
Deploy your agent to ECR
Create an agent runtime in Amazon Bedrock AgentCore
Invoke your deployed agent
By following these steps, you can create and deploy custom agents that leverage the power of
Amazon Bedrock AgentCore while maintaining full control over your agent's implementation.

Use any agent framework........................................................................................................................
You can use open source AI frameworks to create an agent or tool. This topic shows examples for a
variety of frameworks, including Strands Agents, LangGraph, and Google ADK.

Topics

Strands Agents
LangGraph
Google Agent Development Kit (ADK)
OpenAI Agents SDK
Microsoft AutoGen
CrewAI
Strands Agents......................................................................................................................................
For the full example, see https://github.com/awslabs/amazon-bedrock-agentcore-samples/tree/
main/03-integrations/agentic-frameworks/strands-agents.

import os
from strands import Agent
Use any agent framework 59

from strands_tools import file_read, file_write, editor
agent = Agent(tools=[file_read, file_write, editor])
from bedrock_agentcore.runtime import BedrockAgentCoreApp
app = BedrockAgentCoreApp()
@app.entrypoint
def agent_invocation(payload, context):
"""Handler for agent invocation"""
user_message = payload.get("prompt", "No prompt found in input, please guide
customer to create a json payload with prompt key")
result = agent(user_message)
print("context:\n-------\n", context)
print("result:\n*******\n", result)
return {"result": result.message}
app.run()
LangGraph..............................................................................................................................................
For the full example, see https://github.com/awslabs/amazon-bedrock-agentcore-samples/tree/
main/03-integrations/agentic-frameworks/langgraph.

from langchain.chat_models import init_chat_model
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
#------------------------------------------------
from bedrock_agentcore.runtime import BedrockAgentCoreApp
app = BedrockAgentCoreApp()
#------------------------------------------------
llm = init_chat_model(
"us.anthropic.claude-3-5-haiku-20241022-v1:0",
model_provider="bedrock_converse",
)
# Create graph
graph_builder = StateGraph(State)
...
# Add nodes and edges
...
LangGraph 60

graph = graph_builder.compile()
# Finally write your entrypoint
@app.entrypoint
def agent_invocation(payload, context):
print("received payload")
print(payload)
tmp_msg = {"messages": [{"role": "user", "content": payload.get("prompt", "No
prompt found in input, please guide customer as to what tools can be used")}]}
tmp_output = graph.invoke(tmp_msg)
print(tmp_output)
return {"result": tmp_output['messages'][-1].content}
app.run()
Google Agent Development Kit (ADK)
For the full example, see https://github.com/awslabs/amazon-bedrock-agentcore-samples/tree/
main/03-integrations/agentic-frameworks/adk.

from google.adk.agents import Agent
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.adk.tools import google_search
from google.genai import types
import asyncio
import os
# adapted form https://google.github.io/adk-docs/tools/built-in-tools/#google-search
APP_NAME="google_search_agent"
USER_ID="user1234"
# Agent Definition
# Add your GEMINI_API_KEY
root_agent = Agent(
model="gemini-2.0-flash",
name="openai_agent",
description="Agent to answer questions using Google Search.",
Google ADK 61

instruction="I can answer your questions by searching the internet. Just ask me
anything!",
# google_search is a pre-built tool which allows the agent to perform Google
searches.
tools=[google_search]
)
# Session and Runner
async def setup_session_and_runner(user_id, session_id):
session_service = InMemorySessionService()
session = await session_service.create_session(app_name=APP_NAME, user_id=user_id,
session_id=session_id)
runner = Runner(agent=root_agent, app_name=APP_NAME,
session_service=session_service)
return session, runner
# Agent Interaction
async def call_agent_async(query, user_id, session_id):
content = types.Content(role='user', parts=[types.Part(text=query)])
session, runner = await setup_session_and_runner(user_id, session_id)
events = runner.run_async(user_id=user_id, session_id=session_id,
new_message=content)
async for event in events:
if event.is_final_response():
final_response = event.content.parts[0].text
print("Agent Response: ", final_response)
return final_response
from bedrock_agentcore.runtime import BedrockAgentCoreApp
app = BedrockAgentCoreApp()
@app.entrypoint
def agent_invocation(payload, context):
return asyncio.run(call_agent_async(payload.get("prompt", "what is Bedrock
Agentcore Runtime?"), payload.get("user_id",USER_ID), context.session_id))
app.run()
Google ADK 62

OpenAI Agents SDK..............................................................................................................................
For the full example, see https://github.com/awslabs/amazon-bedrock-agentcore-samples/tree/
main/03-integrations/agentic-frameworks/openai-agents.

from agents import Agent, Runner, WebSearchTool
import logging
import asyncio
import sys
# Set up logging
logging.basicConfig(
level=logging.DEBUG,
format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
handlers=[
logging.StreamHandler(sys.stdout)
]
)
logger = logging.getLogger("openai_agents")
# Configure OpenAI library logging
logging.getLogger("openai").setLevel(logging.DEBUG)
logger.debug("Initializing OpenAI agent with tools")
agent = Agent(
name="Assistant",
tools=[
WebSearchTool(),
],
)
async def main(query=None):
if query is None:
query = "Which coffee shop should I go to, taking into account my preferences
and the weather today in SF?"
logger.debug(f"Running agent with query: {query}")
try:
logger.debug("Starting agent execution")
result = await Runner.run(agent, query)
logger.debug(f"Agent execution completed with result type: {type(result)}")
return result
OpenAI Agents SDK 63

except Exception as e:
logger.error(f"Error during agent execution: {e}", exc_info=True)
raise
# Integration with Bedrock AgentCore
from bedrock_agentcore.runtime import BedrockAgentCoreApp
app = BedrockAgentCoreApp()
@app.entrypoint
async def agent_invocation(payload, context):
logger.debug(f"Received payload: {payload}")
query = payload.get("prompt", "How can I help you today?")
try:
result = await main(query)
logger.debug("Agent execution completed successfully")
return {"result": result.final_output}
except Exception as e:
logger.error(f"Error during agent execution: {e}", exc_info=True)
return {"result": f"Error: {str(e)}"}
# Run the app when imported
if __name__== "__main__":
app.run()
Microsoft AutoGen................................................................................................................................
For the full example, see https://github.com/awslabs/amazon-bedrock-agentcore-samples/tree/
main/03-integrations/agentic-frameworks/autogen.

from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.ui import Console
from autogen_ext.models.openai import OpenAIChatCompletionClient
import asyncio
import logging
# Set up logging
logging.basicConfig(
level=logging.DEBUG,
format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("autogen_agent")
Microsoft AutoGen 64

# Initialize the model client
model_client = OpenAIChatCompletionClient(
model="gpt-4o",
)
# Define a simple function tool that the agent can use
async def get_weather(city: str) -> str:
"""Get the weather for a given city."""
return f"The weather in {city} is 73 degrees and Sunny."
# Define an AssistantAgent with the model and tool
agent = AssistantAgent(
name="weather_agent",
model_client=model_client,
tools=[get_weather],
system_message="You are a helpful assistant.",
reflect_on_tool_use=True,
model_client_stream=True, # Enable streaming tokens
)
# Integrate with Bedrock AgentCore
from bedrock_agentcore.runtime import BedrockAgentCoreApp
app = BedrockAgentCoreApp()
@app.entrypoint
async def main(payload):
# Process the user prompt
prompt = payload.get("prompt", "Hello! What can you help me with?")
# Run the agent
result = await Console(agent.run_stream(task=prompt))
# Extract the response content for JSON serialization
if result and hasattr(result, 'messages') and result.messages:
last_message = result.messages[-1]
if hasattr(last_message, 'content'):
return {"result": last_message.content}
return {"result": "No response generated"}
app.run()
Microsoft AutoGen 65

CrewAI.....................................................................................................................................................
For the full example, see https://github.com/awslabs/amazon-bedrock-agentcore-samples/blob/
main/01-tutorials/01-AgentCore-runtime/01-hosting-agent/04-crewai-with-bedrock-model/
runtime-with-crewai-and-bedrock-models.ipynb.

from crewai import Agent, Crew, Process, Task
from crewai_tools import MathTool, WeatherTool
from bedrock_agentcore.runtime import BedrockAgentCoreApp
import argparse
import json
app = BedrockAgentCoreApp()
# Define CrewAI agent
def create_researcher():
"""Create a researcher agent"""
from langchain_aws import ChatBedrock
# Initialize LLM
llm = ChatBedrock(
model_id="anthropic.claude-3-sonnet-20240229-v1:0",
model_kwargs={"temperature": 0.1}
)
# Create researcher agent
return Agent(
role="Senior Research Specialist",
goal="Find comprehensive and accurate information about the topic",
backstory="You are an experienced research specialist with a talent for finding
relevant information.",
verbose=True,
llm=llm,
tools=[MathTool(), WeatherTool()]
)
# Define the analyst agent
def create_analyst():
....
# Create the crew
def create_crew():
"""Create and configure the CrewAI crew"""
# Create agents
CrewAI 66

researcher = create_researcher()
analyst = create_analyst()
# Create research task with fields like description filled in as per crewAI docs
research_task = Task(
description="...",
agent=researcher,
expected_output="..."
)
analysis_task = Task(
...
)
# Create crew
return Crew(
agents=[researcher, analyst],
tasks=[research_task, analysis_task],
process=Process.sequential,
verbose=True
)
# Initialize the crew
crew = create_crew()
# Finally write your entrypoint
@app.entrypoint
def crewai_bedrock(payload):
"""
Invoke the crew with a payload
"""
user_input = payload.get("prompt")
# Run the crew
result = crew.kickoff(inputs={"topic": user_input})
# Return the result
return result.raw
if __name__ == "__main__":
app.run()
CrewAI 67

Use any foundation model......................................................................................................................
You can use any foundation model with AgentCore Runtime The following are examples for
Amazon Bedrock, Open AI, and Gemini:

Topics

Amazon Bedrock
Open AI
Gemini
Amazon Bedrock...................................................................................................................................
import boto3
from strands.models import BedrockModel
# Create a Bedrock model with the custom session
bedrock_model = BedrockModel(
model_id="us.anthropic.claude-3-7-sonnet-20250219-v1:0",
boto_session=session
)
Open AI...................................................................................................................................................
from strands.models.openai import OpenAIModel
model = OpenAIModel(
client_args={
"api_key": "<our_OPENAI_API_KEY>",
# **model_config
model_id="gpt-4o",
params={
"max_tokens": 1000,
"temperature": 0.7,
}
)
from strands import Agent
from strands_tools import python_repl
agent = Agent(model=model,tools=[python_repl])
Use any foundation model 68

Gemini.....................................................................................................................................................
import os
from langchain.chat_models import init_chat_model
# Use your Google API key to initialize the chat model
os.environ["GOOGLE_API_KEY"] = "..."
llm = init_chat_model("google_genai:gemini-2.0-flash")
Deploy MCP servers in AgentCore Runtime
Amazon Bedrock AgentCore Runtime lets you deploy and run Model Context Protocol (MCP)
servers in the AgentCore Runtime. This guide walks you through creating, testing, and deploying
your first MCP server.

For an example, see https://github.com/awslabs/amazon-bedrock-agentcore-samples/tree/main/
01-tutorials/01-AgentCore-runtime/02-hosting-MCP-server.

In this section, you learn:

How to create an MCP server with tools
How to test your server locally
How to deploy your server to AWS
How to invoke your deployed server
Topics

How Amazon Bedrock AgentCore supports MCP
Prerequisites
Step 1: Create your MCP server
Step 2: Test your MCP server locally
Step 3: Deploy your MCP server to AWS
Step 4: Invoke your deployed MCP server
Appendix
Gemini 69

How Amazon Bedrock AgentCore supports MCP...........................................................................
When you configure a Amazon Bedrock AgentCore Runtime with the MCP protocol, the service
expects MCP server containers to be available at the path 0.0.0.0:8000/mcp, which is the
default path supported by most official MCP server SDKs.

Amazon Bedrock AgentCore requires stateless streamable-HTTP servers because the Runtime
provides session isolation by default. The platform automatically adds a Mcp-Session-Id header
for any request without it, so MCP clients can maintain connection continuity to the same Amazon
Bedrock AgentCore Runtime session.

The payload of the InvokeAgentRuntime API is passed through directly, allowing RPC messages of
protocols like MCP to be easily proxied.

Prerequisites...........................................................................................................................................
Python 3.10 or higher installed and basic understanding of Python
An AWS account with appropriate permissions and local credentials configured
Step 1: Create your MCP server........................................................................................................
Install required packages

First, install the MCP package:

pip install mcp
Create your first MCP server

Create a new file called my_mcp_server.py:

# my_mcp_server.py
from mcp.server.fastmcp import FastMCP
from starlette.responses import JSONResponse
mcp = FastMCP(host="0.0.0.0", stateless_http=True)
@mcp.tool()
def add_numbers(a: int, b: int) -> int:
How Amazon Bedrock AgentCore supports MCP 70

"""Add two numbers together"""
return a + b
@mcp.tool()
def multiply_numbers(a: int, b: int) -> int:
"""Multiply two numbers together"""
return a * b
@mcp.tool()
def greet_user(name: str) -> str:
"""Greet a user by name"""
return f"Hello, {name}! Nice to meet you."
if __name__ == "__main__":
mcp.run(transport="streamable-http")
Understanding the code

FastMCP : Creates an MCP server that can host your tools
@mcp.tool() : Decorator that turns your Python functions into MCP tools
Tools : Three simple tools that demonstrate different types of operations
Step 2: Test your MCP server locally................................................................................................
Start your MCP server

Run your MCP server locally:

python my_mcp_server.py
You should see output indicating the server is running on port 8000.

Test with MCP client

From a new terminal, create a new file my_mcp_client.py and execute it using python
my_mcp_client.py

# my_mcp_client.py
import asyncio
Step 2: Test your MCP server locally 71

from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client
async def main():
mcp_url = "http://localhost:8000/mcp"
headers = {}
async with streamablehttp_client(mcp_url, headers, timeout=120,
terminate_on_close=False) as (
read_stream,
write_stream,
_,
):
async with ClientSession(read_stream, write_stream) as session:
await session.initialize()
tool_result = await session.list_tools()
print(tool_result)
asyncio.run(main())
You can also test your server using the MCP Inspector as described in the section called â€œLocal
testing with MCP inspectorâ€.

Step 3: Deploy your MCP server to AWS.........................................................................................
Install deployment tools

Install the AgentCore starter toolkit:

pip install bedrock-agentcore-starter-toolkit
You use the starter toolkit to deploy your agent to AgentCore Runtime.

Create a project folder with the following structure:

## Project Folder Structure
your_project_directory/
### mcp_server.py # Your main agent code
### requirements.txt # Dependencies for your agent
### __init__.py # Makes the directory a Python package
Step 3: Deploy your MCP server to AWS 72

Create a new file called requirements.txt, add the following to it:

mcp
requirements.txt specifies the requirements that the agent needs for deployment to
AgentCore Runtime.

Configure your MCP server for deployment

Before configuring your deployment, you need to set up a Cognito user pool for authentication
as described in the section called â€œSet up Cognito user pool for authenticationâ€. This provides the
OAuth tokens required for secure access to your deployed server.

Service-Linked Role for Authentication
Starting October 7, 2025 , Amazon Bedrock AgentCore uses a Service-Linked Role for
workload identity permissions when using OAuth authentication. For detailed information
about this change, see Identity service-linked role.
After setting up authentication, create the deployment configuration:

agentcore configure -e my_mcp_server.py --protocol MCP
This will start a guided prompt workflow:

For execution role, you need to have an IAM execution role with appropriate permissions
For ECR, just press enter to skip and it will auto-create
For dependency file, the CLI will auto-detect from current directory
For OAuth, type yes and provide the discovery URL and client ID token
Deploy to AWS

Deploy your agent:

agentcore launch
This command will:

Step 3: Deploy your MCP server to AWS 73

1.Build a Docker container with your agent

2.Push it to Amazon ECR

3.Create a Amazon Bedrock AgentCore runtime

4.Deploy your agent to AWS

After deployment, you'll receive an agent runtime ARN that looks like:

arn:aws:bedrock-agentcore:us-west-2: accountId :runtime/my_mcp_server-xyz123
Step 4: Invoke your deployed MCP server.......................................................................................
Test with MCP client (remote)

Before testing, set the following environment variables:

Export agent ARN as an environment variable: export AGENT_ARN=" agent_arn "
Export bearer token as an environment variable: export BEARER_TOKEN=" bearer_token "
if you pass in an Accept header, it must follow the MCP standard. Acceptable media types are
application/json and text/event-stream.

Create a new file my_mcp_client_remote.py and execute it using python
my_mcp_client_remote.py

import asyncio
import os
import sys
from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client
async def main():
agent_arn = os.getenv('AGENT_ARN')
bearer_token = os.getenv('BEARER_TOKEN')
if not agent_arn or not bearer_token:
print("Error: AGENT_ARN or BEARER_TOKEN environment variable is not set")
sys.exit(1)
encoded_arn = agent_arn.replace(':', '%3A').replace('/', '%2F')
Step 4: Invoke your deployed MCP server 74

mcp_url = f"https://bedrock-agentcore.us-west-2.amazonaws.com/runtimes/
{encoded_arn}/invocations?qualifier=DEFAULT"
headers = {"authorization": f"Bearer {bearer_token}","Content-Type":"application/
json"}
print(f"Invoking: {mcp_url}, \nwith headers: {headers}\n")
async with streamablehttp_client(mcp_url, headers, timeout=120,
terminate_on_close=False) as (
read_stream,
write_stream,
_,
):
async with ClientSession(read_stream, write_stream) as session:
await session.initialize()
tool_result = await session.list_tools()
print(tool_result)
asyncio.run(main())
You can also test your deployed server using the MCP Inspector as described in the section called
â€œRemote testing with MCP inspectorâ€.

Appendix.................................................................................................................................................
Set up Cognito user pool for authentication

Create a new file setup_cognito.sh and add the following content to it.

Change TEMP_PASSWORD and PERMANENT_PASSWORD to secure passwords of your choosing.

Run the script using the command source setup_cognito.sh.

Note
For detailed OAuth authentication setup and Service-Linked Role information, see
Authenticate and authorize with Inbound Auth and Outbound Auth.
#!/bin/bash
# Create User Pool and capture Pool ID directly
export POOL_ID=$(aws cognito-idp create-user-pool \
Appendix 75

--pool-name "MyUserPool" \
--policies '{"PasswordPolicy":{"MinimumLength":8}}' \
--region us-west-2 | jq -r '.UserPool.Id')
# Create App Client and capture Client ID directly
export CLIENT_ID=$(aws cognito-idp create-user-pool-client \
--user-pool-id $POOL_ID \
--client-name "MyClient" \
--no-generate-secret \
--explicit-auth-flows "ALLOW_USER_PASSWORD_AUTH" "ALLOW_REFRESH_TOKEN_AUTH" \
--region us-west-2 | jq -r '.UserPoolClient.ClientId')
# Create User
aws cognito-idp admin-create-user \
--user-pool-id $POOL_ID \
--username "testuser" \
--temporary-password " TEMP_PASSWORD " \
--region us-west-2 \
--message-action SUPPRESS > /dev/null
# Set Permanent Password
aws cognito-idp admin-set-user-password \
--user-pool-id $POOL_ID \
--username "testuser" \
--password " PERMANENT_PASSWORD " \
--region us-west-2 \
--permanent > /dev/null
# Authenticate User and capture Access Token
export BEARER_TOKEN=$(aws cognito-idp initiate-auth \
--client-id "$CLIENT_ID" \
--auth-flow USER_PASSWORD_AUTH \
--auth-parameters USERNAME='testuser',PASSWORD=' PERMANENT_PASSWORD ' \
--region us-west-2 | jq -r '.AuthenticationResult.AccessToken')
# Output the required values
echo "Pool id: $POOL_ID"
echo "Discovery URL: https://cognito-idp.us-west-2.amazonaws.com/$POOL_ID/.well-known/
openid-configuration"
echo "Client ID: $CLIENT_ID"
echo "Bearer Token: $BEARER_TOKEN"
After running this script, note the following values for use in the deployment configuration:

Appendix 76

Discovery URL: Used during the agentcore configure step
Client ID: Used during the agentcore configure step
Bearer Token: Used when invoking your deployed server
Local testing with MCP inspector

The MCP Inspector is a visual tool for testing MCP servers. To use it, you need:

Node.js and npm installed
Install and run the MCP Inspector:

npx @modelcontextprotocol/inspector
This will:

Start the MCP Inspector server
Display a URL in your terminal (typically http://localhost:6274))
To use the Inspector:

1.Navigate to http://localhost:6274 in your browser

2.Paste the MCP server URL (http://localhost:8000/mcp) into the MCP Inspector connection
field

3.You'll see your tools listed in the sidebar

4.Click on any tool to test it

5.Fill in the parameters (e.g., for add_numbers, enter values for a and b)

6.Click "Call Tool" to see the result

Remote testing with MCP inspector

You can also test your deployed server using the MCP Inspector:

1.Open the MCP Inspector: npx @modelcontextprotocol/inspector

2.In the web interface:

Appendix 77

Select "Streamable HTTP" as the transport
Enter your agent's endpoint URL, which will look like: https://bedrock-agentcore.us-
west-2.amazonaws.com/runtimes/arn%3Aaws%3Abedrock-agentcore
%3Aus-west-2%3A accountId %3Aruntime%2F runtimeName /invocations?
qualifier=DEFAULT
Make sure to URL-encode your agent runtime ARN when constructing the endpoint URL. The
colon (:) characters become %3A and forward slashes (/) become %2F in the encoded URL.
Add your Bearer token under authentication
Click "Connect"
3.Test your tools just like you did locally

Deploy A2A servers in AgentCore Runtime
Amazon Bedrock AgentCore AgentCore Runtime lets you deploy and run Agent-to-Agent (A2A)
servers in the AgentCore Runtime. This guide walks you through creating, testing, and deploying
your first A2A server.

In this section, you learn:

How Amazon Bedrock AgentCore supports A2A
How to create an A2A server with agent capabilities
How to test your server locally
How to deploy your server to AWS
How to invoke your deployed server
How to retrieve agent cards for discovery
Topics

How Amazon Bedrock AgentCore supports A2A
Using A2A with AgentCore Runtime
Appendix
Deploy A2A servers 78

How Amazon Bedrock AgentCore supports A2A...........................................................................
Amazon Bedrock AgentCore's A2A protocol support enables seamless integration with A2A servers
by acting as a transparent proxy layer. When configured for A2A, Amazon Bedrock AgentCore
expects containers to run stateless, streamable HTTP servers on port 9000 at the root path
(0.0.0.0:9000/), which aligns with the default A2A server configuration.

The service provides enterprise-grade session isolation while maintaining protocol transparency

JSON-RPC payloads from the InvokeAgentRuntime API are passed through directly to the A2A
container without modification. This architecture preserves the standard A2A protocol features like
built-in agent discovery through Agent Cards at /.well-known/agent-card.json and JSON-
RPC communication, while adding enterprise authentication (SigV4/OAuth 2.0) and scalability.
The key differentiators from other protocols are the port (9000 vs 8080 for HTTP), mount path (/
vs /invocations), and the standardized agent discovery mechanism, making Amazon Bedrock
AgentCore an ideal deployment platform for A2A agents in production environments.

Key differences from other protocols:

Port

A2A servers run on port 9000 (vs 8080 for HTTP, 8000 for MCP)
Path

A2A servers are mounted at / (vs /invocations for HTTP, /mcp for MCP)
Agent Cards

A2A provides built-in agent discovery through Agent Cards at /.well-known/agent-
card.json
Protocol

Uses JSON-RPC for agent-to-agent communication
Authentication

Supports both SigV4 and OAuth 2.0 authentication schemes
For more information, see https://a2a-protocol.org/.

How Amazon Bedrock AgentCore supports A2A 79

Using A2A with AgentCore Runtime................................................................................................
In this tutorial you create, test, and deploy an A2A server.

Topics

Prerequisites
Step 1: Create your A2A server
Step 2: Test your A2A server locally
Step 3: Deploy your A2A server to Bedrock AgentCore Runtime
Step 4: Get the agent card
Step 5: Invoke your deployed A2A server
Prerequisites

Python 3.10 or higher installed and basic understanding of Python
An AWS account with appropriate permissions and local credentials configured
Understanding of the A2A protocol and agent-to-agent communication concepts
Step 1: Create your A2A server

We are showing an example with strands, but you can use other ways to build with A2A.

Install required packages

First, install the required packages for A2A:

pip install strands-agents[a2a]
pip install bedrock-agentcore
pip install strands-agents-tools
Create your first A2A server

Create a new file called my_a2a_server.py:

import logging
import os
from strands_tools.calculator import calculator
Using A2A with AgentCore Runtime 80

from strands import Agent
from strands.multiagent.a2a import A2AServer
import uvicorn
from fastapi import FastAPI
logging.basicConfig(level=logging.INFO)
# Use the complete runtime URL from environment variable, fallback to local
runtime_url = os.environ.get('AGENTCORE_RUNTIME_URL', 'http://127.0.0.1:9000/')
logging.info(f"Runtime URL: {runtime_url}")
strands_agent = Agent(
name="Calculator Agent",
description="A calculator agent that can perform basic arithmetic operations.",
tools=[calculator],
callback_handler=None
)
host, port = "0.0.0.0", 9000
# Pass runtime_url to http_url parameter AND use serve_at_root=True
a2a_server = A2AServer(
agent=strands_agent,
http_url=runtime_url,
serve_at_root=True # Serves locally at root (/) regardless of remote URL path
complexity
)
app = FastAPI()
@app.get("/ping")
def ping():
return {"status": "healthy"}
app.mount("/", a2a_server.to_fastapi_app())
if __name__ == "__main__":
uvicorn.run(app, host=host, port=port)
Using A2A with AgentCore Runtime 81

Understanding the code

Strands Agent

Creates an agent with specific tools and capabilities
A2AServer

Wraps the agent to provide A2A protocol compatibility
Agent Card URL

Dynamically constructs the correct URL based on deployment context using the
AGENTCORE_RUNTIME_URL environment variable
Port 9000

A2A servers run on port 9000 by default in AgentCore Runtime
Step 2: Test your A2A server locally

Run and test your A2A server in a local development environment.

Start your A2A server

Run your A2A server locally:

python my_a2a_server.py
You should see output indicating the server is running on port 9000.

Invoke agent

curl -X POST http://0.0.0.0:9000 \
-H "Content-Type: application/json" \
-d '{
"jsonrpc": "2.0",
"id": "req-001",
"method": "message/send",
"params": {
"message": {
"role": "user",
"parts": [
Using A2A with AgentCore Runtime 82

{
"kind": "text",
"text": "what is 101 * 11?"
}
],
"messageId": "12345678-1234-1234-1234-123456789012"
}
}
}' | jq.
Test agent card retrieval

You can test the agent card endpoint locally:

curl http://localhost:9000/.well-known/agent-card.json | jq.
You can also test your deployed server using the A2A Inspector as described in Remote testing with
A2A inspector.

Step 3: Deploy your A2A server to Bedrock AgentCore Runtime

Deploy your A2A server to AWS using the Amazon Bedrock AgentCore starter toolkit.

Install deployment tools

Install the Amazon Bedrock AgentCore starter toolkit:

pip install bedrock-agentcore-starter-toolkit
Start by creating a project folder with the following structure:

## Project Folder Structure
your_project_directory/
### a2a_server.py # Your main agent code
### requirements.txt # Dependencies for your agent
Create a new file called requirements.txt, add the following to it:

strands-agents[a2a]
bedrock-agentcore
Using A2A with AgentCore Runtime 83

strands-agents-tools
Set up Cognito user pool for authentication

Configure authentication for secure access to your deployed server. For detailed Cognito setup
instructions, see Set up Cognito user pool for authentication. This provides the OAuth tokens
required for secure access to your deployed server.

Configure your A2A server for deployment

After setting up authentication, create the deployment configuration:

agentcore configure -e my_a2a_server.py --protocol A2A
Select protocol as A2A
Configure with OAuth configuration as setup in the previous step
Deploy to AWS

Deploy your agent:

agentcore launch
After deployment, you'll receive an agent runtime ARN that looks like:

arn:aws:bedrock-agentcore:us-west-2:accountId:runtime/my_a2a_server-xyz123
Step 4: Get the agent card

Agent Cards are JSON metadata documents that describe an A2A server's identity, capabilities,
skills, service endpoint, and authentication requirements. They enable automatic agent discovery in
the A2A ecosystem.

Set up environment variables

Set up environment variables

Export bearer token as an environment variable. For bearer token setup, see Bearer token
setup.
Using A2A with AgentCore Runtime 84

export BEARER_TOKEN="<BEARER_TOKEN>"
Export the agent ARN.
export AGENT_ARN="arn:aws:bedrock-agentcore:us-west-2:accountId:runtime/
my_a2a_server-xyz123"
Retrieve agent card

import os
import json
import requests
from uuid import uuid4
from urllib.parse import quote
def fetch_agent_card():
# Get environment variables
agent_arn = os.environ.get('AGENT_ARN')
bearer_token = os.environ.get('BEARER_TOKEN')
if not agent_arn:
print("Error: AGENT_ARN environment variable not set")
return
if not bearer_token:
print("Error: BEARER_TOKEN environment variable not set")
return
# URL encode the agent ARN
escaped_agent_arn = quote(agent_arn, safe='')
# Construct the URL
url = f"https://bedrock-agentcore.us-west-2.amazonaws.com/runtimes/
{escaped_agent_arn}/invocations/.well-known/agent-card.json"
# Generate a unique session ID
session_id = str(uuid4())
print(f"Generated session ID: {session_id}")
# Set headers
headers = {
Using A2A with AgentCore Runtime 85

'Accept': '*/*',
'Authorization': f'Bearer {bearer_token}',
'X-Amzn-Bedrock-AgentCore-Runtime-Session-Id': session_id
}
try:
# Make the request
response = requests.get(url, headers=headers)
response.raise_for_status()
# Parse and pretty print JSON
agent_card = response.json()
print(json.dumps(agent_card, indent=2))
return agent_card
except requests.exceptions.RequestException as e:
print(f"Error fetching agent card: {e}")
return None
if __name__ == "__main__":
fetch_agent_card()
After you get the URL from the Agent Card, export AGENTCORE_RUNTIME_URL as an environment
variable:

export AGENTCORE_RUNTIME_URL="https://bedrock-agentcore.us-west-2.amazonaws.com/
runtimes/<ARN>/invocations/"
Step 5: Invoke your deployed A2A server

Create client code to invoke your deployed Amazon Bedrock AgentCore A2A server and send
messages to test the functionality.

Create a new file my_a2a_client_remote.py to invoke your deployed A2A server:

import asyncio
import logging
import os
from uuid import uuid4
import httpx
Using A2A with AgentCore Runtime 86

from a2a.client import A2ACardResolver, ClientConfig, ClientFactory
from a2a.types import Message, Part, Role, TextPart
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
DEFAULT_TIMEOUT = 300 # set request timeout to 5 minutes
def create_message(*, role: Role = Role.user, text: str) -> Message:
return Message(
kind="message",
role=role,
parts=[Part(TextPart(kind="text", text=text))],
message_id=uuid4().hex,
)
async def send_sync_message(message: str):
# Get runtime URL from environment variable
runtime_url = os.environ.get('AGENTCORE_RUNTIME_URL')
# Generate a unique session ID
session_id = str(uuid4())
print(f"Generated session ID: {session_id}")
# Add authentication headers for Amazon Bedrock AgentCore
headers = {"Authorization": f"Bearer {os.environ.get('BEARER_TOKEN')}",
'X-Amzn-Bedrock-AgentCore-Runtime-Session-Id': session_id}
async with httpx.AsyncClient(timeout=DEFAULT_TIMEOUT, headers=headers) as
httpx_client:
# Get agent card from the runtime URL
resolver = A2ACardResolver(httpx_client=httpx_client, base_url=runtime_url)
agent_card = await resolver.get_agent_card()
# Agent card contains the correct URL (same as runtime_url in this case)
# No manual override needed - this is the path-based mounting pattern
# Create client using factory
config = ClientConfig(
httpx_client=httpx_client,
streaming=False, # Use non-streaming mode for sync response
)
factory = ClientFactory(config)
client = factory.create(agent_card)
Using A2A with AgentCore Runtime 87

# Create and send message
msg = create_message(text=message)
# With streaming=False, this will yield exactly one result
async for event in client.send_message(msg):
if isinstance(event, Message):
logger.info(event.model_dump_json(exclude_none=True, indent=2))
return event
elif isinstance(event, tuple) and len(event) == 2:
# (Task, UpdateEvent) tuple
task, update_event = event
logger.info(f"Task: {task.model_dump_json(exclude_none=True,
indent=2)}")
if update_event:
logger.info(f"Update:
{update_event.model_dump_json(exclude_none=True, indent=2)}")
return task
else:
# Fallback for other response types
logger.info(f"Response: {str(event)}")
return event
# Usage - Uses AGENTCORE_RUNTIME_URL environment variable
asyncio.run(send_sync_message("what is 101 * 11"))
Appendix.................................................................................................................................................
Topics

Set up Cognito user pool for authentication
Remote testing with A2A inspector
Troubleshooting
Set up Cognito user pool for authentication

For detailed Cognito setup instructions, see Set up Cognito user pool for authentication in the MCP
documentation.

Appendix 88

Remote testing with A2A inspector

See https://github.com/a2aproject/a2a-inspector.

Troubleshooting

Common A2A-specific issues

The following are common issues you might encounter:

Port conflicts

A2A servers must run on port 9000 in the AgentCore Runtime environment
JSON-RPC errors

Check that your client is sending properly formatted JSON-RPC 2.0 messages
Authorization method mismatch

Make sure your request uses the same authentication method (OAuth or SigV4) that the agent
was configured with
Exception handling

A2A specifications for Error handling: https://a2a-protocol.org/latest/specification/#81-standard-
json-rpc-errors

A2A servers return errors as standard JSON-RPC error responses with HTTP 200 status codes.
Internal Runtime errors are automatically translated to JSON-RPC internal errors to maintain
protocol compliance.

The service now provides proper A2A-compliant error responses with standardized JSON-RPC error
codes:

JSON-RPC Error Codes

JSON-RPC
Error Code
Runtime Exception HTTP
Error Code
JSON-RPC Error Message
N/A AccessDeniedExcept
ion
403 N/A
Appendix 89

JSON-RPC
Error Code
Runtime Exception HTTP
Error Code
JSON-RPC Error Message
-32501 ResourceNotFoundEx
ception
404 Resource not found â€“ Requested
resource does not exist
-32502 ValidationExceptio
n
400 Validation error â€“ Invalid request data
-32503 ThrottlingExceptio
n
429 Rate limit exceeded â€“ Too many
requests
-32503 ServiceQuotaExceed
edException
429 Rate limit exceeded â€“ Too many
requests
-32504 ResourceConflictEx
ception
409 Resource conflict â€“ Resource already
exists
-32505 RuntimeClientError 424 Runtime client error â€“ Check your
CloudWatch logs for more information.
Use isolated sessions for agents.............................................................................................................
Amazon Bedrock AgentCore Runtime lets you isolate each user session and safely reuse context
across multiple invocations in a user session. Session isolation is critical for AI agent workloads due
to their unique operational characteristics:

Complete execution environment separation : Each user session in AgentCore Runtime receives
its own dedicated microVM with isolated Compute, memory, and filesystem resources. This
prevents one user's agent from accessing another user's data. After session completion, the
entire microVM is terminated and memory is sanitized to remove all session data, eliminating
cross-session contamination risks.
Stateful reasoning processes : Unlike stateless functions, AI agents maintain complex
contextual state throughout their execution cycle, beyond simple message history for multi-turn
conversations. AgentCore Runtime preserves this state securely within a session while ensuring
complete isolation between different users, enabling personalized agent experiences without
compromising data boundaries.
Use isolated sessions for agents 90

Privileged tool operations : AI agents perform privileged operations on users' behalf through
integrated tools accessing various resources. AgentCore Runtime's isolation model ensures these
tool operations maintain proper security contexts and prevents credential sharing or permission
escalation between different user sessions.
Deterministic security for non-deterministic processes : AI agent behavior can be non-
deterministic due to the probabilistic nature of foundation models. AgentCore Runtime provides
consistent, deterministic isolation boundaries regardless of agent execution patterns, delivering
the predictable security properties required for enterprise deployments.
Understanding ephemeral context....................................................................................................
While AgentCore provides strong session isolation, these sessions are ephemeral in nature. Any
data stored in memory or written to disk persists only for the session duration. This includes
conversation history, user preferences, intermediate calculation results, and any other state
information your agent maintains.

For data that needs to be retained beyond the session lifetime (such as user conversation history,
learned preferences, or important insights), you should use AgentCore Memory. This service
provides purpose-built persistent storage designed specifically for agent workloads, with both
short-term and long-term memory capabilities.

Extended conversations and multi-step workflows.......................................................................
Unlike traditional serverless functions that terminate after each request, AgentCore supports
ephemeral, isolated compute sessions lasting up to 8 hours. This simplifies building multi-step
agentic workflows as you can make multiple calls to the same environment, with each invocation
building upon the context established by previous interactions.

AgentCore Runtime session lifecycle................................................................................................
Session creation

A new session is created on the first invoke with a unique runtimeSessionId provided by your
application. AgentCore Runtime provisions a dedicated execution environment (microVM) for each
session. Context is preserved between invocations to the same session.

Session states

Understanding ephemeral context 91

Sessions can be in one of the following states:

Active : Either processing a sync request or doing background tasks. Sync invocation activity
is automatically tracked based on invocations to a runtime session. Background tasks are
communicated by the agent code by responding with "HealthyBusy" status in pings.
Idle : When not processing any requests or background tasks. The session has completed
processing but remains available for future invocations.
Terminated : Execution environment provisioned for the session is terminated. This can be due
to inactivity (of 15 minutes), reaching max duration (8 hours) or if it's deemed unhealthy based
on health checks. Subsequent invokes to a terminated runtimeSessionId will provision a new
execution environment.
How to use sessions.............................................................................................................................
To use sessions effectively:

Generate a unique session ID for each user or conversation with at least 33 characters
Pass the same session ID for all related invocations
Use different session IDs for different users or conversations
Example Using sessions for a conversation

# First message in a conversation
response1 = agent_core_client.InvokeAgentRuntime(
agentRuntimeArn=agent_arn,
runtimeSessionId="user-123456-conversation-12345678", # or uuid.uuid4()
payload=json.dumps({"prompt": "Tell me about AWS"}).encode()
)
# Follow-up message in the same conversation reuses the runtimeSessionId.
response2 = agent_core_client.InvokeAgentRuntime(
agentRuntimeArn=agent_arn,
runtimeSessionId="user-123456-conversation-12345678", # or uuid.uuid4()
payload=json.dumps({"prompt": "How does it compare to other cloud
providers"}).encode()
How to use sessions 92

)
By using the same runtimeSessionId for related invocations, you ensure that context is maintained
across the conversation, allowing your agent to provide coherent responses that build on previous
interactions.

Configure Amazon Bedrock AgentCore lifecycle settings
The LifecycleConfiguration input parameter to CreateAgentRuntime lets you manage
the lifecycle of runtime sessions and resources in Amazon Bedrock AgentCore Runtime. This
configuration helps optimize resource utilization by automatically cleaning up idle sessions and
preventing long-running instances from consuming resources indefinitely.

You can also configure lifecycle settings for an existing AgentCore Runtime with the
UpdateAgentRuntime operation.

Topics

Configuration attributes
Default behavior
Create an AgentCore Runtime with lifecycle configuration
Update the lifecycle configuration for an AgentCore Runtime
Get the lifecycle configuration for an AgentCore Runtime
Validation and constraints
Best practices
Configuration attributes

Lifecycle configuration attributes

Attribute Type Range
(seconds)
Required Description
idleRunti
meSession
Timeout
Integer 60-28800 No Timeout in seconds for idle runtime
sessions. When a session remains
idle for this duration, it will trigger
termination. Termination can last up
Configure lifecycle settings 93

Attribute Type Range
(seconds)
Required Description
to 15 seconds due to logging and
other process completion. Default:
900 seconds (15 minutes)
maxLifetime Integer 60-28800 No Maximum lifetime for the instance
in seconds. Once reached, instances
will initialize termination. Terminati
on can last up to 15 seconds due to
logging and other process completio
n. Default: 28800 seconds (8 hours)
Constraints

idleRuntimeSessionTimeout must be less than or equal to maxLifetime
Both values are measured in seconds
Valid range: 60 to 28800 seconds (up to 8 hours)
Default behavior

When LifecycleConfiguration is not provided or contains null values, the platform applies
the following logic:

Default behavior logic

Customer Input idleRunti
meSession
Timeout
maxLifetime Result
No configuration 900 sec 28800s Uses defaults: 900s and 28800s
Only maxLifetime
provided
900 sec Customer value If maxLifetime â‰¤ 900s: uses
maxLifetime for both
If maxLifetime > 900s: uses 900s
for idle, customer value for max
Configure lifecycle settings 94

Customer Input idleRunti
meSession
Timeout
maxLifetime Result
Only idleTimeout
provided
Customer value 28800s Uses customer value for idle,
28800s for max
Both values provided Customer value Customer value Uses customer values as-is
Default values

idleRuntimeSessionTimeout: 900 seconds (15 minutes)
maxLifetime: 28800 seconds (8 hours)
Create an AgentCore Runtime with lifecycle configuration

You can specify a lifecycle configuration when you create an AgentCore Runtime.

import boto3
client = boto3.client('bedrock-agentcore-control', region_name=' us-west-2 ')
try:
response = client.create_agent_runtime(
agentRuntimeName='my_agent_runtime',
agentRuntimeArtifact={
'containerConfiguration': {
'containerUri': ' 123456789012.dkr.ecr.us-west-2.amazonaws.com/my-
agent:latest '
}
},
lifecycleConfiguration={
'idleRuntimeSessionTimeout': 1800, # 30 minutes
'maxLifetime': 14400 # 4 hours
},
networkConfiguration={'networkMode': 'PUBLIC'},
roleArn=' arn:aws:iam::123456789012:role/AgentRuntimeRole '
)
print(f"Agent runtime created: {response['agentRuntimeArn']}")
Configure lifecycle settings 95

except client.exceptions.ValidationException as e:
print(f"Validation error: {e}")
except Exception as e:
print(f"Error creating agent runtime: {e}")
Update the lifecycle configuration for an AgentCore Runtime

You can update lifecycle configuration for an existing AgentCore Runtime.

import boto3
client = boto3.client('bedrock-agentcore-control', region_name=' us-west-2 ')
agent_runtime_id = 'my_agent_runtime'
try:
response = client.update_agent_runtime(
agentRuntimeId=agent_runtime_id,
agentRuntimeArtifact={
'containerConfiguration': {
'containerUri': ' 123456789012.dkr.ecr.us-west-2.amazonaws.com/my-
agent:latest '
}
},
networkConfiguration={'networkMode': 'PUBLIC'},
roleArn=' arn:aws:iam::123456789012:role/AgentRuntimeRole ',
lifecycleConfiguration={
'idleRuntimeSessionTimeout': 600, # 10 minutes
'maxLifetime': 7200 # 2 hours
}
)
print("Lifecycle configuration updated successfully")
except client.exceptions.ValidationException as e:
print(f"Validation error: {e}")
except client.exceptions.ResourceNotFoundException:
print("Agent runtime not found")
except Exception as e:
print(f"Error updating configuration: {e}")
Get the lifecycle configuration for an AgentCore Runtime

You can get lifecycle configuration for an existing AgentCore Runtime.

Configure lifecycle settings 96

import boto3
client = boto3.client('bedrock-agentcore-control', region_name='us-west-2')
def get_lifecycle_config():
try:
response = client.get_agent_runtime(agentRuntimeId=" my_agent_runtime ")
lifecycle_config = response.get('lifecycleConfiguration', {})
idle_timeout = lifecycle_config.get('idleRuntimeSessionTimeout', 900)
max_lifetime = lifecycle_config.get('maxLifetime', 28800)
print(f"Current configuration:")
print(f" Idle timeout: {idle_timeout}s ({idle_timeout//60} minutes)")
print(f" Max lifetime: {max_lifetime}s ({max_lifetime//3600} hours)")
return lifecycle_config
except Exception as e:
print(f"Error retrieving configuration: {e}")
return None
# Usage
config = get_lifecycle_config()
print(config)
Validation and constraints

The lifecycle configuration includes validation rules and constraints to prevent invalid
configurations.

Common validation errors

import boto3
client = boto3.client('bedrock-agentcore-control', region_name=' us-west-2 ')
try:
client.create_agent_runtime(
agentRuntimeName='invalid_config_agent',
agentRuntimeArtifact={
'containerConfiguration': {
Configure lifecycle settings 97

'containerUri': ' 123456789012.dkr.ecr.us-west-2.amazonaws.com/my-
agent:latest '
}
},
lifecycleConfiguration={
'idleRuntimeSessionTimeout': 3600, # 1 hour
'maxLifetime': 1800 # 30 minutes - INVALID!
},
networkConfiguration={'networkMode': 'PUBLIC'},
roleArn=' arn:aws:iam::123456789012:role/AgentRuntimeRole '
)
except client.exceptions.ValidationException as e:
print(f"Validation failed: {e}")
# Output: idleRuntimeSessionTimeout must be less than or equal to maxLifetime
Validation helper function

def validate_lifecycle_config(idle_timeout, max_lifetime):
"""Validate lifecycle configuration before API call"""
errors = []
# Check range constraints
if not (1 <= idle_timeout <= 28800):
errors.append(f"idleRuntimeSessionTimeout must be between 1 and 28800 seconds")
if not (1 <= max_lifetime <= 28800):
errors.append(f"maxLifetime must be between 1 and 28800 seconds")
# Check relationship constraint
if idle_timeout > max_lifetime:
errors.append(f"idleRuntimeSessionTimeout ({idle_timeout}s) must be â‰¤
maxLifetime ({max_lifetime}s)")
return errors
# Usage
errors = validate_lifecycle_config(3600, 1800)
if errors:
for error in errors:
print(f"Validation error: {error}")
else:
print("Configuration is valid")
Configure lifecycle settings 98

Best practices.........................................................................................................................................
Best practices..............................................................................................................................................
Best practices.........................................................................................................................................
Follow these best practices when configuring lifecycle settings for optimal resource utilization and
user experience.

Recommendations

Start with defaults (900s idle, 28800s max) and adjust based on usage patterns
Monitor session duration to optimize timeout values
Use shorter timeouts for development environments to save costs
Consider user experience - too short timeouts may interrupt active users
Test configuration changes in non-production environments first
Document timeout rationale for your specific use case
Common patterns

Common configuration patterns

Use Case Idle Timeout Max Lifetime Rationale
Interactive Chat 10-15 minutes 2-4 hours Balance responsiveness with
resource usage
Batch Processing 30 minutes 8 hours Allow for long-running operations
Development 5 minutes 30 minutes Quick cleanup for cost optimizat
ion
Production API 15 minutes 4 hours Standard production workload
Demo/Testing 2 minutes 15 minutes Aggressive cleanup for temporary
usage
Stop a running session........................................................................................................................
The StopRuntimeSession operation lets you immediately terminate active agent AgentCore
Runtime sessions for proper resource cleanup and session lifecycle management.

Stop a running session 99

When called, this operation instantly terminates the specified session and stops any ongoing
streaming responses. This lets system resources be properly released and prevents accumulation of
orphaned sessions.

Use StopRuntimeSession in these scenarios:

User-initiated end : When users explicitly conclude their conversation
Application shutdown : Proactive cleanup before application termination
Error handling : Force termination of unresponsive or stalled sessions
Quota management : Stay within session limits by closing unused sessions
Timeout handling : Clean up sessions that exceed expected duration
Prerequisites

To use StopRuntimeSession, you need:

bedrock-agentcore:StopRuntimeSession IAM permission
Valid agent AgentCore Runtime ARN
The ID of an active session to terminate
AWS SDK
You can use the AWS SDK to stop AgentCore Runtime sessions programmatically.
Python example using boto3 to stop a AgentCore Runtime session.
import boto3
# Initialize the AgentCore client
client = boto3.client('bedrock-agentcore', region_name='us-west-2')
try:
# Stop the runtime session
response = client.stop_runtime_session(
agentRuntimeArn='arn:aws:bedrock-agentcore:us-west-2:123456789012:runtime/
my-agent',
runtimeSessionId='your-session-id',
qualifier='DEFAULT' # Optional: endpoint name
Stop a running session 100

)
print(f"Session terminated successfully")
print(f"Request ID: {response['ResponseMetadata']['RequestId']}")
except client.exceptions.ResourceNotFoundException:
print("Session not found or already terminated")
except client.exceptions.AccessDeniedException:
print("Insufficient permissions to stop session")
except Exception as e:
print(f"Error stopping session: {str(e)}")
HTTPS request

For applications using OAuth authentication, make direct HTTPS requests:
import requests
import urllib.parse
def stop_session_with_oauth(agent_arn, session_id, bearer_token,
qualifier="DEFAULT"):
# URL encode the agent ARN
encoded_arn = agent_arn.replace(':', '%3A').replace('/', '%2F')
# Construct the endpoint URL
url = f"https://bedrock-agentcore.us-west-2.amazonaws.com/runtimes/
{encoded_arn}/stopruntimesession?qualifier={qualifier}"
headers = {
"Authorization": f"Bearer {bearer_token}",
"Content-Type": "application/json",
"X-Amzn-Bedrock-AgentCore-Runtime-Session-Id": session_id
}
try:
response = requests.post(url, headers=headers)
response.raise_for_status()
print(f"Session {session_id} terminated successfully")
return response.json()
except requests.exceptions.HTTPError as e:
Stop a running session 101

if e.response.status_code == 404:
print("Session not found or already terminated")
elif e.response.status_code == 403:
print("Insufficient permissions or invalid token")
else:
print(f"HTTP error: {e.response.status_code}")
raise
except requests.exceptions.RequestException as e:
print(f"Request failed: {str(e)}")
raise
# Usage
stop_session_with_oauth(
agent_arn="arn:aws:bedrock-agentcore:us-west-2:123456789012:runtime/my-agent",
session_id="your-session-id",
bearer_token="your-oauth-token"
)
Response format

Expected response format for successful StopRuntimeSession operations.

{
"ResponseMetadata": {
"RequestId": "12345678-1234-1234-1234-123456789012",
"HTTPStatusCode": 200
}
}
Error handling

Common error responses:

Error responses

Status Code Error Description
404 ResourceNotFoundException Session not found or already terminated
Stop a running session 102

Status Code Error Description
403 AccessDeniedException Insufficient permissions
400 ValidationException Invalid parameters
500 InternalServerException Service error
Best practices

Session lifecycle management

class SessionManager:
def __init__(self, client, agent_arn):
self.client = client
self.agent_arn = agent_arn
self.active_sessions = set()
def invoke_agent(self, session_id, payload):
"""Invoke agent and track session"""
try:
response = self.client.invoke_agent_runtime(
agentRuntimeArn=self.agent_arn,
runtimeSessionId=session_id,
payload=payload
)
self.active_sessions.add(session_id)
return response
except Exception as e:
print(f"Failed to invoke agent: {e}")
raise
def stop_session(self, session_id):
"""Stop session and remove from tracking"""
try:
self.client.stop_runtime_session(
agentRuntimeArn=self.agent_arn,
runtimeSessionId=session_id,
qualifier= endpoint_name
)
self.active_sessions.discard(session_id)
Stop a running session 103

print(f"Session {session_id} stopped")
except Exception as e:
print(f"Failed to stop session {session_id}: {e}")
def cleanup_all_sessions(self):
"""Stop all tracked sessions"""
for session_id in list(self.active_sessions):
self.stop_session(session_id)
Recommendations

Always handle exceptions when stopping sessions
Track active sessions in your application for cleanup
Set timeouts for stop requests to avoid hanging
Log session terminations for debugging and monitoring
Use session managers for complex applications with multiple sessions
Handle asynchronous and long running agents with Amazon
Bedrock AgentCore Runtime
Amazon Bedrock AgentCore Runtime can handle asynchronous processing and long running
agents. Asynchronous tasks allow your agent to continue processing after responding to the client
and handle long-running operations without blocking responses. With async processing, your agent
can:

Start a task that might take minutes or hours
Immediately respond to the user saying "I've started working on this"
Continue processing in the background
Allow the user to check back later for results
Handle asynchronous and long running agents 104

Key concepts........................................................................................................................................
Asynchronous processing model

The Amazon Bedrock AgentCore SDK supports both synchronous and asynchronous processing
through a unified API. This creates a flexible implementation pattern for both clients and
agent developers. Agent clients can work with the same API without differentiating between
synchronous and asynchronous on the client side. With the ability to invoke the same session
across invocations, agent developers can reuse context and build upon this context incrementally
without implementing complex task management logic.

Runtime session lifecycle management

Agent code communicates its processing status using the "/ping" health status. "HealthyBusy"
indicates the agent is busy processing background tasks, while "Healthy" indicates it is idle (waiting
for requests). A session in idle state for 15 minutes gets automatically terminated.

Implementing asynchronous tasks.................................................................................................
To get started, install the bedrock-agentcore package:

pip install bedrock-agentcore
API based task management

To build interactive agents that perform asynchronous tasks, you need to call add_async_task
when starting a task and complete_async_task when the task completes. The SDK handles task
tracking and manages Ping status automatically.

# Start tracking a task manually
task_id = app.add_async_task("data_processing")
# Do work...
# Mark task as complete
app.complete_async_task(task_id)
Key concepts 105

Asynchronous task decorator

The Amazon Bedrock AgentCore SDK helps with tracking asynchronous tasks. You can get started
by simply annotating your asynchronous functions with @app.async_task.

# Automatically track asynchronous functions:
@app.async_task
async def background_work():
await asyncio.sleep(10) # Status becomes "HealthyBusy"
return "done"
@app.entrypoint
async def handler(event):
asyncio.create_task(background_work())
return {"status": "started"}
Here is how it works:

The @app.async_task decorator tracks function execution
When the function runs, ping status changes to "HealthyBusy"
When the function completes, status returns to "Healthy"
Custom ping handler

You can implement your own custom ping handler to manage the Runtime Session's state. Your
agent's health is reported through the /ping endpoint:

@app.ping
def custom_status():
if system_busy():
return PingStatus.HEALTHY_BUSY
return PingStatus.HEALTHY
Status values:

"Healthy": Ready for new work
"HealthyBusy": Processing background task
Implementing asynchronous tasks 106

Complete example.............................................................................................................................
First, install the required package:

pip install strands-agents
Then, create a Python file with the following code:

import threading
import time
from strands import Agent, tool
from bedrock_agentcore.runtime import BedrockAgentCoreApp
# Initialize app with debug mode for task management
app = BedrockAgentCoreApp()
@tool
def start_background_task(duration: int = 5) -> str:
"""Start a simple background task that runs for specified duration."""
# Start tracking the async task
task_id = app.add_async_task("background_processing", {"duration": duration})
# Run task in background thread
def background_work():
time.sleep(duration) # Simulate work
app.complete_async_task(task_id) # Mark as complete
threading.Thread(target=background_work, daemon=True).start()
return f"Started background task (ID: {task_id}) for {duration} seconds. Agent
status is now BUSY."
# Create agent with the tool
agent = Agent(tools=[start_background_task])
@app.entrypoint
def main(payload):
"""Main entrypoint - handles user messages."""
user_message = payload.get("prompt", "Try: start_background_task(3)")
return {"message": agent(user_message).message}
if __name__ == "__main__":
print("# Simple Async Strands Example")
Complete example 107

print("Test: curl -X POST http://localhost:8080/invocations -H 'Content-Type:
application/json' -d '{\"prompt\": \"start a 3 second task\"}'")
app.run()
This example demonstrates:

Creating a background task that runs asynchronously
Tracking the task's status with add_async_task and complete_async_task
Responding immediately to the user while processing continues
Managing the agent's health status automatically
Stream agent responses.........................................................................................................................
The following Strands Agents example shows how an AgentCore Runtime agent can stream a
response back to a client.

from strands import Agent
from bedrock_agentcore import BedrockAgentCoreApp
app = BedrockAgentCoreApp()
agent = Agent()
@app.entrypoint
async def agent_invocation(payload):
"""Handler for agent invocation"""
user_message = payload.get(
"prompt", "No prompt found in input, please guide customer to create a json
payload with prompt key"
)
stream = agent.stream_async(user_message)
async for event in stream:
print(event)
yield (event)
if __name__ == "__main__":
app.run()
Stream agent responses 108

Pass custom headers to Amazon Bedrock AgentCore Runtime
Custom headers let you pass contextual information from your application directly to your
agent code without cluttering the main request payload. This includes authentication tokens
like JWT (JSON Web Tokens, which contain user identity and authorization claims) through the
Authorization header, allowing your agent to make decisions based on who is calling it. You can
also pass custom metadata like user preferences, session identifiers, or trace context using headers
prefixed with X-Amzn-Bedrock-AgentCore-Runtime-Custom-, giving your agent access to
up to 20 pieces of runtime context that travel alongside each request. This information can be
also used in downstream systems like AgentCore Memory that you can namespace based on those
characteristics like user_id or aud in claims like line of business.

Amazon Bedrock AgentCore Runtime lets you pass headers in a request request to your agent code
provided the headers match the following criteria:

Header name is one of the following:
Starts with X-Amzn-Bedrock-AgentCore-Runtime-Custom-
Equal to Authorization. This is reserved for agents with OAuth inbound access to pass in
the incoming JWT token to the agent code.
Header value is not greater than 4KB in size.
Up to 20 headers can be configured per runtime.
Topics

Step 1: Create your agent
Step 2: Deploy your agent
Step 3: Invoke your agent with custom headers
Step 4: (Optional) Pass the JWT token used for OAuth based inbound access to your agent
Step 1: Create your agent................................................................................................................
Start by creating a basic agent with the following project structure:

your_project_directory/
### agent_example.py # Your main agent code
Pass custom headers 109

### requirements.txt # Dependencies for your agent
Create the following files:

agent_example.py

Create your main agent code file and add the following code:

import json
from bedrock_agentcore import BedrockAgentCoreApp, RequestContext
from strands import Agent
app = BedrockAgentCoreApp()
agent = Agent()
@app.entrypoint
def agent_invocation(payload, context: RequestContext):
"""Handler for agent invocation"""
user_message = payload.get(
"prompt", "No prompt found in input, please guide customer to create a json
payload with prompt key"
)
app.logger.info("invoking agent with user message: %s", payload)
response = agent(user_message)
# access request headers here
request_headers = context.request_headers
app.logger.info("Headers: %s", json.dumps(request_headers))
return response
app.run()
requirements.txt

Create your dependencies file and add the following dependencies:

strands-agents
bedrock-agentcore
Step 1: Create your agent 110

Step 2: Deploy your agent...............................................................................................................
Configure your agent with the starter toolkit:

agentcore configure --entrypoint agent_example.py \
--name hello_agent \
--execution-role your-execution-role-arn \
--disable-otel \
--requirements-file requirements.txt \
--request-header-allowlist "X-Amzn-Bedrock-AgentCore-Runtime-Custom-H1"
Deploy your agent with the starter toolkit:

agentcore launch
Note the agent runtime ARN from the output. you need it in the next step.

Step 3: Invoke your agent with custom headers.........................................................................
Starter toolkit

Use the Amazon Bedrock AgentCore starter toolkit command line interface to invoke your agent
with custom headers.
agentcore invoke '{"prompt": "Hello what is 1+1?"}' --headers "X-Amzn-Bedrock-
AgentCore-Runtime-Custom-H1:test header"
Python

Use boto3 with event handlers to add custom headers to your agent invocation.
For more details on botocore events, see botocore events documentation.
import json
import boto3
Step 2: Deploy your agent 111

agent_arn = YOUR_AGENT_ARN_HERE
prompt = "Tell me a joke"
agent_core_client = boto3.client('bedrock-agentcore')
event_system = agent_core_client.meta.events
# Constants for event handler configuration
EVENT_NAME = 'before-sign.bedrock-agentcore.InvokeAgentRuntime'
CUSTOM_HEADER_NAME = 'X-Amzn-Bedrock-AgentCore-Runtime-Custom-H1'
CUSTOM_HEADER_VALUE = 'test header1'
def add_custom_runtime_header(request, **kwargs):
"""Add custom header for agent runtime authentication/identification."""
request.headers.add_header(CUSTOM_HEADER_NAME, CUSTOM_HEADER_VALUE)
handler = event_system.register_first(EVENT_NAME, add_custom_runtime_header)
payload = json.dumps({"prompt": prompt}).encode()
response = agent_core_client.invoke_agent_runtime(
agentRuntimeArn=agent_arn,
payload=payload
)
event_system.unregister(EVENT_NAME, handler)
content = []
for chunk in response.get("response", []):
content.append(chunk.decode('utf-8'))
print(json.loads(''.join(content)))
Step 4: (Optional) Pass the JWT token used for OAuth based inbound
access to your agent
For information about setting up an agent with OAuth inbound access and enabling an
Authorization header to be passed into AgentCore Runtime, see Authenticate and authorize with
Inbound Auth and Outbound Auth.

Step 4: (Optional) Pass the JWT token used for OAuth based inbound access to your agent 112

Authenticate and authorize with Inbound Auth and Outbound Auth..........................................
This section shows you how to implement authentication and authorization for your agent runtime
using OAuth and JWT bearer tokens with AgentCore Identity. You'll learn how to set up Cognito
user pools, configure your agent runtime for JWT authentication (Inbound Auth), and implement
OAuth-based access to third-party resources (outbound Auth).

For a complete example, see https://github.com/awslabs/amazon-bedrock-agentcore-samples/.

For information about using OAuth to with an MCP server, see Deploy MCP servers in AgentCore
Runtime.

Amazon Bedrock AgentCore runtime provides two authentication mechanisms for hosted agents:

IAM SigV4 Authentication

The default authentication and authorization mechanism that works automatically without
additional configuration, similar to other AWS APIs.
X-Amzn-Bedrock-AgentCore-Runtime-User-Id Header
If your solution requires the hosted agent to retrieve OAuth tokens on behalf of end users
(using Authorization Code Grant), you can specify the user identifier by including the X-Amzn-
Bedrock-AgentCore-Runtime-User-Id header in your requests.
Note
Invoking InvokeAgentRuntime with the X-Amzn-Bedrock-AgentCore-
Runtime-User-Id header will require a new IAM action: bedrock-
agentcore:InvokeAgentRuntimeForUser, in addition to the existing bedrock-
agentcore:InvokeAgentRuntime action.
Security Best Practices for X-Amzn-Bedrock-AgentCore-Runtime-User-Id Header
While IAM authentication secures the API access, the X-Amzn-Bedrock-AgentCore-
Runtime-User-Id header requires additional security considerations. Only trusted principals
Authenticate and authorize with Inbound Auth and Outbound Auth 113

with the bedrock-agentcore:InvokeAgentRuntimeForUser permission should be
allowed to set this header. The user-id value should ideally be derived from the authenticated
principalâ€™s context (for example, IAM context or user token) rather than accepting arbitrary
values. This prevents scenarios where an authenticated user could potentially impersonate
another user by manually specifying a different user-id.
Implement audit logging to track the relationship between the authenticated principal and the
user-id being passed.
Remember that Amazon Bedrock AgentCore treats this header value as an opaque identifier
and relies on your application's logic to maintain the security boundary between authenticated
users and their corresponding user-id values.
JWT Bearer Token Authentication

You can configure your agent runtime to accept JWT bearer tokens by providing authorizer
configuration during agent creation.
This configuration requires:
Discovery URL - A string that must match the pattern ^.+/.well-known/openid-
configuration$ for OpenID Connect discovery URLs
Allowed audiences - A list of permitted audiences that will be validated against the aud claim
in the JWT token
Allowed clients - A list of permitted client identifiers that will be validated against the
client_id claim in the JWT token
Note
A runtime can only support either IAM SigV4 or JWT Bearer Token based inbound auth.
You can always create custom endpoints for your runtime and configure them for different
inbound authorization types.
When you create a runtime with Amazon Bedrock AgentCore, a Workload Identity is created
automatically for your runtime with AgentCore Identity service.
Topics

JWT inbound authorization and OAuth outbound access sample
Authenticate and authorize with Inbound Auth and Outbound Auth 114

Prerequisites
Step 1: Prepare your agent
Step 2: Set up AWS Cognito user pool and add a user
Step 3: Deploy your agent
Step 4: Use bearer token to invoke your agent
Step 5: Set up your agent to access tools using OAuth
Step 6: (Optional) Propagate a JWT token to AgentCore Runtime
Troubleshooting
JWT inbound authorization and OAuth outbound access sample............................................
This guide walks you through the process of setting up your agent runtime to be invoked with
an OAuth compliant access token using JWT format. The sample agent will be authorized using
AWS Cognito access tokens. Later, you'll also learn how the agent code can fetch Google tokens on
behalf of the user to check Google Drive and fetch contents.

What you'll learn

In this guide, you'll learn how to:

Set up Cognito user pool, add a user, and get a bearer token for the user
Set up your agent runtime to use the Cognito user pool for authorization
Set up your agent code to fetch OAuth tokens on behalf of the user to call tools
Prerequisites........................................................................................................................................
Before you begin, make sure you have:

An AWS account with appropriate permissions
Basic understanding of Python programming
Familiarity with Docker containers (for advanced deployment)
Set up a basic agent with runtime successfully
Basic understanding of OAuth authorization, mainly JWT bearer tokens, claims, and the various
grant flows
JWT inbound authorization and OAuth outbound access sample 115

Step 1: Prepare your agent..............................................................................................................
Start by creating a basic agent with the following structure:

## Project Folder Structure
your_project_directory/
### agent_example.py # Your main agent code
### requirements.txt # Dependencies for your agent
### __init__.py # Makes the directory a Python package
Create the following files with their respective contents:

agent_example.py

This is your main agent code:

from strands import Agent
from bedrock_agentcore.runtime import BedrockAgentCoreApp
agent = Agent()
app = BedrockAgentCoreApp()
@app.entrypoint
def invoke(payload):
"""Process user input and return a response"""
user_message = payload.get("prompt", "Hello")
response = agent(user_message)
return str(response) # response should be json serializable
if __name__ == "__main__":
app.run()
requirements.txt

This file lists the dependencies for your agent:

strands-agents
bedrock-agentcore
Step 1: Prepare your agent 116

Step 2: Set up AWS Cognito user pool and add a user..............................................................
To set up a Cognito user pool and create a user, you'll use a shell script that automates the process.

For more information, see Step 2: Set up an OAuth 2.0 Credential Provider.

To set up Cognito user pool and create a user

Create a file named setup_cognito.sh with the following content:
Change TEMP_PASSWORD and PERMANENT_PASSWORD to secure passwords of your choosing.
#!/bin/bash
# Create User Pool and capture Pool ID directly
export POOL_ID=$(aws cognito-idp create-user-pool \
--pool-name "MyUserPool" \
--policies '{"PasswordPolicy":{"MinimumLength":8}}' \
--region us-east-1 | jq -r '.UserPool.Id')
# Create App Client and capture Client ID directly
export CLIENT_ID=$(aws cognito-idp create-user-pool-client \
--user-pool-id $POOL_ID \
--client-name "MyClient" \
--no-generate-secret \
--explicit-auth-flows "ALLOW_USER_PASSWORD_AUTH" "ALLOW_REFRESH_TOKEN_AUTH" \
--region us-east-1 | jq -r '.UserPoolClient.ClientId')
# Create User
aws cognito-idp admin-create-user \
--user-pool-id $POOL_ID \
--username "testuser" \
--temporary-password " TEMP_PASSWORD " \
--region us-east-1 \
--message-action SUPPRESS > /dev/null
# Set Permanent Password
aws cognito-idp admin-set-user-password \
--user-pool-id $POOL_ID \
--username "testuser" \
--password " PERMANENT_PASSWORD " \
--region us-east-1 \
--permanent > /dev/null
Step 2: Set up AWS Cognito user pool and add a user 117

# Authenticate User and capture Access Token
export BEARER_TOKEN=$(aws cognito-idp initiate-auth \
--client-id "$CLIENT_ID" \
--auth-flow USER_PASSWORD_AUTH \
--auth-parameters USERNAME='testuser',PASSWORD=' PERMANENT_PASSWORD ' \
--region us-east-1 | jq -r '.AuthenticationResult.AccessToken')
# Output the required values
echo "Pool id: $POOL_ID"
echo "Discovery URL: https://cognito-idp.us-east-1.amazonaws.com/$POOL_ID/.well-
known/openid-configuration"
echo "Client ID: $CLIENT_ID"
echo "Bearer Token: $BEARER_TOKEN"
Run the script to create the Cognito resources:
source setup_cognito.sh
Note the output values, which will look similar to:
Pool id: us-east-1_poolid
Discovery URL: https://cognito-idp.us-east-1.amazonaws.com/us-
east-1_userpoolid/.well-known/openid-configuration
Client ID: clientid
Bearer Token: bearertoken
You'll need these values in the next steps.
This script creates a Cognito user pool, a user pool client, adds a user, and generates a bearer token
for the user. The token is valid for 60 minutes by default.

Step 3: Deploy your agent...............................................................................................................
Service-Linked Role Change - Effective October 13, 2025
Starting October 13, 2025 , Amazon Bedrock AgentCore uses a Service-Linked Role (SLR)
for workload identity permissions instead of requiring manual IAM policy configuration for
new agents.
The Service-Linked Role details:
Step 3: Deploy your agent 118

Name: AWSServiceRoleForBedrockAgentCoreRuntimeIdentity
Service Principal: runtime-identity.bedrock-agentcore.amazonaws.com
Purpose: Manages workload identity access tokens and OAuth credentials
Ensure the role you use to invoke AgentCore Control APIs has permission to create the
Service-Linked Role:
{
"Sid": "CreateBedrockAgentCoreIdentityServiceLinkedRolePermissions",
"Effect": "Allow",
"Action": "iam:CreateServiceLinkedRole",
"Resource": "arn:aws:iam::*:role/aws-service-role/runtime-identity.bedrock-
agentcore.amazonaws.com/AWSServiceRoleForBedrockAgentCoreRuntimeIdentity",
"Condition": {
"StringEquals": {
"iam:AWSServiceName": "runtime-identity.bedrock-
agentcore.amazonaws.com"
}
}
}
Benefit : The Service-Linked Role automatically provides the necessary permissions for
workload identity access without requiring manual policy configuration.
For detailed information about the service-linked role, see Identity service-linked role.
Now you'll deploy your agent with JWT authorization using the Cognito user pool you created.
You will need to create an agent with authorizer configuration. The following table represents the
various authorizer configuration parameters and how we use them to validate the incoming token.

authorizer_configu
ration
claim in decoded
token
Notes
discovery url â†’ issuer iss The discovery url should point to an issuer url.
This should match the iss claim in the decoded
token.
Step 3: Deploy your agent 119

authorizer_configu
ration
claim in decoded
token
Notes
allowedClients client_id client_id in the token should match one of the
allowed clients specified in the authorizer
allowedAudience aud One of the values in aud claim from the token
should match one of the allowed audience
specified in the authorizer
If both client_id and aud is provided, the agent runtime authorizer will verify both.

Starter toolkit

To configure and deploy your agent
Configure your agent runtime with the following command, replacing the placeholder
values with your actual values:
agentcore configure --entrypoint agent_example.py \
--name hello_agent \
--execution-role your-execution-role-arn \
--disable-otel \
--requirements-file requirements.txt \
--authorizer-config "{\"customJWTAuthorizer\":{\"discoveryUrl\":\"$DISCOVERY_URL
\",\"allowedClients\":[\"$CLIENT_ID\"]}}"
Replace $DISCOVERY_URL with the Discovery URL from Step 2, and $CLIENT_ID with the
Client ID from Step 2.
Deploy your agent:
agentcore launch
Note the agent runtime ARN from the output. You'll need this in the next step.
Step 3: Deploy your agent 120

Tip
You can also run the configure command with just the entry point file for a fully
interactive experience:
agentcore configure --entrypoint agent_example.py
Python

import boto3
# Create the client
client = boto3.client('bedrock-agentcore-control', region_name="us-east-1")
# Call the CreateAgentRuntime operation
response = client.create_agent_runtime(
agentRuntimeName='hello_agent',
agentRuntimeArtifact={
'containerConfiguration': {
'containerUri': '111122223333.dkr.ecr.us-east-1.amazonaws.com/my-
agent:latest'
}
},
authorizerConfiguration={
"customJWTAuthorizer": {
"discoveryUrl": 'COGNITO_DISCOVERY_URL',
"allowedClients": ['COGNITO_CLIENT_ID']
}
},
networkConfiguration={"networkMode":"PUBLIC"},
roleArn='arn:aws:iam::111122223333:role/AgentRuntimeRole'
)
Step 4: Use bearer token to invoke your agent...........................................................................
Now that your agent is deployed with JWT authorization, you can invoke it using the bearer token.

Step 4: Use bearer token to invoke your agent 121

Legacy Agent Permissions
Important for existing users : Agents created before October 13, 2025 will continue to
use the agent execution role for identity permissions and require the above policy to be
attached to the agent's execution role.
New agents : For agents created on or after October 13, 2025 , this policy is not required
as permissions are handled automatically by the Service-Linked Role.
{
"Sid": "GetAgentAccessToken",
"Effect": "Allow",
"Action": [
"bedrock-agentcore:GetWorkloadAccessToken",
"bedrock-agentcore:GetWorkloadAccessTokenForJWT",
"bedrock-agentcore:GetWorkloadAccessTokenForUserId"
],
# point to the workload identity for the runtime; the workload identity can
be found in
# the GetAgentRuntime response and has your agent name in it.
"Resource": [
"arn:aws:bedrock-agentcore: region : account-id :workload-identity-
directory/default",
"arn:aws:bedrock-agentcore: region : account-id :workload-identity-
directory/default/workload-identity/ agentname -*"
]
}
Invoke the agent

Fetch a bearer token for the user you created with Amazon Cognito.

# use the password and other details used when you created the cognito user
export TOKEN=$(aws cognito-idp initiate-auth \
--client-id "$CLIENT_ID" \
--auth-flow USER_PASSWORD_AUTH \
--auth-parameters USERNAME='testuser',PASSWORD=' PASSWORD ' \
--region us-east-1 | jq -r '.AuthenticationResult.AccessToken')
Proceed to invoke the agent with the rest of the following instructions.

Step 4: Use bearer token to invoke your agent 122

Invoke the agent with OAuth.

Use cURL

// Invoke with OAuth token
export PAYLOAD='{"prompt": "hello what is 1+1?"}'
export BEDROCK_AGENT_CORE_ENDPOINT_URL="https://bedrock-agentcore.us-
east-1.amazonaws.com"
curl -v -X POST "${BEDROCK_AGENT_CORE_ENDPOINT_URL}/runtimes/${ESCAPED_AGENT_ARN}/
invocations?qualifier=DEFAULT" \
-H "Authorization: Bearer ${TOKEN}" \
-H "X-Amzn-Trace-Id: your-trace-id" \
-H "Content-Type: application/json" \
-H "X-Amzn-Bedrock-AgentCore-Runtime-Session-Id: your-session-id" \
-d ${PAYLOAD}
Use Python

Since boto3 doesn't support invocation with bearer tokens, you'll need to use an HTTP client
like the requests library in Python.
To invoke your agent with a bearer token
Create a Python script named invoke_agent.py with the following content:
import requests
import urllib.parse
import json
import os
# Configuration Constants
REGION_NAME = " AWS_REGION "
# === Agent Invocation Demo ===
invoke_agent_arn = " YOUR_AGENT_ARN_HERE "
auth_token = os.environ.get('TOKEN')
print(f"Using Agent ARN from environment: {invoke_agent_arn}")
# URL encode the agent ARN
escaped_agent_arn = urllib.parse.quote(invoke_agent_arn, safe='')
# Construct the URL
Step 4: Use bearer token to invoke your agent 123

url = f"https://bedrock-agentcore.{REGION_NAME}.amazonaws.com/runtimes/
{escaped_agent_arn}/invocations?qualifier=DEFAULT"
# Set up headers
headers = {
"Authorization": f"Bearer {auth_token}",
"X-Amzn-Trace-Id": "your-trace-id",
"Content-Type": "application/json",
"X-Amzn-Bedrock-AgentCore-Runtime-Session-Id": "testsession123"
}
# Enable verbose logging for requests
import logging
logging.basicConfig(level=logging.DEBUG)
logging.getLogger("urllib3.connectionpool").setLevel(logging.DEBUG)
invoke_response = requests.post(
url,
headers=headers,
data=json.dumps({"prompt": "Hello what is 1+1?"})
)
# Print response in a safe manner
print(f"Status Code: {invoke_response.status_code}")
print(f"Response Headers: {dict(invoke_response.headers)}")
# Handle response based on status code
if invoke_response.status_code == 200:
response_data = invoke_response.json()
print("Response JSON:")
print(json.dumps(response_data, indent=2))
elif invoke_response.status_code >= 400:
print(f"Error Response ({invoke_response.status_code}):")
error_data = invoke_response.json()
print(json.dumps(error_data, indent=2))
else:
print(f"Unexpected status code: {invoke_response.status_code}")
print("Response text:")
print(invoke_response.text[:500])
Replace AWS_REGION with the AWS Region that you are using. from Step 3.
Replace YOUR_AGENT_ARN_HERE with your actual agent runtime ARN from Step 3.
Step 4: Use bearer token to invoke your agent 124

Run the script:
python invoke_agent.py
Use starter toolkit

REplace ADD_TOKEN_HERE with your bearer token.
agentcore invoke '{"prompt": "Hello what is 1+1?"}' --bearer-token ADD_TOKEN_HERE
Step 5: Set up your agent to access tools using OAuth.............................................................
In this section, you'll learn how to connect your agent code with AgentCore Credential Providers for
secure access to external resources using OAuth2 authentication.

The example below demonstrates how your agent running in Agent Runtime can request OAuth
consent from users, enabling them to authenticate with their Google account and authorize the
agent to access their Google Drive contents.

For more information about setting up identity, see Get started with AgentCore Identity.

Step 5.1: Set up Credential Providers

To set up a Google Credential Provider, you need to:

Register your application with Google to obtain client ID and client secret
Create an OAuth credential provider using the AWS CLI. Replace your-client-id and your-
client-secret with your actual Google OAuth2 client ID and client secret:
aws bedrock-agentcore-control create-oauth2-credential-provider \
--name "google-provider" \
--credential-provider-vendor "GoogleOauth2" \
--oauth2-provider-config-input '{
"googleOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret "
}
}'
Step 5: Set up your agent to access tools using OAuth 125

Make sure your invocation role has the necessary permissions for accessing the credential provider.

Step 5.2: Enable agent to read Google Drive contents

Create a tool with agent core SDK annotations as shown below to automatically initiate the three-
legged OAuth process. When your agent invokes this tool, users will be prompted to open the
authorization URL in their browser and grant consent for the agent to access their Google Drive.

import asyncio
from bedrock_agentcore.identity.auth import requires_access_token, requires_api_key
# This annotation helps agent developer to obtain access tokens from external
applications
@requires_access_token(
provider_name="google-provider",
scopes=["https://www.googleapis.com/auth/drive.metadata.readonly"], # Google OAuth2
scopes
auth_flow="USER_FEDERATION", # 3LO flow
on_auth_url=lambda x: print("Copy and paste this authorization url to your
browser", x), # prints authorization URL to console
force_authentication=True,
)
async def read_from_google_drive(*, access_token: str):
print(access_token) #You can see the access_token
# Make API calls...
main(access_token)
asyncio.run(read_from_google_drive(access_token=""))
What happens behind the scenes

When this code runs, the following process occurs:

1.Agent Runtime authorizes the inbound token according to the configured authorizer.

2.Agent Runtime exchanges this token for a Workload Access Token via bedrock-
agentcore:GetWorkloadAccessTokenForJWT API and delivers it to your agent code via the
payload header WorkloadAccessToken.

3.During tool invocation, your agent uses this Workload Access Token to call Token Vault API
bedrock-agentcore:GetResourceOauth2Token and generate a 3LO authentication URL.

4.Your agent sends this URL to the client application as specified in the on_auth_url method.

Step 5: Set up your agent to access tools using OAuth 126

5.The client application presents this URL to the user, who grants consent for the agent to access
their Google Drive.

6.AgentCore Identity service securely receives and caches the Google access token until it expires,
enabling subsequent requests from the user to use this token without needing the user to
provide consent for every request.

Note
AgentCore Identity Service stores the Google access token in the AgentCore Token Vault
using the agent workload identity and user ID (from the inbound JWT token, such as AWS
Cognito token) as the binding key, eliminating repeated consent requests until the Google
token expires.
Step 6: (Optional) Propagate a JWT token to AgentCore Runtime..........................................
Optionally, you can pass an Authorization header to an AgentCore Runtime to extract claims.
This can be done by using the request header allowlist configuration. For more information, see
RequestHeaderConfiguration.

Step 6.1: Modify your agent code to read headers

In this step you make changes to your agent code so that you can decode and extract claims from a
JWT token using PyJWT library.

requirements.txt

Add PyJWT dependency to your requirements.txt file.

PyJWT
agent_example.py

Change your main agent code as shown in the following code. You can skip validating the token
signature here since it has already been validated by AgentCore Runtime when the inbound
authorization was done.

Step 6: (Optional) Propagate a JWT token to AgentCore Runtime 127

import jwt
import json
....
@app.entrypoint
def invoke(payload, context):
auth_header = context.request_headers.get('Authorization')
if not auth_header:
return None
# Remove "Bearer " prefix if present
token = auth_header.replace('Bearer ', '') if auth_header.startswith('Bearer ')
else auth_header
try:
# Skip signature validation as agent runtime has validated the token already.
claims = jwt.decode(token, options={"verify_signature": False})
app.logger.info("Claims: %s", json.dumps(claims))
except jwt.InvalidTokenError as e:
app.logger.exception("Invalid JWT token: %s", e)
.....
Step 6.2: Create the agent with request header allowlist

Use the AgentCore starter toolkit to create the agent with request header allowlist.

agentcore configure --entrypoint agent_example.py \
--name hello_agent \
--execution-role your-execution-role-arn \
--disable-otel \
--requirements-file requirements.txt \
--authorizer-config "{\"customJWTAuthorizer\":{\"discoveryUrl\":\"$DISCOVERY_URL\",
\"allowedClients\":[\"$CLIENT_ID\"]}}" \
--request-header-allowlist "Authorization"
// now launch the agent runtime
agentcore launch
Step 6.3: Invoke your agent

Invoke your agent using OAuth and you should see the claims in your agent logs in CloudWatch
Logs.

Step 6: (Optional) Propagate a JWT token to AgentCore Runtime 128

Troubleshooting..................................................................................................................................
How to debug token related issues

If you encounter issues with token authentication, you can decode the token to inspect its contents:

echo "$TOKEN" | cut -d '.' -f2 | tr '_-' '/+' | awk '{ l=4 - length($0)%4; if (l<4)
printf "%s", $0; for (i=0; i<l; i++) printf "="; print "" }' | base64 -D | jq
This will output the token's payload, which looks similar to:

{
"sub": "subid",
"iss": "https://cognito-idp.us-east-1.amazonaws.com/userpoolid",
"client_id": "clientid",
"origin_jti": "originjti",
"event_id": "eventid",
"token_use": "access",
"scope": "aws.cognito.signin.user.admin",
"auth_time": 1752275688,
"exp": 1752279288,
"iat": 1752275688,
"jti": "jti",
"username": "username"
}
When troubleshooting token issues, check the following:

Issuer url pointed to by the discovery url in the agent authorizer should match the issuer claim in
the token. Do the following to confirm they match:
Select the discovery url you provided in the authorizer configuration when you created
the agent, for example: https://cognito-idp.us-east-1.amazonaws.com/us-
east-1_nnnnnnnnn/.well-known/openid-configuration
Check the issuer url - "issuer": "https://cognito-idp.us-
east-1.amazonaws.com/us-east-1_12345566". This should match the iss claim value
in the token.
client_id claim in the token must match one of the authorizer allowedClients entries if
provided
Note the client id you provided when you created the agent
Troubleshooting 129

Confirm this matches the client_id claim in the decoded token
aud claim in the token must match one of the authorizer allowedAudience entries, if provided
Note the audience list you provided when you created the agent
Confirm this matches the aud claim in the decoded token
Tokens are only valid for several minutes (the default Amazon Cognito expiry is 60 minutes).
Fetch a new token as needed.
AgentCore Runtime versioning and endpoints..................................................................................
Amazon Bedrock AgentCore implements automatic versioning for AgentCore Runtimes and lets
you manage different configurations using endpoints.

Each AgentCore Runtime in Amazon Bedrock AgentCore is automatically versioned:

When you create an AgentCore Runtime, AgentCore Runtime automatically creates version 1 (V1)
Each update to the AgentCore Runtime creates a new version with a complete, self-contained
configuration
Versions are immutable once created
Each version contains all the configuration needed for execution
How endpoints reference versions..................................................................................................
Endpoints provide a way to reference specific versions of your AgentCore Runtime:

The DEFAULT endpoint automatically points to the latest version of your AgentCore Runtime
Endpoints can point to specific versions, allowing you to maintain different environments (e.g.,
development, staging, production)
When you update an AgentCore Runtime, the DEFAULT endpoint is automatically updated to
point to the new version
Endpoints must be explicitly updated to point to new versions
Example Updating an endpoint to a New Version

bedrock_agentcore_client = boto3.client('bedrock-agentcore', region_name='us-west-2')
AgentCore Runtime versioning and endpoints 130

response = bedrock_agentcore_client.update_agent_runtime_endpoint(
agentRuntimeId='agent-runtime-12345',
endpointName='production-endpoint',
agentRuntimeVersion='v2.1',
description='Updated production endpoint'
)
print(response)
Versioning scenarios...........................................................................................................................
The following table illustrates how versioning and endpoints interact during the lifecycle of an
AgentCore Runtime:

Agent Runtime Versioning Scenarios

Change Type Version Creation Behavior Latest
Version
Endpoint Behavior
Initial
Creation
Creates Version 1 (V1)
automatically
V1 DEFAULT points to V1
Protocol
Change
Creates a new version with
updated protocol settings
V2 DEFAULT automatically
updates to V2
Create
"PROD"
endpoint
with V2
No new version created V2 PROD endpoint points to V2
Container
Image
Update
Creates a new version with
new container reference
V3 DEFAULT updates to V3,
PROD remains on V2
Update
"PROD" to V3
No new version created V3 PROD updates to V3
Versioning scenarios 131

Change Type Version Creation Behavior Latest
Version
Endpoint Behavior
Network
Settings
Modification
Creates a new version with
updated security parameters
V4 DEFAULT updates to V4,
PROD remains on V3
Endpoint lifecycle states...................................................................................................................
AgentCore Runtime endpoints go through various states during their lifecycle:

CREATING

Initial state when an endpoint is being created
CREATE_FAILED

Indicates creation failure due to permissions, container, or other issues
READY

Endpoint is ready to accept requests
UPDATING

Endpoint is being updated to a new version
UPDATE_FAILED

Indicates update operation failure
Listing AgentCore Runtime versions and endpoints...................................................................
You can list all versions of an AgentCore Runtime by calling the ListAgentRuntimeVersions
operation. To list the endpoints for an AgentCore Runtime, call ListAgentRuntimeEndpoints.

Invoke an AgentCore Runtime agent
The InvokeAgentRuntime operation lets you send requests to specific AgentCore Runtime
endpoints identified by their Amazon Resource Name (ARN) and receive streaming responses

Endpoint lifecycle states 132

containing the agent's output. The API supports session management through session identifiers,
enabling you to maintain conversation context across multiple interactions. You can target specific
agent endpoints using optional qualifiers.

To call InvokeAgentRuntime, you need bedrock-agentcore:InvokeAgentRuntime
permissions. In the call you can also pass a bearer token that the agent can use for user
authentication.

The InvokeAgentRuntime operation accepts your request payload as binary data up to 100 MB
in size and returns a streaming response that delivers chunks of data in real-time as the agent
processes your request. This streaming approach allows you to receive partial results immediately
rather than waiting for the complete response, making it ideal for interactive applications.

If you plan on integrating your agent with OAuth, you can't use the AWS SDK to call
InvokeAgentRuntime. Instead, make a HTTPS request to InvokeAgentRuntime. For more
information, see Authenticate and authorize with Inbound Auth and Outbound Auth.

Invoke streaming agents...................................................................................................................
The following example shows how to use boto3 to invoke an agent runtime:

import boto3
import json
# Initialize the Bedrock AgentCore client
agent_core_client = boto3.client('bedrock-agentcore')
# Prepare the payload
payload = json.dumps({"prompt": prompt}).encode()
# Invoke the agent
response = agent_core_client.invoke_agent_runtime(
agentRuntimeArn=agent_arn,
runtimeSessionId=session_id,
payload=payload
)
# Process and print the response
if "text/event-stream" in response.get("contentType", ""):
Invoke streaming agents 133

# Handle streaming response
content = []
for line in response["response"].iter_lines(chunk_size=10):
if line:
line = line.decode("utf-8")
if line.startswith("data: "):
line = line[6:]
print(line)
content.append(line)
print("\nComplete response:", "\n".join(content))
elif response.get("contentType") == "application/json":
# Handle standard JSON response
content = []
for chunk in response.get("response", []):
content.append(chunk.decode('utf-8'))
print(json.loads(''.join(content)))
else:
# Print raw response for other content types
print(response)
Invoke multi-modal agents..............................................................................................................
You can use the InvokeAgentRuntime operation to send multi-modal requests that include both
text and images. The following example shows how to invoke a multi-modal agent:

import boto3
import json
import base64
# Read and encode image
with open("image.jpg", "rb") as image_file:
image_data = base64.b64encode(image_file.read()).decode('utf-8')
# Prepare multi-modal payload
payload = json.dumps({
"prompt": "Describe what you see in this image",
"media": {
"type": "image",
"format": "jpeg",
"data": image_data
Invoke multi-modal agents 134

}
}).encode()
# Invoke the agent
response = agent_core_client.invoke_agent_runtime(
agentRuntimeArn=agent_arn,
runtimeSessionId=session_id,
payload=payload
)
Session management.........................................................................................................................
The InvokeAgentRuntime operation supports session management through the
runtimeSessionId parameter. By providing the same session identifier across multiple requests,
you can maintain conversation context, allowing the agent to reference previous interactions.

To start a new conversation, generate a unique session identifier. To continue an existing
conversation, use the same session identifier from previous requests. This approach enables you to
build interactive applications that maintain context over time.

Tip
For best results, use a UUID or other unique identifier for your session IDs to avoid collisions
between different users or conversations.
Error handling.....................................................................................................................................
When using the InvokeAgentRuntime operation, you might encounter various errors. Here are
some common errors and how to handle them:

ValidationException

Occurs when the request parameters are invalid. Check that your agent ARN, session ID, and
payload are correctly formatted.
ResourceNotFoundException

Occurs when the specified agent runtime cannot be found. Verify that the agent ARN is correct
and that the agent exists in your AWS account.
Session management 135

AccessDeniedException

Occurs when you don't have the necessary permissions. Ensure that your IAM policy includes the
bedrock-agentcore:InvokeAgentRuntime permission.
ThrottlingException

Occurs when you exceed the request rate limits. Implement exponential backoff and retry logic
in your application.
Implement proper error handling in your application to provide a better user experience and to
troubleshoot issues effectively.

Best practices......................................................................................................................................
Follow these best practices when using the InvokeAgentRuntime operation:

Use session management to maintain conversation context for a better user experience.
Process streaming responses incrementally to provide real-time feedback to users.
Implement proper error handling and retry logic for a robust application.
Consider payload size limitations (100 MB) when sending requests, especially for multi-modal
content.
Use appropriate qualifiers to target specific agent versions or endpoints.
Implement authentication mechanisms when necessary using bearer tokens.
Observe agents in Amazon Bedrock AgentCore Runtime
For information about the AgentCore Runtime observability metrics, see Add observability to your
Amazon Bedrock AgentCore resources.

Troubleshoot AgentCore Runtime
This troubleshooting topic helps you identify and resolve common issues when working with
AgentCore Runtime. By following these solutions, you can quickly diagnose and fix problems with
your agent runtimes.

Topics

Best practices 136

My agent invocations fail with 504 Gateway Timeout errors
My Docker build fails with "403 Forbidden" when pulling Python base images
I get "Unknown service: 'bedrock-agent-core-runtime'" error when using boto3
I get "AccessDeniedException" when trying to create an Amazon Bedrock AgentCore Runtime
My Docker build fails with "exec /bin/sh: exec format error"
What are the requirements for Docker containers used with Amazon Bedrock AgentCore
Runtime?
My long-running tool gets interrupted after 15 minutes
How do I access the runtimeSessionId in my agent code for tagging or grouping resources?
I have RuntimeClientError (403) issues
I have missing or empty CloudWatch Logs
I have payload format issues
I need help understanding HTTP error codes
I need recommendations for testing my agent
I need help debugging container issues
I need help troubleshooting MCP protocol agents
Best practices
My agent invocations fail with 504 Gateway Timeout errors....................................................
When this occurs: During agent invocation via SDK or console

Why this happens: Multiple factors can prevent your agent from responding within the timeout
period

Several factors can cause this:

Container Issues: Make sure your Docker image exposes port 8080 and has the /invocations
path
ARM64 Compatibility: Currently your container must be ARM64 compatible
Retry Logic: Review retry mechanisms for handling transient issues
My agent invocations fail with 504 Gateway Timeout errors 137

My Docker build fails with "403 Forbidden" when pulling Python base images....................
When this occurs: During docker build or docker run when using public.ecr.aws base
images

Why this happens: ECR Public authentication issues â€” expired or missing authentication is a
common issue.

Solution: Either login to ECR Public or logout completely:

# Option 1: Login to ECR Public
aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --
password-stdin public.ecr.aws
# Option 2: Logout (recommended for avoiding token expiration)
docker logout public.ecr.aws
# Option 3: Use Docker Hub directly in Dockerfile
FROM python:3.10-slim
# instead of public.ecr.aws/docker/library/python:3.10-slim
I get "Unknown service: 'bedrock-agent-core-runtime'" error when using boto3..................
When this occurs: When invoking Amazon Bedrock AgentCore APIs using boto3 SDK

Why this happens: Outdated boto3 library â€” common issue as most installations don't have latest
SDK

Solution: Update to latest boto3 and botocore versions:

pip install --upgrade boto3 botocore
# Minimum versions: boto3 1.39.8+, botocore 1.33.8+
My Docker build fails with "403 Forbidden" when pulling Python base images 138

I get "AccessDeniedException" when trying to create an Amazon
Bedrock AgentCore Runtime
When this occurs: During agent creation via console, SDK, or CLI

Why this happens: Either your user lacks permissions, or the execution role isn't properly
configured for Amazon Bedrock AgentCore

Solution: Several factors can cause this:

Missing permissions for the caller. Make sure that the caller's credentials has bedrock-
agentcore:CreateAgentRuntime.
Execution Role cannot be assumed by Bedrock Amazon Bedrock AgentCore. Make sure that
the execution role follows this guidance on permissions for Amazon Bedrock AgentCore Runtime
execution role.
My Docker build fails with "exec /bin/sh: exec format error"....................................................
When this occurs: When building containers for Amazon Bedrock AgentCore deployment

Why this happens: Building ARM64 containers on x86 systems without proper cross-platform
setup

Solution: Build ARM64 compatible containers. You can consider using buildx for cross-platform
builds. Alternatively, you can use CodeBuild. For example code, see the Amazon Bedrock AgentCore
Samples.

What are the requirements for Docker containers used with Amazon
Bedrock AgentCore Runtime?
Review Amazon Bedrock AgentCore Runtime requirements for full details.

In summary, your Docker container must meet these requirements:

Port: Expose port 8080 (additional ports will be supported soon)
Endpoint: Must have /invocations path available
Architecture: Must be ARM64 compatible
Response: Should handle the expected payload format
I get "AccessDeniedException" when trying to create an Amazon Bedrock AgentCore Runtime 139

My long-running tool gets interrupted after 15 minutes..........................................................
For information, see Handle asynchronous and long running agents with Amazon Bedrock Amazon
Bedrock AgentCore Runtime for full details.

When this occurs: During long-running agent operations or complex workflows

Why this happens: Amazon Bedrock AgentCore automatically terminates sessions after 15 minutes
of inactivity

Example solution: Implement ping handlers with HEALTHY_BUSY status for async tasks:

import asyncio
from bedrock_agentcore.runtime import BedrockAgentCoreApp
app = BedrockAgentCoreApp()
@app.entrypoint
async def long_running_agent(payload, context):
# For long-running tasks, create async task with ping handler
async def ping_handler():
while task_running:
await context.ping(status="HEALTHY_BUSY")
await asyncio.sleep(30) # Ping every 30 seconds
# Start ping handler
ping_task = asyncio.create_task(ping_handler())
# Your long-running work here
result = await perform_long_task()
# Clean up
ping_task.cancel()
return result
How do I access the runtimeSessionId in my agent code for tagging or
grouping resources?
When this applies: You want to group, tag, or trace resources (e.g., S3 objects, logs) by the current
agent runtime session.

My long-running tool gets interrupted after 15 minutes 140

Solutions:

If you're using the Bedrock Agents SDK, use context.session_id.
If you're building a custom runtime server, extract it from the X-Amzn-Bedrock-AgentCore-
Runtime-Session-Id HTTP header.
Solution 1: For agents using the Bedrock Amazon Bedrock AgentCore SDK, use
context.session_id from your agent entrypoint

@app.entrypoint
def my_agent(payload, context):
session_id = context.session_id
# Use session_id for S3 object tagging/organization
s3_client = boto3.client('s3')
s3_client.put_object(
Bucket='my-bucket',
Key=f'agent-outputs/{session_id}/output.json',
Body=json.dumps(result),
Tagging=f'SessionId={session_id}'
)
return result
Solution 2: For custom runtime HTTP servers

The runtime session ID is passed in this HTTP header. Parse it from the incoming request and use it
for tagging, correlation, or downstream propagation.

X-Amzn-Bedrock-AgentCore-Runtime-Session-Id: <value>
I have RuntimeClientError (403) issues..........................................................................................
Problem

You receive a 403 "RuntimeClientError" when attempting to invoke your agent runtime.

Causes

I have RuntimeClientError (403) issues 141

This error typically occurs due to:

Container startup failures
Permissions issues with execution role
Authentication issues with bearer token
Resolution

Follow these steps to resolve the issue:

Check CloudWatch Logs : Any issues with starting up the container will reflect as a 403 -
RuntimeClientError. Navigate to the following CloudWatch log group to check for startup
errors:
/aws/bedrock-agentcore/runtimes/<agent_id>-<endpoint_name>/[runtime-logs]
Verify Execution Role : Ensure your agent's execution role has the necessary permissions. For
more information, see AgentCore Runtime execution role.
Validate Authentication : For MCP protocol agents, ensure your bearer token is valid and not
expired.
I have missing or empty CloudWatch Logs...................................................................................
Problem

You encounter errors but don't see any relevant logs in CloudWatch.

Solution

Try these approaches to diagnose the issue:

Check Correct Log Group : Ensure you're looking in the right CloudWatch log group. The
standard pattern is:
/aws/bedrock-agentcore/runtimes/<agent_id>-<endpoint_name>/runtime-logs
Run Locally for Diagnostics : If there are no CloudWatch Logs, try running the agent container
locally using the exact same payload you used for invocation in AgentCore Runtime. This can
help identify issues that might not be visible in the logs.
I have missing or empty CloudWatch Logs 142

Enable Verbose Logging : Update your agent code to include more detailed logging, especially
around the entry points and any error handling logic.
I have payload format issues...........................................................................................................
Problem

Your agent runtime invocation fails even though the container starts successfully.

Resolution

Follow these steps to resolve payload format issues:

Verify Payload Structure : Ensure your payload structure matches what your agent expects.
Pay special attention to:
If your agent code expects input keyword in the payload, make sure to include it:
{
"input": {
"prompt": "Your question here"
}
}
Not just:
{
"prompt": "Your question here"
}
Check Documentation : Review the expected input format in the documentation.
I need help understanding HTTP error codes..............................................................................
Problem

Your agent returns HTTP error codes that are difficult to interpret.

Resolution

Here are the most common error codes and their meanings:

I have payload format issues 143

422 Unprocessable Entity

This happens when the container encounters validation issues with the input payload.
Common causes:
Missing required fields in the payload (e.g., missing "input" field)
Incorrect data types for fields
Invalid format for the payload
403 Forbidden

Authentication or authorization issues.
Check your bearer token or IAM permissions.
500 Internal Server Error

Runtime exceptions in your agent code.
Check CloudWatch logs for detailed stack traces.
I need recommendations for testing my agent...........................................................................
To systematically debug agent runtime issues:

Test locally first

Before deploying to AgentCore Runtime:

Run your agent container locally using the same Docker image
Verify it works with the exact same payload
Compare payloads

Ensure consistency between environments:

Ensure the payload structure between local testing and AgentCore Runtime invocation is
identical
Pay special attention to nesting of fields like "input" and "prompt"
I need recommendations for testing my agent 144

I need help debugging container issues........................................................................................
If you suspect container-related issues:

Pull and run locally

Test your container image on your local machine:

docker pull <your-ecr-repo-uri>
docker run -p 8080:8080 <your-ecr-repo-uri>
Test with curl

Send test requests to your local container:

curl -X POST http://localhost:8080/invocations \
-H "Content-Type: application/json" \
-d '{"input": {"prompt": "Hello world!"}}'
Check container logs

Examine the container's output for errors:

docker logs <container-id>
I need help troubleshooting MCP protocol agents.....................................................................
For MCP protocol agents, follow these specific troubleshooting steps:

Verify endpoint path

MCP servers should listen on 0.0.0.0:8000/mcp/

Use MCP Inspector

Test with the MCP Inspector tool:

Install and run the MCP Inspector: npx @modelcontextprotocol/inspector
Connect to your local server at http://localhost:8000/mcp
For deployed agents, use the properly URL-encoded endpoint
I need help debugging container issues 145

Authentication issues

Check authentication configuration:

Ensure bearer token is correctly set in the headers
Verify your Cognito user pool is correctly set up
Best practices
Enable comprehensive logging

Implement thorough logging in your agent:

Include request/response logging in your agent
Log critical paths and error conditions
Use structured error handling

Implement clear error reporting:

Return clear error messages with specific codes
Include actionable information in error responses
Test incremental changes

Follow a methodical testing approach:

When modifying your agent, test locally before deployment
Validate payload compatibility with both local and deployed environments
Monitor performance

Set up monitoring for your agent:

Use CloudWatch metrics to track invocation patterns
Set up alarms for error rates and latency
Best practices 146

Add memory to your Amazon Bedrock AgentCore agent
AgentCore Memory is a fully managed service that gives your AI agents the ability to remember
past interactions, enabling them to provide more intelligent, context-aware, and personalized
conversations. It provides a simple and powerful way to handle both short-term context and long-
term knowledge retention without the need to build or manage complex infrastructure.

AgentCore Memory addresses a fundamental challenge in agentic AI: statelessness. Without
memory capabilities, AI agents treat each interaction as a new instance with no knowledge of
previous conversations. AgentCore Memory provides this critical capability, allowing your agent to
build a coherent understanding of users over time.

AgentCore Memory supports a variety of SDKs and agent frameworks. For examples, see Amazon
Bedrock AgentCore Memory examples.

Memory types...........................................................................................................................................
AgentCore Memory offers two types of memory that work together to create intelligent, context-
aware AI agents:

Short-term memory

Short-term memory captures turn-by-turn interactions within a single session. This lets agents
maintain immediate context without requiring users to repeat information.
Memory types 147

Example: When a user asks, "What's the weather like in Seattle?" and follows up with "What
about tomorrow?", the agent relies on recent conversation history to understand that
"tomorrow" refers to the weather in Seattle.
Long-term memory

Long-term memory automatically extracts and stores key insights from conversations across
multiple sessions, including user preferences, important facts, and session summaries â€” for
persistent knowledge retention across multiple sessions.
Example: If a customer mentions they prefer window seats during flight booking, the agent
stores this preference in long-term memory. In future interactions, the agent can proactively
offer window seats, creating a personalized experience.
Memory key benefits..............................................................................................................................
Create more natural conversations: By remembering previous turns in a conversation, agents
can understand context, resolve ambiguous statements, and interact in a way that feels more
human.
Deliver personalized experiences: Retain user preferences, historical data, and key facts across
sessions to tailor responses and actions to individual users.
Reduce development complexity: Offload the undifferentiated heavy lifting of managing
conversational state and memory, allowing you to focus on building your agent's core business
logic.
Common use cases of memory............................................................................................................
Conversational agents: A customer support chatbot remembers a user's previous issues and
preferences, enabling it to provide more relevant assistance in future interactions.
Task-oriented / workflow agents: An AI agent orchestrating a multi-step business process,
such as invoice approval, uses memory to track the status of each step and maintain workflow
progress.
Multi-agent systems: A team of AI agents managing a supply chain shares memory to
synchronize inventory levels, anticipate demand, and optimize logistics.
Autonomous or planning agents: An autonomous vehicle uses memory to plan routes, adjust to
traffic conditions, and learn from past experiences to improve future driving decisions.
Memory key benefits 148

How it works.............................................................................................................................................
AgentCore Memory provides a set of APIs that let your AI agents seamlessly store, retrieve, and
utilize both short-term and long-term memory. The architecture is designed to separate the
immediate context of a conversation from the persistent knowledge that should be retained over
time.

Topics

Memory terminology
Memory types
Memory strategies
Memory terminology.........................................................................................................................
AgentCore Memory

The primary, top-level container for your agent's memory resource. Each AgentCore Memory
holds all the events and extracted insights for agents or applications.
Memory strategy

Memory strategies are configurable rules that determine how to process information from
short-term memory into long-term memory. They determine what type of information is kept,
turning raw conversations into structured and useful knowledge.
Namespace

A namespace is a structured path used to logically group and organize long-term memories. By
defining a namespace in your memory strategy, you maintain that all extracted memories are
organized under predictable paths, which aids in retrieval, filtering, and access control.
Memory record

A memory record is a structured unit of information within the memory resource. Each record
is associated with a unique identifier and is stored within a specified namespace, allowing for
organized retrieval and management.
Session

Represents a single, continuous interaction between a user and the agent, such as a customer
support conversation. A unique sessionId is used to group all events within that conversation.
How it works 149

Actor

Represents the entity interacting with the agent. This can be a human user, another agent, or a
system (software or hardware component) that initiates interactions with the agent. A unique
actorId maintains that memory records are correctly associated with the individual or system.
Event

Event is the fundamental unit of short-term memory. It represents a discrete interaction
or activity within a session, associated with a specific actor. Events are stored using the
CreateEvent operation and are organized by actorId and sessionId. Each event is
immutable and timestamped, capturing real-time data such as user messages, system actions,
or tool invocations.
Event metadata

Event metadata refers to the supplementary information that provides context about an event
in an AgentCore Memory. While not always explicitly required, metadata can enhance the
organization and retrieval of events.
Memory types.....................................................................................................................................
AgentCore Memory offers two types of memory that work together to create intelligent, context-
aware AI agents:

Topics

Short-term memory
Long-term memory
Short-term memory

Short-term memory stores raw interactions that help the agent maintain context within a single
session. For example, in a shopping website's customer support AI agent, short-term memory
captures the entire conversation history as a series of events. Each customer question and agent
response is saved as a separate event (or in batches, depending on your implementation). This lets
the agent reload the entire conversation as it happened, maintaining context even if the service
restarts or the customer returns later to continue the same interaction seamlessly.

When a customer interacts with your agent, each interaction can be captured as an event using
the CreateEvent operation. Events can contain various types of data, including conversational

Memory types 150

exchanges (questions, answers, instructions) or structured information (product details, order
status). Each event is associated with a session via a session identifier (sessionId), which you
can define or let the system generate by default. You can use the sessionId parameter in future
requests to maintain conversation context.

To load previous sessions/conversations or enrich context, your agent needs to access the
raw interactions with the customer. Imagine a customer returns to follow up on their product
support case from last week. To provide seamless assistance, the agent uses ListSessions to locate
their previous support interactions. Through ListEvents, it retrieves the conversation history,
understanding the reported issue, troubleshooting steps attempted, and any temporary solutions
discussed. The agent uses GetEvent to access specific information from key moments in past
conversations. These operations work together to maintain support continuity across sessions,
eliminating the need for customers to re-explain their issue or repeat troubleshooting steps already
attempted.

Event metadata

Event metadata lets you attach additional context information to your short-term memory events
as key-value pairs. When creating events using the CreateEvent operation, you can include
metadata that isn't part of the core event content but provides valuable context for retrieval.
For example, a travel booking agent can attach location metadata to events, making it easy to
find all conversations that mentioned specific destinations. You can then use the ListEvents
operation with metadata filters to efficiently retrieve events based on these attached properties,
enabling your agent to quickly locate relevant conversation history without scanning through
entire sessions. This capability is useful for agents that need to track and retrieve specific attributes
across conversations, such as product categories in e-commerce, case types in customer support, or
project identifiers in task management applications. Event metadata is not meant to store sensitive
content, as it is not encrypted with customer managed key.

Long-term memory

Long-term memory records store structured information extracted from raw agent interactions,
which is retained across multiple sessions. Long-term memory preserves only the key insights
such as summaries of the conversations, facts and knowledge, or user preferences. For example,
if a customer tells the agent their preferred shoe brand during a conversation, the AI agent stores
this as a long-term memory. Later, even in a different conversation, the agent can remember and
suggest the shoe brand, making the interaction personalized and relevant.

Memory types 151

Long-term memory generation is an asynchronous process that runs in the background and
automatically extracts insights after raw conversation/context is stored in short-term memory via
CreateEvent. This efficiently consolidates key information without interrupting live interactions.
As part of the long-term memory generation, AgentCore Memory performs the following
operations:

Extraction : Extracts information from raw interactions with the agent
Consolidation : Consolidates newly extracted information with existing information in the
AgentCore Memory.
Once long-term memory records are generated, you can retrieve these extracted memories to
enhance your agent's responses. Extracted memories are stored as memory records and can be
accessed using the GetMemoryRecord, ListMemoryRecords, or RetrieveMemoryRecords operations.
The RetrieveMemoryRecords operation is powerful as it performs a semantic search to find
memory records that are most relevant to the query. For example, when a customer asks about
running shoes, the agent can use semantic search to retrieve related memory records, such as
customer's preferred shoe size, favorite shoe brands, and previous shoe purchases. This lets the AI
support agent provide highly personalized recommendations without requiring the customer to
repeat information they've shared before.

Memory strategies..............................................................................................................................
In AgentCore Memory, you can add memory strategies to your memory resource. These
strategies determine what types of information to extract from raw conversations. Strategies
are configurations that intelligently capture and persist key concepts from interactions, sent as
events in the CreateEvent operation. You can add strategies to the memory resource as part of
CreateMemory or UpdateMemory operations. Once enabled, these strategies are automatically
executed on raw conversation events associated with that memory resource to extract long-term
memories.

If no strategies are specified, long-term memory records will not be extracted for that memory.

AgentCore Memory supports a variety of memory strategies:

Built-in strategies

AgentCore handles all memory extraction and consolidation automatically with predefined
algorithms.

Memory strategies 152

AgentCore handles all memory extraction and consolidation automatically
No configuration required beyond basic trigger settings
Uses predefined algorithms optimized and benchmarked for common use cases
Suitable for standard conversational AI applications
Limited customization options
Higher cost for storage
Built-in overrides

Extends built-in strategies with targeted customization while using an AgentCore managed
extraction pipeline.

Extends built-in strategies with targetted customization
Allows modification of prompts while still using AgentCore managed extraction pipeline
Provides support for bedrock models (invoked in your account)
Lower cost for storage than built-ins
Self-managed strategies:

You have complete ownership of memory processing pipeline with custom extraction and
consolidation algorithms.

Complete ownership of memory processing pipeline
Custom extraction and consolidation algorithms using any model, prompts, etc.
Full control over memory record schemas, namespaces etc.
Integration with external systems and databases
Requires infrastructure setup and maintenance
Lower cost for storage than built-in strategies
A single memory resource can be configured to utilize both built-in and custom strategies
simultaneously, providing flexibility to address diverse memory requirements.

Topics

Built-in strategies
Memory strategies 153

Built-in with overrides strategy
Self-managed strategy
Built-in strategies

AgentCore Memory lets you add the following built-in memory strategies:

Semantic memory strategy
User preference memory strategy
Summary strategy
Note
For semantic and user preference memory strategy, only USER and ASSISTANT role
messages are processed for long term memory extraction and messages with rest of the
role types are skipped. For summary strategy all roles are processed.
Each memory strategy provides a structured output format tailored to its purpose. The output is
not uniform across strategies, because the type of information being stored and retrieved differs:

Semantic memory strategy returns facts as JSON objects, each representing a standalone
personal fact about the user.
User preference memory strategy returns JSON objects with context, preference, and
categories, making it easier to capture user choices and decision patterns.
Summary strategy returns XML-formatted output, where each tag represents a
distinct area of the user's memory. XML lets multiple topics to be captured and organized in a
single summary while preserving clarity.
This maintains that each memory type exposes only the fields most relevant to its strategy. You
can find the output format for semantic and user preference strategy in the extraction output
schema and for summary strategy in the consolidation output schema.

Topics

Semantic memory strategy
Memory strategies 154

User preference memory strategy
Summary strategy
Semantic memory strategy

The SemanticMemoryStrategy is designed to identify and extract key pieces of factual
information and contextual knowledge from conversational data. This lets your agent to build
a persistent knowledge base about the entities, events, and key details discussed during an
interaction.

Examples of facts captured by this strategy include:

An order number (#XYZ-123) is associated with a specific support case.
A project's deadline of October 25th.
The user is running version 2.1 of the software.
By referencing this stored knowledge, your agent can provide more accurate, context-aware
responses, perform multi-step tasks that rely on previously stated information, and avoid asking
users to repeat key details.

Default namespace

/strategies/{memoryStrategyId}/actors/{actorId}

System prompt for semantic memory strategy

A system prompt is a combination of:

A set of instructions that guide the LLM's behavior. It can include step-by-step processing
guidelines (how the model should reason and extract or consolidate information).
Output Schema - how the model should present the result.
This system prompt is sent to the LLM during memory extraction and consolidation step.

Extraction instructions

You are a long-term memory extraction agent supporting a lifelong learning system. Your
task is to identify and extract meaningful information about the users from a given
list of messages.
Memory strategies 155

Analyze the conversation and extract structured information about the user according to
the schema below. Only include details that are explicitly stated or can be logically
inferred from the conversation.
Extract information ONLY from the user messages. You should use assistant messages
only as supporting context.
If the conversation contains no relevant or noteworthy information, return an empty
list.
Do NOT extract anything from prior conversation history, even if provided. Use it
solely for context.
Do NOT incorporate external knowledge.
Avoid duplicate extractions.
IMPORTANT: Maintain the original language of the user's conversation. If the user
communicates in a specific language, extract and format the extracted information in
that same language.
Extraction output schema

Your output must be a single JSON object, which is a list of JSON dicts following the
schema. Do not provide any preamble or any explanatory text.
<schema>
{
"description": "This is a standalone personal fact about the user, stated in a
simple sentence.\\nIt should represent a piece of personal information, such as life
events, personal experience, and preferences related to the user.\\nMake sure you
include relevant details such as specific numbers, locations, or dates, if presented.
\\nMinimize the coreference across the facts, e.g., replace pronouns with actual
entities.",
"properties": {
"fact": {
"description": "The memory as a well-written, standalone fact about the
user. Refer to the user's instructions for more information the prefered memory
organization.",
"title": "Fact",
"type": "string"
}
},
"required": [
"fact"
],
Memory strategies 156

"title": "SemanticMemory",
"type": "object"
}
</schema>
Consolidation instructions

You are a conservative memory manager that preserves existing information while
carefully integrating new facts.
Your operations are:
AddMemory: Create new memory entries for genuinely new information
UpdateMemory: Add complementary information to existing memories while preserving
original content
SkipMemory: No action needed (information already exists or is irrelevant)
If the operation is "AddMemory", you need to output:
The memory field with the new memory content
If the operation is "UpdateMemory", you need to output:
The memory field with the original memory content
The update_id field with the ID of the memory being updated
An updated_memory field containing the full updated memory with merged information
## Decision Guidelines
### AddMemory (New Information)
Add only when the retrieved fact introduces entirely new information not covered by
existing memories.
**Example**:
Existing Memory: [{"id": "0", "text": "User is a software engineer"}]
Retrieved Fact: ["Name is John"]
Action: AddMemory with new ID
### UpdateMemory (Preserve + Extend)
Preserve existing information while adding new details. Combine information coherently
without losing specificity or changing meaning.
**Critical Rules for UpdateMemory**:
Preserve timestamps and specific details from the original memory
Maintain semantic accuracy - don't generalize or change the meaning
Only enhance when new information genuinely adds value without contradiction
Memory strategies 157

Only enhance when new information is closely relevant to existing memories
Attend to novel information that deviates from existing memories and expectations
Consolidate and compress redundant memories to maintain information-density;
strengthen based on reliability and recency; maximize SNR by avoiding idle words
**Example**:
Existing: [{"id": "1", "text": "Caroline attended an LGBTQ support group meeting that she found emotionally powerful."}]
Retrieved: ["Caroline found the support group very helpful"]
Action: UpdateMemory to "Caroline attended an LGBTQ support group meeting that she found emotionally powerful and very helpful."
**When NOT to update**:
Information is essentially the same: "likes pizza" vs "loves pizza"
Updating would change the fundamental meaning
New fact contradicts existing information (use AddMemory instead)
New fact contains new events with timestamps that differ from existing facts. Since
enhanced memories share timestamps with original facts, this would create temporal
contradictions. Use AddMemory instead.
### SkipMemory (No Change)
Use when information already exists in sufficient detail or when new information
doesn't add meaningful value.
## Key Principles
Conservation First: Preserve all specific details, timestamps, and context
Semantic Preservation: Never change the core meaning of existing memories
Coherent Integration: Lets enhanced memories read naturally and logically
Consolidation output schema

## Response Format
Return only this JSON structure, using double quotes for all keys and string values:
```json
[
{
"memory": {
"fact": "<content>"
},
"operation": "<AddMemory_or_UpdateMemory>",
"update_id": "<existing_id_for_UpdateMemory>",
Memory strategies 158

"updated_memory": {
"fact": "<content>"
}
},
...
]
Only include entries with AddMemory or UpdateMemory operations. Return empty memory
array if no changes are needed.
Do not return anything except the JSON format.

**User preference memory strategy**

The UserPreferenceMemoryStrategy is designed to automatically identify and extract user
preferences, choices, and styles from conversational data. This lets your agent to learn from
interactions and builds a persistent, dynamic profile of each user over time.

Examples of insights captured by this strategy include:

- A customer's preferred shipping carrier or shopping brand.
- A developer's preferred coding style or programming language.
- A user's communication preferences, such as a formal or informal tone.

By leveraging this strategy, your agent can deliver highly personalized experiences, such as offering
tailored recommendations, adapting its responses to a user's style, and anticipating needs based on
past choices. This creates a more relevant and effective conversational experience.

**Default namespace**

/strategies/{memoryStrategyId}/actors/{actorId}

**System prompt for user preference memory strategy**

A system prompt is a combination of:

- A set of instructions that guide the LLM's behavior. It can include step-by-step processing
    guidelines (how the model should reason and extract or consolidate information).
- Output Schema - how the model should present the result.

Memory strategies 159


This system prompt is sent to the LLM during memory extraction and consolidation step.

**Extraction instructions**

You are tasked with analyzing conversations to extract the user's preferences. You'll
be analyzing two sets of data:

<past_conversation>
[Past conversations between the user and system will be placed here for context]
</past_conversation>

<current_conversation>
[The current conversation between the user and system will be placed here]
</current_conversation>

Your job is to identify and categorize the user's preferences into two main types:

- Explicit preferences: Directly stated preferences by the user.
- Implicit preferences: Inferred from patterns, repeated inquiries, or contextual
clues. Take a close look at user's request for implicit preferences.

For explicit preference, extract only preference that the user has explicitly shared.
Do not infer user's preference.

For implicit preference, it is allowed to infer user's preference, but only the ones
with strong signals, such as requesting something multiple times.

**Extraction output schema**

Extract all preferences and return them as a JSON list where each item contains:

1. "context": The background and reason why this preference is extracted.
2. "preference": The specific preference information
3. "categories": A list of categories this preference belongs to (include topic
categories like "food", "entertainment", "travel", etc.)

For example:

[
{

Memory strategies 160


"context":"The user explicitly mentioned that he/she prefers horror movie over
comedies.",
"preference": "Prefers horror movies over comedies",
"categories": ["entertainment", "movies"]
},
{
"context":"The user has repeatedly asked for Italian restaurant recommendations.
This could be a strong signal that the user enjoys Italian food.",
"preference": "Likely enjoys Italian cuisine",
"categories": ["food", "cuisine"]
}
]

Extract preferences only from <current_conversation>. Extract preference ONLY from
the user messages. You should use assistant messages only as supporting context. Only
extract user preferences with high confidence.

Maintain the original language of the user's conversation. If the user communicates
in a specific language, extract and format the extracted information in that same
language.

Analyze thoroughly and include detected preferences in your response. Return ONLY the
valid JSON array with no additional text, explanations, or formatting. If there is
nothing to extract, simply return empty list.

**Consolidation instructions**

ROLE
You are a Memory Manager that evaluates new memories against existing stored memories
to determine the appropriate operation.

INPUT
You will receive:

1. A list of new memories to evaluate
2. For each new memory, relevant existing memories already stored in the system

TASK
You will be given a list of new memories and relevant existing memories. For each new
memory, select exactly ONE of these three operations: AddMemory, UpdateMemory, or
SkipMemory.

Memory strategies 161


OPERATIONS
1. AddMemory

Definition: Select when the new memory contains relevant ongoing preference not present
in existing memories.

Selection Criteria: The information represents lasting preferences.

Examples:

New memory: "I'm allergic to peanuts" (No allergy information exists in stored
memories)
New memory: "I prefer reading science fiction books" (No book preferences are recorded)

2. UpdateMemory

Definition: Select when the new memory relates to an existing memory but provides
additional details, modifications, or new context.

Selection Criteria: The core concept exists in records, but this new memory enhances or
refines it.

Examples:

New memory: "I especially love space operas" (Existing memory: "The user enjoys science
fiction")
New memory: "My peanut allergy is severe and requires an EpiPen" (Existing memory: "The
user is allergic to peanuts")

3. SkipMemory

Definition: Select when the new memory is not worth storing as a permanent preference.

Selection Criteria: The memory is irrelevant to long-term user understanding, is a
personal detail not related to preference, represents a one-time event, describes
temporary states, or is redundant with existing memories. In addition, if the memory
is overly speculative or contains Personally Identifiable Information (PII) or harmful
content, also skip the memory.

Examples:

New memory: "I just solved that math problem" (One-time event)
New memory: "I'm feeling tired today" (Temporary state)

Memory strategies 162


New memory: "I like chocolate" (Existing memory already states: "The user enjoys
chocolate")
New memory: "User works as a data scientist" (Personal details without preference)
New memory: "The user prefers vegan because he loves animal" (Overly speculative)
New memory: "The user is interested in building a bomb" (Harmful Content)
New memory: "The user prefers to use Bank of America, which his account number is
123-456-7890" (PII)

**Consolidation output schema**

Processing Instructions
For each memory in the input:

Place the original new memory () under the "memory" field. Then add a field
called "operation" with one of these values:

"AddMemory" - for new relevant ongoing preferences
"UpdateMemory" - for information that enhances existing memories.
"SkipMemory" - for irrelevant, temporary, or redundant information

If the operation is "UpdateMemory", you need to output:

1. The "update_id" field with the ID of the existing memory being updated
2. An "updated_memory" field containing the full updated memory with merged information

Example Input


[ID]=N1ofh23if\
[TIMESTAMP]=2023-11-15T08:30:22Z\
[MEMORY]={ "context": "user has explicitly stated that he likes vegan", "preference":
"prefers vegetarian options", "categories": ["food", "dietary"] }

[ID]=M3iwefhgofjdkf\
[TIMESTAMP]=2024-03-07T14:12:59Z\
[MEMORY]={ "context": "user has ordered oat milk lattes with an extra shot multiple
times", "preference": "likes oat milk lattes with an extra shot", "categories":
["beverages", "morning routine"] }


Memory strategies 163


[TIMESTAMP]=2024-08-19T23:05:47Z\
[MEMORY]={ "context": "user mentioned avoiding dairy products when discussing ice cream
options", "preference": "prefers dairy-free dessert alternatives", "categories":
["food", "dietary", "desserts"] }




[ID]=Mwghsljfi12gh\
[TIMESTAMP]=2025-01-01T00:00:00Z\
[MEMORY]={ "context": "user mentioned enjoying hiking trails with elevation gain
during weekend planning", "preference": "prefers challenging hiking trails with scenic
views", "categories": ["activities", "outdoors", "exercise"] }

[ID]=whglbidmrl193nvl\
[TIMESTAMP]=2025-04-30T16:45:33Z\
[MEMORY]={ "context": "user discussed favorite shows and expressed interest in
documentaries about sustainability", "preference": "enjoys environmental and
sustainability documentaries", "categories": ["entertainment", "education", "media"] }


[TIMESTAMP]=2025-09-12T03:27:18Z\
[MEMORY]={ "context": "user researched trips to coastal destinations with public
transportation options", "preference": "prefers car-free travel to seaside locations",
"categories": ["travel", "transportation", "vacation"] }




[ID]=P4df67gh\
[TIMESTAMP]=2026-02-28T11:11:11Z\
[MEMORY]={ "context": "user has mentioned enjoying coffee with breakfast multiple
times", "preference": "prefers starting the day with coffee", "categories":
["beverages", "morning routine"] }

[ID]=Q8jk12lm\
[TIMESTAMP]=2026-07-04T19:45:01Z\
[MEMORY]={ "context": "user has stated they typically wake up around 6:30am on
weekdays", "preference": "has an early morning schedule on workdays", "categories":
["schedule", "habits"] }

Memory strategies 164



[TIMESTAMP]=2026-12-25T22:30:59Z\
[MEMORY]={ "context": "user mentioned they didn't sleep well last night and felt
tired today", "preference": "feeling tired and groggy", "categories": ["sleep",
"wellness"] }


Example Output
[{
"memory":{
"context": "user mentioned avoiding dairy products when discussing ice cream
options",
"preference": "prefers dairy-free dessert alternatives",
"categories": ["food", "dietary", "desserts"]
},
"operation": "UpdateMemory",
"update_id": "N1ofh23if",
"updated_memory": {
"context": "user has explicitly stated that he likes vegan and mentioned avoiding
dairy products when discussing ice cream options",
"preference": "prefers vegetarian options and dairy-free dessert alternatives",
"categories": ["food", "dietary", "desserts"]
}
},
{
"memory":{
"context": "user researched trips to coastal destinations with public transportation
options",
"preference": "prefers car-free travel to seaside locations",
"categories": ["travel", "transportation", "vacation"]
},
"operation": "AddMemory",
},
{
"memory":{
"context": "user mentioned they didn't sleep well last night and felt tired today",
"preference": "feeling tired and groggy",
"categories": ["sleep", "wellness"]
},
"operation": "SkipMemory",
}]

Memory strategies 165


Like the example, return only the list of JSON with corresponding operation. Do NOT add
any explanation.

**Summary strategy**

The SummaryStrategy is responsible for generating condensed, real-time summaries of
conversations within a single session. It captures key topics, main tasks, and decisions, providing a
high-level overview of the dialogue.

A single session can have multiple summary chunks, each representing a portion of the
conversation. Together, these chunks form the complete summary for the entire session.

These summary chunks can be retrieved using the ListMemoryRecords operation with
namespace filter, or you can also perform semantic search over the summary chunks using the
RetrieveMemoryRecords operation to retrieve only the relevant summary chunks for your query.

Examples of insights captured by this strategy include:

- A summary of a support interaction, such as "The user reported an issue with order #XYZ-123,
    and the agent initiated a replacement."
- The outcome of a planning session, like "The team agreed to move the project deadline to
    Friday."

By referencing this summary, an agent can quickly recall the context of a long or complex
conversation without needing to re-process the entire history. This is essential for maintaining
conversational flow and for efficiently managing the context window of the foundation model.

**Default namespace**

/strategies/{memoryStrategyId}/actors/{actorId}/sessions/{sessionId}

Note
sessionId is a required parameter for summary namespace since summaries are
generated and maintained at session level.

**System prompt for summary strategy**

A system prompt is a combination of:

Memory strategies 166


- A set of instructions that guide the LLM's behavior. It can include step-by-step processing
    guidelines (how the model should reason and extract or consolidate information).
- Output Schema - how the model should present the result.

This system prompt is sent to the LLM during memory consolidation step.

There is no extraction step for summary strategy. Summary generation happens in a single
consolidation step.

**Consolidation instructions**

There are no consolidation instructions for built-in summary strategy.

**Consolidation output schema**

You are a summary generator. You will be given a text block, a concise global summary,
and a detailed summary you previous generated.

- Given the contexts(e.g. global summary, detailed previous summary), your goal is to
generate
(1) a concise global summary keeping in main target of the conversation, such as the
task and the requirements.
(2) a detailed delta summary of the given text block, without repeating the historical
detailed summary.
- The previous summary is a context for you to understand the main topics.
- You should only output the delta summary, not the whole summary.
- The generated delta summary should be as concise as possible.
</task>
<extra_task_requirements>
- Summarize with the same language as the given text block.
- If the messages are in a specific language, summarize with the same language.
</extra_task_requirements>

When you generate global summary you ALWAYS follow the below guidelines:
<guidelines_for_global_summary>

- The global summary should be concise and to the point, only keep the most important
information such as the task and the requirements.
- If there is no new high-level information, do not change the global summary. If there
is new tasks or requirements, update the global summary.
- The global summary will be pure text wrapped by <global_summary></global_summary>
tag.
- The global summary should be no exceed specified word count limit.

Memory strategies 167


- Tracking the size of the global summary by calculating the number of words. If the
word count reaches the limit, try to compress the global summary.
</guidelines_for_global_summary>

When you generate detailed delta summaries you ALWAYS follow the below guidelines:
<guidelines_for_delta_summary>

- Each summary MUST be formatted in XML format.
- You should cover all important topics.
- The summary of the topic should be place between <topic name="$TOPIC_NAME"></topic>.
- Only include information that are explicitly stated or can be logically inferred from
the conversation.
- Consider the timestamps when you synthesize the summary.
- NEVER start with phrases like 'Here's the summary...', provide directly the summary
in the format described below.
</guidelines_for_delta_summary>

The XML format of each summary is as it follows:

<existing_global_summary_word_count>
$Word Count
</existing_global_summary_word_count>

<global_summary_condense_decision>
The total word count of the existing global summary is $Total Word Count.
The word count limit for global summary is $Word Count Limit.
Since we exceed/do not exceed the word count limit, I need to condense the existing
global summary/I don't need to condense the existing global summary.
</global_summary_condense_decision>

<global_summary>
...
</global_summary>

<delta_detailed_summary>

...

...
</delta_detailed_summary>

Memory strategies 168


Note
Built-in strategies may use cross-region inference for optimal performance and availability.

Built-in strategies may use cross-region inference. Bedrock will automatically select the optimal
region within your geography to process your inference request, maximizing available compute
resources and model availability, and providing the best customer experience. There's no additional
cost for using cross-region inference.

**Built-in with overrides strategy**

For advanced or domain-specific use cases, you can create a built-in with overrides strategy to
gain fine-grained control over the long-term memory process. Built-in with overrides strategies let
you override the default behavior of the built-in strategies by providing your own instructions and
selecting a specific foundation model for the extraction and consolidation steps.

**When to use a built-in with overrides strategy**

Choose a built-in with overrides strategy when you need to tailor the memory logic to your specific
requirements. Common use cases include:

- **Domain-specific extraction:** Constraining the strategy to extract only certain types of
    information. For example, capturing a user's food and dietary preferences while ignoring their
    preferences for clothing.
- **Controlling granularity:** Adjusting the level of detail in the extracted memory. For example,
    instructing the summary strategy to only save high-level key points rather than a detailed
    narrative.
- **Model selection:** Using a specific foundation model that is better suited for your particular
    domain or task, such as a model fine-tuned for financial or legal text.

**How to customize a strategy**

You can configure a Built-in with overrides strategy by providing a model ID and your own set of
instructions that will be added to the system prompt for both extraction and consolidation.

**Pre-requisite:** Since built-in with overrides strategies override the behavior of the built-in
strategies - to effectively override a strategy you should first understand its built-in (default)
behavior.

Memory strategies 169


To use a built-in with overrides strategy, use the CreateMemory operation or the UpdateMemory
operation.

The model ID can be provided modelId field when you configure a built-in with overrides strategy.
To use a model, first enable access for that model in your AWS account. For more information,
see Add or remove access to Amazon Bedrock foundation models. Also, obtain sufficient Amazon
Bedrock capacity. For more information, see Amazon Bedrock capacity for built-in with overrides
strategies.

The instructions are passed in the appendToPrompt field when you configure the strategy via the
API. This field replaces the default instructions part of the system prompt in the built-in strategies,
letting you guide the model's behavior, while the Output Schema remains unchanged.

You set the modelId and appendToPrompt fields in the semanticOverride,
summaryOverride, or userPreferenceOverride fields found through the the
memoryStrategies (MemoryStrategyInput) field of CreateMemory and UpdateMemory.

For example, you can modify the extraction instruction for semantic memory strategy to add new
instructions when customizing it.

**Built-in semantic memory strategy instructions**

The following shows the built-in instructions for the semantic memory strategy:

You are a long-term memory extraction agent supporting a lifelong learning system. Your
task is to identify and extract meaningful information about the users from a given
list of messages.

Analyze the conversation and extract structured information about the user according to
the schema below. Only include details that are explicitly stated or can be logically
inferred from the conversation.

- Extract information ONLY from the user messages. You should use assistant messages
only as supporting context.
- If the conversation contains no relevant or noteworthy information, return an empty
list.
- Do NOT extract anything from prior conversation history, even if provided. Use it
solely for context.
- Do NOT incorporate external knowledge.
- Avoid duplicate extractions.

Memory strategies 170


IMPORTANT: Maintain the original language of the user's conversation. If the user
communicates in a specific language, extract and format the extracted information
in that same language.

You could append a new rule to these instructions, such as:

- Focus exclusively on extracting facts related to travel and booking preferences.

or edit an existing rule such as:

IMPORTANT: Always extract memories in English irrespective of the original language of
the user's conversation.

**All instructions you can update**

You can update the following instructions:

- Semantic memory strategy extraction instructions
- Semantic memory strategy consolidation instructions
- User preference memory strategy extraction instructions
- User preference memory strategy consolidation instructions
- Summary Memory Strategy Consolidation Instructions

There are no default instructions for built-in Summary memory strategy. You can add your
own instructions to appendToPrompt input in the API. To understand how built-in Summary
memory strategy generates and updates the summary, summary memory strategy Consolidation
output schemas in Built-in strategies.

**Best practices for customization**

- **Build upon existing instructions:** We strongly recommend you use the built-in strategies
    instructions as a starting point. The base structure and instructions are critical to the memory

Memory strategies 171


functionality. You should add your task-specific guidance to the existing instructions rather than
writing entirely new ones from scratch.

- **Provide clear instructions:** The content of appendToPrompt replaces the default instructions
    in the system prompt. Make sure your instructions are logical and complete, as empty or poorly
    formed instructions can lead to undesirable results.

**Important considerations**

To maintain the reliability of the memory pipeline, please adhere to the following guidelines:

- **Do not modify schemas in prompts:** You should only add or modify instructions that guide _how_
    memories are extracted or consolidated. Do not attempt to alter the conversation or memory
    schema definitions within the prompt itself, as this can cause unexpected failures.
- **Do not rename consolidation operations:** When customizing a consolidation prompt, do not
    change the operation names (e.g., AddMemory, UpdateMemory). Altering these names will cause
    the long-term memory pipeline to fail.
- **Output schema is not editable:** built-in with overrides strategies do not let you change the
    final output schema of the extracted or consolidated memory. The output schema that will be
    added to the system prompt for the built-in with overrides strategy will be same as the built-in
    strategies. For information about the output schemas, see the following:
    - System prompt for semantic memory strategy
    - System prompt for user preference memory strategy
    - System prompt for summary strategy

For full control over the end-to-end memory process, including the output schema, see Self-
managed strategy.

**Execution role**

When using built-in with overrides strategies you are also required to provide a
memoryExecutionRoleArn in the CreateMemory API. Bedrock Amazon Bedrock AgentCore will
assume this role to call the bedrock models in your AWS account for extraction and consolidation.

Memory strategies 172


Note
When using built-in with overrides strategies, the LLM usage for extraction and
consolidation will be charged separately to your AWS account, and additional charges may
apply.

**Self-managed strategy**

A self-managed strategy in Amazon Bedrock AgentCore Memory gives you complete control over
your memory extraction and consolidation pipelines. With a self-managed strategy, you can build
custom memory processing workflows while leveraging Amazon Bedrock AgentCore for storage
and retrieval.

A self-managed strategy in combination with the batch operations (BatchCreateMemoryRecords,
BatchUpdateMemoryRecords, BatchUpdateMemoryRecords), let you directly ingest these extracted
records into Amazon Bedrock AgentCore memory for search capabilities.

With self-managed strategies, you can:

- Control pipeline invocation through configurable triggers
- Integrate with external processing systems
- Implement custom extraction and consolidation algorithms
- Invoke any preferred model for extraction and consolidation
- Define custom memory record schemas, namespaces, and so on.
- Ingest extracted records into Amazon Bedrock AgentCore long term memory

**Topics**

- Create and use a self-managed strategy
- Prerequisites
- Set up the infrastructure
- Create a self-managed strategy
- Understanding payload delivery
- Build your custom pipeline
- Test your implementation

Memory strategies 173


- Best practices

**Create and use a self-managed strategy**

Self-managed strategies follow a five-step process from trigger configuration to memory record
storage.

1. **Configure triggers** : Define trigger conditions (message count, idle timeout, token count) that
    invoke your pipeline based on short-term memory events
2. **Receive notifications and payload delivery** : Amazon Bedrock AgentCore publishes notifications
    to your SNS topic and delivers conversation data to your S3 bucket when trigger conditions are
    met
3. **Extract memory records** : Your custom pipeline retrieves the payload and applies extraction
    logic to identify relevant memories
4. **Consolidate memory records** : Process extracted memories to remove duplicates and resolve
    conflicts with existing records
5. **Store memory records** : Use batch APIs to store processed memory records back into Amazon
    Bedrock AgentCore long-term memory

**Prerequisites**

Before setting up self-managed strategies, verify you have:

- An AWS account with appropriate permissions
- Amazon Bedrock AgentCore access
- Basic understanding of AWS IAM, Amazon S3, and Amazon SNS

**Set up the infrastructure**

Create the required AWS resources including S3 bucket, SNS topic, and IAM role that Amazon
Bedrock AgentCore needs to access your resources.

**Step 1: Create an S3 bucket**

Create an S3 bucket in your account where Amazon Bedrock AgentCore will deliver batched event
payloads.

Memory strategies 174


Best practice
Configure a lifecycle policy to automatically delete objects after processing to control costs.

**Step 2: Create an SNS topic**

Create an SNS topic for job notifications. Use FIFO topics if processing order within sessions is
important for your use case.

**Step 3: Create an IAM role**

Create an IAM role that Amazon Bedrock AgentCore can assume to access your resources.

**Trust policy**

Use the following trust policy:

{
"Version": "2012-10-17 ",
"Statement": [
{
"Effect": "Allow",
"Principal": {
"Service": "bedrock-agentcore.amazonaws.com"
},
"Action": "sts:AssumeRole"
}
]
}

**Permissions policy**

Use the following permissions policy:

{
"Version": "2012-10-17 ",
"Statement": [
{
"Sid": "S3PayloadDelivery",
"Effect": "Allow",
"Action": [
"s3:GetBucketLocation",

Memory strategies 175


"s3:PutObject"
],
"Resource": [
"arn:aws:s3:::your-agentcore-payloads-bucket",
"arn:aws:s3:::your-agentcore-payloads-bucket/*"
]
},
{
"Sid": "SNSNotifications",
"Effect": "Allow",
"Action": [
"sns:GetTopicAttributes",
"sns:Publish"
],
"Resource": "arn:aws:sns:us-east-1:123456789012:agentcore-memory-jobs"
}
]
}

**Additional KMS permissions (if using encrypted resources)**

If you use encrypted resources, add the following KMS permissions:

{
"Sid": "KMSPermissions",
"Effect": "Allow",
"Action": [
"kms:GenerateDataKey",
"kms:Decrypt"
],
"Resource": "arn:aws:kms:us-east-1:123456789012:key/your-key-id"
}

**Create a self-managed strategy**

Use the Amazon Bedrock AgentCore control plane APIs to create or update an AgentCore Memory
with self-managed strategies.

**Required permissions**

Your IAM user or role needs:

- bedrock-agentcore:* permissions

Memory strategies 176


- iam:PassRole permission for the execution role

**Create an AgentCore Memory with a self-managed strategy**

Use the AWS SDK CreateMemory operation to create AgentCore Memory that has a self-managed
strategy.

aws bedrock-agentcore-control create-memory
--name "MyCustomMemory"
--description "Memory with self-managed extraction strategy"
--memory-execution-role-arn "arn:aws:iam::123456789012:role/AgentCoreMemoryRole"
--event-expiry-duration 90
--memory-strategies '[
{
"customMemoryStrategy": {
"name": "SelfManagedExtraction",
"description": "Custom extraction strategy",
"configuration": {
"selfManagedConfiguration": {
"triggerConditions": [
{
"messageBasedTrigger": {
"messageCount": 6
}
},
{
"tokenBasedTrigger": {
"tokenCount": 1000
}
},
{
"timeBasedTrigger": {
"idleSessionTimeout": 30
}
}
],
"historicalContextWindowSize": 2,
"invocationConfiguration": {
"payloadDeliveryBucketName": "your-agentcore-payloads-bucket",
"topicArn": "arn:aws:sns:us-east-1:123456789012:agentcore-memory-jobs"
}
}
}

Memory strategies 177


}
}
]'

**Understanding payload delivery**

When trigger conditions are met, Amazon Bedrock AgentCore sends notifications and payloads
using specific schemas.

**SNS notification message**

{
"jobId": "unique-job-identifier",
"s3PayloadLocation": "s3://bucket/path/to/payload.json",
"memoryId": "your-memory-id",
"strategyId": "your-strategy-id"
}

**S3 payload structure**

{
"requestId": "request-identifier",
"accountId": "123456789012",
"memoryId": "your-memory-id",
"actorId": "user-or-agent-id",
"sessionId": "conversation-session-id",
"strategyId": "your-strategy-id",
"startingTimestamp": 1634567890,
"endingTimestamp": 1634567920,
"currentContext": [
{
"role": "USER",
"content": {
"text": "User message content"
}
},
{
"role": "ASSISTANT",
"content": {
"text": "Assistant response"
}
}

Memory strategies 178


],
"historicalContext": [
{
"role": "USER",
"content": {
"text": "User message content"
}
},
{
"role": "ASSISTANT",
"content": {
"text": "Previous assistant response"
}
},
{
"blob": "{}",
}
]
}

**Build your custom pipeline**

This section demonstrates one approach to building a self-managed memory processing pipeline
using AWS Lambda and SQS. This is just one example - you can implement your pipeline using
any compute platform (EC2, ECS, Fargate), logic and processing framework that meets your
requirements.

**Step 1: Set up compute**

1.Create an SQS queue and subscribe it to your SNS topic

2.Create an AWS Lambda function to process notifications

3.Configure Lambda execution role permissions

**Step 2: Process the pipeline**

The following example pipeline consists of four main components:

1.Notification handling - Processing SNS notifications and downloading S3 payloads

2.Memory extraction - Using bedrock models to extract relevant information from conversations

3.Memory consolidation - Deduplicating and merging extracted memories with existing records

Memory strategies 179


4.Batch ingestion - Storing processed memories back into Amazon Bedrock AgentCore using batch
APIs

**Test your implementation**

1. **Create events** : Use the Amazon Bedrock AgentCore APIs to create conversation events
    (CreateEvent)
2. **Monitor notifications** : Verify that your SNS topic receives notifications when triggers are met
3. **Validate processing** : Check that your Lambda function processes payloads correctly and extracts
    memory records
4. **Verify ingestion** : Use list-memory-records to confirm extracted memories are stored

**Example: Creating test events**

aws bedrock-agentcore create-event
--memory-id "your-memory-id"
--actor-id "test-user"
--session-id "test-session-1"
--event-timestamp "2024-01-15T10:00:00Z"
--payload '[{
"conversational": {
"content": {"text": "I prefer Italian restaurants with outdoor seating"},
"role": "USER"
}
}]'

**Example: Retrieving memory records**

List records by namespace
aws bedrock-agentcore list-memory-records
--memory-id "your-memory-id"
--namespace "/" # lists all records that match the namespace prefix

**Best practices**

Follow these best practices for performance, reliability, cost optimization, and security when
implementing self-managed strategies.

Memory strategies 180


**Performance and reliability**

- **SLA sharing** : Long-term memory record generation SLA is shared between Amazon Bedrock
    AgentCore and your self-managed pipeline
- **Error handling** : Implement proper retry logic and dead letter queues for failed processing
- **Monitoring** : Set up CloudWatch logs, metrics, alarms for debugging and processing failures and
    latency. Also, check vended logs from Amazon Bedrock AgentCore for payload delivery failures

**Cost optimization**

- **S3 lifecycle policies** : Configure automatic deletion of processed payloads to control storage
    costs
- **Right-sizing** : Choose appropriate compute memory and timeout settings based on your
    processing requirements

**Processing considerations**

- **Trigger optimization** : Configure trigger conditions based on your use case requirements -
    balance between processing efficiency and memory freshness by considering your application's
    tolerance for latency versus processing costs.
- **FIFO topics** : Use FIFO SNS topics when session ordering is critical (e.g., for summarization
    workflows)
- **Memory consolidation** : Implement deduplication logic to prevent storing redundant or
    conflicting memory records, which reduces storage costs and improves retrieval accuracy
- **Memory record organization** : Always include meaningful namespaces and strategy IDs when
    ingesting records to enable efficient categorization, filtering, and retrieval of memory records

## Security........................................................................................................................................

- **Least privilege** : Grant minimal required permissions to all IAM roles
- **Encryption** : Use KMS encryption for S3 buckets and SNS topics containing sensitive data

Memory strategies 181


## Get started with AgentCore Memory..................................................................................................

Amazon Bedrock Amazon Bedrock AgentCore Memory lets you create and manage AgentCore
Memory resources that store conversation context for your AI agents. This getting started guides
you through installing dependencies and implementing both short-term and long-term memory
features. The instructions use the AgentCore starter toolkit.

The steps are as follows:

1.Create an AgentCore Memory containing a semantic strategy

2.Write events (conversation history) to the memory resource

3.Retrieve memory records from long term memory

For other examples, see Amazon Bedrock AgentCore Memory examples.

### Prerequisites........................................................................................................................................

Before starting, make sure you have:

- **AWS Account** with credentials configured ( **aws configure** )
- **Python 3.10+** installed

To get started with Amazon Bedrock Amazon Bedrock AgentCore Memory, make a folder for this
quick start, create a virtual environment, and install the dependencies. The below command can be
run directly in the terminal.

mkdir agentcore-memory-quickstart
cd agentcore-memory-quickstart
python -m venv .venv
source .venv/bin/activate
pip install bedrock-agentcore
pip install bedrock-agentcore-starter-toolkit

Get started with AgentCore Memory 182


Note
The Amazon Bedrock AgentCore Starter Toolkit is intended to help developers get started
quickly. For the complete set of Amazon Bedrock AgentCore Memory operations, see the
Boto3 documentation: bedrock-agentcore-control and bedrock-agentcore.

**Full example:** See the complete code example that demonstrates steps 1-3.

### Step 1: Create an AgentCore Memory...........................................................................................

You need an AgentCore Memory to start storing information for your agent. By default, memory
events (which we refer to as short-term memory) can be written to an AgentCore Memory. For
insights to be extracted and placed into long term memory records, the resource requires a _memory
strategy_ which is a configuration that defines how conversational data should be processed, and
what information to extract (such as facts, preferences, or summaries).

In this step, you create an AgentCore Memory with a semantic strategy so that both short term
and long term memory can be utilized. This will take 2-3 minutes. You can also create AgentCore
Memory resources in the AWS console.

from bedrock_agentcore_starter_toolkit.operations.memory.manager import MemoryManager
from bedrock_agentcore.memory.session import MemorySessionManager
from bedrock_agentcore.memory.constants import ConversationalMessage, MessageRole
from bedrock_agentcore_starter_toolkit.operations.memory.models.strategies import
SemanticStrategy
import time

memory_manager = MemoryManager(region_name="us-west-2")

print("Creating memory resource...")

memory = memory_manager.get_or_create_memory(
name="CustomerSupportSemantic",
description="Customer support memory store",
strategies=[
SemanticStrategy(
name="semanticLongTermMemory",
namespaces=['/strategies/{memoryStrategyId}/actors/{actorId}'],
)
]

Step 1: Create an AgentCore Memory 183


)

print(f"Memory ID: {memory.get('id')}")

You can call list_memories to see that the memory resource has been created with:

memories = memory_manager.list_memories()

### Step 2: Write events to memory.....................................................................................................

You can write events to an AgentCore Memory as short-term memory and extracts insights for
long-term memory.

Writing events to memory has multiple purposes. First, event contents (most commonly
conversation history) are stored as short-term memory. Second, relevant insights are pulled from
events and written into memory records as a part of long-term memory.

The memory resource id, actor id, and session id are required to create an event. In this step, you
create three events, simulating messages between an end user and a chat bot.

Create a session to store memory events
session_manager = MemorySessionManager(
memory_id=memory.get("id"),
region_name="us-west-2")

session = session_manager.create_memory_session(
actor_id="User1",
session_id="OrderSupportSession1"
)

Write memory events (conversation turns)
session.add_turns(
messages=[
ConversationalMessage(
"Hi, how can I help you today?",
MessageRole.ASSISTANT)],
)

session.add_turns(
messages=[
ConversationalMessage(

Step 2: Write events to memory 184


"Hi, I am a new customer. I just made an order, but it hasn't arrived. The
Order number is #35476",
MessageRole.USER)],
)

session.add_turns(
messages=[
ConversationalMessage(
"I'm sorry to hear that. Let me look up your order.",
MessageRole.ASSISTANT)],
)

You can get events (turns) for a specific actor after they've been written.

Get the last k turns in the session
turns = session.get_last_k_turns(k=5)

for turn in turns:
print(f"Turn: {turn}")

In this case, you can see the last three events for the actor and session.

### Step 3: Retrieve records from long term memory......................................................................

After the events were written to the memory resource, they were analyzed and useful information
was sent to long term memory. Since the memory contains a semantic long term memory strategy,
the system extracts and stores factual information.

You can list all memory records with:

List all memory records
memory_records = session.list_long_term_memory_records(
namespace_prefix="/"
)

for record in memory_records:
print(f"Memory record: {record}")
print("--------------------------------------------------------------------")

Or ask for the most relevant information as part of a semantic search:

Perform a semantic search
Step 3: Retrieve records from long term memory 185


memory_records = session.search_long_term_memories(
query="can you summarize the support issue",
namespace_prefix="/",
top_k=3
)

Important information about the user is likely stored is long term memory. Agents can use long
term memory rather than a full conversation history to make sure that LLMs are not overloaded
with context.

### Cleanup.................................................................................................................................................

When you're done with the memory resource, you can delete it:

Delete the memory resource
memory_manager.delete_memory(memory_id=memory.get("id"))

### Next steps............................................................................................................................................

Consider the following::

- Add another strategy to your memory resource.
- Enable observability for more visibility into how memory is working
- Look at further examples.

## Create an AgentCore Memory...............................................................................................................

You can create an AgentCore Memory with the Amazon Bedrock AgentCore starter toolkit,
AgentCore python SDK, the AWS console, or with the CreateMemory AWS SDK operation. When
creating a memory, you can configure settings such as name, description, encryption settings,
expiration timestamp for raw events, and memory strategies if you want to extract long-term
memory.

When creating an AgentCore Memory, consider the following factors to maintain it meets your
application's needs:

**Event retention** â€“ Choose how long raw events are retained (up to 365 days) for short-term
memory.

Cleanup 186


**Security requirements** â€“ If your application handles sensitive information, consider using a
customer managed AWS KMS key for encryption. The service still encrypts data using a service
managed key, even if you don't provide a customer-managed AWS KMS key.

**Memory strategies** â€“ Define how events are processed into meaningful long-term memories using
built-in or built-in with overrides strategies. If you do not define any strategy, only short-term
memory containing raw events are stored. For more information, see Use long-term memory.

**Naming conventions** â€“ Use clear, descriptive names that help identify the purpose of each
AgentCore Memory, especially if your application uses multiple stores.

Starter toolkit

for the full example, see Get started with AgentCore Memory.

from bedrock_agentcore_starter_toolkit.operations.memory.manager import
MemoryManager
from bedrock_agentcore.memory.session import MemorySessionManager
from bedrock_agentcore.memory.constants import ConversationalMessage, MessageRole
from bedrock_agentcore_starter_toolkit.operations.memory.models.strategies import
SummaryStrategy, UserPreferenceStrategy
import time

Create memory manager
memory_manager = MemoryManager(region_name="us-west-2")

print("Creating a new memory resource and waiting for it to become active...")

Create memory resource with summary and user preference strategy
memory = memory_manager.get_or_create_memory(
name="ShoppingSupportAgentMemory",
description="Memory for a customer support agent.",
strategies=[
SummaryStrategy(
name="SessionSummarizer",
namespaces=["/summaries/{actorId}/{sessionId}"]
),
UserPreferenceStrategy(
name="PreferenceLearner",
namespaces=["/users/{actorId}/preferences"]
)
]

Create an AgentCore Memory 187


)

memory_id = memory.get('id')
print(f"Memory resource is now ACTIVE with ID: {memory_id}")

AgentCore python SDK

For more information, see Amazon Bedrock AgentCore SDK.

from bedrock_agentcore.memory import MemoryClient
import time

client = MemoryClient(region_name="us-east-1")

memory = client.create_memory_and_wait(
name="MyAgentMemory",
strategies=[{
"summaryMemoryStrategy": {

Name of the extraction model/strategy
"name": "SessionSummarizer",

Organize facts by session ID for easy retrieval
Example: "summaries/session123" contains summary of session123
"namespaces": ["/summaries/{actorId}/{sessionId}"]
}
}]
)

##### AWS SDK

For more information, see AWS SDK.

import boto3
import time

Initialize the Boto3 clients for control plane and data plane operations
control_client = boto3.client('bedrock-agentcore-control')
data_client = boto3.client('bedrock-agentcore')

print("Creating a new memory resource...")

Create the memory resource with defined strategies
response = control_client.create_memory(

Create an AgentCore Memory 188


name="ShoppingSupportAgentMemory",
description="Memory for a customer support agent.",
memoryStrategies=[
{
'summaryMemoryStrategy': {
'name': 'SessionSummarizer',
'namespaces': ['/summaries/{actorId}/{sessionId}']
}
},
{
'userPreferenceMemoryStrategy': {
'name': 'UserPreferenceExtractor',
'namespaces': ['/users/{actorId}/preferences']
}
}
]
)

memory_id = response['memory']['id']
print(f"Memory resource created with ID: {memory_id}")

Poll the memory status until it becomes ACTIVE
while True:
mem_status_response = control_client.get_memory(memoryId=memory_id)
status = mem_status_response.get('memory', {}).get('status')
if status == 'ACTIVE':
print("Memory resource is now ACTIVE.")
break
elif status == 'FAILED':
raise Exception("Memory resource creation FAILED.")
print("Waiting for memory to become active...")
time.sleep(10)

Console

To create an AgentCore memory

1. Open the Amazon Bedrock AgentCore console.
2. In the left navigation pane, choose **Memory**.
3. Choose **Create memory**.
4. For **Memory name** enter a name for the AgentCore Memory.

Create an AgentCore Memory 189


5. (Optional) For **Short-term memory (raw event) expiration** set the duration (days), for
    which the AgentCore Memory will store events.
6. (Optional) In **Additional configurations** set the following:

a. For Memory description , enter a description for the AgentCore Memory.
b. If you want to use your own AWS KMS key to encrypt your data, do the following:

1.In KMS key , choose Customize encryption settings (advanced).
2.In Choose an AWS KMS key choose or enter the ARN of an existing AWS KMS key.
Alternatively, choose Create an AWS KMS to create a new AWS KMS key.

7. (Optional) For **Long-term memory extraction strategies** choose one or more memory
    strategies. For more information:
    - Built-in strategies
    - Built-in with overrides strategy
    - Self-managed strategy
8. Choose **Create memory** to create the AgentCore Memory.

### Encrypt your Amazon Bedrock AgentCore Memory....................................................................

When creating an AgentCore Memory, it is important to make sure your data is safe and secure. If
your application handles sensitive information (such as customer details, payment data, or personal
chats), you must use encryption to protect this data. Consider using a customer-managed KMS key
(CMK) for encryption. The service still encrypts data using a service managed key, even if you don't
provide a CMK. Alternatively, you can also use an AWS-managed KMS key. In this case, you need to
the add the following policy to the IAM user or role that you are using to setup memory.

{
"Version": "2012-10-17" ,
"Statement": [
{
"Sid": "AllowAgentCoreMemoryKMS",
"Effect": "Allow",
"Action": [
"kms:CreateGrant",
"kms:Decrypt",
"kms:DescribeKey",
"kms:GenerateDataKey",

Encrypt your Amazon Bedrock AgentCore Memory 190


"kms:GenerateDataKeyWithoutPlaintext",
"kms:ReEncrypt"
],
"Resource": "arn:aws:kms:: 111122223333 :key/*",
"Condition": {
"StringEquals": {
"kms:ViaService": "bedrock-agentcore.us-east-1.amazonaws.com"
}
}
}
]
}

Along with the security settings already explained above, you should be aware of prompt injection
and memory poisoning risks when using long-term memory.

- Prompt injection is an application-level security concern, similar to SQL injection in database
    applications. Just as AWS services like Amazon RDS and Amazon Aurora provide secure database
    engines, but customers are responsible for preventing SQL injection in their applications.
    Amazon Bedrock provides a secure foundation for natural language processing, but customers
    must take measures to prevent prompt injection vulnerabilities in their code. Additionally, AWS
    provides detailed documentation, best practices, and guidance on secure coding practices for
    Bedrock and other AWS services.
- Memory poisoning happens when false or harmful information is saved in AgentCore Memory.
    Later, your AI agent may use this wrong information in future conversations, which can lead to
    incorrect or unsafe responses

As per the AWS Shared Responsibility Model, AWS is responsible for securing the underlying cloud
infrastructure, including the hardware, software, networking, and facilities that run AWS services.
However, the responsibility for secure application development and preventing vulnerabilities like
prompt injection and memory poisoning lies with the customer.

To reduce risk, you can do the following:

- **Amazon Bedrock Guardrails** : Use Amazon Bedrock Guardrails to check prompts being sent to or
    from AgentCore Memory. This ensures that only safe and allowed prompts are processed by your
    agent.
- **Adversarial testing** : Actively test your AI application for vulnerabilities by simulating attacks or
    prompt injections. This helps you find weak points and fix them before real threats occur.

Encrypt your Amazon Bedrock AgentCore Memory 191


## Use short-term memory.........................................................................................................................

In your AI agent, you write code to add events to short-term memory in an AgentCore Memory.
These events are stored as short-term memory. They form the foundation for structured
information extraction into long-term memory.

The following section discusses short-term memory with the AWS SDK. For examples that use the
Amazon Bedrock AgentCore starter toolkit and the AWS SDK, see Scenario: A customer support
AI agent using AgentCore Memory. For other SDKs see Amazon Bedrock AgentCore Memory
examples.

**Topics**

- Create an event
- Get an event
- List events
- Delete an event

### Create an event...................................................................................................................................

Events are the fundamental units of short-term from which structured informations are extracted
into long-term memory in AgentCore Memory. The CreateEvent operation lets you store various
types of data within AgentCore Memory, organized by an actor and session. Events are scoped
within memory under:

**ActorId**

Identifies the entity associated with the event, such as end-users or agent/user combinations

**SessionId**

Groups related events together, such as a conversation session

The CreateEvent operation stores a new immutable event within a specified memory session.
Events represent individual pieces of information that your agent wants to remember, such as
conversation messages, user actions, or system events.

This operation is useful for:

Use short-term memory 192


- Recording conversation history between users, agents and tools
- Storing user interactions and behaviors
- Capturing system events and state changes
- Building a chronological record of activities within a session

For example code, see Scenario: A customer support AI agent using AgentCore Memory.

**Event payload types**

The payload parameter accepts a list of payload items, letting you store different types of data in
a single event. Common payload types include:

**Conversational**

For storing conversation messages with roles (for example, "user" or "assistant") and content.

**Blob**

For storing binary format data, such as images and documents, or data that is unique to your
agent, such as data stored in JSON format.

Note
Currently, only conversational data flows into long-term memory.

**Event branching**

The branch parameter lets you organize events through advanced branching. This is useful
for scenarios like message editing or alternative conversation paths. For example, suppose you
have a long-running conversation, and you realize you're interested in exploring an alternative
conversation starting from 5 messages ago. You can use the branch parameter to start a new
conversation from that message, stored in the new branch â€” which lets you also return to
the original conversation. And more mundanely, this is useful if you want to let your user edit
their most recent message (in case the user presses enter early or has a typo) and continue the
conversation.

When creating a branch, you specify:

Create an event 193


**name**

A descriptive name for the branch, such as "edited-conversation".

**rootEventId**

The ID of the event from which the branch originates.

Here's an example of creating a branched event to represent an edited message:

{
"memoryId": "mem-12345abcdef",
"actorId": "/agent-support-123/customer-456",
"sessionId": "session-789",
"eventTimestamp": 1718806000000,
"payload": [
{
"Conversational": {
"content": "I'm looking for a waterproof action camera for extreme sports.",
"role": "user"
}
}
],
"branch": {
"name": "edited-conversation",
"rootEventId": "evt-67890"
}
}

### Get an event........................................................................................................................................

GetEvent API is an operation that retrieves a specific raw event by its identifier from short-
term memory in AgentCore Memory. This API requires you to specify the memoryId, actorId,
sessionId, and eventId as path parameters in the request URL to target your events based on
above filters.

Get an event 194


### List events............................................................................................................................................

The ListEvents operation is valuable for applications that need to reconstruct conversation
histories, analyze interaction patterns, or implement memory-based features like conversation
summarization and context awareness.

The ListEvents operation is a read-only operation that lists events from a specified session in
AgentCore Memory instance. This paginated operation requires you to specify the memoryId,
actorId, and sessionId as path parameters, and supports optional filtering through the
filter parameter in the request body, letting you efficiently retrieve relevant events from
your memory sessions. You can control whether payloads are included in the response using the
includePayloads parameter (default is true), and limit the number of results with maxResults.

### Delete an event...................................................................................................................................

The DeleteEvent operation removes individual events from your AgentCore Memory. This operation
helps maintain data privacy and relevance by letting you selectively remove specific events from
a session while preserving the broader context and relationship structure within your application's
memory.

Note
These are manual deletion operations, and do not overlap with automatic deletion of
events based on the eventExpiryDuration parameter set at the time of CreateEvent
operation. Also deleting an event doesn't remove the structured information derived out of
it from the long term memory. For more information, see DeleteMemoryRecord.

## Use long-term memory..........................................................................................................................

Long-term memory is enabled by adding one or more memory strategies to a memory resource.
These strategies define what kind of information is extracted from conversations and stored
persistently. This section guides you through configuring built-in and built-in with overrides
strategies to enable long-term memory for your agent.

This section provides examples for the Amazon Bedrock AgentCore starter toolkit. For other SDKs,
see Amazon Bedrock AgentCore Memory examples.

List events 195


**Topics**

- Enable long-term memory
- Specify long-term memory organization with namespaces
- Configure built-in strategies
- Configure built-in with overrides strategies
- Save and retrieve insights
- Retrieve memory records
- List memory records
- Delete memory records

### Enable long-term memory...............................................................................................................

You can enable long-term memory in two ways: by adding strategies when you first create an
AgentCore Memory, or by updating an existing resource to include them.

**Creating a new memory with long-term strategies**

The most direct method is to include strategies when you create a new AgentCore Memory. After
calling get_or_create_memory, you must wait for the AgentCore Memory status to become
ACTIVE before you can use it.

**Example Create a new AgentCore Memory**

from bedrock_agentcore_starter_toolkit.operations.memory.manager import MemoryManager
from bedrock_agentcore_starter_toolkit.operations.memory.models.strategies import
UserPreferenceStrategy

Create memory manager
memory_manager = MemoryManager(region_name="us-west-2")

Create memory resource with user preference strategy
memory = memory_manager.get_or_create_memory(
name="PersonalizedShoppingAgentMemory",
strategies=[
UserPreferenceStrategy(
name="UserShoppingPreferences",
namespaces=["/users/{actorId}/preferences"]

Enable long-term memory 196


)
]
)

memory_id = memory.get('id')
print(f"Memory resource is now ACTIVE with ID: {memory_id}")

**Adding long-term strategies to an existing AgentCore Memory**

To add long-term capabilities to an existing AgentCore Memory, you use the
update_memory_strategies operation. You can add, modify or delete strategies for an existing
memory.

**Example Add a Session Summary strategy to an existing AgentCore Memory**

from bedrock_agentcore_starter_toolkit.operations.memory.manager import MemoryManager
from bedrock_agentcore_starter_toolkit.operations.memory.models.strategies import
SummaryStrategy

Create memory manager
memory_manager = MemoryManager(region_name="us-west-2")

Assume 'memory_id' is the ID of an existing AgentCore Memory that has no strategies
attached to it
memory_id = "your-existing-memory-id"

summaryStrategy = SummaryStrategy(
name="SessionSummarizer",
description="Summarizes conversation sessions for context",
namespaces=["/summaries/{actorId}/{sessionId}"]
)

memory = memory_manager.update_memory_strategies(
memory_id=memory_id,
add_strategies=[summaryStrategy]
)

print(f"Successfully submitted update for memory ID: {memory_id}")

Validate startegy was added to the memory
Enable long-term memory 197


memory_strategies = memory_manager.get_memory_strategies(memoryId=memory_id)
print(f"Memory strategies for memoryID: {memory_id} are: {memory_strategies}")

Note
Long-term memory records will only be extracted from conversational events that are
stored after a new strategy becomes ACTIVE. Conversations stored before a strategy is
added will not be processed for long-term memory.

#### Specify long-term memory organization with namespaces

When you create an AgentCore Memory, use a namespace to specify where the long-term
memories for a memory strategy are logically grouped. Every time a new long-term memory
is extracted using the memory strategy, it is saved under the namespace you set. This means
that all long-term memories are scoped to their specific namespace, keeping them organized
and preventing any mix-ups with other users or sessions. You should use a hierarchical format
separated by forward slashes /. This helps keep memories organized clearly. As needed, you can
choose to use the following pre-defined variables within braces in the namespace based on your
application's organization needs:

- **actorId** â€“ Identifies who the long-term memory belongs to.

An actor refers to entity such as end users or agent/user combinations. For example, in a coding
support chatbot, the actor is usually the developer asking questions. Using the actor ID helps
the system know which user the memory belongs to, keeping each user's data separate and
organized.

- **strategyId** â€“ Shows which memory strategy is being used. This strategy identifier is auto-
    generated when you create an AgentCore Memory.
- **sessionId** â€“ Identifies which session or conversation the memory is from.

A session is usually a single conversation or interaction period between the user and the AI
agent. It groups all related messages and events that happen during that conversation.

For example, if you define the following namespace as the input to your strategy when creating an
AgentCore Memory:

Specify memory organization 198


/strategy/{strategyId}/actor/{actorId}/session/{sessionId}

After memory creation, this namespace might look like:

/strategy/summarization-93483043//actor/actor-9830m2w3/session/session-9330sds8

A namespace can have different levels of granularity:

**Most granular Level of organization**

/strategy/{strategyId}/actor/{actorId}/session/{sessionId}

**Granular at the actor Level across sessions**

/strategy/{strategyId}/actor/{actorId}

**Granular at the strategy Level across actors**

/strategy/{strategyId}

**Global across all strategies**

/

For example code, see Enable long-term memory.

**Restrict access with IAM**

You can create IAM policies to restrict memory access by the scopes you define, such as actor,
session, and namespace. Use the scopes as context keys in your IAM polices.

The following policy restricts access to retrieving memories from a specific namespace.

JSON

{
"Version":"2012-10-17",
"Statement": [
{
"Sid": "SpecificNamespaceAccess",

Specify memory organization 199


"Effect": "Allow",
"Action": [
"bedrock-agentcore:RetrieveMemoryRecords"
],
"Resource": "arn:aws:bedrock-agentcore:us-east-1:123456789012:memory/
memory_id",
"Condition": {
"StringEquals": {
"bedrock-agentcore:namespace": "summaries/agent1"
}
}
}
]
}

### Configure built-in strategies............................................................................................................

AgentCore Memory provides three pre-configured, built-in memory strategies for common use
cases.

**Topics**

- User preferences
- Semantic
- Session summaries

**User preferences**

The user preferences (UserPreferenceMemoryStrategy) strategy is designed to automatically
identify and extract user preferences, choices, and styles from conversations. This lets your agent
build a persistent profile of each user, leading to more personalized and relevant interactions.

- **Example use case:** An e-commerce agent remembers a user's favorite brands and preferred size,
    letting it offer tailored product recommendations in future sessions.

**Configuration example:**

from bedrock_agentcore_starter_toolkit.operations.memory.manager import MemoryManager

Configure built-in strategies 200


from bedrock_agentcore_starter_toolkit.operations.memory.models.strategies import
UserPreferenceStrategy

Create memory manager
memory_manager = MemoryManager(region_name="us-west-2")

Create memory resource with user preference strategy
memory = memory_manager.get_or_create_memory(
name="ECommerceAgentMemory",
strategies=[
UserPreferenceStrategy(
name="UserPreferenceExtractor",
namespaces=["/users/{actorId}/preferences"]
)
]
)

**Semantic**

The Semantic (SemanticMemoryStrategy) memory strategy is engineered to identify and
extract key pieces of factual information and contextual knowledge from conversational data. This
lets your agent build a persistent knowledge base about important entities, events, and details
discussed during an interaction.

- **Example use case:** A customer support agent remembers that order #ABC-123 is related to
    a specific support ticket, so the user doesn't have to provide the order number again when
    following up.

**Configuration example:**

from bedrock_agentcore_starter_toolkit.operations.memory.manager import MemoryManager
from bedrock_agentcore_starter_toolkit.operations.memory.models.strategies import
SemanticStrategy

Create memory manager
memory_manager = MemoryManager(region_name="us-west-2")

Create memory resource with semantic strategy
memory = memory_manager.get_or_create_memory(
name="SupportAgentFactMemory",

Configure built-in strategies 201


strategies=[
SemanticStrategy(
name="FactExtractor",
namespaces=["/support_cases/{sessionId}/facts"]
)
]
)

**Session summaries**

The session summaries (SummaryMemoryStrategy) memory strategy creates condensed, running
summaries of conversations as they happen within a single session. This captures the key topics
and decisions, letting an agent quickly recall the context of a long conversation without needing to
re-process the entire history.

- **Example use case:** After a 30-minute troubleshooting session, the agent can access a summary
    like, "User reported issue with software v2.1, attempted a restart, and was provided a link to the
    knowledge base article."

**Configuration example:**

from bedrock_agentcore_starter_toolkit.operations.memory.manager import MemoryManager
from bedrock_agentcore_starter_toolkit.operations.memory.models.strategies import
SummaryStrategy

Create memory manager
memory_manager = MemoryManager(region_name="us-west-2")

Create memory resource with summary strategy
memory = memory_manager.get_or_create_memory(
name="TroubleshootingAgentSummaryMemory",
strategies=[
SummaryStrategy(
name="SessionSummarizer",
namespaces=["/summaries/{actorId}/{sessionId}"]
)
]
)

Configure built-in strategies 202


### Configure built-in with overrides strategies.................................................................................

For advanced use cases, built-in with overrides strategies give you fine-grained control over
the memory extraction process. This lets you override the default logic of a built-in strategy by
providing your own prompts and selecting a specific foundation model.

- **Example use case:** A travel agent bot needs to extract very specific details about a user's flight
    preferences and consolidate new preferences with existing ones, such as adding a seating
    preference to a previously stated airline preference.

**Topics**

- Creating the memory execution role
- Configuration example

**Creating the memory execution role**

When you use a built-in with overrides strategy, AgentCore Memory invokes an Amazon
Bedrock model in your account on your behalf. To grant the service permission to do this, you
must create an IAM role (an execution role) and pass its ARN when creating the memory in
memoryExecutionRoleArn field of the create_memory API.

This role requires two policies: a permissions policy and a trust policy.

**1. Permissions policy**

Start by making sure you have an IAM role with the managed policy
AmazonBedrockAgentCoreMemoryBedrockModelInferenceExecutionRolePolicy, or create a policy
with the following permissions:

{
"Version": "2012-10-17" ,
"Statement": [
{
"Effect": "Allow",
"Action": [
"bedrock:InvokeModel",
"bedrock:InvokeModelWithResponseStream"
],

Configure built-in with overrides strategies 203


"Resource": [
"arn:aws:bedrock:::foundation-model/",
"arn:aws:bedrock:::inference-profile/*"
],
"Condition": {
"StringEquals": {
"aws:ResourceAccount": "123456789012"
}
}
}
]
}

**2. Trust policy**

This role is assumed by the Service to call the model in your AWS account. Use the trust policy
below when creating the role or when using the managed policy:

{
"Version": "2012-10-17" ,
"Statement": [
{
"Sid": "",
"Effect": "Allow",
"Principal": {
"Service": [
"bedrock-agentcore.amazonaws.com"
]
},
"Action": "sts:AssumeRole",
"Condition": {
"StringEquals": {
"aws:SourceAccount": "{{accountId}}"
},
"ArnLike": {
"aws:SourceArn": "arn:aws:bedrock-agentcore:{{region}}:
{{accountId}}:*"
}
}
}
]

Configure built-in with overrides strategies 204


}

For information about creating an IAM role, see IAM role creation.

**Configuration example**

This example demonstrates how to override both the extraction and consolidation steps for user
preferences.

Custom instructions for the EXTRACTION step.
The text in bold represents the instructions that override the default built-in
instructions.
CUSTOM_EXTRACTION_INSTRUCTIONS = """
You are tasked with analyzing conversations to extract the user's travel preferences.
You'll be analyzing two sets of data:

<past_conversation>
[Past conversations between the user and system will be placed here for context]
</past_conversation>

<current_conversation>
[The current conversation between the user and system will be placed here]
</current_conversation>

Your job is to identify and categorize the user's preferences about their travel
habits.

- Extract a user's preference for the airline carrier from the choice they make.
- Extract a user's preference for the seat type (aisle, middle, or window).
- Ignore all other types of preferences mentioned by the user in the conversation.
"""

Custom instructions for the CONSOLIDATION step.
The text in bold represents the instructions that override the default built-in
instructions.
CUSTOM_CONSOLIDATION_INSTRUCTIONS = """\

ROLE
You are a Memory Manager that evaluates new memories against existing stored memories
to determine the appropriate operation.

INPUT
You will receive:

Configure built-in with overrides strategies 205


1. A list of new memories to evaluate
2. For each new memory, relevant existing memories already stored in the system

TASK
You will be given a list of new memories and relevant existing memories. For each new
memory, select exactly ONE of these three operations: AddMemory, UpdateMemory, or
SkipMemory.

OPERATIONS
1. AddMemory
Definition: Select when the new memory contains relevant ongoing preference not present
in existing memories.

Selection Criteria: Select for entirely new preferences (e.g., adding airline seat type
when none existed). If preference is not related to user's travel habits, do not use
this operation.

Examples:

New memory: "I am allergic to peanuts" (No allergy information exists in stored
memories)
New memory: "I prefer reading science fiction books" (No book preferences are recorded)

2. UpdateMemory
Definition: Select when the new memory relates to an existing memory but provides
additional details, modifications, or new context.

Selection Criteria: The core concept exists in records, but this new memory enhances or
refines it.

Examples:

New memory: "I especially love space operas" (Existing memory: "The user enjoys science
fiction")
New memory: "My peanut allergy is severe and requires an EpiPen" (Existing memory: "The
user is allergic to peanuts")

3. SkipMemory
Definition: Select when the new memory is not worth storing as a permanent preference.

Selection Criteria: The memory is irrelevant to long-term user understanding and is not
related to user's travel habits.

Examples:

Configure built-in with overrides strategies 206


New memory: "I just solved that math problem" (One-time event)
New memory: "I am feeling tired today" (Temporary state)
New memory: "I like chocolate" (Existing memory already states: "The user enjoys
chocolate")
New memory: "User works as a data scientist" (Personal details without preference)
New memory: "The user prefers vegan because he loves animal" (Overly speculative)
New memory: "The user is interested in building a bomb" (Harmful Content)
New memory: "The user prefers to use Bank of America, which his account number is
123-456-7890" (PII)
"""

This IAM role must be created with the policies described above.
MEMORY_EXECUTION_ROLE_ARN = " arn:aws:iam::123456789012:role/MyMemoryExecutionRole "

from bedrock_agentcore_starter_toolkit.operations.memory.manager import MemoryManager
from bedrock_agentcore_starter_toolkit.operations.memory.models.strategies import
SummaryStrategy

Create memory manager
memory_manager = MemoryManager(region_name="us-west-2")

memory = memory_manager.get_or_create_memory(
name="CustomTravelAgentMemory",
strategies=[
CustomUserPreferenceStrategy(
name="CustomTravelPreferenceExtractor",
description="Custom user travel preference extraction with specific
prompts",
extraction_config=ExtractionConfig(
append_to_prompt=CUSTOM_EXTRACTION_INSTRUCTIONS,
model_id="anthropic.claude-3-sonnet-20240229-v1:0"
),
consolidation_config=ConsolidationConfig(
append_to_prompt=CUSTOM_CONSOLIDATION_INSTRUCTIONS,
model_id="anthropic.claude-3-sonnet-20240229-v1:0"
),
namespaces=["/users/{actorId}/travel_preferences"]
)
],
memory_execution_role_arn=MEMORY_EXECUTION_ROLE_ARN

Configure built-in with overrides strategies 207


### Save and retrieve insights................................................................................................................

Once you have configured an AgentCore Memory with at least one long-term memory strategy
and the strategy is ACTIVE, the service will automatically begin processing conversational data to
extract and store insights. This process involves two distinct steps: saving the raw conversation and
then retrieving the structured insights after they have been processed.

**Step 1: Save conversational events to trigger extraction**

The entire long-term memory process is triggered when you save conversational data to short-
term memory using the create_event operation. Each time you record an event, you are
providing new raw material for your active memory strategies to analyze.

Important
Only events that are created after a memory strategy's status becomes ACTIVE will be
processed for long-term memory extraction. Any conversations stored before the strategy
was added and activated will not be included.

The following example shows how to save a multi-turn conversation to a memory resource.

**Example Save a conversation as a series of events**

#'memory_id' is the ID of your memory resource with an active summary strategy.

from bedrock_agentcore.memory.session import MemorySessionManager
from bedrock_agentcore.memory.constants import ConversationalMessage, MessageRole
import time

actor_id = "User84"
session_id = "OrderSupportSession1"

Create session manager
session_manager = MemorySessionManager(
memory_id=memory_id,
region_name="us-west-2"
)

Create a session
session = session_manager.create_memory_session(

Save and retrieve insights 208


actor_id=actor_id,
session_id=session_id
)

print("Capturing conversational events...")

Add all conversation turns
session.add_turns(
messages=[
ConversationalMessage("Hi, I'm having trouble with my order #12345",
MessageRole.USER),
ConversationalMessage("I am sorry to hear that. Let me look up your order.",
MessageRole.ASSISTANT),
ConversationalMessage("lookup_order(order_id='12345')", MessageRole.TOOL),
ConversationalMessage("I see your order was shipped 3 days ago. What specific
issue are you experiencing?", MessageRole.ASSISTANT),
ConversationalMessage("The package arrived damaged", MessageRole.USER),
]
)

print("Conversation turns added successfully!")

**Step 2: Retrieve extracted insights**

The extraction and consolidation of long-term memories is an **asynchronous process** that runs
in the background. It may take a minute or more for insights from a new conversation to become
available for retrieval. Your application logic should account for this delay.

To retrieve the structured insights, you use the retrieve_memory_records operation. This
operation performs a powerful semantic search against the long-term memory store. You must
provide the correct namespace that you defined in your strategy and a searchQuery that
describes the information you are looking for.

The following example demonstrates how to wait for processing and then retrieve a summary of
the conversation saved in the previous step.

**Example Wait and retrieve a session summary**

'session' is an existing session object that you created when adding the coversation
turns

session should be created on a memory resource with an active summary strategy.
--- Example 1: Retrieve the userâ€™s shipping preference ---
Save and retrieve insights 209


memories = session.search_long_term_memories(
namespace_prefix=f"/summaries/{actor_id}/{session_id}",
query="What problem did the user report with their order?",
top_k=5
)

print(f"Found {len(memories)} memories:")
for memory_record in memories:
print(f"Retrieved Issue Detail: {memory_record}")
print("--------------------------------------------------------------------")

Example Output:
Retrieved Issue Detail: The user reported that their package for order #12345 arrived
damaged.

### Retrieve memory records..................................................................................................................

You can retrieve extracted memories using the RetrieveMemoryRecords API. This operation lets
you search extracted memory records based on semantic queries, making it easy to find relevant
information from your agent's memory.

**Required parameters**

The RetrieveMemoryRecords operation requires the following key parameters:

**memoryId**

The identifier of the memory resource containing the records you want to retrieve.

**namespace**

The namespace where the memory records are stored. This is the same namespace you
configured in your memory strategy.

**searchCriteria**

A structure containing search parameters:

- _searchQuery_ - The semantic query text used to find relevant memories (up to 10,000
    characters).
- _memoryStrategyId_ (optional) - Limits the search to memories created by a specific strategy.

Retrieve memory records 210


- _topK_ - The maximum number of most relevant results to return (default: 10, maximum: 100).

**Response format**

The operation returns a list of memory record summaries that match your search criteria. Each
summary includes a _relevance score_ , which is derived from the cosine similarity of embedding
vectors. This score does **not** represent a percentage match, but instead measures how closely two
vectors align in a high-dimensional space. Higher scores indicate greater relevance of the memory
record to the search query. The results are paginated, with a default maximum of 100 results per
page. You can use the nextToken parameter to retrieve additional pages of results.

**Best practices**

When retrieving memories, consider the following best practices:

- Craft specific search queries that clearly describe the information you're looking for.
- Use the topK parameter to control the number of results based on your application's needs.
- When working with large memories, implement pagination to efficiently process all relevant
    results.
- Consider filtering by memoryStrategyId when you need memories from a specific extraction
    strategy.

Once retrieved, these memory records can be incorporated into your agent's context, enabling
more personalized and contextually aware responses.

### List memory records..........................................................................................................................

The ListMemoryRecords operation lets you retrieve memory records from a specific namespace
without performing a semantic search. This is useful when you want to browse all memory records
in a namespace or when you need to retrieve records based on criteria other than semantic
relevance.

### Delete memory records.....................................................................................................................

The DeleteMemoryRecord API removes individual memory records from your AgentCore Memory,
giving you control over what information persists in your application's memory. This API helps
maintain data hygiene by letting selective removal of outdated, sensitive, or irrelevant information
while preserving the rest of your memory context.

List memory records 211


### Amazon Bedrock AgentCore Memory examples

You can use AgentCore Memory with a variety of SDKS and agent frameworks.

**Topics**

- Scenario: A customer support AI agent using AgentCore Memory
- Integrate AgentCore Memory with LangChain or LangGraph
- AWS SDK
- Amazon Bedrock AgentCore SDK
- Strands Agents SDK

#### Scenario: A customer support AI agent using AgentCore Memory

In this section you learn how to build a customer support AI agent that uses AgentCore Memory
to provide personalized assistance by maintaining conversation history and extracting long-
term insights about user preferences. The topic includes code examples for the Amazon Bedrock
AgentCore toolkit and the AWS SDK.

Consider a customer, Sarah, who engages with your shopping website's support AI agent to inquire
about a delayed order. The interaction flow through the AgentCore Memory APIs would look like
this:

**Topics**

- Step 1: Create a AgentCore Memory
- Step 2: Start the session
- Step 3: Capture the conversation history
- Step 4: Generate long-term memory

AgentCore Memory examples 212


- Step 5: Retrieve past interactions from short-term memory
- Step 6: Use long-term memories for personalized assistance

**Step 1: Create a AgentCore Memory**

First, you create a memory resource with both short-term and long-term memory capabilities,
configuring the strategies for what long-term information to extract.

Starter toolkit

from bedrock_agentcore_starter_toolkit.operations.memory.manager import
MemoryManager
from bedrock_agentcore.memory.session import MemorySessionManager
from bedrock_agentcore.memory.constants import ConversationalMessage, MessageRole
from bedrock_agentcore_starter_toolkit.operations.memory.models.strategies import
SummaryStrategy, UserPreferenceStrategy
import time

Create memory manager
memory_manager = MemoryManager(region_name="us-west-2")

print("Creating a new memory resource and waiting for it to become active...")

Create memory resource with summary and user preference strategy
memory = memory_manager.get_or_create_memory(
name="ShoppingSupportAgentMemory",
description="Memory for a customer support agent.",
strategies=[
SummaryStrategy(
name="SessionSummarizer",
namespaces=["/summaries/{actorId}/{sessionId}"]
),
UserPreferenceStrategy(
name="PreferenceLearner",
namespaces=["/users/{actorId}/preferences"]
)
]
)

memory_id = memory.get('id')
print(f"Memory resource is now ACTIVE with ID: {memory_id}")

Customer support AI agent 213


##### AWS SDK

import boto3
import time

Initialize the Boto3 clients for control plane and data plane operations
control_client = boto3.client('bedrock-agentcore-control')
data_client = boto3.client('bedrock-agentcore')

print("Creating a new memory resource...")

Create the memory resource with defined strategies
response = control_client.create_memory(
name="ShoppingSupportAgentMemory",
description="Memory for a customer support agent.",
memoryStrategies=[
{
'summaryMemoryStrategy': {
'name': 'SessionSummarizer',
'namespaces': ['/summaries/{actorId}/{sessionId}']
}
},
{
'userPreferenceMemoryStrategy': {
'name': 'UserPreferenceExtractor',
'namespaces': ['/users/{actorId}/preferences']
}
}
]
)

memory_id = response['memory']['id']
print(f"Memory resource created with ID: {memory_id}")

Poll the memory status until it becomes ACTIVE
while True:
mem_status_response = control_client.get_memory(memoryId=memory_id)
status = mem_status_response.get('memory', {}).get('status')
if status == 'ACTIVE':
print("Memory resource is now ACTIVE.")
break
elif status == 'FAILED':
raise Exception("Memory resource creation FAILED.")
print("Waiting for memory to become active...")

Customer support AI agent 214


time.sleep(10)

**Step 2: Start the session**

When Sarah initiates the conversation, the agent creates a new, and unique, session ID to track this
interaction separately.

Starter toolkit

Unique identifier for the customer, Sarah
sarah_actor_id = "user-sarah-123"

Unique identifier for this specific support session
support_session_id = "customer-support-session-1"

Create session manager
session_manager = MemorySessionManager(
memory_id=memory.get("id"),
region_name="us-west-2"
)

Create a session
session = session_manager.create_memory_session(
actor_id=sarah_actor_id,
session_id=support_session_id
)

print(f"Session started for Actor ID: {sarah_actor_id}, Session ID:
{support_session_id}")

##### AWS SDK

Unique identifier for the customer, Sarah
sarah_actor_id = "user-sarah-123"

Unique identifier for this specific support session
support_session_id = "customer-support-session-1"

print(f"Session started for Actor ID: {sarah_actor_id}, Session ID:
{support_session_id}")

Customer support AI agent 215


**Step 3: Capture the conversation history**

As Sarah explains her issue, the agent captures each turn of the conversation (both her questions
and the agent's responses). This populates the the full conversation in short-term memory and
provides the raw data for the long-term memory strategies to process.

Starter toolkit

print("Capturing conversational events...")

Add all conversation turns
session.add_turns(
messages=[
ConversationalMessage("Hi, my order #ABC-456 is delayed.",
MessageRole.USER),
ConversationalMessage("I am sorry to hear that, Sarah. Let me check the
status for you.", MessageRole.ASSISTANT),
ConversationalMessage("By the way, for future orders, please always use
FedEx. I've had issues with other carriers.", MessageRole.USER),
ConversationalMessage("Thank you for that information. I have made a note to
use FedEx for your future shipments.", MessageRole.ASSISTANT),
]
)

print("Conversation turns added successfully!")

AWS SDK

print("Capturing conversational events...")

full_conversation_payload = [
{
'conversational': {
'role': 'USER',
'content': {'text': "Hi, my order #ABC-456 is delayed."}
}
},
{
'conversational': {
'role': 'ASSISTANT',
'content': {'text': "I'm sorry to hear that, Sarah. Let me check the
status for you."}
}

Customer support AI agent 216


},
{
'conversational': {
'role': 'USER',
'content': {'text': "By the way, for future orders, please always use
FedEx. I've had issues with other carriers."}
}
},
{
'conversational': {
'role': 'ASSISTANT',
'content': {'text': "Thank you for that information. I have made a note
to use FedEx for your future shipments."}
}
}
]

data_client.create_event(
memoryId=memory_id,
actorId=sarah_actor_id,
sessionId=support_session_id,
eventTimestamp=time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
payload=full_conversation_payload
)

print("Conversation history has been captured in short-term memory.")

**Step 4: Generate long-term memory**

In the background, the asynchronous extraction process runs. This process analyzes the recent
raw events using your configured memory strategies to extract long-term memories such as
summaries, semantic facts, or user preferences, which are then stored for future use.

**Step 5: Retrieve past interactions from short-term memory**

o provide context-aware assistance, the agent loads the current conversation history. This helps the
agent understand what issues Sarah has raised in the ongoing chat.

Starter toolkit

print("\nRetrieving current conversation history from short-term memory...")

Customer support AI agent 217


Get the last k turns in the session
turns = session.get_last_k_turns(k=7)
for turn in turns:
print(f"Turn: {turn}")

##### AWS SDK

print("\nRetrieving current conversation history from short-term memory...")

response = data_client.list_events(
memoryId=memory_id,
actorId=sarah_actor_id,
sessionId=support_session_id,
maxResults=10
)

Reverse the list of events to display them in chronological order
event_list = reversed(response.get('events', []))

for event in event_list: print(event)

**Step 6: Use long-term memories for personalized assistance**

The agent performs a semantic search across extracted long-term memories to find relevant
insights about Sarah's preferences, order history, or past concerns. This lets the agent provide
highly personalized assistance without needing to ask Sarah to repeat information she has already
shared in previous chats.

Starter toolkit

Wait for meaningful memories to be extracted from the conversation
print("Waiting 60 seconds for memory extraction...")
time.sleep(60)

--- Example 1: Retrieve the userâ€™s shipping preference ---
memories = session.search_long_term_memories(
namespace_prefix=f"/users/{sarah_actor_id}/preferences",
query="Does the user have a preferred shipping carrier?",
top_k=5
)

Customer support AI agent 218


print(f"Found {len(memories)} memories:")
for memory_record in memories:
print(f"Memory: {memory_record}")
print("--------------------------------------------------------------------")

--- Example 2: Broad query about the userâ€™s issue ---
memories = session.search_long_term_memories(
namespace_prefix=f"/summaries/{sarah_actor_id}/{support_session_id}",
query="What problem did the user report with their order?",
top_k=5
)

print(f"Found {len(memories)} memories:")
for memory_record in memories:
print(f"Memory: {memory_record}")
print("--------------------------------------------------------------------")

##### SDK

Wait for the asynchronous extraction to finish
print("\nWaiting 60 seconds for long-term memory processing...")
time.sleep(60)

--- Example 1: Retrieve the user's shipping preference ---
print("\nRetrieving user preferences from long-term memory...")
preference_response = data_client.retrieve_memory_records(
memoryId=memory_id,
namespace=f"/users/{sarah_actor_id}/preferences",
searchCriteria={"searchQuery": "Does the user have a preferred shipping
carrier?"}
)
for record in preference_response.get('memoryRecordSummaries', []):
print(f"- Retrieved Record: {record}")

--- Example 2: Broad query about the user's issue ---
print("\nPerforming a broad search for user's reported issues...")
issue_response = data_client.retrieve_memory_records(
memoryId=memory_id,
namespace=f"/summaries/{sarah_actor_id}/{support_session_id}",
searchCriteria={"searchQuery": "What problem did the user report with their
order?"}
)
for record in issue_response.get('memoryRecordSummaries', []):

Customer support AI agent 219


print(f"- Retrieved Record: {record}")

This integrated approach lets the agent maintain rich context across sessions, recognize returning
customers, recall important details, and deliver personalized experiences seamlessly, resulting in
faster, more natural, and effective customer support.

#### Integrate AgentCore Memory with LangChain or LangGraph

LangChain and LangGraph are powerful open-source frameworks for developing agents through a
graph-based architecture. They provide a simple interface for defining agent interactions with the
user, its tools, and memory.

Within LangGraph there are two main memory concepts when it comes to memory persistence.
Short-term, raw context is saved through checkpoint objects, while intelligent long term memory
retrieval is done by saving and searching through memory stores. To address these two use cases,
integrations were created to cover both the checkpointing workflow and the store workflow:

- AgentCoreMemorySaver - used to save and load checkpoint objects that include user and AI
    messages, graph execution state, and additional metadata
- AgentCoreMemoryStore - used to save conversational messages, leaving the AgentCore
    Memory service to extract insights, summaries, and user preferences in the background, then
    letting the agent search through those intelligent memories in future conversations

These integrations are easy to set up, requiring only specifying the Memory ID of a AgentCore
Memory. Because they are saved to persistent storage within the service, there is no need to worry
about losing these interactions through container exits, unreliable in-memory solutions, or agent
application crashes.

**Topics**

- Prerequisites
- Configuration for short term memory persistence
- Configuration for intelligent long term memory search
- Create the agent with configurations
- Invoke the agent
- Resources

Integrate with LangChain or LangGraph 220


**Prerequisites**

Requirements you need before integrating AgentCore Memory with LangChain and LangGraph.

1.AWS account with Bedrock Amazon Bedrock AgentCore access

2.Configured AWS credentials (boto3)

3.An AgentCore Memory

4.Required IAM permissions:

- bedrock-agentcore:CreateEvent
- bedrock-agentcore:ListEvents
- bedrock-agentcore:RetrieveMemories

**Configuration for short term memory persistence**

The AgentCoreMemorySaver in LangGraph handles all the saving and loading of conversational
state, execution context, and state variables under the hood through AgentCore Memory blob
types. This means that the only setup required is to specify the checkpointer when compiling the
agent graph, then providing an actor_id and thread_id in the RunnableConfig when invoking
the agent. The configuration is shown below and the agent invocation is shown in the next section.
If simple conversation persistence is all your application needs, feel free to skip the long term
memory section.

Import LangGraph and LangChain components
from langchain.chat_models import init_chat_model
from langgraph.prebuilt import create_react_agent

Import the AgentCore Memory integrations
from langgraph_checkpoint_aws import AgentCoreMemorySaver

REGION = "us-west-2"
MEMORY_ID = "YOUR_MEMORY_ID"
MODEL_ID = "us.anthropic.claude-3-7-sonnet-20250219-v1:0"

Initialize checkpointer for state persistence. No additional setup required.
Sessions will be saved and persisted for actor_id/session_id combinations
checkpointer = AgentCoreMemorySaver(MEMORY_ID, region_name=REGION)

Integrate with LangChain or LangGraph 221


**Configuration for intelligent long term memory search**

For long term memory stores in LangGraph, you have more flexibility on how messages are
processed. For instance, if the application is only concerned with user preferences, you would
only need to store the HumanMessage objects in the conversation. For summaries, all types
HumanMessage, AIMessage, and ToolMessage would be relevant. There are numerous ways to
do this, but a common implementation pattern is using pre and post model hooks, as shown in the
example below. For retrieval of memories, you may add a store.search(query) call in the pre-
model hook and append it to the user's message so the agent has all the context. Alternatively, the
agent could be provided a tool to search for information as needed. All of these implementation
patterns are supported and the implementation will vary based on the application.

from langgraph_checkpoint_aws import (
AgentCoreMemoryStore
)

Initialize store for saving and searching over long term memories
such as preferences and facts across sessions
store = AgentCoreMemoryStore(MEMORY_ID, region_name=REGION)

Pre-model hook runs and saves messages of your choosing to AgentCore Memory
for async processing and extraction
def pre_model_hook(state, config: RunnableConfig, *, store: BaseStore):
"""Hook that runs pre-LLM invocation to save the latest human message"""
actor_id = config["configurable"]["actor_id"]
thread_id = config["configurable"]["thread_id"]

Saving the message to the actor and session combination that we get at runtime
namespace = (actor_id, thread_id)

messages = state.get("messages", [])

Save the last human message we see before LLM invocation
for msg in reversed(messages):
if isinstance(msg, HumanMessage):
store.put(namespace, str(uuid.uuid4()), {"message": msg})
break

OPTIONAL: Retrieve user preferences based on the last message and append to state
user_preferences_namespace = ("preferences", actor_id)
preferences = store.search(user_preferences_namespace, query=msg.content,
limit=5)

Integrate with LangChain or LangGraph 222


# Add to input messages as needed
return {"llm_input_messages": messages}

**Create the agent with configurations**

Initialize the LLM and create a LangGraph agent with a memory configuration.

Initialize LLM
llm = init_chat_model(MODEL_ID, model_provider="bedrock_converse", region_name=REGION)

Create a pre-built langgraph agent (configurations work for custom agents too)
graph = create_react_agent(
model=llm,
tools=tools,
checkpointer=checkpointer, # AgentCoreMemorySaver we created above
store=store, # AgentCoreMemoryStore we created above
pre_model_hook=pre_model_hook, # OPTIONAL: Function we defined to save user
messages

post_model_hook=post_model_hook # OPTIONAL: Can save AI messages to memory if
needed
)

**Invoke the agent**

Invoke the agent.

Specify config at runtime for ACTOR and SESSION
config = {
"configurable": {
"thread_id": "session-1", # REQUIRED: This maps to Bedrock AgentCore session_id
under the hood
"actor_id": "react-agent-1", # REQUIRED: This maps to Bedrock AgentCore
actor_id under the hood
}
}

Invoke the agent
response = graph.invoke(

Integrate with LangChain or LangGraph 223


{"messages": [("human", "I like sushi with tuna. In general seafood is great.")]},
config=config
)

... agent will answer
Agent will have the conversation and state persisted on the next message
Because the session ID is the same in the runtime config
response = graph.invoke(
{"messages": [("human", "What did I just say?")]},
config=config
)

Define a new session in the runtime config to test long term retrieval
config = {
"configurable": {
"thread_id": "session-2", # New session ID
"actor_id": "react-agent-1", # Same actor ID
}
}

Invoke the agent (it will retrieve long term memories from other session)
response = graph.invoke(
{"messages": [("human", "Lets make a meal tonight, what should I cook?")]},
config=config
)

**Resources**

- LangChain x AWS Github Repo
- Pypi package
- AgentCoreMemorySaver implementation
- AgentCoreMemorySaver sample notebook (checkpointing only)

### AWS SDK..............................................................................................................................................

Use the AWS SDK to directly interact with AgentCore Memory fine-grained control over memory
operations. The following examples show how to access the AWS SDK with the SDK for Python
(Boto3).

AWS SDK 224


**Install dependencies**

pip install boto3

**Add short-term memory**

import boto3
from datetime import datetime

Initialize boto3 clients
control_client = boto3.client('bedrock-agentcore-control', region_name='us-east-1')
data_client = boto3.client('bedrock-agentcore', region_name='us-east-1')

Create short-term memory
memory_response = control_client.create_memory(
name="BasicMemory",
description="Basic memory for short-term event storage",
eventExpiryDuration=90
)

memory_id = memory_response['memory']['id']
actor_id = f"actor_{datetime.now().strftime('%Y%m%d%H%M%S')}"
session_id = f"session_{datetime.now().strftime('%Y%m%d%H%M%S')}"

Create event with multiple conversation turns
event = data_client.create_event(
memoryId=memory_id,
actorId=actor_id,
sessionId=session_id,
eventTimestamp=datetime.now(),
payload=[
{
'conversational': {
'content': {'text': 'I like sushi with tuna'},
'role': 'USER'
}
},
{
'conversational': {
'content': {'text': 'That sounds delicious! Tuna sushi is a great
choice.'},
'role': 'ASSISTANT'
}

AWS SDK 225


},
{
'conversational': {
'content': {'text': 'I also like pizza'},
'role': 'USER'
}
},
{
'conversational': {
'content': {'text': 'Pizza is another excellent choice! You have great
taste in food.'},
'role': 'ASSISTANT'
}
}
]
)

**Add long-term memory with strategies**

import boto3
import time
from datetime import datetime

Initialize boto3 clients
control_client = boto3.client('bedrock-agentcore-control', region_name='us-east-1')
data_client = boto3.client('bedrock-agentcore', region_name='us-east-1')

Create long-term memory
memory_response = control_client.create_memory(
name=f"ComprehensiveMemory",
description="Memory with strategies for long-term memory extraction",
eventExpiryDuration=90,
memoryStrategies=[
{
'summaryMemoryStrategy': {
'name': 'SessionSummarizer',
'namespaces': ['/summaries/{actorId}/{sessionId}']
}
},
{
'userPreferenceMemoryStrategy': {
'name': 'PreferenceLearner',
'namespaces': ['/preferences/{actorId}']

AWS SDK 226


}
},
{
'semanticMemoryStrategy': {
'name': 'FactExtractor',
'namespaces': ['/facts/{actorId}']
}
}
]
)

memory_id = memory_response['memory']['id']
actor_id = f"actor_{datetime.now().strftime('%Y%m%d%H%M%S')}"
session_id = f"session_{datetime.now().strftime('%Y%m%d%H%M%S')}"

########## Wait for long-term memory to become active ##########

Create single event with all conversation turns
event = data_client.create_event(
memoryId=memory_id,
actorId=actor_id,
sessionId=session_id,
eventTimestamp=datetime.now(),
payload=[
{
'conversational': {
'content': {'text': 'I like sushi with tuna'},
'role': 'USER'
}
},
{
'conversational': {
'content': {'text': 'That sounds delicious! Tuna sushi is a great
choice.'},
'role': 'ASSISTANT'
}
},
{
'conversational': {
'content': {'text': 'I also like pizza'},
'role': 'USER'
}

AWS SDK 227


},
{
'conversational': {
'content': {'text': 'Pizza is another excellent choice! You have great
taste in food.'},
'role': 'ASSISTANT'
}
}
]
)

Full AWS SDK Amazon Bedrock AgentCore AgentCore Memory API reference can be found at:

- https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-
    agentcore.html
- https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-
    agentcore-control.html

### Amazon Bedrock AgentCore SDK....................................................................................................

Use the Amazon Bedrock AgentCore Python SDK for a higher-level abstraction that simplifies
memory operations and provides convenient methods for common use cases.

**Install dependencies**

pip install bedrock-agentcore

**Add short-term memory**

from bedrock_agentcore.memory import MemoryClient

client = MemoryClient(region_name="us-east-1")

memory = client.create_memory(
name="CustomerSupportAgentMemory",
description="Memory for customer support conversations",
)

client.create_event(
memory_id=memory.get("id"), # This is the id from create_memory or list_memories

Amazon Bedrock AgentCore SDK 228


actor_id="User84", # This is the identifier of the actor, could be an agent or
end-user.
session_id="OrderSupportSession1", #Unique id for a particular request/
conversation.
messages=[
("Hi, I'm having trouble with my order #12345", "USER"),
("I'm sorry to hear that. Let me look up your order.", "ASSISTANT"),
("lookup_order(order_id='12345')", "TOOL"),
("I see your order was shipped 3 days ago. What specific issue are you
experiencing?", "ASSISTANT"),
("Actually, before that - I also want to change my email address", "USER"),
(
"Of course! I can help with both. Let's start with updating your email.
What's your new email?",
"ASSISTANT",
),
("newemail@example.com", "USER"),
("update_customer_email(old='old@example.com', new='newemail@example.com')",
"TOOL"),
("Email updated successfully! Now, about your order issue?", "ASSISTANT"),
("The package arrived damaged", "USER"),
],
)

**Add long-term memory with strategies**

from bedrock_agentcore.memory import MemoryClient
import time

client = MemoryClient(region_name="us-east-1")

memory = client.create_memory_and_wait(
name="MyAgentMemory",
strategies=[{
"summaryMemoryStrategy": {

Name of the extraction model/strategy
"name": "SessionSummarizer",

Organize facts by session ID for easy retrieval
Example: "summaries/session123" contains summary of session123
"namespaces": ["/summaries/{actorId}/{sessionId}"]
}
}]
)

Amazon Bedrock AgentCore SDK 229


event = client.create_event(
memory_id=memory.get("id"), # This is the id from create_memory or list_memories
actor_id="User84", # This is the identifier of the actor, could be an agent or
end-user.
session_id="OrderSupportSession1",
messages=[
("Hi, I'm having trouble with my order #12345", "USER"),
("I'm sorry to hear that. Let me look up your order.", "ASSISTANT"),
("lookup_order(order_id='12345')", "TOOL"),
("I see your order was shipped 3 days ago. What specific issue are you
experiencing?", "ASSISTANT"),
("Actually, before that - I also want to change my email address", "USER"),
(
"Of course! I can help with both. Let's start with updating your email.
What's your new email?",
"ASSISTANT",
),
("newemail@example.com", "USER"),
("update_customer_email(old='old@example.com', new='newemail@example.com')",
"TOOL"),
("Email updated successfully! Now, about your order issue?", "ASSISTANT"),
("The package arrived damaged", "USER"),
],
)

Wait for meaningful memories to be extracted from the conversation.
time.sleep(60)

Query for the summary of the issue using the namespace set in summary strategy above
memories = client.retrieve_memories(
memory_id=memory.get("id"),
namespace=f"/summaries/User84/OrderSupportSession1",
query="can you summarize the support issue"
)

### Strands Agents SDK...........................................................................................................................

Use the Strands Agents SDK for seamless integration with agent frameworks, providing automatic
memory management and retrieval within conversational agents.

**Install dependencies**

Strands Agents SDK 230


pip install bedrock-agentcore
pip install strands-agents

**Add short-term memory**

from datetime import datetime
from strands import Agent
from bedrock_agentcore.memory import MemoryClient
from bedrock_agentcore.memory.integrations.strands.config import AgentCoreMemoryConfig,
RetrievalConfig
from bedrock_agentcore.memory.integrations.strands.session_manager import
AgentCoreMemorySessionManager

client = MemoryClient(region_name="us-east-1")
basic_memory = client.create_memory(
name="BasicTestMemory",
description="Basic memory for testing short-term functionality"
)

MEM_ID = basic_memory.get('id')
ACTOR_ID = "actor_id_test_%s" % datetime.now().strftime("%Y%m%d%H%M%S")
SESSION_ID = "testing_session_id_%s" % datetime.now().strftime("%Y%m%d%H%M%S")

Configure memory
agentcore_memory_config = AgentCoreMemoryConfig(
memory_id=MEM_ID,
session_id=SESSION_ID,
actor_id=ACTOR_ID
)

Create session manager
session_manager = AgentCoreMemorySessionManager(
agentcore_memory_config=agentcore_memory_config,
region_name="us-east-1"
)

Create agent
agent = Agent(
system_prompt="You are a helpful assistant. Use all you know about the user to
provide helpful responses.",
session_manager=session_manager,
)

Strands Agents SDK 231


agent("I like sushi with tuna")

Agent remembers this preference
agent("I like pizza")

Agent acknowledges both preferences
agent("What should I buy for lunch today?")

Agent suggests options based on remembered preferences
**Add long-term memory with strategies**

from bedrock_agentcore.memory import MemoryClient
from strands import Agent
from bedrock_agentcore.memory.integrations.strands.config import AgentCoreMemoryConfig,
RetrievalConfig
from bedrock_agentcore.memory.integrations.strands.session_manager import
AgentCoreMemorySessionManager
from datetime import datetime

Create comprehensive memory with all built-in strategies
client = MemoryClient(region_name="us-east-1")
comprehensive_memory = client.create_memory_and_wait(
name="ComprehensiveAgentMemory",
description="Full-featured memory with all built-in strategies",
strategies=[
{
"summaryMemoryStrategy": {
"name": "SessionSummarizer",
"namespaces": ["/summaries/{actorId}/{sessionId}"]
}
},
{
"userPreferenceMemoryStrategy": {
"name": "PreferenceLearner",
"namespaces": ["/preferences/{actorId}"]
}
},
{
"semanticMemoryStrategy": {
"name": "FactExtractor",
"namespaces": ["/facts/{actorId}"]
}
}

Strands Agents SDK 232


]
)

MEM_ID = comprehensive_memory.get('id')
ACTOR_ID = "actor_id_test_%s" % datetime.now().strftime("%Y%m%d%H%M%S")
SESSION_ID = "testing_session_id_%s" % datetime.now().strftime("%Y%m%d%H%M%S")

Configure memory
agentcore_memory_config = AgentCoreMemoryConfig(
memory_id=MEM_ID,
session_id=SESSION_ID,
actor_id=ACTOR_ID
)

Create session manager
session_manager = AgentCoreMemorySessionManager(
agentcore_memory_config=agentcore_memory_config,
region_name="us-east-1"
)

Create agent
agent = Agent(
system_prompt="You are a helpful assistant. Use all you know about the user to
provide helpful responses.",
session_manager=session_manager,
)

agent("I like sushi with tuna")

Agent remembers this preference
agent("I like pizza")

Agent acknowledges both preferences
agent("What should I buy for lunch today?")

Agent suggests options based on remembered preferences
More examples are available on GitHub: https://github.com/aws/bedrock-agentcore-sdk-python/
tree/main/src/bedrock_agentcore/memory/integrations/strands

Strands Agents SDK 233


## Amazon Bedrock capacity for built-in with overrides strategies....................................................

When configuring built-in with overrides strategies with CreateMemory or UpdateMemory, you
must provide an IAM exeecution role (memoryExecutionRoleArn). The AgentCore Memory
service assumes this role to perform Amazon Bedrock operations (such as LLM calls for memory
extraction and/or consolidation) within your AWS account.

Since Amazon Bedrock usage is attributed to your account, it consumes your allocated capacity and
is subject to your Bedrock service quotas. If Amazon Bedrock calls are throttled due to quota limits,
memory ingestion operations might fail.

Note
Amazon Bedrock usage is attributed to customer account only for custom memory
strategies.

To monitor and troubleshoot these issues, enable log delivery on your memory configuration to
observe error logs when ingestion failures occur. You can also request quota increases for the
Bedrock models you're using to prevent throttling issues.

## Observability.............................................................................................................................................

You can monitor usage metrics for your memory in CloudWatch metrics. Some of the critical
metrics are displayed in AgentCore Memory console.

**CloudWatch metrics** : AgentCore Memory emits metrics to CloudWatch under the Bedrock-
AgentCore namespace. The metrics contains:

- Data plane usage statistics: CreateEvent/RetrieveMemoryRecord Invocations, Latency,
    Errors, etc

Amazon Bedrock capacity for built-in with overrides strategies 234


- Ingestion metrics: Invocations, Latency, Errors NumberOfMemoryRecords for extraction/
    consolidation step during ingestion in each memory resource.

In addition to CloudWatch metrics, customer can monitor the memory extraction process via
CloudWatch logs if they enabled log delivery. Application logs during ingestion will be published
to a log group in customer account. Customer can use the application logs to debug any errors
encountered during asynchronous ingestion process.

For more information, see Observe your agent applications on Amazon Bedrock AgentCore
Observability.

### Best practices

We recommend these best practices for using AgentCore Memory effectively in your AI agent
applications.

**Topics**

- Encrypting your memory
- Memory poisoning or prompt injection
- Least-privilege principle

### Encrypting your memory..................................................................................................................

Your data stored in AgentCore Memory is always encrypted at rest using AWS KMS keys. By default,
encryption uses an AWS-owned and managed KMS key. You can optionally configure a customer-
managed KMS key from your own AWS account for additional control over encryption by specifying
encryptionKeyArn when creating memory.

### Memory poisoning or prompt injection.........................................................................................

When processing conversational data through the CreateEvent API and extracting long-term
memory via LLM, it is important to protect against memory poisoning and prompt injection attacks

Best practices 235


that could compromise data integrity or system behavior. These security concerns are critical as
they can lead to corrupted memory stores and manipulated system responses.

Following AWS's shared responsibility model, AWS is responsible for securing Amazon Bedrock
Amazon Bedrock AgentCore infrastructure. However, customers bear the responsibility for secure
application development, input validation, and preventing prompt injection vulnerabilities in the
memory extraction service. This is similar to how AWS provides secure database engines like RDS,
but customers must prevent SQL injection in their applications.

**Threats**

- **Memory poisoning** represents a threat where attackers embed false information in
    conversations to corrupt long-term memory stores. This can manifest as context pollution, where
    misleading context influences future memory retrieval, or as deliberate data integrity attacks
    designed to degrade service quality over time.
- **Prompt injection** attacks occur when users attempt to override system prompts during memory
    extraction or when malicious content in conversational data manipulates LLM behavior. These
    attacks can also involve privilege escalation attempts to access or modify memory beyond user
    permissions.

**Prevention techniques**

- **Input validation** forms the foundation of protection at the CreateEvent API level. Sanitize the
    user input data with guardrails prior to persistence to memory
- **Security testing** â€“ Regularly test your applications for prompt injection and other security
    vulnerabilities using techniques like penetration testing, static code analysis, and dynamic
    application security testing (DAST).

#### Least-privilege principle....................................................................................................................

Identity-based policies determine whether someone can create, access, or delete Amazon Bedrock
Amazon Bedrock AgentCore resources in your account. These actions can incur costs for your
AWS account. When you create or edit identity-based policies, follow these guidelines and
recommendations:

- **Get started with AWS managed policies and move toward least-privilege permissions** â€“ To
    get started granting permissions to your users and workloads, use the AWS managed policies

Least-privilege principle 236


that grant permissions for many common use cases. They are available in your AWS account. We
recommend that you reduce permissions further by defining AWS customer managed policies
that are specific to your use cases.

- **Apply least-privilege permissions** â€“ When you set permissions with IAM policies, grant only the
    permissions required to perform a task. You do this by defining the actions that can be taken on
    specific resources under specific conditions, also known as least-privilege permissions.
- **Use conditions in IAM policies to further restrict access** â€“ You can add a condition to your
    policies to limit access to actions and resources. For example, you can write a policy condition to
    specify the service role can only be assumed by a particular AgentCore Memory resource.
- **Use IAM Access Analyzer to validate your IAM policies to maintain secure and functional**
    **permissions** â€“ IAM Access Analyzer validates new and existing policies so that the policies
    adhere to the IAM policy language (JSON) and IAM best practices. IAM Access Analyzer provides
    more than 100 policy checks and actionable recommendations to help you author secure and
    functional policies.

Least-privilege principle 237


## Amazon Bedrock AgentCore Gateway: Securely connect

## tools and other resources to your Gateway

Amazon Bedrock AgentCore Gateway provides an easy and secure way for developers to build,
deploy, discover, and connect to tools at scale. AI agents need tools to perform real-world tasksâ€”
from querying databases to sending messages to analyzing documents. With Gateway, developers
can convert APIs, Lambda functions, and existing services into Model Context Protocol (MCP)-
compatible tools and make them available to agents through Gateway endpoints with just a few
lines of code. Gateway supports OpenAPI, Smithy, and Lambda as input types, and is the only
solution that provides both comprehensive ingress authentication and egress authentication in
a fully-managed service. Gateway also provides 1-click integration with several popular tools
such as Salesforce, Slack, Jira, Asana, and Zendesk. Gateway eliminates weeks of custom code
development, infrastructure provisioning, and security implementation so developers can focus on
building innovative agent applications.

### Key benefits..............................................................................................................................................

**Simplify tool development and integration**

Transform existing enterprise resources into agent-ready tools in just a few lines of code.
Instead of spending months writing custom integration code and managing infrastructure,
developers can focus on building differentiated agent capabilities while Gateway handles the
undifferentiated heavy lifting of tool management and security at enterprise scale. Gateway
also provides 1-click integration with several popular tools such as Salesforce, Slack, Jira, Asana,
and Zendesk.

**Accelerate agent development through unified access**

Enable your agents to discover and use tools through a single, secure endpoint. By combining
multiple tool sourcesâ€”from APIs to Lambda functionsâ€”into one unified interface, developers
can build and scale agent workflows faster without managing multiple tool connections or
reimplementing integrations.

**Scale with confidence through intelligent tool discovery**

As your tool collection grows, help your agents find and use the right tools through contextual
search. Built-in semantic search capabilities help agents effectively utilize available tools based

Key benefits 238


on their task context, improving agent performance and reducing development complexity at
scale.

**Comprehensive authentication**

Manage both inbound authentication (verifying agent identity) and outbound authentication
(connecting to tools) in a single service. Handle OAuth flows, token refresh, and secure
credential storage for third-party services.

**Framework compatibility**

Work with popular open-source frameworks including CrewAI, LangGraph, LlamaIndex, and
Strands Agents. Integrate with any model while maintaining enterprise-grade security and
reliability.

**Serverless infrastructure**

Eliminate infrastructure management with a fully managed service that automatically scales
based on demand. Built-in observability and auditing capabilities simplify monitoring and
troubleshooting.

### Key capabilities.........................................................................................................................................

Gateway provides the following key capabilities:

- **Security Guard** - Manages OAuth authorization to ensure only valid users and agents can access
    tools and resources.
- **Translation** - Converts agent requests using protocols like Model Context Protocol (MCP) into
    API requests and Lambda invocations, eliminating the need to manage protocol integration or
    version support.
- **Composition** - Combines multiple APIs, functions, and tools into a single MCP endpoint for
    streamlined agent access.
- **Secure Credential Exchange** - Handles credential injection for each tool, enabling agents to use
    tools with different authentication requirements seamlessly.
- **Semantic Tool Selection** - Enables agents to search across available tools to find the most
    appropriate ones for specific contexts, allowing agents to leverage thousands of tools while
    minimizing prompt size and reducing latency.
- **Infrastructure Manager** - Provides a serverless solution with built-in observability and auditing,
    eliminating infrastructure management overhead.

Key capabilities 239


### Get started with AgentCore Gateway.................................................................................................

In this quick start guide you'll learn how to set up a gateway and integrate it into your agents using
the AgentCore starter toolkit. For more comprehensive guides and examples, see the Amazon
Bedrock AgentCore Gateway GitHub repository.

Note
The AgentCore starter toolkit abstracts the Boto3 Python SDK into simplified methods
and is intended to help developers get started quickly. For a more comprehensive set of
operations, you should use an AWS SDK such as Boto3. For more information on Boto3
operations for AgentCore, see AgentCore Control Plane operations.

**Topics**

- Prerequisites
- Step 1: Setup and install
- Step 2: Create gateway setup script
- Step 3: Run the setup
- Step 4: Use the gateway with an agent
- What you've built
- Troubleshooting
- Quick validation
- Cleanup
- Next steps

#### Prerequisites........................................................................................................................................

Before starting, make sure you have the followinsg:

- **AWS Account** with credentials configured. To configure credentials, you can install and use the
    AWS Command Line Interface by following the steps at Getting started with the AWS CLI.
- **Python 3.10+** installed.
- **IAM permissions** for creating roles, Lambda functions, and using Amazon Bedrock AgentCore.

Get started with AgentCore Gateway 240


- **Model Access** â€“ Enable Anthropic's Claude Sonnet 3.7 in the Amazon Bedrock console (or
    another model for the demo agent)

#### Step 1: Setup and install..................................................................................................................

Run the following in a terminal to set up the virtual environment in which to install the
dependencies.

mkdir agentcore-gateway-quickstart
cd agentcore-gateway-quickstart
python3 -m venv .venv
source .venv/bin/activate # On Windows: .venv\Scripts\activate

Then, run the following to install the dependencies

pip install boto3
pip install bedrock-agentcore-starter-toolkit
pip install strands-agents

#### Step 2: Create gateway setup script..............................................................................................

Create a new file called setup_gateway.py and insert the following complete code into it:

"""
Setup script to create Gateway with Lambda target and save configuration
Run this first: python setup_gateway.py
"""

from bedrock_agentcore_starter_toolkit.operations.gateway.client import GatewayClient
import json
import logging
import time

def setup_gateway():

Configuration
region = "us-east-1" # Change to your preferred region

print("# Setting up AgentCore Gateway...")
print(f"Region: {region}\n")

Step 1: Setup and install 241


Initialize client
client = GatewayClient(region_name=region)
client.logger.setLevel(logging.INFO)

Step 2.1: Create OAuth authorizer
print("Step 2.1: Creating OAuth authorization server...")
cognito_response = client.create_oauth_authorizer_with_cognito("TestGateway")
print("# Authorization server created\n")

Step 2.2: Create Gateway
print("Step 2.2: Creating Gateway...")
gateway = client.create_mcp_gateway(

the name of the Gateway - if you don't set one, one will be generated.
name=None,

the role arn that the Gateway will use - if you don't set one, one will be
created.

NOTE: if you are using your own role make sure it has a trust policy that
trusts bedrock-agentcore.amazonaws.com
role_arn=None,

the OAuth authorization server details. If you are providing your own
authorization server,

then pass an input of the following form: {"customJWTAuthorizer":
{"allowedClients": [""], "discoveryUrl": ""}}
authorizer_config=cognito_response["authorizer_config"],

enable semantic search
enable_semantic_search=True,
)
print(f"# Gateway created: {gateway['gatewayUrl']}\n")

If role_arn was not provided, fix IAM permissions
NOTE: This is handled internally by the toolkit when no role is provided
client.fix_iam_permissions(gateway)
print("# Waiting 30s for IAM propagation...")
time.sleep(30)
print("# IAM permissions configured\n")

Step 2.3: Add Lambda target
print("Step 2.3: Adding Lambda target...")
lambda_target = client.create_mcp_gateway_target(

the gateway created in the previous step
gateway=gateway,

the name of the Target - if you don't set one, one will be generated.
name=None,

the type of the Target
Step 2: Create gateway setup script 242


target_type="lambda",

the target details - set this to define your own lambda if you pre-created
one.

Otherwise leave this None and one will be created for you.
target_payload=None,

you will see later in the tutorial how to use this to connect to APIs using
API keys and OAuth credentials.
credentials=None,
)
print("# Lambda target added\n")

Step 2.4: Save configuration for agent
config = {
"gateway_url": gateway["gatewayUrl"],
"gateway_id": gateway["gatewayId"],
"region": region,
"client_info": cognito_response["client_info"]
}

with open("gateway_config.json", "w") as f:
json.dump(config, f, indent=2)

print("=" * 60)
print("# Gateway setup complete!")
print(f"Gateway URL: {gateway['gatewayUrl']}")
print(f"Gateway ID: {gateway['gatewayId']}")
print("\nConfiguration saved to: gateway_config.json")
print("\nNext step: Run 'python run_agent.py' to test your Gateway")
print("=" * 60)

return config

if name == "main":
setup_gateway()

Expand the following section for a step-by-step understanding of each component.

**Understanding the setup script â€“ Step-by-step explanation**

The following topics explain what happns in each part of the setup script:

**Topics**

- Import required libraries

Step 2: Create gateway setup script 243


- Create the Setup Function
- Create an OAuth Authorization Server
- Create a Gateway
- Adding Lambda Targets
- Save the gateway configuration

**Import required libraries**

First, import the necessary libraries for gateway creation and configuration.

from bedrock_agentcore_starter_toolkit.operations.gateway.client import GatewayClient
import json
import logging
import time

**Create the Setup Function**

Initialize the setup function with your AWSs region configuration.

def setup_gateway():

Configuration
region = "us-east-1" # Change to your preferred region

print("# Setting up AgentCore Gateway...")
print(f"Region: {region}\n")

Initialize client
client = GatewayClient(region_name=region)
client.logger.setLevel(logging.INFO)

**Create an OAuth Authorization Server**

Gateways are secured by OAuth authorization servers which ensure that only allowed users can
access your Gateway. Let's create an OAuth authorization server using Amazon Cognito.

Step 2.1: Create OAuth authorizer
print("Step 2.1: Creating OAuth authorization server...")
cognito_response = client.create_oauth_authorizer_with_cognito("TestGateway")
print("# Authorization server created\n")

Step 2: Create gateway setup script 244


**What happens here** : This creates an Amazon Cognito user pool with an OAuth 2.0 client
credentials flow configured. You'll get a client ID and secret that can be used to obtain access
tokens.

**Create a Gateway**

Now, let's create a gateway. The gateway acts as your MCP server endpoint that agents will connect
to.

Step 2.2: Create Gateway
print("Step 2.2: Creating Gateway...")
gateway = client.create_mcp_gateway(

the name of the Gateway - if you don't set one, one will be generated.
name=None,

the role arn that the Gateway will use - if you don't set one, one will be
created.

NOTE: if you are using your own role make sure it has a trust policy that
trusts bedrock-agentcore.amazonaws.com
role_arn=None,

the OAuth authorization server details. If you are providing your own
authorization server,

then pass an input of the following form: {"customJWTAuthorizer":
{"allowedClients": [""], "discoveryUrl": ""}}
authorizer_config=cognito_response["authorizer_config"],

enable semantic search
enable_semantic_search=True,
)
print(f"# Gateway created: {gateway['gatewayUrl']}\n")

If role_arn was not provided, fix IAM permissions
NOTE: This is handled internally by the toolkit when no role is provided
client.fix_iam_permissions(gateway)
print("# Waiting 30s for IAM propagation...")
time.sleep(30)
print("# IAM permissions configured\n")

**What happens here** : Creates a gateway with MCP protocol support, configures OAuth
authorization, and enables semantic search for tool discovery. If you don't provide a role, one is
created and configured automatically.

Step 2: Create gateway setup script 245


**Adding Lambda Targets**

Let's add a Lambda function target. This code will automatically create a Lambda function with
weather and time tools.

s# Step 2.3: Add Lambda target
print("Step 2.3: Adding Lambda target...")
lambda_target = client.create_mcp_gateway_target(

the gateway created in the previous step
gateway=gateway,

the name of the Target - if you don't set one, one will be generated.
name=None,

the type of the Target
target_type="lambda",

the target details - set this to define your own lambda if you pre-created
one.

Otherwise leave this None and one will be created for you.
target_payload=None,

you will see later in the tutorial how to use this to connect to APIs using
API keys and OAuth credentials.
credentials=None,
)
print("# Lambda target added\n")

**What happens here** : Creates a test Lambda function with two tools (get_weather and
get_time) and registers it as a target in your gateway.

**Save the gateway configuration**

Save the gateway configuration to a file for use by the agent.

Step 2.4: Save configuration for agent
config = {
"gateway_url": gateway["gatewayUrl"],
"gateway_id": gateway["gatewayId"],
"region": region,
"client_info": cognito_response["client_info"]
}

with open("gateway_config.json", "w") as f:
json.dump(config, f, indent=2)

print("=" * 60)

Step 2: Create gateway setup script 246


print("# Gateway setup complete!")
print(f"Gateway URL: {gateway['gatewayUrl']}")
print(f"Gateway ID: {gateway['gatewayId']}")
print("\nConfiguration saved to: gateway_config.json")
print("\nNext step: Run 'python run_agent.py' to test your Gateway")
print("=" * 60)

return config

if name == "main":
setup_gateway()

#### Step 3: Run the setup.......................................................................................................................

Execute the setup script to create your gateway and invoke the Lambda target.

python setup_gateway.py

**What to expect** : The script will take about 2-3 minutes to complete. You'll see progress messages
for each step.

#### Step 4: Use the gateway with an agent........................................................................................

Create a new file called run_agent.py and insert the following code:

"""
Agent script to test the Gateway
Run this after setup: python run_agent.py
"""

from strands import Agent
from strands.models import BedrockModel
from strands.tools.mcp.mcp_client import MCPClient
from mcp.client.streamable_http import streamablehttp_client
from bedrock_agentcore_starter_toolkit.operations.gateway.client import GatewayClient
import json
import sys

def create_streamable_http_transport(mcp_url: str, access_token: str):
return streamablehttp_client(mcp_url, headers={"Authorization": f"Bearer
{access_token}"})

Step 3: Run the setup 247


def get_full_tools_list(client):
"""Get all tools with pagination support"""
more_tools = True
tools = []
pagination_token = None
while more_tools:
tmp_tools = client.list_tools_sync(pagination_token=pagination_token)
tools.extend(tmp_tools)
if tmp_tools.pagination_token is None:
more_tools = False
else:
more_tools = True
pagination_token = tmp_tools.pagination_token
return tools

def run_agent():

Load configuration
try:
with open("gateway_config.json", "r") as f:
config = json.load(f)
except FileNotFoundError:
print("# Error: gateway_config.json not found!")
print("Please run 'python setup_gateway.py' first to create the Gateway.")
sys.exit(1)

gateway_url = config["gateway_url"]
client_info = config["client_info"]

Get access token for the agent
print("Getting access token...")
client = GatewayClient(region_name=config["region"])
access_token = client.get_access_token_for_cognito(client_info)
print("# Access token obtained\n")

Model configuration - change if needed
model_id = "anthropic.claude-3-7-sonnet-20250219-v1:0"

print("# Starting AgentCore Gateway Test Agent")
print(f"Gateway URL: {gateway_url}")
print(f"Model: {model_id}")
print("-" * 60)

Setup Bedrock model
bedrockmodel = BedrockModel(

Step 4: Use the gateway with an agent 248


inference_profile_id=model_id,
streaming=True,
)

Setup MCP client
mcp_client = MCPClient(lambda: create_streamable_http_transport(gateway_url,
access_token))

with mcp_client:

List available tools
tools = get_full_tools_list(mcp_client)
print(f"\n# Available tools: {[tool.tool_name for tool in tools]}")
print("-" * 60)

Create agent
agent = Agent(model=bedrockmodel, tools=tools)

Interactive loop
print("\n# Interactive Agent Ready!")
print("Try asking: 'What's the weather in Seattle?'")
print("Type 'exit', 'quit', or 'bye' to end.\n")

while True:
user_input = input("You: ")
if user_input.lower() in ["exit", "quit", "bye"]:
print("# Goodbye!")
break

print("\n# Thinking...\n")
response = agent(user_input)
print(f"\nAgent: {response.message.get('content', response)}\n")

if name == "main":
run_agent()

**Run your agent**

Test your gateway by running the agent and interacting with the tools.

python run_agent.py

That's it! The agent will start and you can ask questions like:

Step 4: Use the gateway with an agent 249


- "What's the weather in Seattle?"
- "What time is it in New York?"

#### What you've built...............................................................................................................................

Through this getting started tutorial, you've created the following resources:

- **MCP Server (Gateway)** : A managed endpoint at https://gateway-id.gateway.bedrock-
    agentcore.region.amazonaws.com/mcp
- **Lambda tools** : Mock functions that return test data (weather: "72Â°F, Sunny", time: "2:30 PM")
- **OAuth authentication** : Secure access using Cognito tokens
- **AI agent** : Claude-powered assistant that can discover and use your tools

#### Troubleshooting..................................................................................................................................

The following table shows some possible issues and their solutions:

Issue Solution

"No module named 'strands'" Run: pip install strands-agents

"Model not enabled" Enable Claude Sonnet 3.7 in Bedrock console â†’ Model access

"AccessDeniedException" Check IAM permissions for bedrock-agentcore:*

Gateway not responding Wait 30-60 seconds after creation for DNS propagation

OAuth token expired Tokens expire after 1 hour, get new one with get_acces
s_token_for_cognito()

#### Quick validation..................................................................................................................................

Run the following commands in a terminal to check that your gateway is working.

Check your Gateway is working
curl -X POST YOUR_GATEWAY_URL \

What you've built 250


-H "Authorization: Bearer YOUR_TOKEN"
-H "Content-Type: application/json"
-d '{"jsonrpc":"2.0","id":1,"method":"tools/list","params":{}}'

Watch live logs
aws logs tail /aws/bedrock-agentcore/gateways/YOUR_GATEWAY_ID --follow

#### Cleanup.................................................................................................................................................

Create a cleanup_gateway.py file and insert the following contents:

from bedrock_agentcore_starter_toolkit.operations.gateway.client import GatewayClient
import json

with open("gateway_config.json", "r") as f:
config = json.load(f)

client = GatewayClient(region_name=config["region"])
client.cleanup_gateway(config["gateway_id"], config["client_info"])
print("# Cleanup complete!")

Run the following in a terminal:

python cleanup_gateway.py

#### Next steps............................................................................................................................................

- **Custom Lambda Tools** : Create Lambda functions with your business logic
- **Add Your Own APIs** : Extend your Gateway with OpenAPI specifications for real services
- **Production Setup** : Configure VPC endpoints, custom domains, and monitoring

### Core concepts for Amazon Bedrock AgentCore Gateway

Amazon Bedrock AgentCore Gateway provides a standardized way for AI agents to discover
and interact with tools. Understanding the core concepts of Gateway will help you design and
implement effective tool integration strategies for your AI agents.

Cleanup 251


#### Key concepts........................................................................................................................................

**Gateway**

An Gateway acts like an MCP server, providing a single access point for an agent to interact with
its tools. A Gateway can have multiple targets, each representing a different tool or set of tools.

**Gateway Target**

A target defines the APIs or Lambda function that a Gateway will provide as tools to an agent.
Targets can be Lambda functions, OpenAPI specifications, Smithy models, or other tool
definitions.

**AgentCore Gateway Authorizer**

Since MCP only supports OAuth, each Gateway must have an attached OAuth authorizer. If you
donâ€™t have an OAuth authorization server already, you will be able to create one in this guide
using Cognito.

**AgentCore Credential Provider**

When Gateway makes calls to your APIs or Lambda function it must use some credentials to
access those functionalities. When you create a Smithy or Lambda target, Gateway uses the
attached execution role to make calls to those targets. When you create an OpenAPI target, you
must attach an AgentCore credential provider which stores the API Key or OAuth credentials
that Gateway will use to access the OpenAPI target.

#### Tool types.............................................................................................................................................

Gateway supports several types of tools and integration methods:

**OpenAPI specifications**

Transform existing REST APIs into MCP-compatible tools by providing an OpenAPI specification.
The gateway automatically handles the translation between MCP and REST formats.

**Lambda functions**

Connect Lambda functions as tools, allowing you to implement custom business logic in your
preferred programming language. The gateway invokes the Lambda function and translates the
response into the MCP format.

Key concepts 252


**Smithy models**

Use Smithy models to define your API interfaces and generate MCP-compatible tools. Smithy is
a language for defining services and SDKs that can be used with AWS services. The gateway can
use Smithy models to generate tools that interact with AWS services or custom APIs.

**MCP servers**

Use remote MCP servers to connect tools to your agent runtime. Only MCP tools capabilities
are supported. For both control plane and data plane operations, if tools are not available the
operations will fail.

### Supported targets for Amazon Bedrock AgentCore gateways

Targets define the tools that your gateway will host. Amazon Bedrock AgentCore Gateway supports
multiple target types that are detailed in the following topics. You can attach different credential
providers to different targets, which lets you securely control access to targets. By adding targets,
your gateway becomes a single MCP URL that enables access to all of the relevant tools for an
agent.

The following topics explain the target types that are supported for AgentCore Gateway and how
they integrate into your gateway. You should review these pages to make sure that a resource that
you want to add as a target for your gateway is compatible. The final topic discusses how target
names are constructed for a gateway so you can understand how to incorporate them.

**Topics**

- AWS Lambda function targets
- OpenAPI schema targets
- Smithy model targets
- MCP servers targets
- Built-in templates from integration providers as targets
- Understand how AgentCore Gateway tools are named

#### AWS Lambda function targets

Lambda targets allow you to connect your gateway to AWS Lambda functions that implement your
tools. This is useful when you want to execute custom code in response to tool invocations.

Supported gateway targets 253


You create a Lambda function using the AWS Lambda service. In order to create the function, you
should do the following:

- Create a tool schema that defines the tools that your Lambda function can call.
- Understand the Lambda input format. You can then follow the steps in the AWS Lambda
    Developer Guide for **Building with** the language of your choice.

After you create the function, you configure permissions for the gateway to be able to access it.

Review the key considerations and limitations to help you decide whether a Lambda target is
applicable to your use case. If it is, you can create the tool schema and the Lambda function and
then set up permissions for the gateway to be able to access the target. Select a topic to learn
more:

**Topics**

- Key considerations and limitations
- Lambda function tool schema
- Lambda function input format

**Key considerations and limitations**

When working with Lambda targets, be aware of the following limitations and considerations:

- Tool name prefixes will need to be manually stripped off from the toolname in your AWS
    Lambda function. For more information, see Understand how AgentCore Gateway tools are
    named.
- If you are using an existing AWS Lambda function and import it as a tool into the gateway, you
    will need to change the function code to account for a schema change for event and context
    objects
- The Lambda function must return a valid JSON response that can be parsed by the gateway
- Lambda function timeouts should be configured appropriately to handle the expected processing
    time of your tools
- Consider implementing error handling in your LLambda function to provide meaningful error
    messages to the client

Lambda functions 254


**Lambda function tool schema**

This section explains the structure of the tool schema that defines a tool that your Lambda
function can return. After you define your tool schema, you can do one of the following:

- Upload it to an Amazon S3 bucket and refer to the S3 location when you add the target to your
    gateway.
- Paste the definition inline when you add the target to your gateway.

Select a topic to learn more about the details of the tool schema or to see examples:

**Topics**

- Tool definition
- Top level schema definition for input and output schemas
- Property schema definition
- Example Lambda tool definitions

**Tool definition**

When you add a Lambda function as a gateway target, you provide a ToolDefinition when
providing the target configuration. The structure of the tool definition is as follows:

{
"name": " string ",
"description": " string ",
"inputSchema": {
"type": "object",
"description" " string ",
"properties": {
" string ": SchemaDefinition
},
"required": [" string "]
},
"outputSchema": {
"type": "object",
"description" " string ",
"properties": {
" string ": SchemaDefinition
},

Lambda functions 255


"required": [" string "]
}
}

The tool definition contains the following fields:

- **name** (required) â€“ The name of the tool.
- **description** (required) â€“ A description of the tool and its purpose and usage.
- **inputSchema** (required) â€“ A JSON object that defines the structure of the input that the tool
    accepts.
- **outputSchema** (optional) â€“ A JSON object that defines the structure of the output that the tool
    produces.

The inputSchema and outputSchema fields both map to an object-type SchemaDefinition,
described in the following section.

**Top level schema definition for input and output schemas**

The inputSchema and outputSchema fields at the top level of the tool definition both map to an
object-type SchemaDefinition that contains the following fields:

{
"type": "object",
"description": " string ",
"properties": {
" string ": SchemaDefinition
},
"required": [" string "]
}

- **type** (required) â€“ Must be object.
- **description** (optional) â€“ A description of the schema and its purpose and usage.
- **properties** (optional) â€“ A JSON object that defines the properties or arguments of the tool. Each
    key is a name of a property and maps to a SchemaDefinition object that defines the property.
- **required** (optional) â€“ An array that enumerates the properties that are reqired in the
    properties object.

Lambda functions 256


If you include a properties field to define arguments for the tool, you provide a schema
definition for each argument. The different types of schema definitions are outlined in the next
section.

**Property schema definition**

Each property in the top level SchemaDefinition maps to a SchemaDefinition object that has
slightly different requirements from the top level schema definition. The available fields depend on
the type for the property. To see the shape of the SchemaDefinition for a type, select from the
following tabs:

String

The SchemaDefinition for a string property has the following structure:

{
"type": "string",
"description": " string "
}

Number

The SchemaDefinition for a number property has the following structure:

{
"type": "number",
"description": " string "
}

Integer

The SchemaDefinition for a integer property has the following structure:

{
"type": "integer",
"description": " string "
}

Boolean

The SchemaDefinition for a boolean property has the following structure:

Lambda functions 257


{
"type": "boolean",
"description": " string "
}

Array

The SchemaDefinition for an array property has the following structure:

{
"type": "array",
"description": " string ",
"items": SchemaDefinition
}

The value of the items field is a SchemaDefinition that defines the structure of each item in
the array.

Object

The SchemaDefinition for an object property has the following structure and matches the
top level property schema definition.

{
"type": "object",
"description": " string ",
"properties": {
" string ": SchemaDefinition
},
"required": [" string "]
}

If you include another object-type property, you will recursively add another SchemaDefinition.

**Example Lambda tool definitions**

Select a tab to see example tool definitions that you can include in your Lambda function.

Weather tool

The following get_weather tool requires a location string argument and can be used to
return the weather for that location:

Lambda functions 258


{
"name": "get_weather",
"description": "Get weather for a location",
"inputSchema": {
"type": "object",
"properties": {
"location": {
"type": "string",
"description": "the location e.g. seattle, wa"
}
},
"required": [
"location"
]
}
}

Time tool

The following get_time tool requires a timezone string argument and can be used to return
the time for that timezone:

{
"name": "get_time",
"description": "Get time for a timezone",
"inputSchema": {
"type": "object",
"properties": {
"timezone": {
"type": "string"
}
},
"required": [
"timezone"
]
}
}

Lambda functions 259


**Lambda function input format**

When an Amazon Bedrock AgentCore gateway invokes a Lambda function, it passes an event
object and a context object to the function. The Lambda event handler that you write can access
values in these objects.

**Event object**

A map of properties from the inputSchema to their values, as returned by the tool. For
example, if your input schema contains the properties keywords and category, the event object
could be the following:

{
"keywords": "wireless headphones",
"category": "electronics"
}

**Context object**

Contains the following metadata:

- bedrockAgentCoreMessageVersion â€“ The version of the message.
- bedrockAgentCoreAwsRequestId â€“ The ID of the request made to the Amazon Bedrock
    AgentCore service.
- bedrockAgentCoreMcpMessageId â€“ The ID of the message sent to the MCP server.
- bedrockAgentCoreGatewayId â€“ The ID of the gateway that was invoked.
- bedrockAgentCoreTargetId â€“ The ID of the gateway target that was invoked.
- bedrockAgentCoreToolNameâ€“ The name of the tool that was called. The tool name is in the
    format _${target_name}_ __ _${tool_name}_.

The format of the context object is as follows:

{
"bedrockAgentCoreMessageVersion": "1.0",
"bedrockAgentCoreAwsRequestId": " string ",
"bedrockAgentCoreMcpMessageId": " string ",
"bedrockAgentCoreGatewayId": " string ",
"bedrockAgentCoreTargetId": " string ",

Lambda functions 260


"bedrockAgentCoreToolName": " string "
}

The Lambda function that you write can access the properties of the event and context object. You
can use the following boilerplate code to get started:

Access context properties in your Lambda function
def lambda_handler(event, context):

Since the visible tool name includes the target name as a prefix, we can use this
delimiter to strip the prefix
delimiter = "___"

Get the tool name from the context
originalToolName = context.client_context.custom['bedrockAgentCoreToolName']
toolName = originalToolName[originalToolName.index(delimiter) + len(delimiter):]

Get other context properties
message_version = context.client_context.custom['bedrockAgentCoreMessageVersion']
aws_request_id = context.client_context.custom['bedrockAgentCoreAwsRequestId']
mcp_message_id = context.client_context.custom['bedrockAgentCoreMcpMessageId']
gateway_id = context.client_context.custom['bedrockAgentCoreGatewayId']
target_id = context.client_context.custom['bedrockAgentCoreTargetId']

Process the request based on the tool name
if tool_name == 'searchProducts':

Handle searchProducts tool
pass
elif tool_name == 'getProductDetails':

Handle getProductDetails tool
pass
else:

Handle unknown tool
pass

#### OpenAPI schema targets

OpenAPI (formerly known as Swagger) is a widely used standard for describing RESTful APIs.
Gateway supports OpenAPI 3.0 specifications for defining API targets.

OpenAPI targets connect your gateway to REST APIs defined using OpenAPI specifications. The
Gateway translates incoming MCP requests into HTTP requests to these APIs and handles the
response formatting.

OpenAPI schemas 261


Review the key considerations and limitations, including feature support, to help you decide
whether an OpenAPI target is applicable to your use case. If it is, you can create a schema that
follows the specifications and then set up permissions for the gateway to be able to access the
target. Select a topic to learn more:

**Topics**

- Key considerations and limitations
- OpenAPI schema specification

**Key considerations and limitations**

Important
The OpenAPI specification must include operationId fields for all operations that you
want to expose as tools. The operationId is used as the tool name in the MCP interface.

When using OpenAPI targets, keep in mind the following requirements and limitations:

- OpenAPI versions 3.0 and 3.1 are supported (Swagger 2.0 is not supported)
- The OpenAPI file must be free of semantic errors
- The server attribute needs to have a valid URL of the actual endpoint
- Only application/json content type is fully supported
- Complex schema features like oneOf, anyOf, and allOf are not supported
- Path parameter serializers and parameter serializers for query, header, and cookie parameters are
    not supported
- Each LLM will have ToolSpec constraints. If OpenAPI has APIs/properties/object names not
    compliant to ToolSpec of the respective downstream LLMs, the data plane will fail. Common
    errors are property name exceeding the allowed length or the name containing unsupported
    character.

For best results with OpenAPI targets:

- Always include operationId in all operations
- Use simple parameter structures instead of complex serialization

OpenAPI schemas 262


- Implement authentication and authorization outside of the specification
- Only use supported media types for maximum compatibility

In considering using OpenAPI schema targets with AgentCore Gateway, review the following
feature support table.

**OpenAPI feature support**

The following table outlines the OpenAPI features that are supported and unsupported by
Gateway:

**OpenAPI feature support**

Supported Features Unsupported Features

Schema Definitions

- Basic data types (string, number, integer,
    boolean, array, object)
- Required field validation
- Nested object structures
- Array definitions with item specifications

Schema Composition

- oneOf specifications
- anyOf specifications
- allOf specifications

HTTP Methods

- Standard HTTP methods (GET, POST, PUT,
    DELETE, PATCH, HEAD, OPTIONS)

Security Schemes

- Security schemes at the OpenAPI specifica
    tion level (authentication must be configure
    d using the Gateway's outbound authoriza
    tion configuration)

Media Types

- application/json
- application/xml
- multipart/form-data
- application/x-www-form-urlencoded

Media Types

- Custom media types beyond the supported
    list
- Binary media types

Path Parameters Parameter Serialization

OpenAPI schemas 263


Supported Features Unsupported Features

- Simple path parameter definitions
    (Example: /users/{userId})
       - Complex path parameter serializers
          (Example: `/users{;id\*}{?metadata}`)
       - Query parameter arrays with complex
          serialization
       - Header parameter serializers
       - Cookie parameter serializers

Query Parameters

- Basic query parameter definitions
- Simple string, number, and boolean types

Callbacks and Webhooks

- Callback operations
- Webhook definitions

Request/Response Bodies

- JSON request and response bodies
- XML request and response bodies
- Standard HTTP status codes (200, 201, 400,
    404, 500, etc.)

Links

- Links between operations

**OpenAPI schema specification**

The OpenAPI specification defines the REST API that your Gateway will expose. Refer to the
following resources when setting up your OpenAPI specification:

- For information about the format of the OpenAPI specification, see OpenAPI Specification.
- For information about supported and unsupported features when using an OpenAPI
    specification with AgentCore Gateway, see the table in OpenAPI feature support. Adhere to these
    requirements to prevent errors during target creation and invocation.

After you define your OpenAPI schema, you can do one of the following:

- Upload it to an Amazon S3 bucket and refer to the S3 location when you add the target to your
    gateway.
- Paste the definition inline when you add the target to your gateway.

OpenAPI schemas 264


Expand a section to see examples of supported and unsupported OpenAPI specifications:

**Supported OpenAPI specification Example 1**

Following shows an example of a supported OpenAPI specification

Example of a supported OpenAPI specification:

{
"openapi": "3.0.0",
"info": {
"title": "Weather API",
"version": "1.0.0",
"description": "API for retrieving weather information"
},
"paths": {
"/weather": {
"get": {
"summary": "Get current weather",
"description": "Returns current weather information for a location",
"operationId": "getCurrentWeather",
"parameters": [
{
"name": "location",
"in": "query",
"description": "City name or coordinates",
"required": true,
"schema": {
"type": "string"
}
},
{
"name": "units",
"in": "query",
"description": "Units of measurement (metric or imperial)",
"required": false,
"schema": {
"type": "string",
"enum": ["metric", "imperial"],
"default": "metric"
}
}
],
"responses": {

OpenAPI schemas 265


"200": {
"description": "Successful response",
"content": {
"application/json": {
"schema": {
"type": "object",
"properties": {
"location": {
"type": "string"
},
"temperature": {
"type": "number"
},
"conditions": {
"type": "string"
},
"humidity": {
"type": "number"
}
}
}
}
}
},
"400": {
"description": "Invalid request"
},
"404": {
"description": "Location not found"
} } } } } }

**Supported OpenAPI Specification Example 2**

Following shows another example of a supported OpenAPI specification.

{
"openapi": "3.0.0",
"info": {
"title": "Search API",

OpenAPI schemas 266


"version": "1.0.0",
"description": "API for searching content"
},
"servers": [
{
"url": "https://api.example.com/v1"
}
],
"paths": {
"/search": {
"get": {
"summary": "Search for content",
"operationId": "searchContent",
"parameters": [
{
"name": "query",
"in": "query",
"description": "Search query",
"required": true,
"schema": {
"type": "string"
}
},
{
"name": "limit",
"in": "query",
"description": "Maximum number of results",
"required": false,
"schema": {
"type": "integer",
"default": 10
}
}
],
"responses": {
"200": {
"description": "Successful response",
"content": {
"application/json": {
"schema": {
"type": "object",
"properties": {
"results": {
"type": "array",

OpenAPI schemas 267


"items": {
"type": "object",
"properties": {
"title": {
"type": "string"
},
"url": {
"type": "string"
},
"snippet": {
"type": "string"
}
}
}
},
"total": {
"type": "integer"
}
}
}
}
}
},
"400": {
"description": "Bad request"
} } } } } }

**Unsupported OpenAPI schema**

The following shows an example of an unsupported schema with oneOf:

{
"oneOf": [
{"$ref": "#/components/schemas/Pencil"},
{"$ref": "#/components/schemas/Pen"}
]
}

OpenAPI schemas 268


#### Smithy model targets

Smithy is a language for defining services and software development kits (SDKs). Smithy models
provide a more structured approach to defining APIs compared to OpenAPI, and are particularly
useful for connecting to AWS services, such as AgentCore Gateway.

Smithy model targets connect your AgentCore gateway to services that are defined using Smithy
API models. When you invoke a Smithy model gateway target, the gateway translates incoming
MCP requests into API calls that are sent to these services. The gateway also handles the response
formatting.

Review the key considerations and limitations, including feature support, to help you decide
whether a Smithy target is applicable to your use case. If it is, you can create a schema that follows
the specifications and then set up permissions for the gateway to be able to access the target.
Select a topic to learn more:

**Topics**

- Key considerations and limitations
- Smithy model specification

**Key considerations and limitations**

When using Smithy models with AgentCore Gateway, be aware of the following limitations:

- Maximum model size: 10MB
- Only JSON protocol bindings are fully supported
- Only RestJson protocol is supported
- Complex endpoint creation rule sets are not supported
- Only simple URL parameters like {region} are supported

In considering using Smithy models with AgentCore Gateway, review the following feature support
table.

**Smithy feature support for AgentCore Gateway**

The following table outlines the Smithy features that are supported and unsupported by Gateway:

Smithy models 269


**Smithy feature support**

Supported Features Unsupported Features

Service Definitions

- Service structure definitions based on
    Smithy specifications
- Operation definitions with input/output
    shapes
- Resource definitions
- Trait shapes

Endpoint Rules

- Endpoint creation rule sets
- Runtime endpoint determination based on
    conditions
- Complex URL parameters beyond simple
    {region} substitution

Protocol Support

- RestJson protocol
- Standard HTTP request/response patterns

Protocol Support

- RestXml protocol
- JsonRpc protocol
- AwsQuery protocol
- Ec2Query protocol
- Custom protocols

Data Types

- Primitive types (string, integer, boolean,
    float, double)
- Complex types (structures, lists, maps)
- Timestamp handling
- Blob data types

Authentication

- Multiple egress authentication types for
    specific APIs
- Complex authentication schemes requiring
    runtime decisions

HTTP Bindings

- Basic HTTP method bindings
- Simple path parameter bindings
- Query parameter bindings
- Header bindings for simple cases

Operations

- Streaming operations
- Operations requiring custom protocol
    implementations

Smithy models 270


**Smithy model specification**

AgentCore Gateway provides built-in Smithy models for common AWS services via an AWS-
provided S3 bucket that hosts the Smithy files. You can pass the Smithy file URIs to the create
target API.

To see Smithy models for AWS services, see the AWS API Models repository.

After you define your Smithy model, you can do one of the following:

- Upload it to an Amazon S3 bucket and refer to the S3 location when you add the target to your
    gateway.
- Paste the definition inline when you add the target to your gateway.

Expand a section to see examples of supported and unsupported Smithy model specifications:

**Example: Valid Smithy model for weather service**

The following example shows a valid Smithy model specification for a weather service:

namespace example.weather

use aws.protocols#restJson1
use smithy.framework#ValidationException

/// Weather service for retrieving weather information
@restJson1
service WeatherService {
version: "1.0.0",
operations: [GetCurrentWeather]
}

/// Get current weather for a location
@http(method: "GET", uri: "/weather")
operation GetCurrentWeather {
input: GetCurrentWeatherInput,
output: GetCurrentWeatherOutput,
errors: [ValidationException]
}

structure GetCurrentWeatherInput {
/// City name or coordinates

Smithy models 271


@required
@httpQuery("location")
location: String,

/// Units of measurement (metric or imperial)
@httpQuery("units")
units: Units = metric
}

structure GetCurrentWeatherOutput {
/// Location name
location: String,

/// Current temperature
temperature: Float,

/// Weather conditions description
conditions: String,

/// Humidity percentage
humidity: Float
}

enum Units {
metric
imperial
}

**Example: Invalid Smithy model specification**

The following example shows an invalid endpoint rules configuration using Smithy:

@endpointRuleSet({
"rules": [
{
"conditions": [{"fn": "booleanEquals", "argv": [{"ref": "UseFIPS"}, true]}],
"endpoint": {"url": "https://weather-fips.{Region}.example.com"}
},
{
"endpoint": {"url": "https://weather.{Region}.example.com"}
}
]
})

Smithy models 272


#### MCP servers targets...........................................................................................................................

MCP servers provide local tools, data access, or custom functions for your interactions with models
and agents in Bedrock AgentCore. In Bedrock AgentCore, you can define a preconfigured MCP
server as a target when creating a gateway.

MCP servers host tools which agents can discover and invoke. In Bedrock AgentCore, you use a
gateway to associate targets to tools to connect to your agent runtime. You connect with external
MCP servers through the SynchronizeGatewayTargets API that performs protocol handshakes
and indexes available tools. For more information about installing and using MCP servers, see
Amazon Bedrock AgentCore MCP Server: Vibe coding with your coding assistant.

**Topics**

- Key considerations and limitations
- Configuring permissions

**Key considerations and limitations**

Tool discovery is managed through the synchronization operation provided by the
SynchronizeGatewayTargets API as follows.

**Implicit Synchronization**

Implicity synchronization is the automatic tool discovery and indexing that occurs during
CreateGatewayTarget and UpdateGatewayTarget operations. Gateway immediately calls the
MCP server's tools/list capability to fetch available tools and make tools available in the unified
catalog without requiring separate user action.

**Explicit Synchronization**

Manual tool catalog refresh triggered by calling the SynchronizeGatewayTargets API. Invoke
this when the MCP server has changed its tool definitions. The API performs discovery process on-
demand operation, allowing users to control when Gateway updates its view of available tools.

Synchronization is a critical mechanisms for maintaining accurate tool catalogs when integrating
MCP servers. Implicit synchronization occurs automatically during target creation and updates,
where Gateway immediately discovers and indexes tools from the MCP server to ensure tools are
available for semantic search and unified listing. Explicit synchronization is performed on-demand

MCP servers targets 273


through the SynchronizeGatewayTargets API, allowing discovery of MCP tool catalog when
MCP servers independently modify their capabilities.

**When to call SynchronizeGatewayTargets**

Use this API whenever your MCP server's tools change - whether adding new tools, modifying
existing tool schemas, or removing deprecated tools. Since Gateway pre-computes vector
embeddings for semantic search and maintains normalized tool catalogs, synchronization ensures
users can discover and invoke the latest available tools across all target types.

**How to call the API**

Make a PUT request to /gateways/{gatewayIdentifier}/synchronize with the target ID in the
request body. The API returns a 202 response immediately and processes synchronization
asynchronously. Monitor the target status through GetGatewayTarget to track synchronization
progress, as the operation can take several minutes for large tool sets.

**Authorization strategy**

Two types of the authorization strategy are supported.

- NoAuth - Gateway will invoke the MCP server's tool capabilities without preconfigured Auth. This
    is not the recommended approach.
- OAuth2 - Gateway supports two-legged OAuth. You configure the authorization provider in
    AgentCore Identity in the same account and Region for the Gateway to be able to make calls to
    the MCP server.

**Configuration considerations** For the MCP servers target type, the following must be configured.

1.The MCP server must have tool capabilities.

2.Supported MCP protocol versions are - **2025-06-18** and **2025-03-26**.

3.For the provided URL/endpoint of the server, the URL should be encoded. The Gateway will use
the same URL to invoke the server.

**Configuring permissions**

The IAM role which you use to create, update or synchronize MCP servers targets should have the
permissions shown in the following example.

MCP servers targets 274


{
"Version": "2012-10-17",
"Statement": [
{
"Effect": "Allow",
"Action": [
"bedrock-agentcore:CreateGateway",
"bedrock-agentcore:GetGateway",
"bedrock-agentcore:CreateGatewayTarget",
"bedrock-agentcore:GetGatewayTarget",
"bedrock-agentcore:SynchronizeGatewayTargets",
"bedrock-agentcore:UpdateGatewayTarget"
],
"Resource": "arn:aws:bedrock-agentcore:::gateway"
},
{
"Effect": "Allow",
"Action": [
"bedrock-agentcore:CreateWorkloadIdentity",
"bedrock-agentcore:GetWorkloadAccessToken",
"bedrock-agentcore:GetResourceOauth2Token",
"secretsmanager:GetSecretValue"
],
"Resource": ""
},
{
"Effect": "Allow",
"Action": [
"kms:EnableKeyRotation",
"kms:Decrypt",
"kms:Encrypt",
"kms:GenerateDataKey",
"kms:ReEncrypt",
"kms:CreateAlias",
"kms:DisableKey",
"kms:"
],
"Resource": "arn:aws:kms::123456789012:key/"
}
]
}

MCP servers targets 275


#### Built-in templates from integration providers as targets

Amazon Bedrock AgentCore lets you add open source templates from the following integration
providers as targets in your gateway:

- Amazon
- Asana
- BambooHR
- Brave
- Confluence
- Jira
- Microsoft
- PagerDuty
- Salesforce
- SAP
- ServiceNow
- Slack
- Smartsheet
- Tavily
- Zendesk
- Zoom

**Topics**

- Key considerations and limitations
- Supported APIs by template

**Key considerations and limitations**

When using templates from integration providers as targets, keep in mind the following
requirements and limitations:

- You can only add an integration provider template as a target through the AWS Management
    Console and not through the API.

Integration provider templates 276


- Amazon Bedrock AgentCore doesn't host any servers natively, so you must set up server hosting
    yourself. After you add the template, you can invoke the server URL that you set up using the
    authorization that you configure.
- Amazon Bedrock AgentCore supports a subset of APIs that the provider supports for interacting
    with these templates. For a list of APIs supported by AgentCore, see Supported APIs by template.

**Supported APIs by template**

This section lists the APIs that are supported for each template from an integration provider. To
learn more about a specific API and schemas, do the following:

- Search for the provider's API documentation.
- Send a tools/list call to the target after setting it up.

The following sections show, for each template, the outbound authentication types supported, the
server URL, and the supported APIs and their paths.

Note
If an API path has a replaceable {variable} , pass the variable in the params field of the
JSON RPC request.

Select a topic to learn about which APIs are supported for each template:

**Topics**

- Agents for Amazon Bedrock Runtime
- Amazon Bedrock Runtime
- Amazon CloudWatch
- Amazon DynamoDB
- Asana
- BambooHR
- Brave Search
- The Confluence Cloud REST API v2
- The Jira Cloud platform

Integration provider templates 277


- Microsoft Exchange
- Microsoft OneDrive
- Microsoft SharePoint
- Microsoft Teams
- PagerDuty Advance
- Salesforce Lightning Platform
- SAP Bill of Material
- SAP Business Partner (A2X)
- SAP Material Stock
- SAP Physical Inventory
- SAP Product Master (A2X)
- ServiceNow
- Slack Web
- Smartsheet
- Tavily Search
- Zendesk Suite
- Zoom

**Agents for Amazon Bedrock Runtime**

The following list provides key information for this template

- Server URL â€“ https://bedrock-agent-runtime. _{region}_ .amazonaws.com

Replace {region} with an actual value. Look up supported Regions at Agents for Amazon
Bedrock runtime APIs.

- Outbound authentication types accepted:
    - IAM credentials of gateway service role

To learn more about the Amazon Bedrock Agents Runtime API, see the Agents for Amazon Bedrock
API reference

The following table shows the APIs that you can call if you add this target type to your gateway:

Integration provider templates 278


REST API type Operation name REST API path Description

POST CreateSession / Creates a session
to temporarily
store conversations
for generative AI
applications.

POST DeleteAgentMemory / Deletes a memory
from an agent.

POST DeleteSession / Deletes a session
for temporarily
storing conversat
ions for generative AI
applications.

POST EndSession / Ends a session
for temporarily
storing conversat
ions for generative AI
applications.

POST GenerateQuery / Generates a query to
submit to an Amazon
Bedrock knowledge
base.

POST GetAgentMemory / Gets a memory from
an agent.

POST GetSession / Gets a session for
temporarily storing
conversations
for generative AI
applications.

Integration provider templates 279


REST API type Operation name REST API path Description

POST InvokeAgent / Invokes an Amazon
Bedrock agent.

POST InvokeInlineAgent / Invokes an agent that
you define inline.

POST ListSessions / Lists sessions for
temporarily storing
conversations
for generative AI
applications.

POST ListTagsForResource / Lists tags for an
Agents for Amazon
Bedrock Runtime
resource.

POST OptimizePrompt / Optimizes a prompt
for a specific task.

POST Rerank / Reranks the relevance
of cited sources
based on a query.

POST Retrieve / Retrieves results
from querying a
knowledge base.

POST RetrieveAndGenerate / Generate a
natural language
response based on
results retrieved
from querying a
knowledge base.

Integration provider templates 280


REST API type Operation name REST API path Description

POST TagResource / Tag an Agents for
Amazon Bedrock
resource.

POST UntagResource / Untag an Agents for
Amazon Bedrock
resource.

POST UpdateSession / Update a session
for temporarily
storing conversat
ions for generative AI
applications.

**Amazon Bedrock Runtime**

The following list provides key information for this template

- Server URL â€“ https://bedrock-runtime. _{region}_ .amazonaws.com

Replace {region} with an actual value. look up supported Regions at Amazon Bedrock runtime
APIs).

- Outbound authentication types accepted:
    - IAM credentials of gateway service role

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

POST Converse / Invoke an Amazon
Bedrock model to
generate a response
in a conversational
interface.

Integration provider templates 281


REST API type Operation name REST API path Description

POST ApplyGuardrail / Apply a guardrail to
content.

POST InvokeModel / Invoke an Amazon
Bedrock model to
generate a response
for a prompt.

**Amazon CloudWatch**

The following list provides key information for this template

- Server URL â€“ https://monitoring. _{region}_ .amazonaws.com

Replace {region} with an actual value. Look up supported Regions at Amazon CloudWatch
endpoints and quotas.

- Outbound authentication types accepted:
    - IAM credentials of gateway service role

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

POST DescribeAlarmHistory / Retrieve the history
for an alarm you've
set up.

POST DescribeAlarms / Retrieve information
about specific alarms.

POST DescribeAlarmsForM
etric

/ Retrieve information
about alarms for a
metric.

POST DescribeAnomalyDet
ectors

/ Retrieve anomaly
detection models

Integration provider templates 282


REST API type Operation name REST API path Description
that you've created in
your account.

POST DescribeInsightRules / Retrieve a list of
Contributor Insights
rules in your account.

POST DisableAlarmActions / Disable actions for
the specified alarms.

POST DisableInsightRules / Disable the specified
Contributor Insights
rules.

POST GetDashboard / Display the details of
the dashboard that
you specify.

POST GetInsightRuleReport / Get the time series
data collected by a
Contributor Insights
rule.

POST GetMetricData / Get metric values.

POST GetMetricStatistics / Get statistics for a
specified metric.

POST GetMetricStream / Get information
about a metric
stream.

POST GetMetricWidgetIma
ge

/ Get a snapshot graph
of a metric as a
bitmap image.

Integration provider templates 283


REST API type Operation name REST API path Description

POST ListDashboards / Return a list of
dashboards.

POST ListManagedInsight
Rules

/ Return a list of
managed Contributor
Insights rules.

POST ListMetricStreams / Return a list of metric
streams.

POST ListMetrics / Retrieve a list of
metrics.

POST ListTagsForResource / List tags for a
CloudWatch resource.

**Amazon DynamoDB**

The following list provides key information for this template

- Server URL â€“ https://dynamodb. _{region}_ .amazonaws.com

Replace {region} with an actual value. Look up supported Regions at Amazon DynamoDB
endpoints and quotas.

- Outbound authentication types accepted:
    - IAM credentials of gateway service role

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

POST BatchExecuteStatem
ent

/ Perform batch read
or writes on data
using PartiQL.

Integration provider templates 284


REST API type Operation name REST API path Description

POST BatchGetItem / Returns the attributes
of items from one or
more tables.

POST BatchWriteItem / Puts or deletes items
in one or more tables.

POST CreateBackup / Create a backup for a
table.

POST CreateTable / Create a table.

POST DeleteItem / Delete an item from a
table.

POST DeleteTable / Delete a table and all
its items.

POST DescribeBackup / Get information
about a backup.

POST DescribeContinuous
Backups

/ Check the status
of continuous
backups and point in
time recovery on a
specified table.

POST DescribeEndpoints / Return regional
endpoint informati
on.

POST DescribeLimits / Return your current
provisioned-capaci
ty quotas for your
account in an AWS
Region and for a
table you create in it.

Integration provider templates 285


REST API type Operation name REST API path Description

POST DescribeTable / Get information
about a table.

POST DescribeTimeToLive / Get information
about the time to
live (TTL) status on a
specified table.

POST ExecuteStatement / Perform a read or
singleton write on
data using PartiQL.

POST ExecuteTransaction / Perform transactional
reads or writes on
data using PartiQL.

POST GetItem / Get a set of attribute
s for an item in your
data.

POST GetResourcePolicy / Get a resource-based
IAM policy attached
to a resource, such as
a table or stream.

POST ListBackups / List backups for a
table.

POST ListGlobalTables / List all global tables
that have a replica in
the specified Region.

POST ListTables / List table names
associated with
an account and
endpoint.

Integration provider templates 286


REST API type Operation name REST API path Description

POST ListTagsOfResource / List the tags for a
DynamoDB resource.

POST PutItem / Create or update an
item in a table.

POST PutResourcePolicy / Attach a resource-
based IAM policy to
a resource, such as a
table or stream.

POST Query / Return the results for
a database query.

POST Scan / Return items and
item attributes by
accessing every
item in a table or
secondary index.

POST TagResource / Add a tag to a
DynamoDB resource.

POST TransactGetItems / Retrieve items from
one or more tables in
the same account and
Region.

POST TransactWriteItems / Carry out the
specified action on
items in one or more
tables in the same
account and Region.

POST UntagResource / Remove a tag from a
DynamoDB resource.

Integration provider templates 287


REST API type Operation name REST API path Description

POST UpdateItem / Modify an item's
attributes or add the
item to the table if it
doesn't exist.

POST UpdateTable / Modify provision
ed throughput
settings, global
secondary indexes, or
DynamoDB Streams
settings for a table.

**Asana**

The following list provides key information for this template

- Server URL â€“ https://app.asana.com/api/1.0
- Outbound authentication types accepted:
    - API key

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

POST createTask /tasks Create new task in
workspace

PUT updateTask /tasks/ {task_gid} Update existing task
details

**BambooHR**

The following list provides key information for this template

- Server URL â€“ https://api.bamboohr.com/api/gateway.php/ _{companyDomain}_

Integration provider templates 288


- Outbound authentication types accepted:
    - OAuth2

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

GET getCompanyInformat
ion

/v1/company_inform
ation

View company details

GET getCompanyEINs /v1/company_eins View company tax IDs

GET getEmployee /v1/emplo
yees/ {employee
Id}

Retrieve employee
information

POST updateEmployee /v1/emplo
yees/ {employee
Id}

Update employee
information

POST addEmployee /v1/employees Add new employee
with basic info

GET getEmployeesDirect
ory

/v1/employees/dire
ctory

View employee
directory

GET getTimeOffTypes /v1/meta/time_off/
types

View types of time
off

GET getTimeOffPolicies /v1/meta/time_off/
policies

View time off policy
list

GET getTimeOffRequests /v1/time_off/reque
sts

View time off
requests

PUT addTimeOffRequest /v1/emplo
yees/ {employee

Submit time off
request

Integration provider templates 289


REST API type Operation name REST API path Description
Id} /time_off/
request

PUT changeRequestStatus /v1/time_off/reque
sts/ {requestId} /
status

Update time off
request status

PUT adjustTimeOffBalan
ce

/v1/emplo
yees/ {employee
Id} /time_off/
balance_adjustment

Adjust employee time
off balance

PUT assignTimeOffPolicies /v1_1/emp
loyees/ {employee
Id} /time_off/
policies

Assign employee time
off policies

GET listTimeOffPolicies /v1/emplo
yees/ {employee
Id} /time_off/
policies

View time off policies

GET estimateFutureTime
OffBalances

/v1/emplo
yees/ {employee
Id} /time_off/
calculator

Calculate future time
off estimates

GET getWhosOutList /v1/time_off/whos_
out

See who's on leave

GET listEmployeeFiles /v1/emplo
yees/ {employee
Id} /files/view

View employee
documents

POST uploadEmployeeFile /v1/emplo
yees/ {employee
Id} /files

Upload Employee File

Integration provider templates 290


REST API type Operation name REST API path Description

GET getEmployeeTableRo
w

/v1/emplo
yees/ {employee
Id} /
tables/ {table}

Get employee table
data

**Brave Search**

The following list provides key information for this template

- Server URL â€“ https://api.search.brave.com/res/v1
- Outbound authentication types accepted:
    - API key

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

GET BraveWebSearch /web/search Performs a web
search query

**The Confluence Cloud REST API v2**

The following list provides key information for this template

- Server URL â€“ https:// _{your-domain}_
- Outbound authentication types accepted:
    - API key

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

GET getPages /wiki/api/v2/pages Get pages

Integration provider templates 291


REST API type Operation name REST API path Description

POST createPage /wiki/api/v2/pages Create page

PUT updatePage /wiki/api/v2/pages
/ {id}

Update page

GET getPageById /wiki/api/v2/pages
/ {id}

Get page by id

GET searchByCQL /wiki/rest/api/search Search content

GET getSpaces /wiki/api/v2/spaces Get spaces

**The Jira Cloud platform**

The following list provides key information for this template

- Server URL â€“ https://api.atlassian.com/ex/jira/ _{customerInstanceId}_
- Outbound authentication types accepted:
    - API key

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

POST moveIssuesToBacklog /rest/agile/1.0/ba
cklog/issue

Move issues to
backlog

GET GetAllBoards /rest/agile/1.0/board Get boards

GET getBoard /rest/agile/1.0/bo
ard/{boardId}

Get board

GET getAllSprints /rest/agile/1.0/bo
ard/{boardId}/sprint

Get all sprints

POST createSprint /rest/agile/1.0/sprint Create sprint

Integration provider templates 292


REST API type Operation name REST API path Description

DELETE deleteSprint /rest/agile/1.0/sp
rint/{sprintId}

Delete sprint

GET getSprint /rest/agile/1.0/sp
rint/{sprintId}

Get sprint

PUT updateSprint /rest/agile/1.0/sp
rint/{sprintId}

Update sprint

POST moveIssuesToSprint
AndRank

/rest/agile/1.0/sp
rint/{sprintId}/issue

Move issues to sprint
and rank

GET getAttachmentConte
nt

/rest/api/3/attach
ment/content/ {id}

Get attachment
content

POST createIssue /rest/api/3/issue Create an issue

PUT editIssue /rest/api/3/issue/
{issueIdOrKey}

Edit issue

GET getIssue /rest/api/3/issue/
{issueIdOrKey}

Get issue

DELETE deleteIssue /rest/api/3/issue/
{issueIdOrKey}

Delete issue

POST addAttachment /rest/api/3/issue/
{issueIdOrKey}/att
achments

Add attachment

GET getComments /rest/api/3/issue/
{issueIdOrKey}/com
ment

Get comments

POST addComment /rest/api/3/issue/
{issueIdOrKey}/com
ment

Add comment

Integration provider templates 293


REST API type Operation name REST API path Description

DELETE deleteComment /rest/api/3/issue/
{issueIdOrKey}/com
ment/ {id}

Delete comment

PUT updateComment /rest/api/3/issue/
{issueIdOrKey}/com
ment/ {id}

Update comment

GET getTransitions /rest/api/3/issue/
{issueIdOrKey}/tra
nsitions

Get transitions

POST DoTransition /rest/api/3/issue/
{issueIdOrKey}/tra
nsitions

Transition issue

GET getIssueTypesForPr
oject

/rest/api/3/issuet
ype/project

Get issue types for
project

GET getAllLabels /rest/api/3/label Get all labels

GET getPriorities /rest/api/3/priority Get priorities

POST createProject /rest/api/3/project Create project

GET listProjects /rest/api/3/project Get all projects

GET searchProjects /rest/api/3/project/
search

Get projects
paginated

DELETE deleteProject /rest/api/3/project/
{projectIdOrKey}

Delete project

GET getProject /rest/api/3/project/
{projectIdOrKey}

Get project

PUT updateProject /rest/api/3/project/
{projectIdOrKey}

Update project

Integration provider templates 294


REST API type Operation name REST API path Description

GET searchStatuses /rest/api/3/statuses/
search

Search statuses
paginated

GET SearchIssues /rest/api/3/search/
jql

Search for issues
using JQL enhanced
search (GET)

GET getAllUsers /rest/api/3/users Get all users default

GET findUsers /rest/api/3/user/s
earch

Find users

**Microsoft Exchange**

The following list provides key information for this template

- Server URL â€“ https://graph.microsoft.com/v1.0
- Outbound authentication types accepted:
    - API key

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

POST sendUserEmail /users/ {userId} /
microsoft.graph.s
endMail

Send Email

GET listUserMails /users/ {userId} /
messages

Get messages from
users

GET ListFolderMessage /users/ {userId} /
mailFold
ers/ {mailFold
erId} /messages

Get messages from
users

Integration provider templates 295


REST API type Operation name REST API path Description

GET getEmailById /users/ {userId} /
messages
/ {messageId}

Get messages from
users

PATCH updateEmail /users/ {userId} /
messages
/ {messageId}

Update the navigatio
n property messages
in users

DELETE deleteEmail /users/ {userId} /
messages
/ {messageId}

Delete navigation
property messages
for users

POST moveEmailToFolder /users/ {userId} /
messages
/ {messageId} /
move

Move Email to Folder

POST forwardUserEmail /users/ {userId} /
messages
/ {messageId} /
forward

Forward User Email

POST replyToEmail /users/ {userId} /
messages
/ {messageId} /
reply

Reply to a message

GET listEmailAttachment /users/ {userId} /
messages
/ {messageId} /
attachments

Get attachments
from users

Integration provider templates 296


REST API type Operation name REST API path Description

GET getAttachmentById /users/ {userId} /
messages
/ {messageI
d} /attachme
nts/ {attachme
ntId}

Get attachments
from users

GET listCalendarEvents /users/ {userId} /
calendar/events

Get events from users

POST createCalendarEvent /users/ {userId} /
calendar/events

Create new navigatio
n property to events
for users

PATCH updateCalendarEvent /users/ {userId} /
calendar/
events/ {eventId}

Update the calender
events in users

POST findMeetingTimes /users/ {userId} /
findMeetingTimes

Suggest meeting
times and locations

GET listMailFolders /users/ {userId} /
mailFolders

Get mailFolders from
users

GET listContacts /users/ {userId} /
contacts

Get contacts from
users

GET listUsers /users List users

GET getUser /users/ {userId} Get a user

GET getMailboxSettings /users/ {userId} /
mailboxSettings

Get current mailbox
settings of the user.

GET listPlaces /places/microsoft.
graph.room

List places

Integration provider templates 297


**Microsoft OneDrive**

The following list provides key information for this template

- Server URL â€“ https://graph.microsoft.com/v1.0
- Outbound authentication types accepted:
    - API key

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

GET getUser /users/ {userId} Get a user

GET getDrive /users/ {userId} /
drive

Get drive from users

GET listItem /users/ {userId} /
drive/root/children

Get items from users

POST createItem /users/ {userId} /
drive/root/children

Create new navigatio
n property to items
for users

GET getItem /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId}

Get items from users

PATCH updateItem /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId}

Update file or folder
metadata

DELETE deleteItem /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId}

Delete navigation
property items for
users

Integration provider templates 298


REST API type Operation name REST API path Description

GET listChildren /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId} /children

Get children from
users

POST copyItem /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId} /copy

Copy item within a
drive

POST addPermisions /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId} /invite

Add permission

PUT uploadFile /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId} :/ {fileName
} :/content

Upload new file

POST addSheet /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId} /workbook/
worksheets/add

Add worksheet

GET readSheet /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId} /workbook
/workshee
ts/ {workshee
tIdOrName}

Get worksheets from
drives

Integration provider templates 299


REST API type Operation name REST API path Description

PATCH updateSheet /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId} /workbook
/workshee
ts/ {workshee
tIdOrName}

Update worksheet

DELETE deleteSheet /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId} /workbook
/workshee
ts/ {workshee
tIdOrName}

Delete worksheet

GET readCell /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId} /workbook
/workshee
ts/ {workshee
tIdOrName
} /cell(row
= {row} ,column= {column} )

Read cell within a
sheet

PATCH writeCell /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId} /workbook
/workshee
ts/ {workshee
tIdOrName
} /cell(row
= {row} ,column= {column} )

Write cell within a
sheet

Integration provider templates 300


REST API type Operation name REST API path Description

GET readRange /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId} /workbook
/workshee
ts/ {workshee
tIdOrName
} /range(ad
dress=' {address} ')

Read range

PATCH writeRange /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId} /workbook
/workshee
ts/ {workshee
tIdOrName
} /range(ad
dress=' {address} ')

Write range

POST deleteRange /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId} /workbook
/workshee
ts/ {workshee
tIdOrName
} /range(ad
dress=' {address}
')/delete

Delete Range within a
sheet

Integration provider templates 301


REST API type Operation name REST API path Description

GET listSheets /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId} /workbook/
worksheets

Get worksheets from
drives

GET readUsedRange /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId} /workbook
/workshee
ts/ {workshee
tIdOrName} /
usedRange

Read used range of a
sheet

POST clearRange /users/ {userId} /
drives/ {driveId}
/items/ {driveIte
mId} /workbook
/workshee
ts/ {workshee
tIdOrName
} /range(ad
dress=' {address}
')/clear

Clear range within a
sheet

**Microsoft SharePoint**

The following list provides key information for this template

- Server URL â€“ https://graph.microsoft.com/v1.0
- Outbound authentication types accepted:
    - API key

Integration provider templates 302


The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

GET listSites /sites Search for sites

GET getSite /sites/ {siteId} Get a site resource

GET listLists /sites/ {siteId} /
lists

Get lists in a site

GET getList /sites/ {siteId} /
lists/ {listId}

List operations on a
list

GET listItem /sites/ {siteId} /
lists/ {listId} /
items

Enumerate items in a
list

POST createItem /sites/ {siteId} /
lists/ {listId} /
items

Create a new item in
a list

GET getItem /sites/ {siteId} /
lists/ {listId} /
items/ {listItem
Id}

Get listItem

PATCH updateItem /sites/ {siteId} /
lists/ {listId} /
items/ {listItem
Id}

Update the navigatio
n property items in
sites

DELETE deleteItem /sites/ {siteId} /
lists/ {listId} /
items/ {listItem
Id}

Delete an item from a
list

POST addSheet /sites/ {siteId} /
drive/it

Add worksheet

Integration provider templates 303


REST API type Operation name REST API path Description
ems/ {itemId} /
workbook/workshee
ts/add

GET readSheet /sites/ {siteId} /
drive/it
ems/ {itemId} /
workbook/workshee
ts/ {workshee
tIdOrName}

Read a sheet

DELETE deleteSheet /sites/ {siteId} /
drive/it
ems/ {itemId} /
workbook/workshee
ts/ {workshee
tIdOrName}

Delete a new sheet

PATCH updateSheet /sites/ {siteId} /
drive/it
ems/ {itemId} /
workbook/workshee
ts/ {workshee
tIdOrName}

Update worksheet

GET listSheets /sites/ {siteId} /
drive/it
ems/ {itemId} /
workbook/workshee
ts

List worksheet
collection

PUT uploadFile /sites/ {siteId} /
drive/it
ems/ {parentId
} :/ {fileName} :/
content

Create or upload a
file

Integration provider templates 304


REST API type Operation name REST API path Description

GET readCell /sites/ {siteId} /
drive/it
ems/ {itemId} /
workbook/workshee
ts/ {workshee
tIdOrName
} /cell(row
= {row} ,column= {column} )

Read cell

PATCH writeCell /sites/ {siteId} /
drive/it
ems/ {itemId} /
workbook/workshee
ts/ {workshee
tIdOrName
} /cell(row
= {row} ,column= {column} )

Write cell

GET readRange /sites/ {siteId} /
drive/it
ems/ {itemId} /
workbook/workshee
ts/ {workshee
tIdOrName
} /range(ad
dress=' {address} ')

Read range

PATCH writeRange /sites/ {siteId} /
drive/it
ems/ {itemId} /
workbook/workshee
ts/ {workshee
tIdOrName
} /range(ad
dress=' {address} ')

Write range

Integration provider templates 305


REST API type Operation name REST API path Description

POST deleteRange /sites/ {siteId} /
drive/it
ems/ {itemId} /
workbook/workshee
ts/ {workshee
tIdOrName
} /range(ad
dress=' {address}
')/delete

Delete range

POST clearRange /sites/ {siteId} /
drive/it
ems/ {itemId} /
workbook/workshee
ts/ {workshee
tIdOrName
} /range(ad
dress=' {address}
')/clear

Clear range

GET getUsedRange /sites/ {siteId} /
drive/it
ems/ {itemId} /
workbook/workshee
ts/ {workshee
tIdOrName} /
usedRange

Get used range

**Microsoft Teams**

The following list provides key information for this template

- Server URL â€“ https://graph.microsoft.com/v1.0
- Outbound authentication types accepted:
    - API key

Integration provider templates 306


The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

GET listChats /chats List chats

POST CreateChat /chats Create a new chat
object

GET GetIndividualChat /chats/ {chatId} Get chat

GET ListAllChatMessages /chats/ {chatId} /
messages

List messages in a
chat

POST SendChatMessage /chats/ {chatId} /
messages

Send a message in a
chat

GET listTeams /teams List teams

GET GetTeam /teams/ {teamId} Get team

GET ListAllChannels /teams/ {teamId} /
channels

List channels

POST CreateChannel /teams/ {teamId} /
channels

Create channel

GET GetChannel /teams/ {teamId} /
channels/ {channelI
d}

Get channel

POST InviteChannelMembe
r

/teams/ {teamId} /
channels/ {channelI
d} /members

Add conversat
ionMember

GET ListAllChannelMess
ages

/teams/ {teamId} /
channels/ {channelI
d} /messages

List channel
messages

Integration provider templates 307


REST API type Operation name REST API path Description

POST SendChannelMessage /teams/ {teamId} /
channels/ {channelI
d} /messages

Send a message in a
channel

POST ReplyToChannelMess
age

/teams/ {teamId} /
channels/ {channelI
d} /messages
/ {chatMess
ageId} /replies

Reply to a message in
a channel

GET ListAllTeamMembers /teams/ {teamId} /
members

List members of team

POST InviteUserToTeam /teams/ {teamId} /
members

Add member to team

GET listUsers /users List users

GET getUser /users/ {userId} Get a user

POST CreateOnlineTeamsM
eeting

/users/ {userId} /
onlineMeetings

Create an online
meeting.

GET GetOnlineTeamsMeet
ing

/users/ {userId} /
onlineMe
etings/ {meetingI
d}

Get an online
meeting.

GET ListAllRecordings /users/ {userId} /
onlineMe
etings/ {meetingI
d} /recordings

List all recordings.

GET ListAllTranscripts /users/ {userId} /
onlineMe
etings/ {meetingI
d} /transcripts

List all transcripts.

Integration provider templates 308


**PagerDuty Advance**

The following list provides key information for this template

- Server URL â€“ https://api.pagerduty.com
- Outbound authentication types accepted:
    - API key

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

GET listIncidents /incidents View incidents in my
account

POST createIncident /incidents Create new incident

GET getIncident /incidents/ {id} View incident details

PUT updateIncident /incidents/ {id} Update an incident

GET listUsers /users View user list

**Salesforce Lightning Platform**

The following list provides key information for this template

- Server URL â€“ https:// _{domainName}_ .develop.my.salesforce.com/services/data/v60.0
- Outbound authentication types accepted:
    - OAUTH2

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

GET getAccountList /sobjects/Account View all accounts

Integration provider templates 309


REST API type Operation name REST API path Description

POST createAccount /sobjects/Account Create new account

GET getAccount /sobjects/Account/
{id}

Get account details

DELETE deleteAccount /sobjects/Account/
{id}

Remove account

PATCH updateAccount /sobjects/Account/
{id}

Edit account details

POST createAccountTeamM
ember

/sobjects/AccountT
eamMember

Add account team
member

GET getAccoun
tTeamMember

/sobjects/AccountT
eamMember/ {id}

View account team
member

DELETE deleteAccountTeamM
ember

/sobjects/AccountT
eamMember/ {id}

Remove account
team member

GET getCaseList /sobjects/Case View all cases

POST createCase /sobjects/Case Create new case

GET getCase /sobjects/Case/ {id} View case details

DELETE deleteCase /sobjects/Case/ {id} Remove case

PATCH updateCase /sobjects/Case/ {id} Edit case

GET getCampaignList /sobjects/Campaign View all campaigns

POST createCampaign /sobjects/Campaign Create new campaign

GET getCampaign /sobjects/Campaign
/ {id}

Get campaign details

DELETE deleteCampaign /sobjects/Campaign
/ {id}

Remove campaign

Integration provider templates 310


REST API type Operation name REST API path Description

PATCH updateCampaign /sobjects/Campaign
/ {id}

Edit campaign

POST createCam
paignMember

/sobjects/Campaign
Member

Add campaign
member

GET getCampaignMember /sobjects/Campaign
Member/ {id}

Get campaign
member details

DELETE deleteCam
paignMember

/sobjects/Campaign
Member/ {id}

Remove campaign
member

GET getContactList /sobjects/Contact View all contacts

POST createContact /sobjects/Contact Create new contact

GET getContact /sobjects/Contact/
{id}

Get contact informati
on

DELETE deleteContact /sobjects/Contact/
{id}

Remove contact

PATCH updateContact /sobjects/Contact/
{id}

Edit contact

POST createFeedItem /sobjects/FeedItem Create new feed item

GET getFeedItem /sobjects/FeedItem
/ {id}

View feed item

DELETE deleteFeedItem /sobjects/FeedItem
/ {id}

Remove feed item

PATCH updateFeedItem /sobjects/FeedItem
/ {id}

Edit feed item

GET getLeadList /sobjects/Lead View all leads

Integration provider templates 311


REST API type Operation name REST API path Description

POST createLead /sobjects/Lead Create new lead

GET getLead /sobjects/Lead/ {id} Get lead details

DELETE deleteLead /sobjects/Lead/ {id} Remove lead

PATCH updateLead /sobjects/Lead/ {id} Edit lead details

GET getOpportunityList /sobjects/Opportun
ity

View list of opportuni
ties

POST createOpportunity /sobjects/Opportun
ity

Create new opportuni
ty

GET getOpportunity /sobjects/Opportun
ity/ {id}

View opportunity
details

DELETE deleteOpportunity /sobjects/Opportun
ity/ {id}

Remove opportunity

PATCH updateOpportunity /sobjects/Opportun
ity/ {id}

Edit opportunity

GET getUser /sobjects/User View user details

GET describeSObject /sobjects
/ {sObject} /
describe

Get object metadata
and field details

GET queryAccounts /query Executes a SOQL
query to retrieve
account data from
Salesforce

**SAP Bill of Material**

The following list provides key information for this template

Integration provider templates 312


- Server URL â€“ https:// _{host}_ /sap/opu/odata/sap/API_BILL_OF_MATERIAL_SRV;v=0002
- Outbound authentication types accepted:
    - OAuth2

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

GET getMaterialBOMItem /MaterialBOMItem View bill of material
details

**SAP Business Partner (A2X)**

The following list provides key information for this template

- Server URL â€“ https:// _{host}_ /sap/opu/odata/sap/API_BUSINESS_PARTNER
- Outbound authentication types accepted:
    - OAuth2

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

GET getBusinessPartner /A_BusinessPartner Retrieves business
partner general data.

GET getBusinessPartner
ByID

/A_BusinessPartner
(' {Business
Partner} ')

Retrieves business
partner data by using
business partner
number.

GET getBusinessPartner
Address

/A_BusinessPartner
Address

Retrieves business
partner address data.

GET getBusinessPartner
Role

/A_BusinessPartner
Role

Retrieves business
partner role data.

Integration provider templates 313


REST API type Operation name REST API path Description

GET getBusinessPartner
RoleByID

/A_BusinessPartner
Role(BusinessPartn
er=' {Business
Partner} ',Busines
sPartnerR
ole=' {Business
PartnerRole} ')

Retrieves business
partner role data
using the key fields.

**SAP Material Stock**

The following list provides key information for this template

- Server URL â€“ https:// _{host}_ /sap/opu/odata/sap/API_MATERIAL_STOCK_SRV
- Outbound authentication types accepted:
    - OAuth2

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

GET getMaterialStockIn
Account

/A_MatlStkInAcctMod View material stocks
details for stocks that
has been posted

**SAP Physical Inventory**

The following list provides key information for this template

- Server URL â€“ https:// _{host}_ /sap/opu/odata/sap/API_PHYSICAL_INVENTORY_DOC_SRV
- Outbound authentication types accepted:
    - OAuth2

The following table shows the APIs that you can call if you add this target type to your gateway:

Integration provider templates 314


REST API type Operation name REST API path Description

GET getPhysInventoryDo
cItem

/A_PhysInventoryDo
cItem

View physical
inventory document
for an item

**SAP Product Master (A2X)**

The following list provides key information for this template

- Server URL â€“ https:// _{host}_ /sap/opu/odata/sap/API_PRODUCT_SRV
- Outbound authentication types accepted:
    - OAuth2

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

GET getProductMaster /A_Product View product master
general details

GET getPlantDataByMate
rial

/A_Produc
t(' {Product} ')/
to_Plant

View plant details of
the product

GET getSupplyPlanningD
ataByMaterial

/A_Produc
tSupplyPlanning(Pr
oduct=' {Product}
',Plant=' {Plant} ')

View supply planning
details by product
number and plant

**ServiceNow**

The following list provides key information for this template

- Server URL â€“ https:// _{instance}_ .service-now.com
- Outbound authentication types accepted:

Integration provider templates 315


- API key

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

GET retrieveAttachment
sMetadata

/api/now/attachmen
t

Get all attachments
info

POST uploadBinaryAttach
ment

/api/now/attachmen
t/file

Upload binary file

GET retrieveAttachment
Metadata

/api/now/attachmen
t/ {sys_id}

Get attachment info

DELETE deleteAttachment /api/now/attachmen
t/ {sys_id}

Remove attachment

GET retrieveAttachment
Content

/api/now/attachmen
t/ {sys_id} /file

Get attachment
content

GET listIncidents /api/now/table/inc
ident

View all incidents

POST createIncident /api/now/table/inc
ident

Create new incident

GET getIncident /api/now/table/inc
ident/ {sys_id}

View incident details

PATCH updateIncident /api/now/table/inc
ident/ {sys_id}

Edit incident

DELETE deleteIncident /api/now/table/inc
ident/ {sys_id}

Remove incident

GET listProblem /api/now/table/pro
blem

View all problems

Integration provider templates 316


REST API type Operation name REST API path Description

POST createProblem /api/now/table/pro
blem

Create new problem

GET getProblem /api/now/table/pro
blem/ {sys_id}

View problem details

DELETE deleteProblem /api/now/table/pro
blem/ {sys_id}

Remove problem

PATCH updateProblem /api/now/table/pro
blem/ {sys_id}

Edit problem

POST createKnowledgeBas
eArticle

/api/now/table/kb_
knowledge

Create KB article

DELETE deleteKnowledgeBas
eArticle

/api/now/table/
kb_knowledge
/ {sys_id}

Remove KB article

PATCH updateKnowledgeBas
eArticle

/api/now/table/
kb_knowledge
/ {sys_id}

Edit KB article

GET listChoices /api/now/table/sys
_choice

View all system
choices

GET listUsers /api/now/table/sys
_user

View all users

GET listChangeRequest /api/sn_chg_rest/c
hange

View all change
requests

POST createChangeRequest /api/sn_chg_rest/c
hange

Create new change
request

GET getChangeRequest /api/sn_chg_rest/c
hange/ {sys_id}

View change request
details

Integration provider templates 317


REST API type Operation name REST API path Description

DELETE deleteChangeRequest /api/sn_chg_rest/c
hange/ {sys_id}

Remove change
request

PATCH updateChangeReques
t

/api/sn_chg_rest/c
hange/ {sys_id}

Edit change request

**Slack Web**

The following list provides key information for this template

- Server URL â€“ https://slack.com/api
- Outbound authentication types accepted:
    - API key

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

POST chatPostEphemeral /chat.postEphemeral Send temporary
message

POST chatPostMessage /chat.postMessage Send new message

POST conversationsCreate /conversations.create Start new channel

GET conversationsHistory /conversations.his
tory

View message history

POST conversationsInvite /conversations.invite Add users to channel

POST conversationsJoin /conversations.join Enter existing
conversation

POST conversationsKick /conversations.kick Remove user from
chat

Integration provider templates 318


REST API type Operation name REST API path Description

POST conversationsLeave /conversations.leave Exit conversation

GET conversationsList /conversations.list View all channels

GET conversationsMembe
rs

/conversations.mem
bers

View chat participa
nts

POST conversationsOpen /conversations.open Start or resume direct
message

GET conversationsReplies /conversations.replies View message thread

POST conversationsSetTo
pic

/conversations.set
Topic

Set chat topic

GET filesList /files.list List for a team, in
a channel, or from
a user with applied
filters.

GET filesInfo /files.info View file details

GET searchAll /search.all Search messages and
files

POST userGroupsCreate /usergroups.create Create new user
group

GET userGroupsList /usergroups.list View all user groups

POST userGroupsUsersUpd
ate

/usergroups.users.
update

Edit user group

GET usersList /users.list View team members

POST remindersAdd /reminders.add Set new reminder

POST usersProfileSet /users.profile.set Update user profile

Integration provider templates 319


REST API type Operation name REST API path Description

GET GetUploadURLExtern
al

/files.getUploadUR
LExternal

Get an upload URL
for a file to be
uploaded externally
to Slack.

POST completeUploadExte
rnal

/files.completeUpl
oadExternal

Finalize file upload to
Slack. Should be used
after Upload File.

**Smartsheet**

The following list provides key information for this template

- Server URL â€“ https://api.smartsheet.com/2.0
- Outbound authentication types accepted:
    - API key

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

GET listSearch /search Search all sheets

GET getSheet /sheets/ {sheetId} View sheet details

GET listReports /reports View all reports

GET getReport /reports/ {reportId
}

View report informati
on

**Tavily Search**

The following list provides key information for this template

- Server URL â€“ https://api.tavily.com

Integration provider templates 320


- Outbound authentication types accepted:
    - API key

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

POST TavilySearchPost /search Executeasearchquer
yusingTavilySearch

POST TavilySearchExtract /extract Extractwebpagecont
entfromURLsusingTa
vilyExtract

**Zendesk Suite**

The following list provides key information for this template

- Server URL â€“ https:// _{customerInstanceId}_ .zendesk.com
- Outbound authentication types accepted:
    - OAUTH2

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

GET listSearchResults /api/v2/search List Search Results

GET listTickets /api/v2/tickets List Tickets

POST createTicket /api/v2/tickets Create Ticket

GET showTicket /api/v2/t
ickets/ {ticket_i
d}

Show Ticket

Integration provider templates 321


REST API type Operation name REST API path Description

PUT updateTicket /api/v2/t
ickets/ {ticket_i
d}

Update Ticket

GET ListTicketEmailCCs /api/v2/t
ickets/ {ticket_i
d} /email_ccs

List Email CCs for a
Ticket

GET ListTicketFollowers /api/v2/t
ickets/ {ticket_i
d} /followers

List Followers for a
Ticket

GET ListTicketIncidents /api/v2/t
ickets/ {ticket_i
d} /incidents

List Ticket Incidents

GET TicketRelatedInfor
mation

/api/v2/t
ickets/ {ticket_i
d} /related

Ticket Related
Information

**Zoom**

The following list provides key information for this template

- Server URL â€“ https://api.zoom.us/v2
- Outbound authentication types accepted:
    - API key

The following table shows the APIs that you can call if you add this target type to your gateway:

REST API type Operation name REST API path Description

GET recordingsList /users/ {userId} /
recordings

List all recordings

Integration provider templates 322


REST API type Operation name REST API path Description

GET meeting /meetings
/ {meetingId}

Get a meeting

GET meetings /users/ {userId} /
meetings

List meetings

POST meetingCreate /users/ {userId} /
meetings

Create a meeting

GET recordingGet /meetings
/ {meetingId} /
recordings

Get meeting
recordings

#### Understand how AgentCore Gateway tools are named

The name of a tool in your gateway is dependent on the name of the target through which the tool
can be accessed. Tool names are constructed in the following pattern:

${target_name} __ ${tool_name}

For example, if your target's name is LambdaUsingSDK and you have a tool named
get_order_tool that is accessible at that target, the tool name that is visible through the Model
Context Protocol (MCP) is LambdaUsingSDK__get_order_tool.

You should ensure that your application code accounts for the discrepancy between the tool name
visible through the MCP and the tool name itself.

For an example of a Lambda handler function that strips the target name prefix from the tool
name before passing it to a handler function, see Lambda function input format.

### Prerequisites for trying out Amazon Bedrock AgentCore

### gateway examples

To interact with the AgentCore Gateway service, you'll need to complete the following
prerequisites:

Understand gateway tool naming 323


**Prerequisites for using the AgentCore Gateway service**

1. Install and set up the tools that you wish to use and ensure that you have the necessary
    permissions to use AgentCore Gateway methods and access AgentCore Gateway resources.
2. Set up and retrieve your AWS credentials. To access your AWS credentials and configure them,
    follow the steps at Using IAM Identity Center to authenticate AWS SDK and Tools. You need
    AWS credentials for the following tools:
    - AWS CLI
    - The AWS SDKs
    - The AgentCore starter toolkit.
    - The Strands Agents SDK
3. Ensure you have the necessary permissions to perform AgentCore Gateway-related API
    operations and access AgentCore Gateway resources.
4. Set up inbound authorization to authenticate requests made to your gateway.
5. Set up at least one target for your gateway.
6. Set up outbound authorization to authenticate access to your gateway targets.

The following topics describe where you can find information about setting up the tools that you
can use to interact with the AgentCore Gateway service.

**Topics**

- Set up dependencies and credentials to create, maintain, and use gateway resources
- Set up permissions for AgentCore Gateway
- Set up inbound authorization for your gateway
- Set up outbound authorization for your gateway

#### Set up dependencies and credentials to create, maintain, and use

#### gateway resources

The AgentCore Gateway service involves the following main processes:

- **Creation and maintenance of gateway resources** â€“ You can create gateway and gateway target
    resources through the Amazon Bedrock AgentCore Control Plane service.

Set up dependencies and credentials 324


- **Invocation of gateways** â€“ After creating a gateway and gateway target, you can invoke the
    gateway through direct HTTP requests to the gateway or through the help of an MCP client or
    agent.

Select a topic to learn about setting up tools and credentials for carrying out these processes:

**Topics**

- Set up tools and credentials for the creation and maintenance of gateway resources
- Invocation of gateways

**Set up tools and credentials for the creation and maintenance of gateway**

**resources**

You create, modify, delete, and retrieve information about gateway and gateway target resources
through making calls to the Amazon Bedrock AgentCore Control Plane service. The Amazon
Bedrock AgentCore Control Plane service API reference details information about the API
operations and structures in this service.

You can interact with the Amazon Bedrock AgentCore Control Plane service in the following ways.
Expand a topic to learn how to install the tool and set up authentication for it.

**AWS Management Console**

The AWS Management Console lets you create and maintain gateway and gateway target resources
through an interactive graphical interface in a web browser.

- **Installation** â€“ None needed. To manage gateways through the AgentCore console, you can
    navigate to https://console.aws.amazon.com/bedrock-agentcore/home# and select **Gateways**
    from the left navigation pane.
- **Authentication** â€“ Sign in with an IAM identity with permissions to use AgentCore Gateway
    actions.

**Direct HTTP requests**

The Amazon Bedrock AgentCore Control Plane service API reference page for each API operations
provides the information you need to make an API request.

- **Installation** â€“ None needed.

Set up dependencies and credentials 325


- **Authentication** â€“ You can use the Authorization header or query parameters (using AWS
    Signature Version 4) to authenticate.

**AWS software development kits SDKs**

AWS SDKs let you make API requests to AWS services through a programming language of your
choice. Refer to the following resources in the AWS SDKs and Tools Reference Guide to get set up:

- **Installation** â€“ To learn about an SDK and how to install it, select the **AWS SDK for** link that
    corresponds to your programming language of choice.
- **Authentication** â€“ To learn about configuring SDKs and authentication, refer to the links in the
    **This guide's relevant sections for you are:** column.
- **Other resources** â€“ In the language-specific reference, search for the Amazon Bedrock AgentCore
    Core Control service to see the syntax of specific API methods.

**AWS Command Line Interface**

The AWS Command Line Interface (CLI) lets you interact with the AWS API in a command line
interface. To learn how to install and set up the AWS CLI, see Getting started with the AWS CLI in
the AWS Command Line Interface User Guide.

- **Installation** â€“ To learn how to install the AWS CLI see Installing or updating to the latest version
    of the AWS CLI.
- **Authentication** â€“ To learn about configuring your credentials in the AWS CLI see Setting up the
    AWS CLI.
- **Other resources** â€“ To see the syntax of specific API methods in the Amazon Bedrock AgentCore
    control plane service, see the bedrock-agentcore-control reference.

**AgentCore starter toolkit**

The AgentCore starter toolkit is a Python SDK that provides tools to help you easily interact with
the AgentCore API. Refer to the following resources in the AgentCore starter toolkit repository.

- **Installation** â€“ To learn how to install the starter toolkit, follow the steps at Installation.
- **Authentication** â€“ To access your AWS credentials and configure them for the AgentCore starter
    toolkit, follow the steps at Using IAM Identity Center to authenticate AWS SDK and Tools.

Set up dependencies and credentials 326


- **Other resources** â€“ You use the Gateway client in this toolkit to interact with AgentCore Gateway.
    For more information, see AgentCore Gateway client.

**Invocation of gateways**

After you create a gateway and gateway targets, you can interact with the gateway through direct
HTTP requests or through an MCP client or agent.

**Direct HTTP requests**

To make an HTTP request to an AgentCore gateway, you make a POST request to a gateway
endpoint that you set up when creating a gateway.

- **Installation** â€“ None needed.
- **Authentication** â€“ You can use the Authorization header or query parameters (using AWS
    Signature Version 4) to authenticate.

**MCP client**

To interact with an AgentCore gateway using an MCP client, you need to install the MCP client by
following the **Setting up your environment** and **Setting up your API key** steps at Build an MCP
client after choosing your programming language of choice. By following the steps, you'll also
retrieve an Anthropic API key for authentication.

**Strands Agents SDK**

To interact with an AgentCore gateway using the Strands Agents SDK, you need to install the
Strands SDK by following the steps at Strands Agents SDK to install the SDK and set up credentials.

**Langgraph agent**

To interact with an AgentCore gateway using a Langgraph agent, you need to install Langgraph by
navigating to LangGraph, selecting **Docs** , and choosing the **LangGraph** page that corresponds to
your programming language of choice. By following these steps, you'll also receive an API key to
help set up your credentials.

#### Set up permissions for AgentCore Gateway

Amazon Bedrock AgentCore Gateway can connect to both AWS resources and external services.
This means that along with the standard AWS Identity and Access Management (IAM) for managing

Set up permissions 327


permissions in Amazon Bedrock AgentCore Gateway, the permissions model supports additional
external authentication mechanisms.

When working with Gateways, there are three main categories of permissions to consider:

1.Gateway management permissions - Permissions needed to create and manage Gateways

2.Gateway Access Permissions or Inbound Auth Configuration - Who can invoke what via the MCP
protocol

3.Gateway execution permissions - Permissions provided to a service role to allow the Amazon
Bedrock AgentCore service to perform actions on behalf of the identity that invokes the
gateway.

**Topics**

- Gateway Management Permissions
- Gateway Access Permissions or Inbound Auth Configuration
- AgentCore Gateway service role permissions
- Best practices for Gateway permissions

**Gateway Management Permissions**

These permissions allow you to create and manage Gateways. You can create a gateway specific
policy (example name BedrockAgentCoreGatewayFullAccess) which could look like:

JSON

{
"Version":"2012-10-17",
"Statement": [
{
"Effect": "Allow",
"Action": [
"bedrock-agentcore:Gateway",
"bedrock-agentcore:WorkloadIdentity",
"bedrock-agentcore:CredentialProvider",
"bedrock-agentcore:Token",
"bedrock-agentcore:Access"
],

Set up permissions 328


"Resource": "arn:aws:bedrock-agentcore:::gateway"
}
]
}

You may also need additional permissions for related services:

- s3:GetObject and s3:PutObject for storing and retrieving schemas when you configure
    targets based on S3
- kms:Encrypt, kms:Decrypt, kms:GenerateDataKey* for encryption operations
- Other service-specific permissions based on your Gateway's functionality or configuration

For more comprehensive permissions across all AgentCore services, consider using the
BedrockAgentCoreFullAccess managed policy, especially when working with multiple
AgentCore products.

If you prefer to follow the principle of least privilege, you can create a custom policy that grants
only specific permissions. Here's an example of a ReadOnly Gateway permission policy:

JSON

{
"Version":"2012-10-17",
"Statement": [
{
"Effect": "Allow",
"Action": [
"bedrock-agentcore:ListGateways",
"bedrock-agentcore:GetGateway",
"bedrock-agentcore:ListGatewayTargets",
"bedrock-agentcore:GetGatewayTarget"
],
"Resource": "arn:aws:bedrock-agentcore:::gateway"
}
]
}

Set up permissions 329


**Gateway Access Permissions or Inbound Auth Configuration**

Unlike other AWS services, which use standard AWS IAM mechanisms for access control, Amazon
Bedrock AgentCore Gateway uses JWT token-based authentication as specified in the Model
Context Protocol (MCP). These configurations have to be specified as a property of the gateway.

You'll configure these permissions when Creating gateways in the next section.

**AgentCore Gateway service role permissions**

When creating a gateway, you need a service role that has permissions to assume an IAM role and
to access AWS resources and external services on the IAM role's behalf. You can create the service
role in the following ways:

- If you create a gateway in the AWS Management Console or through the AgentCore starter
    toolkit, you can choose to let AgentCore automatically create a service role for you with the
    necessary permissions. If you prefer this method, you can skip this prerequisite.
- If you prefer to create your own service role for greater customization, you'll need to configure
    the role with the permissions outlined in this topic. To learn how to create a service role and
    attach permissions to it, see Create a role to delegate permissions to an AWS service.

The required permissions for a service role are in the following topics:

**Topics**

- Trust permissions
- Outbound authorization permissions
- Permissions to access AWS resources

**Trust permissions**

A service role must have a trust policy attached that allows the AgentCore service to assume an
IAM identity and carry out actions on its behalf.

The following is an example of a trust policy that you can use.

JSON

{

Set up permissions 330


"Version":"2012-10-17",
"Statement": [
{
"Sid": "GatewayAssumeRolePolicy",
"Effect": "Allow",
"Principal": {
"Service": "bedrock-agentcore.amazonaws.com"
},
"Action": "sts:AssumeRole",
"Condition": {
"StringEquals": {
"aws:SourceAccount": " 111122223333 "
},
"ArnLike": {
"aws:SourceArn": "arn:aws:bedrock-agentcore: us-
east-1 : 111122223333 :gateway/ gateway-name -*"
}
}
}
]
}

Note
Because you won't know the gateway ARN before you create it, you can omit the
Condition field when you first create the service role. After you create the gateway, add
the Condition field back to the policy as a best security practice and do the following:

- Replace the aws:SourceAccount condition key value with the ID of the account that
    the gateway belongs to.
- Replace the aws:SourceArn condition key with the ARN of the gateway.

**Outbound authorization permissions**

Depending on the type of outbound authorization you use for your gateway targets, you need to
add permissions to the service role to allow it to invoke the target. These permissions allow the
gateway service role to retrieve authorization credentials for invoking the target. You can do this in
the process of setting up outbound authorization.

Set up permissions 331


**Permissions to access AWS resources**

Depending on your gateway setup or the targets that you choose to add to the gateway, you
might need to add permissions to the gateway service role to allow it to access AWS resources. The
following topics cover some resources that your gateway service role might need access to:

**Access a Lambda function**

If you attach a Lambda target to your gateway, you need to add permissions for the AgentCore
Gateway service role to be able to invoke the function by doing the following:

- Attach an identity-based policy to the AgentCore Gateway service role that allows the
    lambda:InvokeFunction action on the Lambda function resource.
- (If the function is in a different account from the gateway service role) Attach a resource-based
    policy to the Lambda function that allows the gateway service role principal to perform the
    lambda:InvokeFunction action on the Lambda function resource.

Select a topic to learn how to set up the permissions:

**Topics**

- Attach an identity-based policy to the gateway service role
- (If function is in another account) Attach a resource-based policy to the Lambda function

**Attach an identity-based policy to the gateway service role**

To allow the gateway service role to access a Lambda target, attach the following identity-based
policy to your AgentCore Gateway service role by choosing the topic at Adding and removing IAM
identity permissions that pertains to your use case and following the steps..

{
"Version": "2012-10-17",
"Statement": [{
"Sid": "AmazonBedrockAgentCoreGatewayLambdaProd",
"Effect": "Allow",
"Action": [
"lambda:InvokeFunction"
],
"Resource": [
"arn:aws:lambda: us-east-1 : 123456789012 :function: FunctionName "
]

Set up permissions 332


}]
}

Replace the ARN in the Resource field with the ARN of your Lambda function gateway target.
If your gateway has multiple Lambda targets, you can add the ARN of each function to the
Resource list.

**(If function is in another account) Attach a resource-based policy to the Lambda function**

If the Lambda function target is in a different account from the gateway service role, you need to
attach a resource-based policy to allow the gateway service role to access it. The following is an
example policy that you can use:

{
"Version":"2012-10-17",
"Statement": [
{
"Sid": "LambdaAllowGatewayServiceRoleMyFunction",
"Effect": "Allow",
"Principal": {
"AWS": "arn:aws:iam:: 123456789012 :role/ MyGatewayExecutionRole "
},
"Action": "lambda:InvokeFunction",
"Resource": "arn:aws:lambda: us-east-1 : 123456789012 :function: MyFunction "
}
]
}

Replace the values of the following fields:

- AWS â€“ Use the ARN of your gateway service role.
- Resource â€“ Use the ARN of your Lambda function.

To learn how to attach a resource-based policy to the Lambda function that allows your gateway
service role to access the function, select one of the following methods::

Console

To attach a resource-based policy to your Lambda function in the AWS Management Console

1. Follow the steps in the **Console** tab at Viewing resource-based IAM policies in Lambda.

Set up permissions 333


2. In the **Resource-based policy statements** section, choose **Add permissions**.
3. Select **AWS account** and fill out the following fields:
    - **Statement ID** â€“ A unique identifier for the the statement providing permissions for the
       gateway service role to access the function.
    - **Principal** â€“ Specify the ARN of your gateway service role.
    - **Action** â€“ Select lambda:InvokeFunction.

##### CLI

To attach a resource-based policy to your Lambda function using the AWS CLI, follow the steps
at Granting Lambda function access to AWS services and specify your gateway service role as
the principal.

You can run the following code in a terminal to add permissions for your gateway service role to
access the function in us-east-1 :

aws lambda add-permission
--function-name " MyFunction "
--statement-id "GatewayInvoke"
--action "lambda:InvokeFunction"
--principal "arn:aws:iam:: 123456789012 :role/ MyGatewayServiceRole "
--region us-east-1

**Smithy model permissions**

If you plan to add a Smithy target, you need to add permissions for the gateway service role to
access AWS services that your Smithy models refer to. To determine which permissions need to be
attached to the service role, refer to that service's documentation.

You can add permissions to the service role by choosing the topic at Adding and removing IAM
identity permissions that pertains to your use case and following the steps.

For example, if your Smithy model target accesses a DynamoDB table, you can attach the following
policy to allow the service role to perform DynamoDB operations on the table:

Set up permissions 334


##### JSON

{
"Version":"2012-10-17",
"Statement": [
{
"Effect": "Allow",
"Action": [
"dynamodb:GetItem",
"dynamodb:PutItem",
"dynamodb:UpdateItem",
"dynamodb:DeleteItem",
"dynamodb:Query",
"dynamodb:Scan"
],
"Resource": "arn:aws:dynamodb:::table/*"
}
]
}

**Best practices for Gateway permissions**

**Follow the principle of least privilege**

- Grant only the permissions necessary for your Gateway to function
- Use specific resource ARNs rather than wildcards when possible
- Regularly review and audit permissions

**Separate roles by function**

- Use different roles for management and execution
- Create separate roles for different Gateways with different purposes

**Secure credential storage**

- Store API keys and OAuth credentials in AWS Secrets Manager
- Rotate credentials regularly

**Monitor and audit**

- Enable CloudTrail logging for Gateway operations

Set up permissions 335


- Regularly review access patterns and permissions usage

**Use conditions in policies**

- Add conditions to limit when and how permissions can be used
- Consider using source IP restrictions for management operations

#### Set up inbound authorization for your gateway

Before you create your gateway, you must set up inbound authorization. Inbound authorization
validates users who attempt to access targets through your AgentCore gateway. AgentCore
supports the following types of inbound authorization:

- **JSON Web Token (JWT)** â€“ A secure and compact token used for authorization. After creating
    the JWT, you specify it as the authorization configuration when you create the gateway. You can
    create a JWT with any of the identity providers at Provider setup and configuration.
- **IAM identity** â€“ Authorizes through the credentials of the AWS IAM identity trying to access the
    gateway.

Note
If use the AWS Management Console or AgentCore starter toolkit to create your gateway,
you can create a default inbound authorization configuration using Amazon Cognito during
gateway creation. If you plan to use the default authorization configuration, you can skip
this prerequisite.

If you don't plan to use the default authorization configuration using Amazon Cognito, select the
topic that corresponds to the type of authorization that you plan to use to learn how to set it up:

**Topics**

- IAM-based inbound authorization
- JSON Web Token (JWT)-based inbound authorization

Set up inbound authorization 336


**IAM-based inbound authorization**

IAM-based inbound authorization lets you use the gateway caller's IAM credentials for
authorization. You can use this option if you want to create an IAM identity through which users
that call your gateway can be authenticated.

**To set up IAM-based inbound authorization**

1. Create or use an existing IAM identity for your gateway callers.
2. Create an identity-based IAM policy that contains the following permissions:
    - bedrock-agentcore:InvokeGateway â€“ After you create the gateway, you should modify
       this policy such that the Resource field is scoped to the gateway that you create as a
       security best practice.
3. Attach the policy to the gateway caller identity.

**Example policy**

The following example shows a policy you could attach to an identity to allow it to invoke a
gateway with the ID _my-gateway-12345_

{
"Version": "2012-10-17",
"Statement": [
{
"Sid": "AllowGatewayInvocation",
"Effect": "Allow",
"Action": [
"bedrock-agentcore:InvokeGateway"
],
"Resource": [
"arn:aws:bedrock-agentcore:us-east-1:123456789012:gateway/ my-gateway-12345 "
]
}
]
}

**Resources**

Set up inbound authorization 337


- For more information about AWS Identity and Access Management, see Identity and access
    management for Amazon Bedrock AgentCore.
- For more information about Amazon Bedrock AgentCore actions, resources, and condition keys
    that you can specify in IAM policies, see Actions, resources, and condition keys for Amazon
    Bedrock AgentCore.

**JSON Web Token (JWT)-based inbound authorization**

A JSON Web Token (JWT) is a secure and compact token used for authorization. You can create a
JWT with a supported identity provider. After you create a JWT, you can retrieve it and specify it as
the authorization configuration when you create the gateway.

Important
Using inbound authorization based on JWT tokens will result in logging of some claims of
the JWT token in CloudTrail. The entry includes the Subject of the provided web identity
token. We recommend that you avoid using any personally identifiable information (PII) in
this field. For example, you could instead use a GUID or a pairwise identifier, as suggested
in the OIDC specification.

You can use the AgentCore starter toolkit to set up a default JWT, or create one manually with a
supported identity provider. To learn more about different methods for setting up a JWT, select
from the following topics:

**Topics**

- Set up a default JWT
- Set up a JWT manually

**Set up a default JWT**

The AgentCore starter toolkit lets you easily create a default authorization configuration using
Amazon Cognito that you can then use when creating a gateway. To create this default JWT, run
the following code example:

Initialize gateway client from starter toolkit
from bedrock_agentcore_starter_toolkit.operations.gateway.client import GatewayClient

Set up inbound authorization 338


client = GatewayClient()

Retrieve JWT from the create response and store as the authorization configuration.
When you create the gateway, specify it in the authorizer_config field
cognito_result = client.create_oauth_authorizer_with_cognito("my-gateway")
authorizer_configuration = cognito_result["authorizer_config"]

The cognito_result contains authentication and authorization information:

- You'll use the authorizer configuration when you create the gateway.
- For inbound authorization when invoking your gateway, you'll need to obtain an access token
    by using your client ID, client secret, and the token endpoint. For more information on how to
    obtain your access token, see The token issuer endpoint in the Amazon Cognito Developer Guide.

**Set up a JWT manually**

Amazon Bedrock AgentCore supports JWTs from all identity providers. You can see some examples
at Provider setup and configuration.

In the process of creating the JWT, you should record the following values that will be created:

- **Discovery URL** â€“ The URL from which login credentials and the token endpoint can be retrieved.
- **Client ID** â€“ The public identifier of a client application that requests a token.
- **Client secret** â€“ The private key that authenticates access for the client application to retrieve a
    token.
- **Allowed audience** â€“ The identifier that validates the intended recipients or consumers of a token.

You'll need these values to do the following:

- Create the gateway by specifying values in the authorizer configuration.
- Obtain authorization credentials to invoke the gateway. To learn how to obtain your credentials,
    look up your identity provider's documentation. For example, if you used Amazon Cognito, see
    The token issuer endpoint in the Amazon Cognito Developer Guide.

#### Set up outbound authorization for your gateway

Outbound authorization lets Amazon Bedrock AgentCore gateways securely access gateway targets
on behalf of users that were authenticated and authorized during inbound authorization.

Set up outbound authorization 339


AgentCore Gateway supports the following types of outbound authorization:

- **No authorization (not recommended)** â€“ Some target types provide you the option to bypass
    outbound authorization. This less secure option is not recommended.
- **IAM-based outbound authorization** â€“ Use the gateway service role to authenticate access to the
    gateway target with AWS Signature Version 4 (Sig V4).
- **2-legged OAuth (OAuth 2LO)** â€“ An open authorization framework that allows a client
    application to access resources on the application's behalf, rather than on behalf of the user. For
    more information, see OAuth 2.0. You can use OAuth 2LO with a built-in identity provider or with
    a custom one.
- **API key** â€“ Use the AgentCore service to generate an API key to authenticate access to the
    gateway target.

The type of outbound authorization that you can set up is dependent on the gateway target type
to which you authorize access:

Target type No authoriza
tion

Gateway service
role

OAuth client API key

Lambda
function

No Yes No No

MCP server Yes No Yes No

OpenAPI schema No No Yes Yes

Smithy schema No Yes No No

Note
If you use an integration provider template as a target, review the supported authorization
types for different templates at Built-in templates from integration providers as targets.

Before adding a target to your gateway, you must set up authorization for it through one of the
supported methods.

Set up outbound authorization 340


Note
You can skip this prerequisite if you plan to use the AWS Management Console or
AgentCore starter toolkit to create your gateway. If you use either of these tools, you can
let AgentCore automatically create a service role for you with the necessary permissions
to access the target. Each time you add a target, the necessary permissions will be
automatically attached to your service role.

Select a topic to learn how to set up that type of authorization:

**Topics**

- Set up IAM-based outbound authorization with a gateway service role
- Set up outbound authorization with an OAuth client
- Set up outbound authorization with an API key

**Set up IAM-based outbound authorization with a gateway service role**

IAM-based outbound authorization lets you use the gateway service role's IAM credentials to
authorize with AWS Signature Version 4 (Sig V4). This option lets the Amazon Bedrock AgentCore
service to authenticate to gateway targets on your gateway callers' behalf.

If you use this option, you don't need to do any additional set up. The service role's credentials will
be used for authentication during gateway invocation.

**Set up outbound authorization with an OAuth client**

To set up outbound authorization with an OAuth client, you use the AgentCore Identity service and
specify client credentials that you receive from creating a client in either a built-in identity provider
(see Provider setup and configuration or a custom identity provider.

**To set up outbound authorization with an OAuth client**

1. Register your client application with a supported third-party provider.
2. You'll receive a client ID, client secret, and possibly other values that you'll reference when you
    set up the outbound authorization.
3. Follow one of the steps below, depending on your requirements:

Set up outbound authorization 341


- To configure outbound authorization in the console using a built-in identity provider,
    follow the steps at Add OAuth client using included provider.
- To configure outbound authorization in the console using a custom identity provider,
    follow the steps at Add OAuth client using custom provider.
- To configure outbound authorization using the API, send a
    CreateOauth2CredentialProvider with one of the AgentCore control plane endpoints. For
    examples, see Examples for setting OAuth client authorization.

Note
The shape of the JSON object that the oauth2ProviderConfigInput field
maps to depends on the provider that you use and must be congruent with
the credentialProviderVendor value that you specify. To see examples of
different configurations for different credential providers, see the outbound
authorization examples in your credential provider of choice at Provider setup and
configuration.

4. Take note of the generated credential ARN (credentialProviderArn in the API) and the
    AWS Secrets Manager secret ARN (secretArn in the API). You'll use these values when you
    create your gateway target.
5. (If you're using a custom gateway service role) Attach the following identity-based policy to
    your gateway service role:

{
"Version": "2012-10-17",
"Statement": [
{
"Sid": "GetWorkloadAccessToken",
"Effect": "Allow",
"Action": [
"bedrock-agentcore:GetWorkloadAccessToken",
],
"Resource": [
"arn:aws:bedrock-agentcore: us-east-1 : 123456789012 :workload-identity-
directory/default",
"arn:aws:bedrock-agentcore: us-east-1 : 123456789012 :workload-identity-
directory/default/workload-identity/ GatewayName -*"
]
},

Set up outbound authorization 342


{
"Sid": "GetResourceOauth2Token",
"Effect": "Allow",
"Action": [
"bedrock-agentcore:GetResourceOauth2Token",
],
"Resource": [
"arn:aws:bedrock-agentcore: us-east-1 : 123456789012 :token-
vault/ TokenVaultId /oauth2credentialprovider/ CredentialName "
]
},
{
"Sid": "GetSecretValue",
"Effect": "Allow",
"Action": [
"secretsmanager:GetSecretValue",
],
"Resource": [
"arn:aws:secretsmanager: us-east-1 : 123456789012 :secret: SecretId "
]
}
]
}

Replace the values of the following fields:

- In the GetWorkloadAccessToken statement, replace the _GatewayName_ in the Resource
    list with the name of your gateway.
- In the GetResourceOauth2Token statement, replace the value in the Resource list with
    the ARN of the credential that you just generated.
- In the GetSecretValue statement, replace the value in the Resource list with the ARN of
    the AWS secret returned in the response when you generated the credential.

**Examples for setting OAuth client authorization**

The following examples show you how to set authorization through an OAuth client for your
gateway target:

CLI

aws bedrock-agentcore-control create-oauth2-credential-provider \

Set up outbound authorization 343


--name oauth-credential-provider
--credential-provider-vendor CustomOAuth2
--oauth2-provider-config-input '{
"customOAuth2ProviderConfig": {
"oauthDiscovery": {
"discoveryUrl": ""
},
"clientId": "",
"clientSecret": ""
}
}'

Boto3

import boto3

client = boto3.client("bedrock-agentcore-control")

client.create_oauth2_credential_provider(
name="oauth-credential-provider",
credentialProviderVendor="CustomOAuth2",
oauth2ProviderConfigInput={
"oauthDiscovery": {
"discoveryUrl": ""
},
"clientId": "",
"clientSecret": ""
}
)

**Set up outbound authorization with an API key**

To set up outbound authorization with an API key, you use the AgentCore Identity service and
specify an API key that you receive from a supported identity provider.

**To set up outbound authorization with an OAuth client**

1. Register your client application with a supported third-party provider.
2. Set up an API key for the provider's service. Take note of the following values, which you'll
    specify when you add the gateway target:

Set up outbound authorization 344


- **Credential location** â€“ Whether the API key should be placed in the header or as a query
    parameter.
- **Credential prefix** â€“ The prefix for the credential (ex. Bearer).
3. Follow one of the steps below, depending on your requirements:
- To create an API key in the AgentCore console, follow the steps at Add API key and specify
the value of the API key.
- To create an API key using the AgentCore API, send a CreateApiKeyCredentialProvider
request with one of the AgentCore control plane endpoints and specify the value of the
API key in the apiKey field. For examples, see Examples for setting an API key.
4. Take note of the following values, which you'll specify when you add the gateway target:
- **Credential provider ARN** â€“ An Amazon Resource Name (ARN) generated for the credential
provider.
- **Name** â€“ The name you gave to the API key.
- **Secret ARN** â€“ An AWS Secrets Manager secret ARN generated for the API key.
5. (If you're using a custom gateway service role) Attach the following identity-based policy to
your gateway service role:

{
"Version": "2012-10-17",
"Statement": [
{
"Sid": "GetWorkloadAccessToken",
"Effect": "Allow",
"Action": [
"bedrock-agentcore:GetWorkloadAccessToken",
],
"Resource": [
"arn:aws:bedrock-agentcore: us-east-1 : 123456789012 :workload-identity-
directory/default",
"arn:aws:bedrock-agentcore: us-east-1 : 123456789012 :workload-identity-
directory/default/workload-identity/ GatewayName -*"
]
},
{
"Sid": "GetResourceApiKey",
"Effect": "Allow",
"Action": [

Set up outbound authorization 345


"bedrock-agentcore:GetResourceApiKey",
],
"Resource": [
"arn:aws:bedrock-agentcore: us-east-1 : 123456789012 :token-
vault/ TokenVaultId /apikeycredentialprovider/ Name "
]
},
{
"Sid": "GetSecretValue",
"Effect": "Allow",
"Action": [
"secretsmanager:GetSecretValue",
],
"Resource": [
"arn:aws:secretsmanager:us-east-1:123456789012:secret: SecretId "
]
}
]
}

Replace the values of the following fields:

- In the GetWorkloadAccessToken statement, replace the _GatewayName_ in the Resource
    list with the name of your gateway.
- In the GetResourceApiKey statement, replace the value in the Resource list with the
    ARN of the credential that you just generated.
- In the GetSecretValue statement, replace the value in the Resource list with the ARN of
    the AWS secret returned in the response when you generated the credential.

**Examples for setting an API key**

The following examples show you how to set an API key for your gateway target:

CLI

aws bedrock-agentcore-control create-api-key-credential-provider
--name api-key-credential-provider
--api-key <API_KEY_VALUE>

Set up outbound authorization 346


Boto3

import boto3

client = boto3.client("bedrock-agentcore-control")

client.create_api_key_credential_provider(
name="api-key-credential-provider",
apiKey="<API_KEY_VALUE>"
)

### Set up an Amazon Bedrock AgentCore gateway

Amazon Bedrock AgentCore Gateway provides a unified connectivity layer between agents and the
tools and resources they need to interact with. Before setting up your Gateway, it's important to
understand how to specify permissions so that you can secure your gateway properly.

#### Gateway workflow..............................................................................................................................

The Gateway workflow involves the following steps to connect your agents to external tools:

1. **Create the tools for your Gateway** - Define your tools using schemas such as OpenAPI
    specifications for REST APIs or JSON schemas for Lambda functions. The OpenAPI
    specifications or tool schemas for your tools are then parsed by Amazon Bedrock AgentCore
    for creating the Gateway.
2. **Create a Gateway endpoint** - Use the AWS console or AWS SDK to create the gateway that will
    serve as the MCP entry point. Each API endpoint or function will become an MCP-compatible
    tool, and will be made available through your MCP server URL. To secure the gateway, you can
    use inbound authorization to control the ingress to the gateway.
3. **Add targets to your Gateway** - Configure targets that define how the gateway routes requests
    to specific tools. To securely connect to backend resources on behalf of authenticated users,
    use Outbound Authorization. Together, Inbound and Outbound Authorization create a secure
    bridge between users and their target resources, supporting both IAM credentials and OAuth-
    based authentication flows.
4. **Update your agent code** - Connect your agent to the Gateway endpoint to access all
    configured tools through the unified MCP interface.

Set up a gateway 347


**Topics**

- Create an Amazon Bedrock AgentCore gateway
- Add targets to an existing AgentCore gateway

#### Create an Amazon Bedrock AgentCore gateway

This guide walks you through the process of creating and configuring an Amazon Bedrock
AgentCore Gateway. The Gateway serves as a unified entry point for agents to access tools and
resources through the Model Context Protocol (MCP) and creating it is the first step in building
your tool integration platform. When you create a gateway, you create a managed service that
handles authentication and invokes callable endpoints as tools.

To create a gateway, you set up inbound authorization and configure invocable targets. Targets
establish the connection between your gateway and various tool types, including Lambda
functions and REST API services. Each target contains configuration details that specify the tool
location, authentication requirements, and any necessary request transformation rules.

You can create a gateway in the following ways:

- AWS Management Console â€“ With the console, you can configure authorization, create the
    gateway, and add targets all on one page.
- Amazon Bedrock AgentCore API â€“ You can directly invoke the CreateGateway API or through the
    help of a supported tool. If you use the API, you will add targets to your gateway in a separate
    step.

When creating a gateway, you provide the following required fields:

- A name for the gateway.
- The Amazon Resource Name (ARN) of an AgentCore service role with permissions to make
    requests to the gateway on your behalf.
- The type of authorizer to use for inbound requests to the gateway. AgentCore Gateway supports
    the following types of authentication:
    - JSON Web Token (JWT) authentication
    - AWS IAM credentials
- (If you use JWT authentication) An authorizer configuration that specifies how incoming requests
    to the gateway should be authenticated.

Create a gateway 348


- The protocol type for the gateway.

You can optionally provide the following fields:

- A description of the gateway.
- A client token value to ensure that a request completes no more than once. If you don't include
    this token, one is randomly generated for you. If you don't include a value, one is randomly
    generated for you. For more information, see Ensuring idempotency.

**Gateway features that can be set during creation**

You can activate the following features of the gateway during creation:

- **Protocol configuration** â€“ Configure how the gateway implements the protocol.
- **Custom encryption of the gateway** â€“ Specify the Amazon Resource Name (ARN) of a customer-
    managed AWS KMS key for greater control over the encryption process of your resource. If you
    don't include one, AWS encrypts the resource with an AWS-managed key. For more information,
    see Encrypt your AgentCore gateway with a customer-managed KMS key.
- **Debug mode** â€“ Allow the return of specific error messages during gateway invocation to help you
    with debugging. For more information, see Turn on debugging messages.
- **Semantic search** â€“ Add the x_amz_bedrock_agentcore_search to the gateway so that the
    target can deliver tools that are relevant to the search query. For more information, see Search
    for tools in your AgentCore gateway with a natural language query.

Select a topic to learn how to create a gateway using that method:

**Topics**

- Create an AgentCore gateway using the AWS Management Console
- Create an AgentCore gateway using the API

**Create an AgentCore gateway using the AWS Management Console**

**To create a gateway using the console**

1. Open the AgentCore console at https://console.aws.amazon.com/bedrock-agentcore/home#.
2. From the left navigation pane, select **Gateways**.

Create a gateway 349


3. In the **Gateways** section, choose **Create gateway**.
4. (Optional) In the **Gateway details** section, do the following:

a. Change the generated Gateway name
b. Expand the Additional configurations section and do the following:

i. In the Gateway description field, provide a description for your gateway.
ii. In the Instruction field, enter any special instructions or context that should be
passed to tools when they are invoked.
iii. To enable a built-in tool for searching tools in the gateway, select Enable semantic
search. If you enable this tool, you can't disable it later. For more information, see
Search for tools in your AgentCore gateway with a natural language query.
iv. To enable detailed debugging messages to be returned in the gateway response,
select Exception level debug. You can disable debugging messages later. For more
information, see Turn on debugging messages.

5. In the **Inbound Auth configurations** section, select one of the following options:
    - To allow Amazon Cognito to create authorization resources for you, select **Quick create**
       **configurations with Cognito**.
    - To use an authorization configuration that you have set up already, select **Use existing**
       **identity provider configurations** and then configure the following fields:
       - **Discovery URL** â€“ Enter the discovery URL from your identity provider.
       - **Allowed audiences** â€“ Enter the audience value that your gateway will accept. To add
          more audiences, choose **Add audience**.
       - **Allowed clients** â€“ Enter the public identifier of the client that your gateway will accept.
          To add more clients, choose **Add client**.
6. In the **Permissions** section, do the following:

a. To use an IAM service role to invoke the gateway on the user's behalf, select Use an IAM
service role.
b. (If you use an IAM service role) Choose one of the following options under IAM role :

- To create a service role with the necessary permissions to access your gateway, choose
    **Create and use a new service role** and optionally change the generated **Service role**
    **name**.

Create a gateway 350


- To use an existing service role, choose **Use an existing service role** and then select
    a role from the **Service role name** dropdown menu. Make sure that the service role
    that you choose has the necessary permissions. For more information, see AgentCore
    Gateway service role permissions.
7. (Optional) By default, your gateway is encrypted with an AWS managed key. To encrypt your
gateway with a custom KMS key, expand the **KMS key** section, select **Customize encryption
settings (advanced)** , and choose a customer managed key. For more information, see Encrypt
your AgentCore gateway with a customer-managed KMS key.
8. In the **Target:** **_${target-name}_** section, do the following:

a. (Optional) Change the generated Target name.
b. (Optional) Provide a Target description.
c. For the Target type , choose an option. For more information about different target types,
see Add targets to an existing AgentCore gateway.
d. Select or enter how the target type is defined.
e. For the Outbound Auth configurations , select an outbound authorization method. Then,
select or provide the necessary details and any optional additional configurations. For
more information, see Set up outbound authorization for your gateway.

9. To add more targets, choose **Add another target** and repeat the target configuration steps.
10. Choose **Create gateway**.

After creating your gateway, you can view its details, including the endpoint URL and associated
targets.

**Create an AgentCore gateway using the API**

To create a AgentCore gateway using the API, make a CreateGateway request with one of the
AgentCore control plane endpoints.

To see examples of how to create a gateway, expand the section that corresponds to your use case:

**Create a gateway: basic example (Custom JWT authorization)**

This section provides basic examples of creating a gateway.

Select one of the following methods:

Create a gateway 351


AgentCore starter toolkit

The AgentCore starter toolkit helps you easily create a gateway with minimal specifications.

from bedrock_agentcore_starter_toolkit.operations.gateway.client import
GatewayClient

Initialize the Gateway client
client = GatewayClient(region_name="us-west-2")

Automatically set up Cognito OAuth. Replace with a name of your choice
cognito_result = client.create_oauth_authorizer_with_cognito(gateway_name="my-
gateway")

Get the authorizer configuration
authorization=cognito_result["authorizer_config"]

Create the gateway.
gateway = client.create_mcp_gateway(
name=None, # You can omit this field
role_arn=None, # the role arn that the Gateway will use - if you don't set one,
one will be created.
authorizer_config=authorization, # Variable from inbound authorization setup
steps. Contains the OAuth authorizer details for authorizing callers to your
Gateway (MCP only supports OAuth).
enable_semantic_search=True, # enable semantic search.
exception_level="DEBUG" # enable debugging
)

print(f"MCP Endpoint: {gateway.get_mcp_url()}")
print(f"OAuth Credentials:")
print(f" Client ID: {cognito_result['client_info']['client_id']}")
print(f" Scope: {cognito_result['client_info']['scope']}")

CLI

The AgentCore CLI provides a simple way to create and manage gateways:

Create a Gateway with Lambda target
agentcore create_mcp_gateway
--name my-gateway
--target arn:aws:lambda:us-west-2:123456789012:function:MyFunction \

Create a gateway 352


--execution-role BedrockAgentCoreGatewayRole

The CLI automatically:

- Detects target type from ARN patterns or file extensions
- Sets up Cognito OAuth (EZ Auth)
- Detects your AWS region and account
- Builds full role ARN from role name

Console

To create your Gateway endpoint

1. Open the AgentCore console at https://console.aws.amazon.com/bedrock-agentcore/
    home#.
2. Choose **Gateways**.
3. Choose **Create gateway**.
4. In the **Gateway details** section:

a. Enter a Gateway name
b. Expand the Additional configurations section and:

i. Enter an optional Description for your gateway.
ii. (Optional) For Instructions , enter any special instructions or context that should
be passed to tools when they are invoked.
iii. (Optional) Optionally enable Semantic search to enable the built-in tool that can
be used to search the tools on the gateway.

5. In the **Inbound Identity** section, configure authentication for users accessing your gateway:

a. For Discovery URL , enter the OpenID Connect discovery URL for your identity
provider (for example, https://auth.example.com/.well-known/openid-
configuration).
b. For Allowed audiences , enter the audience values that your gateway will accept. Add
multiple audiences by choosing Add audience.

6. In the **Permissions** section:

Create a gateway 353


a. For Service role , choose an existing IAM role or create a new one that allows Amazon
Bedrock AgentCore to access your tools on your behalf.
b. (Optional) For KMS key , choose a customer managed key for encrypting your gateway
data, or leave blank to use the default Amazon Bedrock AgentCore managed key.

7. In the **Target configuration** section:

a. Enter a Target name.
b. (Optional) Provide an optional Target description.
c. For Target type , choose either:

- **Lambda ARN** - To connect to an Lambda function that implements your tools
- **REST API** - To connect to a REST API service
d. Configure the target based on your selection:
- **For Lambda function targets:**
- For **Lambda ARN** , enter the ARN of your Lambda function.
- For **Tool schema** , choose to either provide the schema inline or reference an
Amazon S3 location containing your tool schema.
- **For REST API targets:**
- For **OpenAPI schema** , choose to either provide the schema inline or reference an
Amazon S3 location containing your OpenAPI specification.
e. (Optional) In the **Outbound authentication** section, configure authentication for
accessing external services:
- For **Authentication type** , choose **OAuth client** or **API key**.
- Select the appropriate authentication resource from your account.
8. To add more targets, choose **Add another target** and repeat the target configuration steps.
9. Choose **Create gateway**.

After creating your gateway, you can view its details, including the endpoint URL and associated
targets, in the AgentCore console. The gateway endpoint URL follows the format: https://
{gatewayId}.gateway.{region}.amazonaws.com/mcp.

Create a gateway 354


Boto3

The following Python code shows how to create a gateway with boto3 (AWS SDK for Python)

import boto3

Create the agentcore client
agentcore_client = boto3.client('bedrock-agentcore-control')

Create a gateway
gateway = agentcore_client.create_gateway(
name="<target-name e.g. ProductSearch>",
roleArn="<existing role ARN e.g. arn:aws:iam::123456789012:role/MyRole>",
protocolType="MCP",
authorizerType="CUSTOM_JWT",
authorizerConfiguration= {
"customJWTAuthorizer": {
"discoveryUrl": "<existing discovery URL e.g. https://cognito-idp.us-
west-2.amazonaws.com/some-user-pool/.well-known/openid-configuration>",
"allowedClients": [""]
}
}
)

API

Use CreateGateway to create a gateway. The operation requires a gateway name and protocol
type, while accepting optional parameters like role ARN for IAM permissions, authorizer
configuration for JWT-based authentication, and custom transform configuration for request/
response processing.

Example request

The following example creates a Gateway with MCP protocol and JWT authorization:

POST /gateways/ HTTP/1.1
Content-Type: application/json

{
"name": "my-ai-gateway",
"description": "Gateway for AI model interactions",

Create a gateway 355


"clientToken": "12345678-1234-1234-1234-123456789012",
"roleArn": "arn:aws:iam::123456789012:role/AgentCoreGatewayRole",
"protocolType": "MCP",
"protocolConfiguration": {
"mcp": {
"version": "1.0",
"searchType": "SEMANTIC"
}
},
"authorizerConfiguration": {
"customJWTAuthorizer": {
"discoveryUrl": "https://auth.example.com/.well-known/openid-
configuration",
"allowedAudience": ["api.example.com"],
"allowedClients": ["client-app-123"]
}
},
"encryptionKeyArn": "arn:aws:kms:us-
east-1:123456789012:key/12345678-1234-1234-1234-123456789012"
}

**Create a gateway: basic example (IAM authorization)**

This section provides basic examples of creating a gateway using IAM authorization. With IAM
authorization, you don't need an authorizer configuration.

Select one of the following methods:

AWS CLI

Run the following in a terminal:

aws bedrock-agentcore create-gateway --name my-gateway --role-arn
arn:aws:iam::123456789012:role/MyAgentCoreServiceRole --protocol-type MCP --
authorizer-type AWS_IAM

Boto3

import boto3

Create the AgentCore client
Create a gateway 356


agentcore_client = boto3.client('bedrock-agentcore-control')

Create a gateway
gateway = agentcore_client.create_gateway(
name="MyGateway",
roleArn="arn:aws:iam::123456789012:role/MyAgentCoreServiceRole",
protocolType="MCP",
authorizerType="AWS_IAM"
)

**Create a gateway with semantic search**

Semantic search enables intelligent tool discovery so that we are not limited by typical list tools
limits (typically 100 or so). Our semantic search capability delivers contextually relevant tool
subsets, significantly improving tool selection accuracy through focused, relevant results, inference
performance with reduced token processing and overall orchestration efficiency and response
times.

To enable it, add "searchType": "SEMANTIC" to the CreateGateway request in the MCP
object within the protocolConfiguration field:

"protocolConfiguration": {
"mcp": {
"searchType": "SEMANTIC"
}
}

Note
You can only enable it during create, you cannot update a gateway later to be able to
support search.

For an identity to create a gateway with semantic search, ensure that it has permissions to use the
bedrock-agentcore:SynchronizeGatewayTargets" IAM action.

#### Add targets to an existing AgentCore gateway

After creating a gateway, you can add targets, which define the tools that your gateway will host.
AgentCore Gateway supports multiple target type that are detailed in the following topics. Each

Add targets to a gateway 357


target can have its own credential provider attached, enabling you to securely control access
targets. By adding targets, your gateway becomes a single MCP URL that enables access to all of
the relevant tools for an agent.

When you add a target, you provide the following required fields:

- The ID of the gateway to which to add the target.
- A name for the gateway target. To understand how the target name affects tool names, see
    Understand how AgentCore Gateway tools are named.
- A target configuration. The configuration differs depending on your gateway target type.
- A credential provider configuration. The configuration depends on the outbound authorization.

You can optionally provide the following fields:

- A description of the gateway target.
- A client token value to ensure that a request completes no more than once. If you don't include
    this token, one is randomly generated for you. If you don't include a value, one is randomly
    generated for you. For more information, see Ensuring idempotency.

Select a topic to learn how to add a target to an existing gateway using that method:

**Topics**

- Add a target using the AWS Management Console
- Add a target using the API

**Add a target using the AWS Management Console**

In the AWS Management Console, you can add gateway targets when you create the gateway. After
you've created a gateway, you can add targets by doing the following:

**To add a target to an existing gateway**

1. Open the AgentCore console at https://console.aws.amazon.com/bedrock-agentcore/home#.
2. Choose **Gateways**.
3. Select the gateway to which you want to add a target.
4. In the **Targets** section, choose **Add**.

Add targets to a gateway 358


5. (Optional) Change the auto-generated **Target name**.
6. (Optional) Provide an **Target description**.
7. Select the **Target type** and fill in the fields that appear.
8. (If applicable) Choose whether to define the target inline or by selecting an S3 location.
9. Select a supported outbound authorization configuration and choose the outbound
    authorization resource, if applicable.
10. (Optional, if applicable) Expand **Additional configurations** and configure them.
11. Choose **Add target**.

**Add a target using the API**

To add a target using the API, make a CreateGatewayTarget request with one of the AgentCore
control plane endpoints.

Note
To add an integration provider template as a gateway target, you must use the AWS
Management Console. For more information, see Built-in templates from integration
providers as targets.

To see examples of adding different target types, expand the following sections:

**Add a Lambda target**

Select one of the following methods:

AgentCore CLI

Create a gateway with Lambda target
agentcore create_mcp_gateway_target
--region us-east-1
--gateway-arn arn:aws:bedrock-agentcore:us-east-1:123456789012:gateway/gateway-id

--gateway-url https://gateway-id.gateway.bedrock-agentcore.us-
west-2.amazonaws.com/mcp
--role-arn arn:aws:iam::123456789012:role/BedrockAgentCoreGatewayRole
--target-type lambda

Add targets to a gateway 359


AgentCore starter toolkit

With the AgentCore starter toolkit, you can easily create a Lambda target with default
configurations.s

Import dependencies
from bedrock_agentcore_starter_toolkit.operations.gateway.client import
GatewayClient

Initialize the client
client = GatewayClient(region_name="us-east-1")

Create a lambda target.
lambda_target = client.create_mcp_gateway_target(
gateway=gateway,
name=None, # If you don't set one, one will be generated.
target_type="lambda",
target_payload=None, # Define your own lambda if you pre-created one. Otherwise
leave this as None and one will be created for you.
credentials=None, # If you leave this as None, one will be created for you
)

The following is an example argument you can provide for the target_payload. If you omit
the target_payload argument, this payload is used:

{
"lambdaArn": "",
"toolSchema": {
"inlinePayload": [
{
"name": "get_weather",
"description": "Get weather for a location",
"inputSchema": {
"type": "object",
"properties": {
"location": {
"type": "string",
"description": "the location e.g. seattle, wa"
}
},
"required": [
"location"
]

Add targets to a gateway 360


}
},
{
"name": "get_time",
"description": "Get time for a timezone",
"inputSchema": {
"type": "object",
"properties": {
"timezone": {
"type": "string"
}
},
"required": [
"timezone"
] } } ] } }

Boto3

The following Python code shows how to add a Lambda target using the Boto3 Python SDK:

import boto3

Create the agentcore client
agentcore_client = boto3.client('bedrock-agentcore-control')

Create a Lambda target
target = agentcore_client.create_gateway_target(
gatewayIdentifier="your-gateway-id",
name="LambdaTarget",
targetConfiguration={
"mcp": {
"lambda": {
"lambdaArn": "arn:aws:lambda:us-
west-2:123456789012:function:YourLambdaFunction",
"toolSchema": {
"inlinePayload": [
{
"name": "get_weather",
"description": "Get weather for a location",

Add targets to a gateway 361


"inputSchema": {
"type": "object",
"properties": {"location": {"type": "string"}},
"required": ["location"],
},
},
{
"name": "get_time",
"description": "Get time for a timezone",
"inputSchema": {
"type": "object",
"properties": {"timezone": {"type": "string"}},
"required": ["timezone"],
},
},
]
}
}
}
},
credentialProviderConfigurations=[
{
"credentialProviderType": "GATEWAY_IAM_ROLE"
}
]
)

**Add an OpenAPI target**

Select one of the following methods:

AgentCore starter toolkit

Example with S3 definition and API key outbound authorization

The following example demonstrates adding an OpenAPI schema target to a gateway. The
schema has been uploaded to an S3 location whose URI is referenced in the target_payload.
Outbound authorization for the target is through an API key.

Import dependencies
from bedrock_agentcore_starter_toolkit.operations.gateway.client import
GatewayClient

Add targets to a gateway 362


Initialize the client
gateway_client = GatewayClient(region_name="us-west-2")

Create an OpenAPI target with API Key authentication
open_api_target = gateway_client.create_mcp_gateway_target(
gateway="your-gateway-id",
target_type="openApiSchema",
target_payload={
"s3": {
"uri": "s3://your-bucket/path/to/open-api-spec.json"
}
},
credentials={
"api_key": "your-api-key",
"credential_location": "HEADER",
"credential_parameter_name": "X-API-Key"
}
)

Example with S3 definition and OAuth outbound authorization

The following example demonstrates adding an OpenAPI schema target to a gateway. The
schema has been uploaded to an S3 location whose URI is referenced in the target_payload.
Outbound authorization for the target is through an OAuth.

Import dependencies
from bedrock_agentcore_starter_toolkit.operations.gateway.client import
GatewayClient

Initialize the client
gateway_client = GatewayClient(region_name="us-west-2")

Create an OpenAPI target with OAuth authentication
open_api_with_oauth_target = gateway_client.create_mcp_gateway_target(
gateway="your-gateway-id",
target_type="openApiSchema",
target_payload={
"s3": {
"uri": "s3://your-bucket/path/to/open-api-spec.json"
}
},
credentials={

Add targets to a gateway 363


"oauth2_provider_config": {
"customOauth2ProviderConfig": {
"oauthDiscovery": {
"authorizationServerMetadata": {
"issuer": "https://example.auth0.com",
"authorizationEndpoint": "https://example.auth0.com/authorize",
"tokenEndpoint": "https://example.auth0.com/oauth/token"
}
},
"clientId": "your-client-id",
"clientSecret": "your-client-secret"
}
}
}
)

Boto3

The following Python code shows how to add an OpenAPI target using the Boto3 Python
SDK. The schema has been uploaded to an S3 location whose URI is referenced in the
target_payload. Outbound authorization for the target is through an API key.

import boto3

Create the client
agentcore_client = boto3.client('bedrock-agentcore-control')

Create an OpenAPI target with API Key authentication
target = agentcore_client.create_gateway_target(
gatewayIdentifier="your-gateway-id",
name="SearchAPITarget",
targetConfiguration={
"mcp": {
"openApiSchema": {
"s3": {
"uri": "s3://your-bucket/path/to/open-api-spec.json",
"bucketOwnerAccountId": "123456789012"
}
}
}
},
credentialProviderConfigurations=[
{

Add targets to a gateway 364


"credentialProviderType": "API_KEY",
"credentialProvider": {
"apiKeyCredentialProvider": {
"providerArn": "arn:aws:agent-credential-provider:us-
east-1:123456789012:token-vault/default/apikeycredentialprovider/abcdefghijk",
"credentialLocation": "HEADER",
"credentialParameterName": "X-API-Key"
}
}
}
]
)

**Add a Smithy target**

Select one of the following methods:

AgentCore starter toolkit

The AgentCore starter toolkit lets you create a Smithy target with a default model definition
in DynamoDB if you omit the targetConfiguration field. The following example shows the
creation of the default Smithy model definition and also a custom one uploaded to S3.

from bedrock_agentcore_starter_toolkit.operations.gateway.client import
GatewayClient

Initialize the Gateway client
gateway_client = GatewayClient(region_name="us-west-2")

Create a Smithy model target for a built-in AWS service (this default
configuration uses a DynamoDB Smithy model)
smithy_target = gateway_client.create_mcp_gateway_target(
gateway=gateway,
target_type="smithyModel"
)

Or create a Smithy model target with a custom model
custom_smithy_target = gateway_client.create_mcp_gateway_target(
gateway=gateway,
target_type="smithyModel",
target_payload={
"s3": {

Add targets to a gateway 365


"uri": "s3://your-bucket/path/to/smithy-model.json"
}
}
)

Boto3

The following Python code shows how to add a Smithy model target using the Boto3 Python
SDK:

import boto3

Create the agentcore client
agentcore_client = boto3.client('bedrock-agentcore-control')

Create a Smithy model target
target = agentcore_client.create_gateway_target(
gatewayIdentifier="your-gateway-id",
name="DynamoDBTarget",
targetConfiguration={
"mcp": {
"smithyModel": {
"s3": {
"uri": "s3://your-bucket/path/to/smithy-model.json",
"bucketOwnerAccountId": "123456789012"
}
}
}
},
credentialProviderConfigurations=[
{
"credentialProviderType": "GATEWAY_IAM_ROLE"
}
]
)

**Add an MCP server target**

You can add an MCP server target and synchronize targets using the CLI.

Add targets to a gateway 366


##### CLI

The AgentCore CLI provides a simple way to add MCP server targets:

Create MCP server as target
{gatewayUrl}/gateways/{gatewayIdentifier}/targets
{
"name": "myMCPTarget",
"description": "description of my MCP target",
"credentialProviderConfigurations": [{
"credentialProviderType": "OAUTH",
"credentialProvider": {
"oauthCredentialProvider": {
"providerArn": "arn:aws:bedrock-agentcore:{region}:{account}:token-
vault/default/oauth2credentialprovider/resource-provider-oauth-test",
"scopes": []
}
}
}],
"targetConfiguration": {
"mcp": {
"mcpServer": {
"endpoint": "myMCPServerURL"
}
}
}
}

SynchronizeGatewayTargets
{gatewayUrl}/gateways/{gatewayIdentifier}/synchronizeTargets
{
"targetIdList": [
""
]
}

### Use an AgentCore gateway

After setting up your gateway with targets, you can configure your application or agent to use the
gateway through the Model Context Protocol (MCP). The MCP provides a standardized way for
agents to discover and invoke tools.

Use a gateway 367


Note
AgentCore Gateway supports the following MCP versions:

- 2025-06-18
- 2025-03-26

You can use the following MCP operations with an AgentCore gateway:

Operation Description

tools/call Invokes a specific tool with the provided
arguments

tools/list Lists all available tools provided by the
gateway

The following topics describe the capabilities that AgentCore gateways offer.

**Topics**

- List available tools in an AgentCore gateway
- Call a tool in a AgentCore gateway
- Search for tools in your AgentCore gateway with a natural language query
- Create an agent that uses your AgentCore gateway

#### List available tools in an AgentCore gateway

To list all available tools that an AgentCore gateway provides, make a POST request to the
gateway's MCP endpoint and specify tools/list as the method in the request body:

POST /mcp HTTP/1.1
Host: ${GatewayEndpoint}
Content-Type: application/json
Authorization: ${Authorization header}

List gateway tools 368


${RequestBody}

Replace the following values:

- _${GatewayEndpoint}_ â€“ The URL of the gateway, as provided in the response of the
    CreateGateway API.
- _${Authorization header}_ â€“ The authorization credentials from the identity provider when
    you set up inbound authorization.
- _${RequestBody}_ â€“ The JSON payload of the request body, as specified in Listing tools in the
    Model Context Protocol (MCP). Include tools/list as the method.

Note
For a list of optionally supported parameters for tools/list, see the params object in
the request body at Tools in the Model Context Protocol documentation. At the top of the
page next to the search bar, you can select the MCP version whose documentation you
want to view. Make sure that the version is one supported by Amazon Bedrock AgentCore.

The response returns a list of available tools with their names, descriptions, and parameter
schemas.

**Code samples for listing tools**

To see examples of listing available tools in the gateway, select one of the following methods:

Python requests package

import requests
import json

def list_tools(gateway_url, access_token):
headers = {
"Content-Type": "application/json",
"Authorization": f"Bearer {access_token}"
}

payload = {
"jsonrpc": "2.0",

List gateway tools 369


"id": "list-tools-request",
"method": "tools/list"
}

response = requests.post(gateway_url, headers=headers, json=payload)
return response.json()

Example usage
gateway_url = "https:// ${GatewayEndpoint} /mcp" # Replace with your actual gateway
endpoint
access_token = " ${AccessToken}" # Replace with your actual access token
tools = list_tools(gateway_url, access_token)
print(json.dumps(tools, indent=2))

MCP Client

import asyncio
from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client

async def execute_mcp(
url,
token,
headers=None
):
default_headers = {
"Authorization": f"Bearer {token}"
}
headers = {**default_headers, **(headers or {})}

async with streamablehttp_client(
url=url,
headers=headers,
) as (
read_stream,
write_stream,
callA,
):
async with ClientSession(read_stream, write_stream) as session:

1. Perform initialization handshake
print("Initializing MCP...")
_init_response = await session.initialize()
print(f"MCP Server Initialize successful! - {_init_response}")

List gateway tools 370


2. List available tools
print("Listing tools...")
cursor = True
tools = []
while cursor:
next_cursor = cursor
if type(cursor) == bool:
next_cursor = None
list_tools_response = await session.list_tools(next_cursor)
tools.extend(list_tools_response.tools)
cursor = list_tools_response.nextCursor

tool_names = []
if tools:
for tool in tools:
tool_names.append(tool.name)
tool_names_string = "\n".join(tool_names)
print(
f"List MCP tools. # of tools - {len(tools)}"
f"List of tools - \n{tool_names_string}\n"
)

async def main():
url = "https://${GatewayEndpoint}/mcp"
token = "your_bearer_token_here"

Optional additional headers
additional_headers = {
"Content-Type": "application/json",
}

await execute_mcp(
url=url,
token=token,
headers=additional_headers
)

Run the async function
if name == "main":
asyncio.run(main())

List gateway tools 371


Strands MCP Client

from strands.tools.mcp.mcp_client import MCPClient
from mcp.client.streamable_http import streamablehttp_client
import os

def create_streamable_http_transport(mcp_url: str, access_token: str):
return streamablehttp_client(mcp_url, headers={"Authorization": f"Bearer
{access_token}"})

def get_full_tools_list(client):
"""
List tools w/ support for pagination
"""
more_tools = True
tools = []
pagination_token = None
while more_tools:
tmp_tools = client.list_tools_sync(pagination_token=pagination_token)
tools.extend(tmp_tools)
if tmp_tools.pagination_token is None:
more_tools = False
else:
more_tools = True
pagination_token = tmp_tools.pagination_token
return tools

def run_agent(mcp_url: str, access_token: str):
mcp_client = MCPClient(lambda: create_streamable_http_transport(mcp_url,
access_token))

with mcp_client:
tools = get_full_tools_list(mcp_client)
print(f"Found the following tools: {[tool.tool_name for tool in tools]}")

run_agent(, )

LangGraph MCP Client

import asyncio

List gateway tools 372


from langchain_mcp_adapters.client import MultiServerMCPClient

def list_tools(
url,
headers
):
mcp_client = MultiServerMCPClient(
{
"agent": {
"transport": "streamable_http",
"url": url,
"headers": headers,
}
}
)
tools = asyncio.run(mcp_client.get_tools())
tool_details = []
tool_names = []
for tool in tools:
tool_names.append(f"{tool.name}")
tool_detail = f"{tool.name} - {tool.description} \n"

tool_properties = tool.args_schema.get('properties', {})
properties = []
for property_name, tool_property in tool_properties.items():
properties.append(f"{property_name} - {tool_property.get('description',
None)} \n")
tool_details.append(f"{tool_detail}{"\n".join(properties)}")

tool_details_string = "\n".join(tool_details)
tool_names_string = "\n".join(tool_names)
print(
f"Langchain: List MCP tools. # of tools - {len(tools)}\n",
f"Langchain: List of tool names - \n{tool_names_string}\n"
f"Langchain: Details of tools - \n{tool_details_string}\n"
)

List gateway tools 373


Note
If search is enabled on the gateway, then the search tool,
x_amz_bedrock_agentcore_search will be listed first in the response.

#### Call a gateway tool............................................................................................................................

To call a specific tool, make a POST request to the gateway's MCP endpoint and specify tools/
call as the method in the request body, name of the tool, and the arguments:

POST /mcp HTTP/1.1
Host: ${GatewayEndpoint}
Content-Type: application/json
Authorization: ${Authorization header}

${RequestBody}

Replace the following values:

- _${GatewayEndpoint}_ â€“ The URL of the gateway, as provided in the response of the
    CreateGateway API.
- _${Authorization header}_ â€“ The authorization credentials from the identity provider when
    you set up inbound authorization.
- _${RequestBody}_ â€“ The JSON payload of the request body, as specified in Calling tools in the
    Model Context Protocol (MCP). Include tools/call as the method and include the name of the
    tool and its arguments.

The response returns the content returned by the tool and associated metadata.

**Code samples for calling tools**

To see examples of listing available tools in the gateway, select one of the following methods:

curl

The following curl request shows an example request to call a tool called searchProducts
through a gateway with the ID mygateway-abcdefghij.

Call a gateway tool 374


curl -X POST
https://mygateway-abcdefghij.gateway.bedrock-agentcore.us-west-2.amazonaws.com/mcp

-H "Content-Type: application/json"
-H "Authorization: Bearer YOUR_ACCESS_TOKEN"
-d '{
"jsonrpc": "2.0",
"id": "invoke-tool-request",
"method": "tools/call",
"params": {
"name": "searchProducts",
"arguments": {
"query": "wireless headphones",
"category": "Electronics",
"maxResults": 2,
"priceRange": {
"min": 50.00,
"max": 200.00
}
}
}
}'

Python requests package

import requests
import json

def call_tool(gateway_url, access_token, tool_name, arguments):
headers = {
"Content-Type": "application/json",
"Authorization": f"Bearer {access_token}"
}

payload = {
"jsonrpc": "2.0",
"id": "call-tool-request",
"method": "tools/call",
"params": {
"name": tool_name,
"arguments": arguments
}
}

Call a gateway tool 375


response = requests.post(gateway_url, headers=headers, json=payload)
return response.json()

Example usage
gateway_url = "https:// ${GatewayEndpoint} /mcp" # Replace with your actual gateway
endpoint
access_token = " ${AccessToken}" # Replace with your actual access token
result = call_tool(
gateway_url,
access_token,
"openapi-target-1___get_orders_byId", # Replace with <{TargetId}__{ToolName}>
{"orderId": "ORD-12345-67890", "customerId": "CUST-98765"}
)
print(json.dumps(result, indent=2))

MCP Client

from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client
import asyncio

async def execute_mcp(
url,
token,
tool_params,
headers=None
):
default_headers = {
"Authorization": f"Bearer {token}"
}
headers = {**default_headers, **(headers or {})}

async with streamablehttp_client(
url=url,
headers=headers,
) as (
read_stream,
write_stream,
callA,
):
async with ClientSession(read_stream, write_stream) as session:

1. Perform initialization handshake
Call a gateway tool 376


print("Initializing MCP...")
_init_response = await session.initialize()
print(f"MCP Server Initialize successful! - {_init_response}")

2. Call specific tool
print(f"Calling tool: {tool_params['name']}")
tool_response = await session.call_tool(
name=tool_params['name'],
arguments=tool_params['arguments']
)
print(f"Tool response: {tool_response}")
return tool_response

async def main():
url = "https://${GatewayEndpoint}/mcp"
token = "your_bearer_token_here"
tool_params = {
"name": "LambdaTarget___get_order_tool",
"arguments": {
"orderId": "order123"
}
}
await execute_mcp(
url=url,
token=token,
tool_params=tool_params
)

if name == "main":
asyncio.run(main())

Strands MCP Client

Note
This is for invoking agent

from strands.tools.mcp.mcp_client import MCPClient
from mcp.client.streamable_http import streamablehttp_client

Call a gateway tool 377


def create_streamable_http_transport(mcp_url: str, access_token: str):
return streamablehttp_client(mcp_url, headers={"Authorization": f"Bearer
{access_token}"})

def run_agent(mcp_url: str, access_token: str):
mcp_client = MCPClient(lambda: create_streamable_http_transport(mcp_url,
access_token))

with mcp_client:
result = mcp_client.call_tool_sync(
tool_use_id="tool-123", # A unique ID for the tool call
name="openapi-target-1___get_orders", # The name of the tool to invoke
arguments={} # A dictionary of arguments for the tool
)
print(result)

url = {gatewayUrl}
token = {AccessToken}
run_agent(url, token)

LangGraph MCP Client

Note
This is for invoking agent

import asyncio

from langgraph.prebuilt import create_react_agent

def execute_agent(
user_prompt,
model_id,
region,
tools
):
model = ChatBedrock(model_id=model_id, region_name=region)

agent = create_react_agent(model, tools)
_response = asyncio.run(agent.ainvoke({

Call a gateway tool 378


"messages": user_prompt
}))

_response = _response.get('messages', {})[1].content
print(
f"Invoke Langchain Agents Response"
f"Response - \n{_response}\n"
)
return _response

**Errors**

The tools/call operation can return the following types of errors:

- Errors returned as part of the HTTP status code:

AuthenticationError

The request failed due to invalid authentication credentials.

HTTP Status Code : 401
AuthorizationError

The caller does not have permission to invoke the tool.

HTTP Status Code : 403
ResourceNotFoundError

The specified tool does not exist.

HTTP Status Code : 404
ValidationError

The provided arguments do not conform to the tool's input schema.

HTTP Status Code : 400
ToolExecutionError

An error occurred while executing the tool.

Call a gateway tool **HTTP Status Code** : 500 379


InternalServerError

An internal server error occurred.

HTTP Status Code : 500

- MCP errors. For more information about these types of errors, Error Handling in the Model
    Context Protocol (MCP) documentation.

#### Search for tools in your AgentCore gateway with a natural language

#### query

If you enabled semantic search for your gateway when you created it, you can call the
x_amz_bedrock_agentcore_search tool to search for tools in your gateway with a natural
language query. Semantic search is particularly useful when you have many tools and need to
find the most appropriate ones for your use case. To learn how to enable semantic search during
gateway creation, see Create an Amazon Bedrock AgentCore gateway.

To search for a tool using this AgentCore tool, make the following POST request with the tools/
call method to the gateway's MCP endpoint:

POST /mcp HTTP/1.1
Host: ${GatewayEndpoint}
Content-Type: application/json
Authorization: ${Authorization header}

{
"jsonrpc": "2.0",
"id": " ${RequestName} ",
"method": "tools/call",
"params": {
"name": "x_amz_bedrock_agentcore_search",
"arguments": {
"query": ${Query}
}
}
}

Replace the following values:

Search for a gateway tool 380


- _${GatewayEndpoint}_ â€“ The URL of the gateway, as provided in the response of the
    CreateGateway API.
- _${Authorization header}_ â€“ The authorization credentials from the identity provider when
    you set up inbound authorization.
- _${RequestName}_ â€“ A name for the request.
- _${Query}_ â€“ A natural language query to search for tools.

The response returns a list of tools that are relevant to the query.

**Code samples for tool searching**

To see examples of using natural language queries to find tools in the gateway, select one of the
following methods:

Python requests package

import requests
import json

def search_tools(gateway_url, access_token, query):
headers = {
"Content-Type": "application/json",
"Authorization": f"Bearer {access_token}"
}

payload = {
"jsonrpc": "2.0",
"id": "search-tools-request",
"method": "tools/call",
"params": {
"name": "x_amz_bedrock_agentcore_search",
"arguments": {
"query": query
}
}
}

response = requests.post(gateway_url, headers=headers, json=payload)
return response.json()

Example usage
Search for a gateway tool 381


gateway_url = "https:// ${GatewayEndpoint} /mcp" # Replace with your actual gateway
endpoint
access_token = " ${AccessToken}" # Replace with your actual access token
results = search_tools(gateway_url, access_token, "find order information")
print(json.dumps(results, indent=2))

MCP Client

from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client
import asyncio

async def execute_mcp(
url,
token,
tool_params,
headers=None
):
default_headers = {
"Authorization": f"Bearer {token}"
}
headers = {**default_headers, **(headers or {})}

async with streamablehttp_client(
url=url,
headers=headers,
) as (
read_stream,
write_stream,
callA,
):
async with ClientSession(read_stream, write_stream) as session:

1. Perform initialization handshake
print("Initializing MCP...")
_init_response = await session.initialize()
print(f"MCP Server Initialize successful! - {_init_response}")

2. Call specific tool
print(f"Calling tool: {tool_params['name']}")
tool_response = await session.call_tool(
name=tool_params['name'],
arguments=tool_params['arguments']
)

Search for a gateway tool 382


print(f"Tool response: {tool_response}")
return tool_response

async def main():
url = "https://${GatewayEndpoint}/mcp"
token = "your_bearer_token_here"
tool_params = {
"name": "x_amz_bedrock_agentcore_search",
"arguments": {
"query": "How do I find order details?"
}
}
await execute_mcp(
url=url,
token=token,
tool_params=tool_params
)

if name == "main":
asyncio.run(main())

Strands MCP Client

from strands.tools.mcp.mcp_client import MCPClient
from mcp.client.streamable_http import streamablehttp_client

def create_streamable_http_transport(mcp_url: str, access_token: str):
return streamablehttp_client(mcp_url, headers={"Authorization": f"Bearer
{access_token}"})

def get_full_tools_list(client):
"""
List tools w/ support for pagination
"""
more_tools = True
tools = []
pagination_token = None
while more_tools:
tmp_tools = client.list_tools_sync(pagination_token=pagination_token)

Search for a gateway tool 383


tools.extend(tmp_tools)
if tmp_tools.pagination_token is None:
more_tools = False
else:
more_tools = True
pagination_token = tmp_tools.pagination_token
return tools

def run_agent(mcp_url: str, access_token: str):
mcp_client = MCPClient(lambda: create_streamable_http_transport(mcp_url,
access_token))

with mcp_client:
tools = get_full_tools_list(mcp_client)
print(f"Found the following tools: {[tool.tool_name for tool in tools]}")
result = mcp_client.call_tool_sync(
tool_use_id="tool-123", # A unique ID for the tool call
name="x_amz_bedrock_agentcore_search", # The name of the tool to invoke
arguments={"query": "find order information"} # A dictionary of
arguments for the tool
)
print(result)

url = {gatewayUrl}
token = {AccessToken}
run_agent(url, token)

LangGraph MCP Client

import asyncio

from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent

url = ""
headers = {}

def filter_search_tool(
):
mcp_client = MultiServerMCPClient(
{

Search for a gateway tool 384


"agent": {
"transport": "streamable_http",
"url": url,
"headers": headers,
}
}
)
tools = asyncio.run(mcp_client.get_tools())
builtin_search_tool = []
for tool in tools:
if tool.name == "x_amz_bedrock_agentcore_search":
builtin_search_tool.append(tool)
return builtin_search_tool

def execute_agent(
user_prompt,
model_id,
region,
tools
):
model = ChatBedrock(model_id=model_id, region_name=region)

agent = create_react_agent(model, filter_search_tool())
_response = asyncio.run(agent.ainvoke({
"messages": user_prompt
}))

_response = _response.get('messages', {})[1].content
print(
f"Invoke Langchain Agents Response"
f"Response - \n{_response}\n"
)
return _response

#### Create an agent that uses your AgentCore gateway

After creating and testing your gateway, you can create and connect AI agents to your gateway.
An agent connected to your gateway is able to call the tools in the gateway and use a Amazon
Bedrock model to respond to queries.

To learn how to create an agent, connect it to a gateway, and invoke it to answer queries, select
one of the following methods:

Connect an agent 385


Strands

from strands import Agent
from strands.models import BedrockModel
from strands.tools.mcp.mcp_client import MCPClient
from mcp.client.streamable_http import streamablehttp_client

def _invoke_agent(
bedrock_model,
mcp_client,
prompt
):
with mcp_client:
tools = mcp_client.list_tools_sync()
agent = Agent(
model=bedrock_model,
tools=tools
)
return agent(prompt)

def _create_streamable_http_transport(headers=None):
url = {gatewayUrl}
access_token = {AccessToken}
headers = {**headers} if headers else {}
headers["Authorization"] = f"Bearer {access_token}"
return streamablehttp_client(
url,
headers=headers
)

def _get_bedrock_model(model_id):
return BedrockModel(
inference_profile_id=model_id,
temperature=0.0,
streaming=True,
)

mcp_client = MCPClient(_create_streamable_http_transport)

if name == "main":
user_prompt = "What all orders do I have?"
_response = _invoke_agent(

Connect an agent 386


bedrock_model=_get_bedrock_model("us.anthropic.claude-sonnet-4-20250514-
v1:0"),
mcp_client=mcp_client,
prompt=user_prompt
)
print(_response)

LangGraph

from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client

from langgraph.prebuilt import create_react_agent
from langchain_mcp_adapters.tools import load_mcp_tools

Replace with actual values and the Amazon Bedrock model of your choice
gateway_url = " ${GatewayUrl} "
access_token = " ${AccessToken} "
model = ChatBedrock(model_id="anthropic.claude-3-sonnet-20240229-v1:0",
region_name="us-west-2")

async with streamablehttp_client(gateway_url, headers={"Authorization": f"Bearer
{access_token}"}) as (read, write, _):
async with ClientSession(read, write) as session:

Initialize the connection
await session.initialize()

Get tools
tools = await load_mcp_tools(session)
agent = create_react_agent(model, tools)
math_response = await agent.ainvoke({"messages": "what's (3 + 5) x 12?"})

Claude Code

#!/bin/bash

Script to add MCP server to Claude
Server configuration
SERVER_NAME= ${ServerName} # Write your server name
GATEWAY_MCP_SERVER_URL= ${GatewayUrl} # The gateway MCP URL
AUTH_TOKEN= ${AuthToken} # Claude authentication token

echo "Adding MCP server to Claude..."

Connect an agent 387


echo "Server Name: $SERVER_NAME"
echo "Server URL: $SERVER_URL"
echo ""

Add the MCP server
claude mcp add "$SERVER_NAME" "$GATEWAY_MCP_SERVER_URL"
--transport http
--header "Authorization: Bearer $AUTH_TOKEN"

Check if the command was successful
if [ $? -eq 0 ]; then
echo "MCP server added successfully!"
echo ""
echo "You can now check mcp server health with: claude mcp list"
else
echo "Failed to add MCP server"
exit 1
fi

Q Dev CLI

Integration with Q Dev CLI is available through MCP protocol support.

Configure Q Dev CLI to use your gateway
q config set mcp-server-url https:// ${GatewayId} .gateway.bedrock-
agentcore. ${Region} .amazonaws.com/mcp
q config set mcp-auth-token ${AccessToken}

### Debug and assess your gateway..........................................................................................................

You can use different tools to help debug your gateway before putting it into a production
environment, including built-in AWS and AgentCore Gateway tools, as well as external tools such as
the MCP inspector.

You can also debug, monitor, troubleshoot, and assess your gateway's performance and tool
integrations with the help of Amazon CloudWatch. To learn more, see AgentCore generated
gateway observability data.

Debug and assess your gateway 388


The following topics provide more details about different methods that you can use to debug your
gateway:

**Topics**

- Turn on debugging messages
- Use the MCP Inspector
- Logging Gateway API calls with CloudTrail

#### Turn on debugging messages..........................................................................................................

While your gateway is in development, you can turn on debugging messages to return details
on target configuration issues, including lambda function errors, egress authorizer errors, target
specification parameter validation errors.

To turn on debugging messages, set the exceptionLevel value as DEBUG when you make a
CreateGateway or UpdateGateway request. After turning on debugging messages, if an issue occurs
when you submit a request through your gateway, the response will return messages to help you
debug.

When you're done debugging your gateway, you can update the gateway and remove the
exceptionLevel field, such that the message to the end user only shows an unspecified internal
error.

**Example**

As an example, suppose that the user doesn't have permissions to invoke a Lambda function that
is targeted by the gateway. A request that calls this function would return a different message
depending on whether debugging is on or off:

- **Debugging on** â€“ A detailed error message would be returned in the content's text field and also
    in the _meta field in the response, as in the following example:

{
"jsonrpc": "2.0",
"id": 24,
"result": {
"content": [
{

Turn on debugging messages 389


"type": "text",
"text": "Access denied while invoking Lambda function arn:aws:lambda:us-
west-2:123456789012:function:TestGatewayLambda. Check the permissions on the Lambda
function and Gateway execution role, and retry the request."
}
],
"_meta": {
"debug": {
"type": "text",
"text": "Access denied while invoking Lambda function arn:aws:lambda:us-
west-2:123456789012:function:TestGatewayLambda. Check the permissions on the Lambda
function and Gateway execution role, and retry the request."
}
},
"isError": true
}
}

- **Debugging off** â€“ A generic error message would be returned in the content's text field in the
    response, as in the following example:

{
"jsonrpc": "2.0",
"id": 24,
"result": {
"content": [
{
"type": "text",
"text": "An internal error occurred. Please retry later."
}
],
"isError": true
}
}

#### Use the MCP Inspector......................................................................................................................

The MCP Inspector, available through the Model Context Protocol (MCP), is a developer tool that
helps you test and debug MCP servers by through an interactive interface. You can connect your
AgentCore gateway to the MCP inspector to help you debug your gateway targets.

For more information about the MCP Inspector, see the MCP Inspector documentation.

Use the MCP Inspector 390


**To connect your gateway to the inspector**

1. Open a terminal and run npx @modelcontextprotocol/inspector to do the following:

a. Install the inspector
b. Start the inspector on localhost.
c. Generate a session token for authentication.
d. Open your browser to the inspector interfacee.

2. In the inspector interface, configure the following fields:
    - **Transport Type** â€“ Select **Streamable HTTP**
    - **URL** â€“ Enter the gateway endpoint URL returned when you created your gateway.
    - Expand **Authentication**. The **Custom Headers** section should be pre-populated with one
       key-value pair.
       - The key's name should be Authorization.
       - Replace the value with your gateway's inbound authorization credentials.
3. Choose **Connect**. You will be connected to your gateway. You can use the MCP Inspector as a
    tool to examine and test your gateway before integrating it with your agent.

For more information about how you can inspect the MCP server that your gateway is connected
to, see **Feature overview** in the Feature overview in the MCP Inspector documentation.

Important
The MCP Inspector is a development tool and should not be used in production
environments. Always secure your access tokens and gateway credentials.

**Troubleshooting**

If you encounter issues when using the MCP Inspector with your gateway, check the following:

- **Connection issues** : Ensure that your gateway URL is correct and accessible from your network
- **Authentication issues** : Verify that your access token is valid and has not expired
- **Tool invocation errors** : Check the error messages in the response and ensure that your input
    parameters match the tool's schema

Use the MCP Inspector 391


- **Proxy errors** : If you see errors related to the proxy connection, try restarting the MCP Inspector

#### Logging Gateway API calls with CloudTrail..................................................................................

Gateway is integrated with CloudTrail, a service that provides a record of actions taken by
a user, role, or an AWS service in Gateway. CloudTrail captures all API calls for Gateway as
events, including calls from the Gateway console and code calls to the Gateway APIs. Using the
information collected by CloudTrail, you can determine the request that was made to Gateway,
who made the request, when it was made, and additional details. There are two types of events:
Management events and Data events:

**Gateway Event Types**

This section provides information about the types of events that Gateway logs to CloudTrail.

**Gateway Management Events in CloudTrail**

Every management event or log entry contains information about who generated the request. The
identity information helps you determine the following:

- Whether the request was made with root user or user credentials.
- Whether the request was made on behalf of an IAM Identity Center user.
- Whether the request was made with temporary security credentials for a role or federated user.
- Whether the request was made by another AWS service.

CloudTrail is active in your AWS account when you create the account and you automatically have
access to the CloudTrail _Event history_. The CloudTrail _Event history_ provides a viewable, searchable,
downloadable, and immutable record of the past 90 days of recorded management events in an
AWS Region.

For an ongoing record of events in your AWS account past 90 days, create a trail or a CloudTrail
Lake event data store.

Gateway logs management events for the following operations:

- CreateGateway - Creates a new gateway
- UpdateGateway - Updates an existing gateway

Logging Gateway API calls with CloudTrail 392


- DeleteGateway - Deletes a gateway
- GetGateway - Gets information about a gateway
- ListGateways - Lists all gateways
- CreateGatewayTarget - Creates a new target for a gateway
- UpdateGatewayTarget - Updates an existing gateway target
- DeleteGatewayTarget - Deletes a gateway target
- GetGatewayTarget - Gets information about a gateway target
- ListGatewayTargets - Lists all targets for a gateway

**Gateway Data Events in CloudTrail**

Data events provide information about the resource operations performed on or in a resource.
These are also known as data plane operations. Data events are often high-volume activities. You
must explicitly enable data events as they are not logged by default. The CloudTrail _Event history_
doesn't record data events.

Additional charges apply for logging data events. For more information about CloudTrail pricing,
see AWS CloudTrail Pricing.

You can enable logging data events for the Gateway resource types by using the CloudTrail
console, AWS CLI, or CloudTrail API operations.

The following table lists the Gateway resource types for which you can enable data events:

Data event type (console) resources.type value Data APIs logged to
CloudTrail

Bedrock-AgentCore gateway AWS::BedrockAgentC
ore::Gateway

InvokeGateway

**Identity Information in Data Events**

Gateway data events differ from standard AWS data events in how identity information is stored.
Since the Data API follows the MCP protocol and uses JWT token-based authentication rather than
SigV4, Gateway data events don't have standard AWS identity information. Instead, identity is
captured by logging specific JWT claims including the "sub" claim.

Logging Gateway API calls with CloudTrail 393


Note
We recommend that you avoid using any personally identifiable information (PII) in this
field. For example, you could use a GUID or a pairwise identifier, as suggested in the OIDC
specification instead of PII data like email.

**Error Information in Data Events**

Gateway provides error information as part of the responseElements field rather than as top-
level errorCode and errorMessage fields. If you're looking for specific error types such as
AccessDenied events, parse through the responseElements field in the CloudTrail event.

**Data Event Routing**

Since Gateway uses JWT tokens for authentication rather than SigV4 credentials, data events are
only routed to the resource owner account.

**Enabling CloudTrail Data Event Logging for Gateway**

You can use CloudTrail data events to get information about Gateway requests. To enable
CloudTrail data events for Gateway, you must create a trail manually in CloudTrail backed by an
Amazon S3 bucket.

Note

- Data event logging incurs additional charges. You must explicitly enable data events as
    they are not captured by default. Check to ensure that you have data events enabled for
    your account.
- With a Gateway that is generating a high workload, you could quickly generate
    thousands of logs in a short amount of time. Be mindful of how long you choose to
    enable CloudTrail data events for a busy Gateway.

CloudTrail stores Gateway data event logs in an Amazon S3 bucket of your choosing. Consider
using a bucket in a separate AWS account to better organize events from multiple resources into a
central place for easier querying and analysis.

Logging Gateway API calls with CloudTrail 394


When you log data events for a trail in CloudTrail, you must use advanced event selectors to log
data events for Gateway operations.

AWS CLI

To enable CloudTrail data events for Gateway using the AWS CLI, you can use the following
command:

aws cloudtrail put-event-selectors
--trail-name brac-gateway-canary-trail-prod-us-east-1
--region us-east-1
--advanced-event-selectors '[
{
"Name": "GatewayDataEvents",
"FieldSelectors": [
{
"Field": "eventCategory",
"Equals": ["Data"]
},
{
"Field": "resources.type",
"Equals": ["AWS::BedrockAgentCore::Gateway"]
}
]
}
]'

##### AWS CDK

Here's an example of how to create a CloudTrail trail with Gateway data events using AWS CDK:

import { Construct } from 'constructs';
import { Trail, CfnTrail } from 'aws-cdk-lib/aws-cloudtrail';
import { Bucket } from 'aws-cdk-lib/aws-s3';
import { Effect, PolicyStatement, ServicePrincipal } from 'aws-cdk-lib/aws-iam';
import { RemovalPolicy } from 'aws-cdk-lib';

export interface DataEventTrailProps {
/**

Whether to enable multi-region trail
Logging Gateway API calls with CloudTrail 395


*/
isMultiRegionTrail?: boolean;

/**

Whether to include global service events
*/
includeGlobalServiceEvents?: boolean;
/**

AWS region
*/
region: string;
/**

Environment account ID
*/
account: string;
}
/**

Creates a CloudTrail trail configured to capture data events for Bedrock Agent
Core Gateway
/
export class BedrockAgentCoreDataEventTrail extends Construct {
/*
The CloudTrail trail
*/
public readonly trail: Trail;
/**

The S3 bucket for CloudTrail logs
*/
public readonly logsBucket: Bucket;
constructor(scope: Construct, id: string, props: DataEventTrailProps) {
super(scope, id);

// Create S3 bucket for CloudTrail logs
const bucketName = brac-gateway-cloudtrail-logs-${props.account}- ${props.region};
this.logsBucket = new Bucket(this, 'CloudTrailLogsBucket', {
bucketName,
removalPolicy: RemovalPolicy.RETAIN,
});

Logging Gateway API calls with CloudTrail 396


// Create trail name (suffixing region since regional trail)
const trailName = brac-gateway-trail-${props.region};

// Add CloudTrail bucket policy
this.logsBucket.addToResourcePolicy(
new PolicyStatement({
sid: 'AWSCloudTrailAclCheck',
effect: Effect.ALLOW,
principals: [new ServicePrincipal('cloudtrail.amazonaws.com')],
actions: ['s3:GetBucketAcl'],
resources: [this.logsBucket.bucketArn],
conditions: {
StringEquals: {
'aws:SourceArn': arn:aws:cloudtrail:${props.region}: ${props.account}:trail/${trailName},
},
},
}),
);

this.logsBucket.addToResourcePolicy(
new PolicyStatement({
sid: 'AWSCloudTrailWrite',
effect: Effect.ALLOW,
principals: [new ServicePrincipal('cloudtrail.amazonaws.com')],
actions: ['s3:PutObject'],
resources: [this.logsBucket.arnForObjects(AWSLogs/${props.account}/*)],
conditions: {
StringEquals: {
's3:x-amz-acl': 'bucket-owner-full-control',
'aws:SourceArn': arn:aws:cloudtrail:${props.region}: ${props.account}:trail/${trailName},
},
},
}),
);

// Create CloudTrail trail
this.trail = new Trail(this, 'GatewayDataEventTrail', {
trailName,
bucket: this.logsBucket,
isMultiRegionTrail: props.isMultiRegionTrail ?? false,
includeGlobalServiceEvents: props.includeGlobalServiceEvents ?? true,

Logging Gateway API calls with CloudTrail 397


enableFileValidation: true,
});

// Add advanced event selectors for Bedrock Agent Core Gateway data events
const cfnTrail = this.trail.node.defaultChild as CfnTrail;

// Define the advanced event selectors
const advancedEventSelectors = [
{
// Log Bedrock Agent Core Gateway Data Events only
fieldSelectors: [
{
field: 'eventCategory',
equalTo: ['Data'],
},
{
field: 'resources.type',
equalTo: ['AWS::BedrockAgentCore::Gateway'],
},
],
},
];

// Clear any existing event selectors and set advanced event selectors
cfnTrail.eventSelectors = undefined;
cfnTrail.advancedEventSelectors = advancedEventSelectors;
}
}

**Understanding Gateway CloudTrail Events**

A trail is a configuration that enables delivery of events as log files to an Amazon S3 bucket that
you specify. CloudTrail log files contain one or more log entries. An event represents a single
request from any source and includes information about the requested action, the date and time of
the action, request parameters, and so on.

Note
The contents of the requests and responses for data events are REDACTED, and the JWT
claims have HTML entities sanitized for security purposes.

Logging Gateway API calls with CloudTrail 398


InvokeGateway Data Event With Authentication Error

The following example shows a CloudTrail log entry that demonstrates the InvokeGateway
action with an authentication error:

{
"eventVersion": "1.11",
"userIdentity": {
"type": "AWSAccount",
"principalId": "",
"accountId": "anonymous"
},
"eventTime": "2025-07-14T02:14:42Z",
"eventSource": "bedrock-agentcore.amazonaws.com",
"eventName": "InvokeGateway",
"awsRegion": "us-west-2",
"sourceIPAddress": "34.XXX.XXX.206",
"userAgent": "python-httpx/0.28.1",
"requestParameters": {
"body": {
"id": 0,
"method": "initialize",
"params": {
"clientInfo": {
"name": "mcp",
"version": "0.1.0"
},
"protocolVersion": "2025-06-18",
"capabilities": {}
},
"jsonrpc": "2.0"
}
},
"responseElements": {
"body": {
"jsonrpc": "2.0",
"id": 0,
"error": {
"code": -32001,
"message": "Invalid Bearer token"
}
},
"contentType": "application/json",

Logging Gateway API calls with CloudTrail 399


"statusCode": 401
},
"requestID": "1234abcd-12ab-34cd-56ef-1234567890ab",
"eventID": "12345678-1234-5678-9abc-123456789012",
"readOnly": false,
"resources": [
{
"accountId": "XXXXXXXXXX",
"type": "AWS::BedrockAgentCore::Gateway",
"ARN": "arn:aws:bedrock-agentcore:us-west-2:XXXXXXXXXX:gateway/test-
openapi-gateway-b24f8c26-u9p3rjw8qw"
}
],
"eventType": "AwsApiCall",
"managementEvent": false,
"recipientAccountId": "XXXXXXXXXX",
"sharedEventID": "12345678-xxxx-xxxx-xxxx-123456789012",
"eventCategory": "Data",
"tlsDetails": {
"tlsVersion": "TLSv1.2",
"cipherSuite": "ECDHE-RSA-AES128-GCM-SHA256",
"clientProvidedHostHeader": "test-openapi-gateway-xxxxxxx-
u9p3rjw8qw.gateway.bedrock-agentcore.us-west-2.amazonaws.com"
}
}

Successful InvokeGateway Data Event

The following example shows a CloudTrail log entry for a successful InvokeGateway action:

{
"eventVersion": "1.11",
"userIdentity": {
"type": "AWSAccount",
"principalId": "",
"accountId": "anonymous"
},
"eventTime": "2025-07-14T02:14:42Z",
"eventSource": "bedrock-agentcore.amazonaws.com",
"eventName": "InvokeGateway",
"awsRegion": "us-west-2",
"sourceIPAddress": "35.88.103.184",

Logging Gateway API calls with CloudTrail 400


"userAgent": "python-httpx/0.28.1",
"requestParameters": {
"body": {
"id": 1,
"method": "tools/call",
"params": {
"name": "SmithyTarget___ListTables",
"arguments": "REDACTED"
},
"jsonrpc": "2.0"
}
},
"responseElements": {
"body": {
"jsonrpc": "2.0",
"id": 1,
"result": {
"isError": false,
"content": "REDACTED"
}
},
"contentType": "application/json",
"statusCode": 200
},
"additionalEventData": {
"targetId": "0JTXXX4YMA",
"jwt": {
"headers": {
"kid": "hGrcJwz5MX6hNeuL6jdXE4hjK7sT6oj+yN7kN+arRv4=",
"alg": "RS256"
},
"claims": {
"sub": "4ammgxxxxxxxxxxxm3b8c",
"token_use": "access",
"scope": "python-cognito-resource-server-id/write python-cognito-
resource-server-id/read",
"auth_time": 1752459276,
"iss": "https://cognito-idp.us-west-2.amazonaws.com/us-
west-2_Fxxxxxhtq",
"exp": 1752462876,
"iat": 1752459276,
"version": 2,
"jti": "1234abcd-12ab-34cd-56ef-1234567890ab"
},

Logging Gateway API calls with CloudTrail 401


"type": "JWS"
},
"downstreamRequestIds": [
"H3RDH6T03DG10996U0M2P1V1IFVV4KQNSO5AEMVJF66Q9ASUAAJG"
]
},
"requestID": "1234abcd-12ab-34cd-56ef-1234567890ab",
"eventID": "12345678-1234-5678-9abc-123456789012",
"readOnly": false,
"resources": [
{
"accountId": "XXXXXXXXXX",
"type": "AWS::BedrockAgentCore::Gateway",
"ARN": "arn:aws:bedrock-agentcore:us-west-2:XXXXXXXXXX:gateway/test-
gateway-65129e91-mtzoadyihf"
}
],
"eventType": "AwsApiCall",
"managementEvent": false,
"recipientAccountId": "XXXXXXXXXX",
"sharedEventID": "1234abcd-12ab-34cd-56ef-1234567890ab",
"eventCategory": "Data",
"tlsDetails": {
"tlsVersion": "TLSv1.2",
"cipherSuite": "ECDHE-RSA-AES128-GCM-SHA256",
"clientProvidedHostHeader": "test-gateway-65129e91-xxxxxxxx.gateway.bedrock-
agentcore.us-west-2.amazonaws.com"
}
}

Management Event

The following example shows a CloudTrail log entry for a management event:

{
"eventVersion": "1.09",
"userIdentity": {
"type": "AssumedRole",
"principalId": "AROXXXXXXXXXXXXNRD7D:xxxxx",
"arn": "arn:aws:sts::XXXXXXXXXXXX:assumed-role/HydraInvocationRole-xxxxxxxxx/
xxxx",
"accountId": "XXXXXXXXXXXX",

Logging Gateway API calls with CloudTrail 402


"accessKeyId": "xxxxxxxxx",
"sessionContext": {
"sessionIssuer": {
"type": "Role",
"principalId": "xxxxxxxx",
"arn": "arn:aws:iam::XXXXXXXXXXXX:role/HydraInvocationRole-xxx",
"accountId": "XXXXXXXXXXXX",
"userName": "HydraInvocationRole-xxxxx"
},
"attributes": {
"creationDate": "2025-07-14T02:42:43Z",
"mfaAuthenticated": "false"
}
},
"invokedBy": "bedrock-agentcore.amazonaws.com"
},
"eventTime": "2025-07-14T02:47:38Z",
"eventSource": "bedrock-agentcore.amazonaws.com",
"eventName": "CreateGateway",
"awsRegion": "us-west-2",
"sourceIPAddress": "bedrock-agentcore.amazonaws.com",
"userAgent": "bedrock-agentcore.amazonaws.com",
"requestParameters": {
"roleArn": "arn:aws:iam::XXXXXXXXXXXX:role/PythonGenesisTestGatewayRole",
"name": "",
"authorizerConfiguration": {
"customJWTAuthorizer": {
"allowedClients": [
"xxxxxxxxx"
],
"discoveryUrl": "https://cognito-idp.us-west-2.amazonaws.com/us-
west-2_xxxxx/.well-known/openid-configuration"
}
},
"description": "",
"protocolType": "MCP",
"authorizerType": "CUSTOM_JWT"
},
"responseElements": {
"authorizerConfiguration": {
"customJWTAuthorizer": {
"allowedClients": [
"xxxxxxxxxxxxxxx"
],

Logging Gateway API calls with CloudTrail 403


"discoveryUrl": "https://cognito-idp.us-west-2.amazonaws.com/us-
west-2_xxxxxx/.well-known/openid-configuration"
}
},
"description": "",
"protocolType": "MCP",
"gatewayArn": "arn:aws:bedrock-agentcore:us-west-2:XXXXXXXXXXXX:gateway/test-
openapi-gateway-xxxxxxx-xxxxxx",
"workloadIdentityDetails": {
"workloadIdentityArn": "arn:aws:bedrock-agentcore:us-
west-2:XXXXXXXXXXXX:workload-identity-directory/default/workload-identity/test-
openapi-gateway-xxxxxx-xxxxx"
},
"createdAt": "2025-07-14T02:47:38.302834063Z",
"gatewayUrl": "https://test-openapi-gateway-xxxxxxx-8fb4mo6pqx.gateway.bedrock-
agentcore.us-west-2.amazonaws.com/mcp",
"roleArn": "arn:aws:iam::XXXXXXXXXXXX:role/PythonGenesisTestGatewayRole",
"name": "",
"authorizerType": "CUSTOM_JWT",
"gatewayId": "test-openapi-gateway-9c8f7109-8fb4mo6pqx",
"status": "CREATING",
"updatedAt": "2025-07-14T02:47:38.302845797Z"
},
"requestID": "0fb99b0b-a4d1-xxxx-8aee-c703adaa6bd9",
"eventID": "b12bf859-xxxx-48d7-952a-d5c6ec00fb68",
"readOnly": false,
"resources": [
{
"accountId": "XXXXXXXXXXXX",
"type": "AWS::BedrockAgentCore::Gateway",
"ARN": "arn:aws:bedrock-agentcore:us-west-2:XXXXXXXXXXXX:gateway/test-openapi-
gateway-xxxxxxx-8fb4mo6pqx"
}
],
"eventType": "AwsApiCall",
"managementEvent": true,
"recipientAccountId": "XXXXXXXXXXXX",
"eventCategory": "Management"
}

Logging Gateway API calls with CloudTrail 404


**Additional Resources**

For more information about using CloudTrail with Gateway, see the following resources:

- AWS CloudTrail User Guide
- Creating a Trail for Your AWS Account
- AWS CloudTrail API Reference
- AWS CloudTrail CLI Reference

### Advanced features and topics for Amazon Bedrock AgentCore

### Gateway

This chapter covers some advanced topics and additional information that can help supplement
your knowledge of gateways and how you can use them effectively in your applications.

**Topics**

- Encrypt your AgentCore gateway with a customer-managed KMS key
- Setting up custom domain names for Gateway endpoints
- Performance optimization

#### Encrypt your AgentCore gateway with a customer-managed KMS key

By default, Gateway encrypts your data at rest using a service-managed AWS Key Management
Service key. However, you can optionally provide your own customer managed KMS key for
encrypting data at rest when you:

- Create a gateway.
- Update a gateway's configurations.

Using a customer managed key gives you more control over the encryption process, including the
ability to:

- Rotate the key on your own schedule
- Control access to the key through IAM policies
- Disable or delete the key when it's no longer needed

Advanced topics 405


- Audit key usage through CloudWatch logs and AWS CloudTrail

For more information, see AWS Key Management Service Developer Guide.

Note
If you choose to use a customer managed key, you are responsible for managing the key
and its permissions. If the key is disabled or deleted, or if Gateway loses permission to use
the key, you will lose access to the encrypted data.

**Prerequisites for encrypting your AgentCore gateway**

Before encrypting your gateway, ensure that you have fulfilled the following prerequsites:

- You have access to a KMS key. For information about creating a KMS key, see Create a KMS key.
- The KMS key has a key policy attached to it that allows the following permissions:
    - Permissions that allow the gateway service role to perform the following actions:
       - kms:CreateGrant
       - kms:DescribeKey
       - kms:Decrypt
       - kms:GenerateDataKey
    - (If you enable CloudWatch Logs for your gateway) Permissions that allow the CloudWatch Logs
       service to decrypt the key.

For more information about controlling IAM permissions for a KMS key, see KMS key access and
permissions in the AWS Key Management Service Developer Guide.

**Example key policy**

The following example policy provides the necessary permissions to encrypt a gateway and use an
encrypted gateway. The fourth statement also allows CloudWatch Logs logging of key usage for
the encrypted gateway. The policy contains condition keys to conform to security best practices.

Customize your gateway's encryption 406


##### JSON

{
"Version":"2012-10-17",
"Statement": [
{
"Sid": "AllowServiceRoleDescribeKey",
"Effect": "Allow",
"Principal": {
"AWS": "arn:aws:iam:: 123456789012 :role/ GatewayServiceRole "
},
"Action": [
"kms:DescribeKey"
],
"Resource": "",
"Condition": {
"StringEquals": {
"kms:ViaService": [
"bedrock-agentcore. us-east-1 .amazonaws.com"
]
}
}
},
{
"Sid": "AllowServiceRoleDecryptKey",
"Effect": "Allow",
"Principal": {
"AWS": "arn:aws:iam:: 123456789012 :role/ GatewayServiceRole "
},
"Action": [
"kms:Decrypt",
"kms:GenerateDataKey"
],
"Resource": "",
"Condition": {
"StringEquals": {
"kms:ViaService": [
"bedrock-agentcore. us-east-1 .amazonaws.com"
]
},
"StringLike": {
"kms:EncryptionContext:aws:bedrock-agentcore-gateway:arn":
"arn:aws:bedrock-agentcore: us-east-1 : 123456789012 :gateway/ GatewayId "

Customize your gateway's encryption 407


}
}
},
{
"Sid": "AllowServiceRoleCreateGrant",
"Effect": "Allow",
"Principal": {
"AWS": "arn:aws:iam:: 123456789012 :role/ GatewayServiceRole "
},
"Action": "kms:CreateGrant",
"Resource": "",
"Condition": {
"StringEquals": {
"kms:ViaService": [
"bedrock-agentcore. us-east-1 .amazonaws.com"
],
"kms:GrantConstraintType": "EncryptionContextSubset"
},
"ForAllValues:StringEquals": {
"kms:GrantOperations": [
"Decrypt",
"GenerateDataKey"
]
},
"StringLike": {
"kms:EncryptionContext:aws:bedrock-agentcore-gateway:arn":
"arn:aws:bedrock-agentcore: us-east-1 : 123456789012 :gateway/ GatewayId "
}
}
},
{
"Sid": "AllowKMSDecryptionLogging",
"Effect": "Allow",
"Principal": {
"Service": "delivery.logs.amazonaws.com"
},
"Action": [
"kms:GenerateDataKey",
"kms:Decrypt"
],
"Resource": "",
"Condition": {
"StringEquals": {

Customize your gateway's encryption 408


"kms:EncryptionContext:SourceArn": "arn:aws:logs: us-
east-1 : 123456789012 :*"
}
}
}
]
}

The policy contains the following statements:

- **AllowServiceRoleDescribeKKey** â€“ Allows the specified principal to describe the key if the request
    is made through the AgentCore service. Replace values in the following fields:
    - Principal â€“ Replace the AWS value with the actual ARN of your gateway service role.
    - Condition â€“ In the kms:ViaService array, replace _us-east-1_ with the actual AWS Region
       for which you want to allow the key to be described.
- **AllowServiceRoleDecryptKey** â€“ Allows the specified principal to decrypt the key if the request is
    made through the AgentCore service and if the ARN of the gateway to which the request is made
    matches the one in the kmsEncryptionContext:aws:bedrock-agentcore-gateway-arn
    field. Replace the following values:
    - Principal â€“ Replace the AWS value with the actual ARN of your gateway service role.
    - Condition â€“ Do the following:
       - In the kms:ViaService array, replace _us-east-1_ with the actual AWS Region for which
          you want to allow the key to be decrypted.
       - Replace the kmsEncryptionContext:aws:bedrock-agentcore-gateway-arn value
          with the actual ARN of your gateway.
- **AllowServiceRoleCreateGrant** â€“ Allows the specified principal to create a grant for a key if the
    request is made through the AgentCore service and if the ARN of the gateway to which the
    request is made matches the one in the kmsEncryptionContext:aws:bedrock-agentcore-
    gateway-arn field. Replace the following values:
    - Principal â€“ Replace the AWS value with the actual ARN of your gateway service role.
    - Condition â€“ Do the following:
       - In the kms:ViaService array, replace _us-east-1_ with the actual AWS Region for which
          you want to allow the key to be decrypted.
       - Replace the kmsEncryptionContext:aws:bedrock-agentcore-gateway-arn value
          with the actual ARN of your gateway (if you want to allow).

Customize your gateway's encryption 409


- **AllowKMSDecryptionLogging** â€“ Allows the specified principal to decrypt a customer-
    managed KMS key for auditing key usage through CloudWatch Logs. In the
    kms:EncryptionContext:SourceArn value, replace _us-east-1_ and _123456789012_ values
    with your actual AWS Region and account ID.

Console

To encrypt your gateway with a customer-managed KMS key

1. Follow the **Console** steps at Create an Amazon Bedrock AgentCore gateway and expand the
    **KMS key - optional** section.
2. Choose **Customize encryption settings (advanced)**.
3. Select a KMS key and confirm its details.

Note
If you don't see your KMS key, go over the Prerequisites for encrypting your
AgentCore gateway and check that the permissions are properly configured.

4. Continue through the remaining console steps.

##### CLI

To encrypt your gateway using the AWS CLI, include the kms-key-arn when sending either of
the following requests through an AgentCore control plane client.:

- create-gateway
- update-gateway

The following example shows an example CLI request to create a gateway with a AWS KMS key
specified using the kms-key-arn argument:

aws bedrock-agentcore-control create-gateway
--name "MyGateway"
--role-arn "arn:aws:iam::123456789012:role/GatewayRole"
--protocol-type "MCP"
--kms-key-arn "arn:aws:kms:us-
west-2:123456789012:key/1234abcd-12ab-34cd-56ef-1234567890ab" \

Customize your gateway's encryption 410


--authorizer-type "CUSTOM_JWT"
--authorizer-configuration '{
"customJWTAuthorizer": {
"allowedAudience": ["myAudience"],
"discoveryUrl": "https://example.com/.well-known/openid-configuration"
}
}'

Python (Boto3)

To encrypt your gateway using the Boto3 Python SDK, include the kms-key-arn when sending
either of the following requests through an AgentCore control plane client.:

- create_gateway
- update_gateway

The following example shows an example Boto3 request to create a gateway with a AWS KMS
key specified using the kmsKeyArn argument:

import boto3

Create client
agentcore_client = boto3.client('bedrock-agentcore-control')

Create gateway and specify
gateway = agentcore_client.create_gateway(
name="MyGateway",
roleArn="arn:aws:iam::123456789012:role/GatewayRole",
protocolType="MCP",
kmsKeyArn="arn:aws:kms:us-
west-2:123456789012:key/1234abcd-12ab-34cd-56ef-1234567890ab"
authorizerType="CUSTOM_JWT",
authorizerConfiguration= {
"customJWTAuthorizer": {
"allowedAudience": ["myAudience"],
"discoveryUrl": "https://example.com/.well-known/openid-configuration"
}
}
)

Customize your gateway's encryption 411


#### Setting up custom domain names for Gateway endpoints

By default, Gateway endpoints are provided with an AWS-managed domain name in the format
<gateway-id>.gateway.bedrock-agentcore.<region>.amazonaws.com. For production
environments or to create a more user-friendly experience, you may want to use a custom domain
name for your gateway endpoint. This section guides you through setting up a custom domain
name using Amazon CloudFront as a reverse proxy.

**Prerequisites**

Before you begin, ensure you have:

- A working Gateway endpoint
- DNS delegation (if your Route 53 domain needs to be publicly reachable)
- AWS CDK installed and configured (if following the CDK approach)
- Appropriate IAM permissions to create and manage CloudFront distributions, Route 53 hosted
    zones, and ACM certificates

**Solution overview**

The solution involves the following components:

- **Route 53 Hosted Zone** : Manages DNS records for your custom domain
- **ACM Certificate** : Provides SSL/TLS encryption for your custom domain
- **CloudFront Distribution** : Acts as a reverse proxy, forwarding requests from your custom domain
    to the Gateway endpoint
- **Route 53 A Record** : Maps your custom domain to the CloudFront distribution

The following steps will guide you through setting up these components using AWS CDK.

**Implementation steps**

**Step 1: Create a Route 53 hosted zone**

First, create a Route 53 hosted zone for your custom domain:

Custom domain names 412


import { RemovalPolicy } from 'aws-cdk-lib';
import { PublicHostedZone } from 'aws-cdk-lib/aws-route53';

const domainName = 'my.example.com';

const hostedZone = new PublicHostedZone(this, 'HostedZone', {
zoneName: domainName,
});
this.hostedZone.applyRemovalPolicy(RemovalPolicy.RETAIN);

Note
We apply a removal policy of RETAIN to prevent accidental deletion of the hosted zone
during stack updates or deletion.

**Step 2: Create a DNS-validated certificate**

Next, create an SSL/TLS certificate for your custom domain using AWS Certificate Manager (ACM)
with DNS validation:

import { RemovalPolicy } from 'aws-cdk-lib';
import { Certificate, CertificateValidation } from 'aws-cdk-lib/aws-
certificatemanager';

const certificate = new Certificate(this, 'SSLCertificate', {
domainName: domainName, // route53 hosted zone domain name from step 1
validation: CertificateValidation.fromDns(hostedZone), // route53 hosted zone from
step 1
});
this.certificate.applyRemovalPolicy(RemovalPolicy.RETAIN);

DNS validation automatically creates the necessary validation records in your Route 53 hosted
zone.

**Step 3: Create a CloudFront distribution**

Create a CloudFront distribution to act as a reverse proxy for your Gateway endpoint:

Custom domain names 413


import {
AllowedMethods,
CachePolicy,
Distribution,
OriginProtocolPolicy,
ViewerProtocolPolicy
} from 'aws-cdk-lib/aws-cloudfront';
import { HttpOrigin } from 'aws-cdk-lib/aws-cloudfront-origins';

const bedrockAgentCoreGatewayHostName = '.gateway.bedrock-
agentcore..amazonaws.com'
const bedrockAgentCoreGatewayPath = '/mcp' // can also be left undefined, depending on
your requirement

const distribution = new Distribution(this, 'Distribution', {
defaultBehavior: {
origin: new HttpOrigin(bedrockAgentCoreGatewayHostName, {
protocolPolicy: OriginProtocolPolicy.HTTPS_ONLY,
originPath: bedrockAgentCoreGatewayPath,
}),
viewerProtocolPolicy: ViewerProtocolPolicy.HTTPS_ONLY,
cachePolicy: CachePolicy.CACHING_DISABLED, // important since caching is
enabled by default and hence is not suitable for a reverse proxy
allowedMethods: AllowedMethods.ALLOW_ALL,
},
domainNames: [domainName], // route53 hosted zone domain name from step 1
certificate: certificate, // ssl certificate for the route53 domain from step 2
});

Important
Set cachePolicy: CachePolicy.CACHING_DISABLED to ensure that CloudFront
doesn't cache responses from your Gateway endpoint, which is important for dynamic API
interactions.

Replace <mymcpserver> with your gateway ID and <region> with your AWS Region (e.g., us-
east-1).

Custom domain names 414


**Step 4: Create a Route 53 A record**

Create a Route 53 A record that points your custom domain to the CloudFront distribution:

import { ARecord, RecordTarget } from 'aws-cdk-lib/aws-route53';
import { CloudFrontTarget } from 'aws-cdk-lib/aws-route53-targets';

const aRecord = new ARecord(this, 'AliasRecord', {
zone: hostedZone, // route53 hosted zone from step 1
recordName: domainName, // route53 hosted zone domain name from step 1
target: RecordTarget.fromAlias(new CloudFrontTarget(distribution)), // cloufront
distribution from from step 3
});

This creates an alias record that maps your custom domain to the CloudFront distribution.

**Step 5: Deploy your infrastructure**

Deploy your CDK stack to create the resources:

cdk deploy

The deployment process may take some time, especially for the certificate validation and
CloudFront distribution creation.

**Testing your custom domain**

After deploying your infrastructure, verify that your custom domain is properly configured:

**Verify DNS resolution**

Use the dig command to verify that your custom domain resolves to the CloudFront distribution:

dig my.example.com

The output should show that your domain resolves to CloudFront's IP addresses.

Custom domain names 415


**Verify SSL certificate**

Use curl to verify that the SSL certificate is properly configured:

curl -v https://my.example.com

The output should show a successful SSL handshake with no certificate errors.

**Configuring MCP clients**

Once your custom domain is set up and verified, you can configure your MCP clients to use it:

**Cursor configuration**

For Cursor, update your configuration file:

{
"mcpServers": {
"my-mcp-server": {
"url": "https://my.example.com"
}
}
}

**Other MCP clients**

For MCP clients that don't natively support streamable HTTP:

{
"mcpServers": {
"my-mcp-server": {
"command": "/path/to/uvx",
"args": [
"mcp-proxy",
"--transport",
"streamablehttp",
"https://my.example.com"
]

Custom domain names 416


}
}
}

**Additional considerations**

**Cost implications**

Using CloudFront as a reverse proxy incurs additional costs for data transfer and request
handling. Review the CloudFront pricing model to understand the cost implications for your
specific use case.

**Security considerations**

Consider implementing additional security measures such as:

- WAF rules to protect your endpoint from common web exploits
- Geo-restrictions to limit access to specific geographic regions
- Custom headers or request signing to add an extra layer of authentication

**Monitoring and logging**

Enable CloudFront access logs and configure CloudWatch alarms to monitor the health and
performance of your custom domain setup.

**Certificate renewal**

ACM certificates issued through DNS validation are automatically renewed as long as the DNS
records remain in place. Ensure that you don't delete the validation records.

**Troubleshooting**

**DNS resolution issues**

If your custom domain doesn't resolve correctly:

- Verify that the A record is correctly configured in your Route 53 hosted zone
- Check that your domain's name servers are correctly set at your domain registrar
- Allow time for DNS propagation (up to 48 hours in some cases)

**SSL certificate issues**

If you encounter SSL certificate errors:

Custom domain names 417


- Verify that the certificate is issued and active in the ACM console
- Check that the certificate is correctly associated with your CloudFront distribution
- Ensure that the certificate covers the exact domain name you're using

**Gateway connectivity issues**

If your custom domain doesn't connect to your gateway:

- Verify that the origin domain and path in your CloudFront distribution are correct
- Check that your gateway endpoint is accessible directly
- Review CloudFront distribution logs for any errors

**Conclusion**

Setting up a custom domain name for your Gateway endpoint enhances the professional
appearance of your application and provides flexibility in managing your API endpoints. By
following the steps outlined in this guide, you can create a secure and reliable custom domain
configuration using CloudFront as a reverse proxy.

For more information about Gateway features and capabilities, see _AgentCore Gateway: Securely
connect to tools and resources_.

#### Performance optimization................................................................................................................

To optimize the performance of your Gateway implementations, consider the following best
practices:

**Minimize tool latency**

The overall latency of your gateway is largely determined by the latency of the underlying
tools. To minimize latency:

- Use Lambda functions in the same region as your gateway
- Optimize your Lambda functions for fast cold starts
- Use provisioned concurrency for Lambda functions that require low latency
- Ensure that REST APIs have low latency and high availability

**Use efficient tool schemas**

Well-designed tool schemas can improve the performance of your gateway:

Performance optimization 418


- Keep schemas as simple as possible
- Use appropriate data types for parameters
- Include clear descriptions for parameters to help agents use the tools correctly
- Use required fields to ensure that agents provide necessary parameters

**Enable semantic search**

Semantic search helps agents find the right tools for their tasks, improving the overall
performance of your agent-gateway interactions. Enable semantic search when creating your
gateway:

from bedrock_agentcore_starter_toolkit.operations.gateway.client import
GatewayClient

Initialize the Gateway client
gateway_client = GatewayClient(region_name="us-west-2")

Create a gateway with semantic search enabled
gateway = gateway_client.create_gateway(
name="semantic-search-gateway",
description="A gateway with semantic search enabled",
protocol_configuration={
"mcp": {
"search_type": "SEMANTIC"
}
}
)

**Monitor and optimize**

Use the observability features described in the previous section to monitor the performance of
your gateway and identify opportunities for optimization:

- Set up CloudWatch alarms for key metrics
- Analyze logs to identify patterns and issues
- Regularly review performance metrics and make adjustments as needed

Performance optimization 419


## Provide identity and credential management for agent

## applications with Amazon Bedrock AgentCore Identity

Amazon Bedrock AgentCore Identity is an identity and credential management service
designed specifically for AI agents and automated workloads. It provides secure authentication,
authorization, and credential management capabilities that enable agents and tools to access
AWS resources and third-party services on behalf of users while helping to maintain strict security
controls and audit trails. Agent identities are implemented as workload identities with specialized
attributes that enable agent-specific capabilities while helping to maintain compatibility with
industry-standard workload identity patterns. The service integrates natively with Amazon Bedrock
AgentCore to provide identity and credential management for agent applications, including Host
agent or tools with Amazon Bedrock AgentCore Runtime and Amazon Bedrock AgentCore Gateway:
Securely connect tools and other resources to your Gateway.

**Topics**

- Overview of Amazon Bedrock AgentCore Identity
- Get started with AgentCore Identity
- Using the AgentCore Identity console
- Manage workload identities with AgentCore Identity
- Manage credential providers with AgentCore Identity
- Provider setup and configuration
- Data protection in Amazon Bedrock AgentCore Identity
- Tagging AgentCore Identity resources

### Overview of Amazon Bedrock AgentCore Identity

In the rapidly evolving landscape of AI agents, organizations need robust identity management
solutions that can handle the unique challenges associated with non-human identities. Amazon
Bedrock AgentCore Identity addresses these challenges by providing a centralized capability for
managing agent identities, securing credentials, and enabling seamless integration with AWS and
third-party services through Sigv4, standardized OAuth 2.0 flows, and API keys.

The service implements authentication and authorization controls that verify each request
independently, requiring explicit verification for all access attempts regardless of source. It

Overview 420


integrates seamlessly with AWS services while also enabling agents to securely access external
tools and services. Whether you're building simple automation scripts or complex multi-agent
systems, AgentCore Identity provides the identity foundation to help your applications operate
securely and efficiently.

**Topics**

- Features of AgentCore Identity
- AgentCore Identity terminology
- Example use cases

#### Features of AgentCore Identity

AgentCore Identity offers a set of features designed to address the unique challenges of workload
identity management and credential security:

**Topics**

- Centralized agent identity management
- Secure credential storage
- OAuth 2.0 flow support
- Agent identity and access controls
- AgentCore SDK Integration
- Request verification security

**Centralized agent identity management**

Create, manage, and organize agent and workload identities through a unified directory service
that acts as the single source of truth for all agent identities within your organization. Each agent
receives a unique identity with associated metadata (such as name, ARN, OAuth return URLs,
created time, last updated time) that can be managed centrally across your organization. The
agent identity directory functions similarly to Cognito User Pools, providing a unit of governance
that allows administrators to configure policies across a common set of agent identities. Agent
identities are managed as specialized workload identities with agent-specific attributes and
capabilities. For detailed procedures on creating and managing agent identities, see Manage
workload identities with AgentCore Identity.

Features 421


The centralized approach eliminates the complexity of managing agent identities across different
environments and systems. Whether your agents run on AgentCore Runtime, self-hosted
environments, or hybrid deployments, the service provides consistent identity management
regardless of where your agents are deployed. Each agent identity receives a unique ARN (such
as `arn:aws:bedrock-agentcore:region:account:workload-identity/directory/default/workload-
identity/agent-name`) that enables precise access control and resource management. This
centralization also enables hierarchical organization and group-based access controls, making it
easier to implement enterprise-wide governance policies and maintain compliance across all agent
operations. The hierarchical structure in the ARN path (with directory/default/workload-identity/
agent-name components) allows administrators to organize agents logically and apply policies at
different levels of the hierarchyâ€”for example, targeting all agents within a specific directory or
with similar attributesâ€”without having to manage each agent identity individually.

**Secure credential storage**

The token vault provides security for storing OAuth 2.0 tokens, OAuth client credentials, and API
keys with comprehensive encryption at rest and in transit. All credentials are encrypted using
either customer-managed or service-managed AWS KMS keys and access-controlled to prevent
unauthorized retrieval. The vault implements strict access controls, ensuring that credentials can
only be accessed by authorized agents for specific purposes and only when they present verifiable
proof of workload identity.

Building on OAuth 2.0's scope-based security model, the token vault implements additional
security measures where every access request is validated independently, even from callers within
the same trust domain. This extra security mechanism is necessary to protect end-user data from
malicious or misbehaving agent code. The vault securely stores OAuth 2.0 tokens, reducing security
risks while improving your overall security posture.

**OAuth 2.0 flow support**

Native support for both OAuth 2.0 client credentials grant (machine-to-machine) and OAuth 2.0
authorization code grant (user-delegated access) flows enables comprehensive authentication
patterns for different use cases. The service handles the complexity of OAuth 2.0 implementations
while providing simple APIs for agents to access AWS resources and third-party services. For 2LO
flows, agents can authenticate themselves directly with resource servers without user interaction,
while 3LO flows enable explicit user consent and authorization for accessing user-specific data
from external services.

Features 422


The service also provides built-in OAuth 2.0 credential providers for popular services such as
Google, GitHub, Slack, Salesforce, and Atlassian (Jira), with authorization server endpoints and
provider-specific parameters pre-filled to reduce development effort. For custom integrations,
the service supports configurable OAuth 2.0 credential providers that can be tailored to work with
any OAuth 2.0-compatible resource server. This comprehensive OAuth 2.0 support eliminates the
heavy-lifting of agent developers implementing complex authorization flows and reduces the
risk of security vulnerabilities in custom implementations. For comprehensive information about
configuring these providers, see Configure credential provider.

**Agent identity and access controls**

AgentCore Identity supports impersonation flow where agents can access resources using
credentials provided to them. This approach enables agents to perform actions on behalf of users
while maintaining audit trails and access controls. The impersonation process allows agents to use
provided credentials to access resources, with authorization decisions based on those credentials.

**AgentCore SDK Integration**

Seamless integration with the AgentCore SDK through declarative annotations like
@requires_access_token and @requires_api_key automatically handles credential retrieval and
injection, reducing boilerplate code and potential security vulnerabilities. These annotations
eliminate the need for developers to implement complex OAuth flows manually, instead providing
a simple declarative interface that abstracts away the underlying complexity of token management
and credential handling.

The SDK integration also provides automatic error handling for common scenarios such as token
expiration and user consent requirements. When tokens expire or user consent is needed, the SDK
automatically generates appropriate authorization URLs and handles the OAuth flow orchestration,
presenting developers with simple success or failure responses. This integration significantly
reduces development time and the likelihood of security vulnerabilities while ensuring that all
credential operations follow security best practices.

**Request verification security**

The service implements validation of all requests, including token signature verification, expiration
checks, and scope validation.

By treating every request as requiring verification and requiring explicit proof of authorization, the
service implements security validation for each request. All operations are logged with detailed
context for security monitoring and compliance reporting, providing visibility into agent activities.

Features 423


These features combine to provide significant benefits for organizations deploying AI agents:

- **Reduced Security Risk** : Centralized credential management eliminates the need to embed
    secrets in agent code or configuration files.
- **Simplified Development** : Declarative APIs and SDK integration reduce the complexity of
    implementing secure authentication in agent applications.
- **Enhanced Compliance** : Comprehensive audit trails and access controls support regulatory
    compliance requirements.
- **Operational Efficiency** : Automated credential refresh reduces operational overhead while
    improving security posture.

#### AgentCore Identity terminology

AgentCore Identity uses specific terminology to describe the components, processes, and
relationships involved in workload identity management and credential handling. Understanding
these terms will help you better comprehend how the service orchestrates secure authentication
and authorization across multiple parties in agent workflows.

**AgentCore Identity terminology definitions**

Term Definition

Identity and Authentication

Agent An AI-powered application or automated workload that
performs tasks on behalf of users by accessing AWS resources
and third-party services. Agents act with pre-authorized user
consent, to accomplish user goals, such as retrieving data
from APIs, processing information, or integrating with third-
party systems. Unlike traditional applications that run with
static credentials, agents require dynamic identity managemen
t to securely access resources across multiple trust domains
while maintaining proper authentication and authorization
boundaries.

Agent identity A unique identifier and associated metadata for an AI agent
or automated workload. Agent identities are implemented
as workload identities with specific attributes that identify

Terminology 424


Term Definition
them as agents, enabling specialized agent capabilities while
maintaining compatibility with broader workload identity
standards. Agent identities enable agents to authenticate
as themselves rather than impersonating users, supporting
delegation-based access patterns.

Agent identity directory A centralized registry that manages agent identities and their
associated metadata and access policies. Similar to Cognito
User Pools, it acts as a unit of governance for organizing agent
identities within an account or region.

Workload identity The underlying technical implementation for agent identitie
s, representing a logical application or workload that is
independent of specific hardware or infrastructure. Workload
identities can operate across different environments while
maintaining consistent authentication. Agent identities are a
specialized type of workload identity with additional agent-spe
cific attributes and capabilities.

Integration and Protocols

Cross-service agents AI agents that perform actions across multiple services, which
may include accessing system resources (using machine-to-
machine authentication) or user-specific data (using user-dele
gated access). Examples include agents that integrate with
multiple backend systems for data processing or agents that
access a user's calendar, email, and document storage. These
agents require sophisticated identity management to operate
securely across different trust domains.

MCP client A client component that allows agents to communicate with
MCP servers to access external tools and resources. MCP clients
present authentication tokens to access MCP tools securely.

Terminology 425


Term Definition

MCP server An intermediate server that hosts tools and resources for MCP
clients. MCP servers act as OAuth 2.0 resource servers when
accessed by agents and as OAuth 2.0 clients when accessing
downstream resources.

Model context protocol (MCP) MCP is an open protocol that standardizes how applications
provide context to language models. AgentCore Identity is
MCP-compliant, supporting standard protocols for agent-to-
tool communication and enabling secure integration with MCP
servers and tools.

OAuth and Token Management

OAuth 2.0 An industry-standard authorization framework (defined in RFC
6749 ) that enables applications to obtain limited access to user
accounts on external services without exposing user credentia
ls. OAuth 2.0 provides secure delegation by allowing users to
grant third-party applications access to their resources through
access tokens rather than sharing passwords. For agent
applications, OAuth 2.0 enables secure access to user data
across multiple services while maintaining proper authentic
ation boundaries and user consent mechanisms.

OAuth 2.0 authorizer An SDK component that authenticates and authorizes
incoming OAuth 2.0 API requests to agent endpoints. It
validates tokens before allowing access to agent services.

OAuth 2.0 client credentials
grant (2LO)

OAuth client credentials grant used for machine-to-machine
authentication where no user interaction is required. Agents
use 2LO to authenticate themselves directly with resource
servers.

OAuth 2.0 authorization code
grant (3LO)

OAuth authorization code grant that involves user consent
and interaction. Agents use 3LO when they need explicit user
permission to access user-specific data from external services
like Google Calendar or Salesforce.

Terminology 426


Term Definition

Agent access token An AWS-signed token that contains both workload identity and
user identity information, enabling downstream services to
make authorization decisions based on both identities. These
tokens are created through the token exchange process.

Security and Trust

Identity propagation The process of maintaining and passing identity context
through a chain of service calls. This enables downstream
services to make authorization decisions based on both the
calling service identity and the original user identity.

Trust domain A security boundary within which entities share common
authentication and authorization mechanisms. Agent
workflows often span multiple trust domains, requiring careful
identity propagation and token exchange.

Request verification security A security model where every request is authenticated and
authorized regardless of source or previous trust relationships.
AgentCore Identity implements request verification to ensure
validation of all access requests.

Service Components

Resource credential provider A component that manages connections to external identity
providers and resource servers, handling OAuth 2.0 authoriza
tion flows and credential retrieval. It orchestrates the complex
process of obtaining and refreshing credentials from third-
party services. For detailed configuration information, see
Configure credential provider.

Token vault A secure storage system for OAuth 2.0 tokens, API keys, and
other credentials that operates with strict access controls. The
token vault ensures credentials can only be accessed by the
specific agent and user combination that originally obtained
them.

Terminology 427


#### Example use cases..............................................................................................................................

Amazon Bedrock AgentCore Identity supports a wide range of use cases across different industries
and application types. This section provides detailed examples of how the service can be applied in
specific scenarios, demonstrating both user-delegated access (OAuth 2.0 authorization code grant)
and machine-to-machine authentication (OAuth 2.0 client credentials grant) patterns.

**Topics**

- Personal assistant agents
- Enterprise automation agents
- Customer service agents
- Data processing and analytics agents
- Development and DevOps agents

**Personal assistant agents**

AI agents that help users manage their personal productivity by accessing services like Google
Drive, Microsoft Office 365, or Slack represent one of the most common and valuable applications
of AgentCore Identity. These agents use OAuth 2.0 authorization code grant to obtain explicit user
consent (3Lo) and access user data securely across multiple systems. For example, a research agent
might search the web using AgentCore Browser, generate a comprehensive report, and save it to
the user's Google Drive, all while maintaining proper authentication and authorization throughout
the entire workflow.

The complexity of managing credentials across multiple third-party services makes AgentCore
Identity particularly valuable for personal assistant scenarios. Consider a meeting agent that
needs to access a user's Google Calendar to check availability, join a Zoom meeting to take notes,
schedule follow-up meetings, and draft emails for approval. Each of these services requires
different authentication mechanisms and user consent, but AgentCore Identity orchestrates the
entire process seamlessly while the agent maintains its own identity and the user retains control
over what data is accessed.

Personal assistant agents also benefit from AgentCore Identity's token storage and secure
credential management, which eliminate the need for users to repeatedly authorize access to
their accounts. Once a user has granted permission for an agent to access their Google Drive, for
instance, the agent can continue to access that service for subsequent tasks without requiring re-

Example use cases 428


authorization, as long as the stored tokens remain valid. This creates a smooth user experience
while maintaining security through proper token management.

**Enterprise automation agents**

Agents that automate business processes by integrating with enterprise systems like Salesforce,
SharePoint, or internal APIs represent a critical use case for organizations seeking to improve
operational efficiency. These agents typically use OAuth 2.0 client credentials grant for machine-
to-machine authentication (2Lo) when accessing systems that don't require user interaction, and
may require access to multiple systems with different authentication requirements. For example,
an HR automation agent might need to access employee data from an HRIS system, update
records in Salesforce, and generate reports in SharePoint, each requiring different credentials and
authorization scopes.

Enterprise automation scenarios often involve complex workflows that span multiple trust domains
and require careful identity propagation to maintain security and compliance. AgentCore Identity
addresses this challenge by providing a centralized approach to credential management that works
across different enterprise systems. The service supports both AWS-hosted resources with IAM-
based authentication and external enterprise systems with OAuth 2.0 or API key authentication,
enabling agents to operate seamlessly across hybrid environments while helping to maintain
consistent security standards.

The audit and compliance capabilities of AgentCore Identity are particularly important for
enterprise automation use cases, where organizations need to maintain detailed records of
automated actions for regulatory compliance and security monitoring. Every action performed by
an enterprise automation agent is logged with both the agent identity and any associated user
context, providing complete traceability of automated business processes. This level of visibility
helps with compliance requirements and enables organizations to quickly identify and respond to
any unauthorized or unexpected agent behavior.

**Customer service agents**

AI agents that assist customer service representatives by accessing customer data from CRM
systems, knowledge bases, and support ticketing systems must authenticate securely while
providing real-time assistance during customer interactions. These agents need to access sensitive
customer information from multiple sources while maintaining strict security controls and audit
trails. For example, a customer service agent might need to access a customer's order history
from an e-commerce platform, check their support ticket status in a ticketing system, and retrieve

Example use cases 429


relevant troubleshooting information from a knowledge base, all while the customer is on the
phone.

The real-time nature of customer service interactions makes credential management particularly
challenging, as agents cannot afford delays caused by authentication failures or expired tokens.
AgentCore Identity addresses this challenge through its comprehensive error handling, ensuring
that customer service agents can access the information they need without interruption. The
service also supports fine-grained access controls that can be configured to have agents only access
customer data that is relevant to the specific interaction, supporting privacy requirements and
regulatory compliance.

**Data processing and analytics agents**

Agents that collect, process, and analyze data from multiple sources, including cloud storage
services, databases, and APIs, often require long-running access to data sources. These agents
typically operate on scheduled or triggered workflows that may run for hours or days, accessing
large datasets from various sources to perform complex analytics operations. For example,
a financial analytics agent might collect transaction data from multiple payment processors,
combine it with customer data from CRM systems, and generate comprehensive reports that are
stored in data warehouses and shared with business stakeholders.

The long-running nature of data processing workflows makes credential management particularly
complex, as tokens may expire during processing and agents need to handle authentication failures
gracefully without losing progress on lengthy operations. AgentCore Identity addresses these
challenges through its robust error handling, helping data processing agents maintain access to
required resources throughout their entire execution lifecycle. The service also supports batch
processing scenarios where agents need to access multiple data sources simultaneously, providing
efficient credential management that scales with the complexity of the data processing workflow.

Data processing and analytics use cases also benefit from AgentCore Identity's support for
different authentication mechanisms across various data sources. A single analytics workflow might
need to access data from AWS services using IAM credentials, third-party APIs using OAuth 2.0
tokens, and on-premise databases using API keys or other authentication methods. AgentCore
Identity provides a unified interface for managing all these different credential types, enabling
data processing agents to focus on their core analytics functions rather than the complexity of
credential management across diverse systems.

Example use cases 430


**Development and DevOps agents**

Agents that automate software development workflows by integrating with version control
systems, CI/CD pipelines, and deployment systems require secure access to development tools
and infrastructure while maintaining comprehensive audit trails for compliance purposes. These
agents might automatically create pull requests, trigger builds, deploy applications, and update
documentation across multiple development tools and systems. For example, a DevOps agent
might monitor application performance, detect issues, automatically create bug reports in JIRA,
generate fixes through code analysis, and deploy patches through CI/CD pipelines, all while
maintaining proper authentication and authorization throughout the entire workflow.

Development and DevOps scenarios present unique security challenges because agents often
need elevated privileges to perform deployment and infrastructure management tasks, while
also needing to maintain strict controls to prevent unauthorized changes to production systems.
AgentCore Identity addresses these challenges through its fine-grained access control capabilities
and comprehensive audit logging, ensuring that DevOps agents can perform necessary automation
tasks while supporting security and compliance. The service supports role-based access controls
that can be configured to limit agent access to specific environments, repositories, or deployment
targets based on the agent's identity and the context of the operation.

The audit and compliance capabilities of AgentCore Identity are particularly valuable for
development and DevOps use cases, where organizations need to maintain detailed records of
all changes to code, infrastructure, and deployment configurations. Every action performed by a
DevOps agent is logged with complete context, including the agent identity, the specific resources
accessed, and the changes made, providing the level of traceability that supports regulatory
compliance and security auditing. This comprehensive logging also enables organizations to quickly
identify the root cause of issues and roll back changes when necessary, supporting the reliability
and stability of development and deployment processes.

### Get started with AgentCore Identity...................................................................................................

If you're building AI agents that need to access external services like Google Drive, Slack, or GitHub,
Amazon Bedrock AgentCore Identity provides the secure authentication infrastructure you need.
This section offers two practical getting started tutorials that demonstrate how to implement
identity features in your agents. Depending on your specific business needs, you can start with a
complete end-to-end agent deployment, or focus on OAuth2 integration patterns with Google
Drive to understand the core authentication flows.

Get started with AgentCore Identity 431


#### Primary getting started tutorial......................................................................................................

Start here for a complete end-to-end walkthrough of AgentCore Identity features:

Build your first authenticated agent

Recommended starting point for new users

What you'll build: A complete working agent with authentication, deployed to AgentCore
Runtime

What you'll learn: Create Cognito user pools, configure credential providers, deploy agents, set
up IAM policies, and test authentication flows

Outcome: Fully deployed agent that can authenticate users and obtain access tokens

#### OAuth2 integration getting started tutorial.................................................................................

After completing the primary tutorial, explore OAuth2 patterns with external services:

Integrate with Google Drive using OAuth2

Focus: OAuth2 flows and Google Drive integration

What you'll learn: Set up OAuth2 credential providers, obtain access tokens, and integrate with
Google services

Best for: Understanding OAuth2 authentication patterns with real external services

#### Common prerequisites......................................................................................................................

Both tutorials require the following:

- An AWS account with appropriate permissions
- Basic familiarity with Python programming
- Understanding of OAuth2 concepts (recommended)

Each tutorial includes specific setup instructions and additional prerequisites as needed.

Primary getting started tutorial 432


**Topics**

- Build your first authenticated agent
- Integrate with Google Drive using OAuth2

#### Build your first agent........................................................................................................................

This getting started tutorial walks you through building a complete authenticated agent from
the ground up using Amazon Bedrock AgentCore Identity and will help you get started with
implementing identity features in your agent applications. You'll learn how to set up your
development environment, create authentication infrastructure with Cognito, deploy your agent to
AgentCore Runtime, and test the full authentication workflow.

By the end of this tutorial, you'll have a fully deployed agent that can authenticate users through
OAuth2 flows, obtain access tokens securely, and demonstrate the complete identity management
lifecycle. Your agent will be running on AgentCore Runtime with proper IAM permissions, creating a
test lab environment where you can demonstrate and test the integration capabilities.

**Topics**

- Prerequisites
- Step 1: Create a Cognito user pool (Optional)
- Step 2: Create a credential provider
- Step 3: Create a sample agent that initiates an OAuth 2.0 flow
- Step 4: Deploy the agent to AgentCore Runtime
- Step 5: Invoke the agent
- Clean up
- Security best practices

**Prerequisites**

Before you begin, ensure you have:

- An AWS account with appropriate permissions
- Python 3.10+ installed
- The latest AWS CLI installed

Build your first agent 433


- AWS credentials and region configured (aws configure)

This tutorial requires that you have an OAuth 2.0 authorization server. If you do not have one, Step
1 will create one for you using Amazon Cognito user pools. If you have an OAuth 2.0 authorization
server with a client id, client secret, and a user configured, you may proceed to step 2. This
authorization server will act as a resource credential provider, representing the authority that
grants the agent an outbound OAuth 2.0 access token.

**Install the SDK and dependencies**

Make a folder for this guide, create a Python virtual environment, and install the AgentCore SDK
and the AWS Python SDK (boto3).

mkdir agentcore-identity-quickstart
cd agentcore-identity-quickstart
python3 -m venv .venv
source .venv/bin/activate
pip install bedrock-agentcore boto3 strands-agents bedrock-agentcore-starter-toolkit
pyjwt

Also create the requirements.txt file with the following content. This will be used later by the
AgentCore deployment tool.

bedrock-agentcore
boto3
pyjwt
strands-agents
bedrock-agentcore-starter-toolkit

**Step 1: Create a Cognito user pool (Optional)**

This tutorial requires an OAuth 2.0 authorization server. If you do not have one available for
testing, or if you want to keep your test separate from your authorization server, this script will
use your AWS credentials to set up an Amazon Cognito instance for you to use as an authorization
server. The script will create:

- A Cognito user pool
- An OAuth 2.0 client, and client secret for that user pool
- A test user and password in that Cognito user pool

Build your first agent 434


Deleting the Cognito user pool AgentCoreIdentityQuickStartPool will delete the associated
client_id and user as well.

You may choose to save this script as create_cognito.sh and execute it from your command line, or
paste the script into your command line.

#!/bin/bash

REGION=$(aws configure get region)

Create user pool
USER_POOL_ID=$(aws cognito-idp create-user-pool
--pool-name AgentCoreIdentityQuickStartPool
--query 'UserPool.Id'
--no-cli-pager
--output text)

Create user pool domain
DOMAIN_NAME="agentcore-quickstart-$(LC_ALL=C tr -dc 'a-z0-9' < /dev/urandom | head -c
5)"
aws cognito-idp create-user-pool-domain
--domain $DOMAIN_NAME
--no-cli-pager
--user-pool-id $USER_POOL_ID > /dev/null

Create user pool client with secret and hosted UI settings
CLIENT_RESPONSE=$(aws cognito-idp create-user-pool-client
--user-pool-id $USER_POOL_ID
--client-name AgentCoreQuickStart
--generate-secret
--callback-urls "https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/
callback"
--allowed-o-auth-flows "code"
--allowed-o-auth-scopes "openid" "profile" "email"
--allowed-o-auth-flows-user-pool-client
--supported-identity-providers "COGNITO"
--query 'UserPoolClient.{ClientId:ClientId,ClientSecret:ClientSecret}'
--output json)

CLIENT_ID=$(echo $CLIENT_RESPONSE | jq -r '.ClientId')
CLIENT_SECRET=$(echo $CLIENT_RESPONSE | jq -r '.ClientSecret')

Generate random username and password
Build your first agent 435


USERNAME="AgentCoreTestUser$(printf "%04d" $((RANDOM % 10000)))"
PASSWORD="$(LC_ALL=C tr -dc 'A-Za-z0-9!@#$%^&*()_+-=[]{}|;:,.<>?' < /dev/urandom | head
-c 16)"

Create user with permanent password
aws cognito-idp admin-create-user
--user-pool-id $USER_POOL_ID
--username $USERNAME
--output text > /dev/null

aws cognito-idp admin-set-user-password
--user-pool-id $USER_POOL_ID
--username $USERNAME
--password $PASSWORD
--output text > /dev/null
--permanent

Get region
ISSUER_URL="https://cognito-idp. region .amazonaws.com/$USER_POOL_ID/.well-known/openid-
configuration"
HOSTED_UI_URL="https://$DOMAIN_NAME.auth. region .amazoncognito.com"

Output results
echo "User Pool ID: $USER_POOL_ID"
echo "Client ID: $CLIENT_ID"
echo "Client Secret: $CLIENT_SECRET"
echo "Issuer URL: $ISSUER_URL"
echo "Hosted UI URL: $HOSTED_UI_URL"
echo "Test User: $USERNAME"
echo "Test Password: $PASSWORD"

echo ""
echo "# Copy and paste these exports to set environment variables for later use:"
echo "export USER_POOL_ID='$USER_POOL_ID'"
echo "export CLIENT_ID='$CLIENT_ID'"
echo "export CLIENT_SECRET='$CLIENT_SECRET'"
echo "export ISSUER_URL='$ISSUER_URL'"
echo "export HOSTED_UI_URL='$HOSTED_UI_URL'"
echo "export COGNITO_USERNAME='$USERNAME'"
echo "export COGNITO_PASSWORD='$PASSWORD'"

Build your first agent 436


**Step 2: Create a credential provider**

Credential providers are how your agent accesses external services. Create a credential provider and
configure it with an OAuth 2.0 client for your authorization server.

If you are using your own authorization server, set the environment variables ISSUER_URL,
CLIENT_ID, and CLIENT_SECRET with their appropriate values from your authorization server. If
you are using the previous script to create an authorization server for you with Cognito, copy the
EXPORT statements from the output into your terminal to set the environment variables.

This credential provider will be used by your agent's code to get access tokens to act on behalf of
your user.

#!/bin/bash

please note the expected ISSUER_URL format for Bedrock AgentCore is the full url,
including .well-known/openid-configuration
aws bedrock-agentcore-control create-oauth2-credential-provider
--name "AgentCoreIdentityQuickStartProvider"
--credential-provider-vendor "CustomOauth2"
--no-cli-pager
--oauth2-provider-config-input '{
"customOauth2ProviderConfig": {
"oauthDiscovery": {
"discoveryUrl": "'$ISSUER_URL'"
},
"clientId": "'$CLIENT_ID'",
"clientSecret": "'$CLIENT_SECRET'"
}
}'

**Step 3: Create a sample agent that initiates an OAuth 2.0 flow**

In this step, we will create an agent that initiates an OAuth 2.0 authorization flow to get tokens to
act on behalf of the user. For simplicity, the agent will not make actual calls to external services on
behalf of a user, but will prove to us that it has obtained consent to act on behalf of our test user.

**Agent code**

Create a file named agentcoreidentityquickstart.py, and save this code.

"""
AgentCore Identity Outbound Token Agent

Build your first agent 437


This agent demonstrates the USER_FEDERATION OAuth 2.0 flow.

It handles the OAuth 2.0 user consent flow and inspects the resulting OAuth 2.0 access
token.
"""

from bedrock_agentcore.runtime import BedrockAgentCoreApp
from bedrock_agentcore.identity import requires_access_token
import asyncio
import jwt
import logging

app = BedrockAgentCoreApp()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(name)

def decode_jwt(token):
try:
decoded = jwt.decode(token, options={"verify_signature": False})
return decoded
except Exception as e:
return {"error": f"Error decoding JWT: {str(e)}"}

class StreamingQueue:
def init(self):
self.finished = False
self.queue = asyncio.Queue()

async def put(self, item):
await self.queue.put(item)

async def finish(self):
self.finished = True
await self.queue.put(None)

async def stream(self):
while True:
item = await self.queue.get()
if item is None and self.finished:
break
yield item

Build your first agent 438


queue = StreamingQueue()

async def handle_auth_url(url):
await queue.put(f"Authorization URL, please copy to your preferred browser: {url}")

@requires_access_token(
provider_name="AgentCoreIdentityQuickStartProvider",
scopes=["openid"],
auth_flow="USER_FEDERATION",
on_auth_url=handle_auth_url, # streams authorization URL to client
force_authentication=True
)
async def introspect_with_decorator(*, access_token: str):
"""Introspect token using decorator"""
logger.info("Inside introspect_with_decorator - decorator succeeded")
await queue.put({
"message": "Successfully received an access token to act on behalf of your
user!",
"token_claims": decode_jwt(access_token),
"token_length": len(access_token),
"token_preview": f"{access_token[:50]}...{access_token[-10:]}"
})
await queue.finish()

@app.entrypoint
async def agent_invocation(payload, context):
"""Handler that uses only the decorator approach"""
logger.info("Agent invocation started")

Start the agent task and immediately begin streaming
task = asyncio.create_task(introspect_with_decorator())

Stream items as they come in
async for item in queue.stream():
yield item

Wait for task completion
await task

if name == "main":
app.run()

Build your first agent 439


**Step 4: Deploy the agent to AgentCore Runtime**

We will host this agent on AgentCore Runtime. We can do this easily with the AgentCore SDK we
installed earlier.

From your terminal, run agentcore configure -e agentcoreidentityquickstart.py
and agentcore launch. The deployment will work with the defaults set by agentcore
configure, but you may customize them. Ensure that you select "No" for the Configure OAuth
authorizer instead step. We want to use IAM authorization for this guide.

**Update the IAM policy of the agent to be able to access the token vault, and client secret**

You will need to update the IAM policy of your agent that was created by or used with agentcore
configure. This script will read your agent's configuration YAML and append the appropriate
policy. You can copy and paste this script, or save it to a file and execute it.

#!/bin/bash

Parse values from .bedrock_agentcore.yaml
EXECUTION_ROLE=$(grep "execution_role:" .bedrock_agentcore.yaml | head -1 | awk '{print
$2}')
AWS_ACCOUNT=$(grep "account:" .bedrock_agentcore.yaml | head -1 | awk '{print $2}' | tr
-d "'")
REGION=$(grep "region:" .bedrock_agentcore.yaml | awk '{print $2}')

echo "Parsed values:"
echo "Execution Role: $EXECUTION_ROLE"
echo "Account: $AWS_ACCOUNT"
echo "Region: $REGION"

Create the policy document with proper variable substitution
cat > agentcore-identity-policy.json << EOF
{
"Version": "2012-10-17",
"Statement": [
{
"Sid": "AccessTokenVault",
"Effect": "Allow",
"Action": [
"bedrock-agentcore:GetResourceOauth2Token",
"secretsmanager:GetSecretValue"
],

Build your first agent 440


"Resource": ["arn:aws:bedrock-agentcore: region : account-id :workload-identity-
directory/default/workload-identity/",
"arn:aws:bedrock-agentcore: region : account-id :token-vault/default/
oauth2credentialprovider/AgentCoreIdentityQuickStartProvider",
"arn:aws:bedrock-agentcore: region : account-id :workload-identity-directory/
default",
"arn:aws:bedrock-agentcore: region : account-id :token-vault/default",
"arn:aws:secretsmanager: region : account-id :secret:bedrock-agentcore-identity!
default/oauth2/AgentCoreIdentityQuickStartProvider"
]
}
]
}
EOF

Create the policy
POLICY_ARN=$(aws iam create-policy
--policy-name AgentCoreIdentityQuickStartPolicy$(LC_ALL=C tr -dc '0-9' < /dev/
urandom | head -c 4)
--policy-document file://agentcore-identity-policy.json
--query 'Policy.Arn'
--output text)

Extract role name from ARN and attach policy
ROLE_NAME=$(echo $EXECUTION_ROLE | awk -F'/' '{print $NF}')
aws iam attach-role-policy
--role-name $ROLE_NAME
--policy-arn $POLICY_ARN

echo "Policy created and attached: $POLICY_ARN"

Cleanup
rm agentcore-identity-policy.json

**Step 5: Invoke the agent**

Now that this is all set up, you can invoke the agent. For this demo, we will use the agentcore
invoke command and our IAM credentials. We will need to pass the --user-id and --session-
id arguments when using IAM authentication.

Build your first agent 441


agentcore invoke "TestPayload" --agent agentcoreidentityquickstart --user-id
"SampleUserID" --session-id
"ALongThirtyThreeCharacterMinimumSessionIdYouCanChangeThisAsYouNeed"

The agent will then return a URL to your agentcore invoke command. Copy and paste that URL
into your preferred browser, and you will then be redirected to your authorization server's login
page. The --user-id parameter is the user ID you are presenting to AgentCore Identity. The --
session-id parameter is the session ID, which must be at least 33 characters long.

Enter the username and password for your user on your authorization server when prompted on
your browser, or use your preferred authentication method you have configured. If you used the
script from Step 1 to create a Cognito instance, you can retrieve this from your terminal history.

Your browser should redirect you to the AgentCore Identity Success Page, and you should have a
success message in your terminal.

Note
If you interrupt an invocation without completing authorization, you may need to request a
new URL using a new session ID (--session-id parameter).

**Debugging**

Should you encounter any errors or unexpected behaviors, the output of the agent is captured in
Amazon CloudWatch logs. A log tailing command is provided after you run agentcore launch.

**Clean up**

After you're done, you can delete the Amazon Cognito user pool, Amazon Elastic Container
Registry repo, CodeBuild Project, IAM roles for the agent and CodeBuild project, and finally delete
the agent, and credential provider.

**Security best practices**

When working with identity information:

1. **Never hardcode credentials** in your agent code
2. **Use environment variables or Amazon SageMaker AI** for sensitive information
3. **Apply least privilege principle** when configuring IAM permissions

Build your first agent 442


4. **Regularly rotate credentials** for external services
5. **Audit access logs** to monitor agent activity
6. **Implement proper error handling** for authentication failures

#### Integrate with Google Drive using OAuth2

This getting started tutorial walks you through the essential steps to start using Amazon Bedrock
AgentCore Identity for your AI agents. You'll learn how to set up your development environment,
install the necessary SDKs, create your first agent identity, and allow your agent to access external
resources securely.

By the end of this tutorial, you'll have a working agent that can retrieve access tokens from Google
with AgentCore Identity OAuth2 Credential Provider, and read files from Google Drive using
access tokens. For detailed information about OAuth2 flows, see Manage credential providers with
AgentCore Identity.

**Topics**

- Prerequisites
- Step 1: Import Identity and Auth modules
- Step 2: Set up an OAuth 2.0 Credential Provider
- Step 3: Obtain an OAuth 2.0 access token
- Step 4: Use OAuth2 Access Token to Invoke External Resource
- What's Next?

**Prerequisites**

Before you start, you need:

- An AWS account with appropriate permissions (for example, BedrockAgentCoreFullAccess)
- Python 3.10 or higher
- Basic understanding of Python programming

**Install the SDK**

To get started, install the bedrock-agentcore package:

Google Drive integration 443


pip install bedrock-agentcore

**Obtain Google Client ID and Client Secret**

To allow your agent to access Google Drive, you need to obtain a Google client ID and client secret
for your agent. Go to the Google Developer Console and follow these steps:

1.Enable Google Drive API

2.Create OAuth consent screen

3.Create a new web application for the agent, for example, "My Agent 1"

4.Add the following OAuth 2.0 scope to your agent application: https://
[http://www.googleapis.com/auth/drive.metadata.readonly](http://www.googleapis.com/auth/drive.metadata.readonly)

5.Create OAuth 2.0 Credentials for the new web application, and note the generated Google client
ID and client secret

Note
You must add the following URI to your application's redirect URI list: https://bedrock-
agentcore.us-east-1.amazonaws.com/identities/oauth2/callback

**Step 1: Import Identity and Auth modules**

Add this import statement to your Python file:

from bedrock_agentcore.services.identity import IdentityClient
from bedrock_agentcore.identity.auth import requires_access_token, requires_api_key

**Step 2: Set up an OAuth 2.0 Credential Provider**

Create a new OAuth 2.0 Credential Provider with the Google client ID and client secret obtained
earlier using the following AWS CLI command:

aws bedrock-agentcore-control create-oauth2-credential-provider
--region us-east-1
--name "google-provider"
--credential-provider-vendor "GoogleOauth2"
--oauth2-provider-config-input '{

Google Drive integration 444


"googleOauth2ProviderConfig": {
"clientId": "<your-google-client-id>",
"clientSecret": "<your-google-client-secret>"
}
}'

Behind the scenes, the SDK makes a call to the CreateOauth2CredentialProvider API.

**Step 3: Obtain an OAuth 2.0 access token**

Once you have the Google Credential Provider created in the previous step, add the
@requires_access_token decorator to your agent code that requires a Google access token.
Copy the authorization URL from your console output, then paste it in your browser and complete
the consent flow with Google Drive.

The following code sample is intended to be integrated into your agent code to invoke an
authorization workflow. This is not standalone code that can be copied and run independently.

import asyncio

Injects Google Access Token
@requires_access_token(

Uses the same credential provider name created above
provider_name="google-provider",

Requires Google OAuth2 scope to access Google Drive
scopes=["https://www.googleapis.com/auth/drive.metadata.readonly"],

Sets to OAuth 2.0 Authorization Code flow
auth_flow="USER_FEDERATION",

Prints authorization URL to console
on_auth_url=lambda x: print("\nPlease copy and paste this URL in your browser:\n" +
x),

If false, caches obtained access token
force_authentication=False,
)
async def write_to_google_drive(*, access_token: str):

Prints the access token obtained from Google
print(access_token)

asyncio.run(write_to_google_drive(access_token=""))

Behind the scenes, the @requires_access_token decorator runs through the following
sequence:

Google Drive integration 445


Google Drive integration 446


1.The SDK makes API calls to CreateWorkloadIdentity, GetWorkloadAccessToken, and
GetResourceOauth2Token.

2.When running the agent code locally, the SDK automatically generates an agent identity ID and
a random user ID for local testing, and stores them in a local file called .agentcore.yaml.

3.When running the agent code with AgentCore Runtime, the SDK does not generate an agent
identity ID or random user ID. Instead, it uses the agent identity ID assigned, and the user ID or
JWT token passed in by the agent caller.

4.Agent access token is an encrypted (opaque) token that contains the agent identity ID and user
ID.

5.AgentCore Identity service stores the Google access token in the Token Vault under the agent
identity ID and user ID. This creates a binding among the agent identity, user identity, and the
Google access token.

**Step 4: Use OAuth2 Access Token to Invoke External Resource**

Once the agent obtains a Google access token with the steps above, it can use the access token to
access Google Drive. Here is a full example that lists the names and IDs of the first 10 files that the
user has access to.

First, install the Google client library for Python:

pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-
oauthlib

Then, copy the following code:

import asyncio
from bedrock_agentcore.identity.auth import requires_access_token, requires_api_key
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

SCOPES = ["https://www.googleapis.com/auth/drive.metadata.readonly"]

def main(access_token):
"""Shows basic usage of the Drive v3 API.

Google Drive integration 447


Prints the names and ids of the first 10 files the user has access to.
"""
creds = Credentials(token=access_token, scopes=SCOPES)

try:
service = build("drive", "v3", credentials=creds)

Call the Drive v3 API
results = (
service.files()
.list(pageSize=10, fields="nextPageToken, files(id, name)")
.execute()
)
items = results.get("files", [])

if not items:
print("No files found.")
return

print("Files:")
for item in items:
print(f"{item['name']} ({item['id']})")

except HttpError as error:

TODO(developer) - Handle errors from drive API.
print(f"An error occurred: {error}")

if name == "main":

This annotation helps agent developer to obtain access tokens from external
applications
@requires_access_token(
provider_name="google-provider",

Google OAuth2 scopes
scopes=["https://www.googleapis.com/auth/drive.metadata.readonly"],

3LO flow
auth_flow="USER_FEDERATION",

prints authorization URL to console
on_auth_url=lambda x: print("Copy and paste this authorization url to your
browser", x),
force_authentication=True,
)
async def read_from_google_drive(*, access_token: str):
print(access_token) # You can see the access_token

Make API calls...
Google Drive integration 448


main(access_token)

asyncio.run(read_from_google_drive(access_token=""))

**What's Next?**

The example in this section focuses on practical implementation patterns that you can adapt for
your specific use cases. You can embed the code as part of an agent, or a Model Context Protocol
(MCP) tool. If you want to host your Agent code or MCP Tool with AgentCore Runtime, follow Host
agent or tools with Amazon Bedrock AgentCore Runtime to copy the code above to AgentCore
Runtime.

### Using the AgentCore Identity console

The AgentCore Identity console provides a centralized interface for managing your agent
authentication configurations. You can use the console to set up outbound identity providers for
external service access, configure inbound identity settings for agent authentication, and manage
API keys for services that require key-based authentication. This section contains step-by-step
procedures for all console-based AgentCore Identity tasks.

**Topics**

- Configure an OAuth client
- Configure an API key

#### Configure an OAuth client................................................................................................................

An OAuth client enables your agent to securely access external services on behalf of users without
requiring them to share their credentials directly. For example, your agent can access a user's
Google Drive files or Microsoft calendar events through OAuth authentication.

**Topics**

- Add OAuth client using included provider
- Add OAuth client using custom provider
- Update OAuth client
- Delete OAuth client

Using the console 449


**Add OAuth client using included provider**

Built-in providers offer streamlined setup for popular services including Google, GitHub, Slack,
and Salesforce. These providers have pre-configured authorization server endpoints and provider-
specific parameters to reduce development effort.

**To add an OAuth client using an included provider**

1. Open the AgentCore Identity console.
2. In the **Outbound Auth** section, choose **Add OAuth client / API key** , and then select **Add**
    **OAuth client**.
3. For **Name** , you can either use the auto-generated name or enter your own descriptive name to
    help you identify this OAuth client in your account. Use alphanumeric characters, hyphens, and
    underscores only, with a maximum length of 50 characters.
4. For **Provider** , choose **Included provider**.
5. Choose your identity provider from the available options (Google, GitHub, Microsoft,
    Salesforce, or Slack).
6. In the **Provider configurations** section, enter your client credentials:

a. For Client ID , enter the unique identifier you received when registering your application
with the identity provider.
b. For Client secret , enter the confidential key associated with your client ID. AgentCore
Identity securely stores this value for authentication.

7. Choose **Add OAuth Client**.

After creating the OAuth client, AgentCore Identity provides an ARN that you can reference in
your agent code to request authentication tokens without embedding sensitive credentials in your
application. You can find this ARN in the properties page of the OAuth client (Choose the client
name in the **Outbound Auth** section).

**Add OAuth client using custom provider**

Custom providers enable you to connect to any OAuth2-compatible resource server beyond
the built-in provider options. You can configure custom providers by having the system retrieve
configuration details automatically, or by providing the server information manually.

Configure an OAuth client 450


**To add an OAuth client using a custom provider**

1. Open the AgentCore Identity console.
2. In the **Outbound Auth** section, choose **Add OAuth client / API key** , and then select **Add**
    **OAuth client**.
3. For **Name** , you can either use the auto-generated name or enter your own descriptive name to
    help you identify this OAuth client in your account. Use alphanumeric characters, hyphens, and
    underscores only, with a maximum length of 50 characters.
4. For **Provider** , choose **Custom provider**.
5. In the **Provider configurations** section, depending on your provider requirements, choose one
    of the following options:

a. Discovery URL (recommended) â€“ Choose this option to have AgentCore Identity
automatically retrieve configuration details from your provider. You provide the discovery
URL where your provider publishes its OpenID Connect configuration, and AgentCore
Identity handles the endpoint discovery process. This is the recommended approach when
available as it reduces manual configuration.

i. For Client ID , enter the unique identifier you received when registering your
application with the identity provider.
ii. For Client secret , enter the confidential key associated with your client ID that
AgentCore Identity securely stores for authentication.
iii. For Discovery URL , enter the URL where your provider publishes its OpenID
Connect configuration. Discovery URLs must end with .well-known/openid-
configuration. For example, https:// example.com /.well-known/openid-
configuration.
b. Manual config â€“ Choose this option to specify server information directly when
your provider doesn't support automatic discovery. You'll define each endpoint URL
individually, giving you complete control over the configuration details.

i. For Client ID , enter the unique identifier you received when registering your
application with the identity provider.
ii. For Client secret , enter the confidential key associated with your client ID that
AgentCore Identity securely stores for authentication.
iii. For Issuer , enter the base URL that identifies your authorization server. This value
appears in the iss claim of issued tokens and helps verify token authenticity.

Configure an OAuth client 451


iv. For Authorization endpoint , enter the URL where users will be directed to grant
permission to your application. This is the entry point for the OAuth authorization
flow.
v. For Token endpoint , enter the URL where your agent exchanges authorization codes
for access tokens. This endpoint handles the credential exchange process.
vi. (Optional) In the Response types section, configure how your OAuth client receives
authentication responses by choosing Add response type and selecting the token
formats your provider should return. Common types include code for authorization
code flow or token for implicit flow.

6. Choose **Add OAuth Client**.

After completing either configuration, AgentCore Identity securely stores your OAuth settings and
provides an ARN you can reference in your agent code, enabling token requests without embedding
sensitive credentials in your application. You can find this ARN in the properties page of the OAuth
client (Choose the client name in the **Outbound Auth** section).

**Update OAuth client**

You can modify the configuration settings for your existing OAuth client. For example, you can
update your client credentials (Client ID and Client secret) when they've been rotated or changed
by your identity provider.

**To update an OAuth client**

1. Open the AgentCore Identity console.
2. In the **Outbound Auth** section, select the OAuth client you want to update.
3. Choose **Edit**.
4. On the **Update OAuth Client** page, update the information as needed.
5. Choose **Update OAuth Client** to save your configuration settings.

The updated OAuth client configuration takes effect immediately and will be used for all
subsequent authentication requests made by your agents.

Configure an OAuth client 452


**Delete OAuth client**

When you no longer need an OAuth client, you can delete it from your account. Deleting an
OAuth client removes the stored configuration and credentials, making them unavailable to your
agents. Any invocations that reference the deleted OAuth client will fail once it's removed, and this
outbound authentication might be used across multiple runtimes and gateways.

**To delete an OAuth client**

1. Open the AgentCore Identity console.
2. In the **Outbound Auth** section, select the OAuth client you want to delete.
3. Choose **Delete**.
4. In the confirmation dialog, type **Delete** to confirm the deletion.
5. Choose **Delete**.

The OAuth client is permanently removed from your account. Any agents or applications that
reference this OAuth client's ARN will no longer be able to access the stored credentials.

#### Configure an API key.........................................................................................................................

API keys provide key-based authentication for services that require direct key access with secure
storage capabilities. An API key is a unique identifier used to authenticate and authorize access to a
resource, enabling your agent to access external services without embedding sensitive credentials
directly in your application code.

**Topics**

- Add API key
- Update API key
- Delete API key

**Add API key**

API keys provide key-based authentication for services that require direct key access with secure
storage capabilities. An API key is a unique identifier used to authenticate and authorize access to a
resource, enabling your agent to access external services without embedding sensitive credentials
directly in your application code.

Configure an API key 453


**To add an API key**

1. Open the AgentCore Identity console.
2. In the **Outbound Auth** section, choose **Add OAuth client / API key** , then choose **Add API key**.
3. For **Name** , you can either use the auto-generated name or enter your own descriptive name
    to help you identify this API key in your account. Use alphanumeric characters, hyphens, and
    underscores only, with a maximum length of 50 characters.
4. For **API key** , enter the key value provided by your external service. AgentCore Identity securely
    stores this value and makes it available to your agent at runtime.
5. Choose **Add**.

After creating the API key, AgentCore Identity provides an ARN that you can reference in your
agent code to access the stored key without exposing sensitive information in your application. You
can find this ARN in the properties page of the API key (Choose the API key name in the **Outbound
Auth** section).

**Update API key**

You can update an existing API key to replace the key value when your external service provider
rotates credentials. Updating the API key ensures your agents continue to have access to the
external service with the current authentication information.

**To update an API key**

1. Open the AgentCore Identity console.
2. In the **Outbound Auth** section, select the API key you want to update.
3. Choose **Edit**.
4. In the **Update API key** dialog, in **API key** , enter the updated key value provided by your
    external service. AgentCore Identity securely stores this new value and makes it available to
    your agent at runtime.
5. Choose **Update**.

The updated API key configuration takes effect immediately. Your agents will use the new API key
for all subsequent requests to the external service.

Configure an API key 454


**Delete API key**

When you no longer need an API key, you can delete it from your account. Deleting an API key
removes the stored credentials and makes them unavailable to your agents. Any invocations that
reference the deleted API key will fail once it's removed.

**To delete an API key**

1. Open the AgentCore Identity console.
2. In the **Outbound Auth** section, select the API key you want to delete.
3. Choose **Delete**.
4. In the confirmation dialog, type **Delete** to confirm the deletion.
5. Choose **Delete**.

The API key is permanently removed from your account. Any agents or applications that reference
this API key's ARN will no longer be able to access the stored credentials.

### Manage workload identities with AgentCore Identity

Agent identities in AgentCore Identity are implemented as workload identities with specialized
attributes that enable agent-specific capabilities. This approach follows established industry
patterns where workloads have granular properties that indicate their specific type and purpose.
Unlike traditional service accounts that are tied to specific infrastructure, agent identities are
designed to be environment-agnostic and can support multiple authentication credentials
simultaneously. The AgentCore Identity directory acts as a centralized registry and management
system for all agent identities. For information about workload identity limits, see AgentCore
Identity Service Quotas.

**Topics**

- Understanding workload identities
- Understanding the agent identity directory
- Create and manage workload identities

Manage agent identities 455


#### Understanding workload identities

Workload identities represent the digital identity of your agents within the AWS environment.
They serve as a stable anchor point that persists across different deployment environments and
authentication schemes, allowing agents to maintain consistent identity whether they're using IAM
roles for AWS resource access, OAuth2 tokens for external service integration, or API keys for third-
party tool access. The identity system abstracts the complexity of managing multiple credential
types while providing a unified interface for authentication and authorization operations.

Workload identities integrate seamlessly with the broader AgentCore Identity framework, including
the token vault for secure credential storage (see Secure credential storage), Resource credential
providers for external service access (see Configure credential provider), and the AgentCore
Identity directory for centralized management. For more information about the directory, see
Understanding the agent identity directory.

**Topics**

- How workload identities are created

**How workload identities are created**

Workload identities are created automatically in several scenarios and can also be created manually
when needed. These identities are used to obtain workload access tokens that authorize agent
access to credentials. For details about how workload identities are used in the authentication flow,
see Get workload access token.

**Automatic creation by Runtime and Gateway**

- When you deploy an agent using AgentCore Runtime, a workload identity is automatically
    created and associated with your agent
- AgentCore Gateway also creates workload identities automatically for agents deployed through
    the gateway service
- These automatically created identities are managed by the service and include the necessary
    settings for your deployment environment
- The workload identity ARN is returned in the deployment response and can be used for IAM
    policies and access control

**Manual creation for custom deployments**

Understanding identities 456


- For agents not hosted by Runtime or Gateway (such as self-hosted or hybrid deployments), you
    can manually create workload identities
- Use the CreateWorkloadIdentity API or AWS CLI to create identities for custom agent
    deployments
- Manual creation gives you control over the identity name and metadata
- This approach is ideal when you need specific identity names or are integrating with existing
    identity management systems

**When to use each approach**

- Use automatic creation when deploying through AgentCore Runtime or Gateway for simplified
    setup
- Use manual creation when you need specific identity names or are deploying agents in non-
    standard environments
- Manual creation is also useful for testing scenarios or when you need multiple identities for the
    same agent in different environments

Workload identities are used to obtain workload access tokens that authorize agent access to
credentials. For details about how workload identities are used in the authentication flow, see Get
workload access token.

Once you have created workload identities, you can use them to control access to credential
providers. For information about implementing fine-grained access control, see Scope down access
to credential providers by workload identity.

#### Understanding the agent identity directory

The agent identity directory is a centralized collection of all workload identities within your AWS
account. It serves as the authoritative registry for managing and organizing agent identities,
providing a unified view of all identities whether they were created automatically by AgentCore
Runtime and Gateway or manually through the AWS CLI and SDK. For information about creating
workload identities, see Create and manage workload identities.

**Topics**

- Directory concepts and structure
- Directory management best practices

Agent identity directory 457


- Listing and viewing directory contents
- Directory access control and permissions

**Directory concepts and structure**

Understanding the fundamental concepts and organizational structure of the agent identity
directory helps you effectively manage workload identities at scale.

**Key characteristics**

- **Single directory per account** â€“ Each AWS account has exactly one agent identity directory
- **Automatic creation** â€“ The directory is automatically created when the first workload identity is
    created in your account
- **Centralized management** â€“ All workload identities, regardless of how they were created, are
    stored in this directory
- **Cross-service visibility** â€“ The directory provides visibility into identities created by Runtime,
    Gateway, and manual processes

**Directory structure**

arn:aws:bedrock-agentcore:region:account-id:workload-identity-directory/default

workload-identity/runtime-created-agent-1
workload-identity/runtime-created-agent-2
workload-identity/gateway-created-agent-1
workload-identity/manually-created-agent-1
workload-identity/manually-created-agent-2
**Directory management best practices**

Following established best practices for directory management helps maintain organization,
security, and operational efficiency as your workload identity usage grows.

**Naming conventions**

- Use descriptive names that indicate the agent's purpose (such as "customer-support-agent",
    "data-analysis-agent")
- Include environment indicators for multi-environment deployments (such as "prod-chatbot",
    "dev-chatbot")

Agent identity directory 458


- Consider team or project prefixes for large organizations (such as "marketing-content-agent")

**Organization strategies**

- Regularly audit your directory to identify unused or obsolete workload identities
- Document the purpose and ownership of each workload identity
- Implement consistent tagging strategies for workload identities when available. For more
    information, see Tagging AgentCore Identity resources.
- Monitor directory growth and establish governance processes for identity creation

**Security considerations**

- Regularly review IAM policies that grant access to the directory
- Use least-privilege principles when granting directory access
- Monitor directory access through AWS CloudTrail logs
- Implement automated alerts for unauthorized directory modifications

**Listing and viewing directory contents**

You can view all workload identities in your directory using the AWS CLI:

**List all workload identities**

aws bedrock-agentcore-control list-workload-identities

This command returns information about all workload identities in your account, including:

- Workload identity names and ARNs
- Creation timestamps
- Associated metadata
- Creation source (Runtime, Gateway, or manual)

**Example output**

{

Agent identity directory 459


"workloadIdentities": [
{
"workloadIdentityArn": "arn:aws:bedrock-agentcore:us-
east-1:123456789012:workload-identity-directory/default/workload-identity/my-runtime-
agent",
"workloadIdentityName": "my-runtime-agent",
"createdAt": "2024-01-15T10:30:00Z",
"createdBy": "AgentCore Runtime"
},
{
"workloadIdentityArn": "arn:aws:bedrock-agentcore:us-
east-1:123456789012:workload-identity-directory/default/workload-identity/my-custom-
agent",
"workloadIdentityName": "my-custom-agent",
"createdAt": "2024-01-16T14:20:00Z",
"createdBy": "Manual"
}
]
}

**Get details about a specific workload identity**

aws bedrock-agentcore-control get-workload-identity
--workload-identity-name my-agent-name

**Directory access control and permissions**

The agent identity directory integrates with IAM to provide fine-grained access control over
workload identities and their associated resources. For information about using workload identities
to control access to credential providers, see Scope down access to credential providers by
workload identity.

**Directory-level permissions**

- **List permissions** â€“ Control who can view the directory contents
- **Create permissions** â€“ Control who can create new workload identities
- **Read permissions** â€“ Control who can view specific workload identity details
- **Delete permissions** â€“ Control who can remove workload identities

**Example IAM policy for directory access**

Agent identity directory 460


{
"Version": "2012-10-17",
"Statement": [
{
"Sid": "ListWorkloadIdentities",
"Effect": "Allow",
"Action": [
"bedrock-agentcore:ListWorkloadIdentities"
],
"Resource": [
"arn:aws:bedrock-agentcore:::workload-identity-directory/default"
]
},
{
"Sid": "ManageSpecificWorkloadIdentity",
"Effect": "Allow",
"Action": [
"bedrock-agentcore:GetWorkloadIdentity",
"bedrock-agentcore:CreateWorkloadIdentity",
"bedrock-agentcore:DeleteWorkloadIdentity"
],
"Resource": [
"arn:aws:bedrock-agentcore:::workload-identity-directory/default/workload-
identity/my-agent-*"
]
}
]
}

#### Create and manage workload identities

You can create agent identities using several methods, including the AWS CLI and the AgentCore
SDK, depending on your workflow and integration requirements. AgentCore Identity provides
multiple interfaces for identity creation including command-line tools for automation and scripting
and programmatic APIs for integration with existing systems. Each creation method supports the
full range of identity properties while providing appropriate interfaces for different use cases and
user preferences.

**Topics**

- Manage identities with AWS CLI
- Create identities with the AgentCore SDK

Create identities 461


**Manage identities with AWS CLI**

The AWS CLI provides a straightforward way to create and delete agent identities.

**Create an identity**

The following command creates a workload identity named _my-agent_.

aws bedrock-agentcore-control create-workload-identity
--name " my-agent "

**List all identities**

The following command lists all workload identities in your account.

aws bedrock-agentcore-control list-workload-identities

**Delete an identity**

The following command deletes the workload identity named _my-agent_.

aws bedrock-agentcore-control delete-workload-identity
--name " my-agent "

**Create identities with the AgentCore SDK**

The AgentCore SDK provides support for creating workload identities in Python.

**Python example**

The following Python code creates a workload identity using the AgentCore SDK.

from bedrock_agentcore.services.identity import IdentityClient

Initialize the client
identity_client = IdentityClient("us-east-1")

Create a new workload identity for agent
response = identity_client.create_workload_identity(name='my-python-agent')

Create identities 462


agentArn = response['workloadIdentityArn']

print(f"Created agent identity with ARN: {agentArn}")

### Manage credential providers with AgentCore Identity

Credential management is a core feature of Amazon Bedrock AgentCore Identity that addresses
the complex challenge of securely storing, retrieving, and managing credentials across multiple
trust domains and authentication systems. The service implements defense-in-depth security
measures to protect sensitive authentication tokens, API keys, and certificates while providing
agents with efficient access to the credentials they need for authorized operations. AgentCore
Identity's credential management architecture separates credential storage from credential access,
helping to ensure that agents never have direct access to long-term secrets or refresh tokens.

The credential management system supports multiple credential types including OAuth2 access
tokens, API keys, client certificates, SAML assertions, and custom authentication tokens. Each
credential type has specific handling requirements for storage encryption and access patterns. All
credential operations are logged and audited to provide complete visibility into credential usage
and access patterns.

Integration with the Resource Credential Provider enables AgentCore Identity to support cross-
capability credential vending, where agents can access resources across different cloud providers,
SaaS applications, and enterprise systems using a unified credential management interface.
The system maintains proper security boundaries while enabling necessary functionality, with
comprehensive monitoring and alerting capabilities that detect unusual credential usage patterns
or potential security threats.

**Topics**

- Supported authentication patterns
- Configure credential provider
- Obtain credentials

#### Supported authentication patterns

AgentCore Identity supports two primary authentication patterns that address different agent use
cases. Understanding these patterns will help you choose the right approach for your specific agent
implementation.

Manage credential providers 463


For detailed examples of how these patterns apply to specific industries and agent types, see
Example use cases.

**Topics**

- User-delegated access (OAuth 2.0 authorization code grant)
- Machine-to-machine authentication (OAuth 2.0 client credentials grant)
- Choosing the right authentication pattern

**User-delegated access (OAuth 2.0 authorization code grant)**

The OAuth 2.0 authorization code grant flow enables agents to access user-specific data with
explicit user consent. This pattern is essential when agents need to access personal data or perform
actions on behalf of specific users. The flow includes a user consent step where the resource owner
(user) explicitly authorizes the agent to access their data within specific scopes.

**Key characteristics**

- Requires explicit user consent through an authorization prompt
- Provides access to user-specific data and resources
- Maintains clear separation between agent identity and user authorization
- Supports fine-grained scopes that limit what data the agent can access

**Example scenario** â€“ A productivity agent needs to access a user's Google Calendar to schedule
meetings, their Gmail to send emails, and their Google Drive to store documents. The agent uses
the OAuth 2.0 authorization code grant to obtain user consent for each service, with specific
scopes that limit access to only the necessary data. The user explicitly authorizes the agent through
Google's consent screen, and AgentCore Identity securely stores the resulting credentials for future
use.

This pattern is ideal for personal assistant agents, customer service agents, and any scenario where
agents need access to user-specific data across multiple services. For detailed industry-specific
examples, see Personal assistant agents and Customer service agents.

Supported authentication patterns 464


**Machine-to-machine authentication (OAuth 2.0 client credentials grant)**

The OAuth 2.0 client credentials grant flow enables direct authentication between systems without
user interaction. This pattern is appropriate when agents need to access resources that aren't user-
specific or when agents act themselves with pre-authorized user consent.

**Key characteristics**

- No user interaction or consent required
- Agent authenticates directly with resource servers using its own credentials
- Suitable for background processes, scheduled tasks, and system-level operations
- Permissions are defined at the agent level rather than per-user

**Example scenario** â€“ An enterprise data processing agent needs to collect data from multiple
internal systems, process it, and store the results in a data warehouse. The agent uses the OAuth
2.0 client credentials grant to authenticate directly with each system using its own identity and
pre-configured permissions. No user interaction is required, and the agent can operate when
agents act themselves with pre-authorized user consent on scheduled intervals.

This pattern is ideal for enterprise automation agents, data processing workflows, and DevOps
automation. For detailed industry-specific examples, see Enterprise automation agents, Data
processing and analytics agents, and Development and DevOps agents.

**Choosing the right authentication pattern**

When designing your agent authentication strategy, consider these factors to determine which
pattern is most appropriate:

**Authentication pattern selection guide**

Factor User-delegated access (OAuth 2.0
authorization code grant)

Machine-to-machine authentic
ation (OAuth 2.0 client credentials
grant)

Data ownership User-specific data (emails,
documents, personal calendars)

System or organization-owned data
(analytics, logs, shared resources)

User interaction User is present and can provide
consent

No user interaction required or
available

Supported authentication patterns 465


Factor User-delegated access (OAuth 2.0
authorization code grant)

Machine-to-machine authentic
ation (OAuth 2.0 client credentials
grant)

Operation
timing

Interactive, real-time operations Background, scheduled, or batch
operations

Permission
scope

Permissions vary by user and their
consent choices

Consistent permissions defined at
the agent level

Many agent implementations will require both patterns for different aspects of their functionality.
For example, a customer service agent might use user-delegated access to retrieve a specific
customer's data while using machine-to-machine authentication to access company knowledge
bases and internal systems. AgentCore Identity supports both patterns simultaneously, allowing
agents to use the most appropriate authentication mechanism for each resource they need to
access.

Both authentication patterns benefit from AgentCore Identity's core capabilities:

- Secure credential storage without exposing secrets to agent code
- Consistent authentication interfaces across multiple resource types
- Comprehensive audit logging for security and compliance
- Fine-grained access controls based on identity and context
- Simplified integration through the AgentCore SDK

#### Configure credential provider..........................................................................................................

Resource credential providers in AgentCore Identity act as intelligent intermediaries that manage
the complex relationships between agents, identity providers, and resource servers. Each provider
encapsulates the specific endpoint configuration required for a particular service or identity
system. The service provides built-in providers for popular services including Google, GitHub,
Slack, and Salesforce, with authorization server endpoints and provider-specific parameters pre-
configured to reduce development effort. AgentCore Identity supports custom configurations
through configurable OAuth2 credential providers that can be tailored to work with any OAuth2-
compatible resource server. For information about OAuth2 credential provider limits, see
AgentCore Identity Service Quotas.

Configure credential provider 466


Resource credential providers integrate deeply with the token vault to provide seamless credential
lifecycle management. When an agent requests access to a resource, the provider handles the
authentication flow, stores the resulting credentials in the token vault, and provides the agent with
the necessary access tokens.

**Creating an OAuth 2.0 credential provider**

Provider configurations in AgentCore Identity define the basic parameters needed for credential
management with different resources and authentication systems. The following example
demonstrates how to use the AgentCore SDK to configure an OAuth 2.0 credential provider to use
with GitHub.

from bedrock_agentcore.services.identity import IdentityClient
identity_client = IdentityClient("us-east-1")
github_provider = identity_client.create_oauth2_credential_provider({
"name": "github-provider",
"credentialProviderVendor": "GithubOauth2",
"oauth2ProviderConfigInput": {
"githubOauth2ProviderConfig": {
"clientId": "your-github-client-id",
"clientSecret": "your-github-client-secret"
}
}
})

**Creating an API key credential provider**

For services that use API keys for authentication rather than OAuth, AgentCore Identity will
securely store and retrieve keys for your agents. The example below illustrates using the AgentCore
SDK to store an API key. For information about API key credential provider limits, see AgentCore
Identity Service Quotas.

from bedrock_agentcore.services.identity import IdentityClient
identity_client= IdentityClient("us-east-1")
apikey_provider= identity_client.create_api_key_credential_provider({
"name": " your-service-name ",
"apiKey": " your-api-key "
})

Configure credential provider 467


#### Obtain credentials..............................................................................................................................

AgentCore Identity uses a workload access token to authorize agent access to credentials stored in
the vault, and this token contains both the identity of the agent and the identity of the end user
on whose behalf the agent is working. AgentCore Runtime will automatically provide a token when
invoking an agent that it is hosting. Agents hosted on other systems can retrieve their agent token
using the AgentCore SDK.

**Topics**

- Get workload access token
- Obtain OAuth 2.0 access token
- OAuth 2.0 authorization URL session binding
- Scope down access to credential providers by workload identity
- Obtain API key

**Get workload access token**

Understanding what workload access tokens are, how to obtain them, and the security aspects of
working with them is essential for building secure agent applications. This section covers the key
concepts and implementation patterns you need to know.

**Topics**

- What is a workload access token?
- How Runtime and Gateway automatically obtain tokens
- How to manually retrieve workload access tokens
- Security controls for GetWorkloadAccessTokenForUserId API

**What is a workload access token?**

A workload access token is an AWS-signed opaque access token that enables agents to access first-
party AgentCore services, such as outbound credential providers. Runtime automatically delivers
workload access tokens to agent execution instances as payload headers, eliminating the need for
manual token management in most scenarios.

**Key characteristics**

Obtain credentials 468


- **First-party services only** â€“ Workload access tokens are exclusively for accessing AWS first-party
    AgentCore services and cannot be used for external services
- **Automatic delivery** â€“ Runtime and Gateway automatically provide these tokens to agents during
    execution
- **Security by design** â€“ Runtime-managed agent identities cannot retrieve workload access tokens
    directly, preventing token extraction and misuse
- **User and agent identity binding** â€“ Tokens contain both user identity and agent identity
    information for secure credential access

**How Runtime and Gateway automatically obtain tokens**

When an agent is invoked through AgentCore Runtime or Gateway with inbound authentication,
the service automatically handles workload access token generation:

1.Runtime validates the inbound identity provider OAuth token (issuer, signature)

2.Runtime extracts issuer and sub claims from the OAuth token representing user identity

3.Runtime fetches the associated workload identity of the agent

4.Runtime invokes GetWorkloadAccessTokenForJWT with both user identity and agent
workload identity

5.Runtime passes the workload access token to agent code as part of the invocation payload
header

This automatic process ensures agents receive properly scoped tokens without manual
intervention.

**How to manually retrieve workload access tokens**

There are two patterns to use to retrieve the workload access token depending on how you are able
to identify the end user of the agent:

- If the agentâ€™s caller has a JWT identifying the end user, request a workload access token based
    on the agentâ€™s identity and the end-user JWT. When you provide a JWT, AgentCore Identity will
    validate the JWT to ensure it is correctly signed and unexpired, and it will use its â€œissâ€ and â€œsubâ€
    claims to uniquely identify the user. Credentials stored by the agent on behalf of the user will be
    associated with this information, and future retrievals by the agent will require a valid workload
    access token containing the same information.

Obtain credentials 469


- If the agentâ€™s caller does not have a JWT identifying the end user, request a workload access
    token based on the agentâ€™s identity and a unique string identifying the user.

The examples below illustrate using the AgentCore SDK to retrieve a workload access token using
these two methods:

from bedrock_agentcore.services.identity import IdentityClient

identity_client= IdentityClient("us-east-1")# Obtain a token using the IAM identity of
the caller to authenticate the agent and providing a JWT containing the identity of
the end user.

This is the recommended pattern whenever a JWT is available for the user.
workload_access_token= identity_client.get_workload_access_token(workload_name= "my-
demo-agent", user_token= "insert-jwt-here")# Obtain a token using the IAM identity of
the caller to authenticate the agent and providing a string representing the identity
of the end user.

Use this pattern when a JWT is not available for the user.
workload_access_token= identity_client.get_workload_access_token(workload_name= "my-
demo-agent", user_id= "insert-user-name-or-identifier")

**Security controls for GetWorkloadAccessTokenForUserId API**

The GetWorkloadAccessTokenForUserId API implements several security controls to prevent
unauthorized access:

- **Workload identity validation** â€“ The API verifies that the requesting identity has permission to
    act on behalf of the specified workload identity
- **Service-managed identity restriction** â€“ Runtime-managed and Gateway-managed workload
    identities cannot retrieve tokens directly. This prevents agents from extracting tokens for misuse
- **IAM permission requirements** â€“ Callers must have appropriate IAM permissions
    including GetWorkloadAccessToken, GetWorkloadAccessTokenForUserId, and
    GetWorkloadAccessTokenForJWT
- **Token scoping** â€“ Tokens are scoped to the specific user-agent pair, ensuring credentials stored
    under one user cannot be accessed by another

If you encounter the error "WorkloadIdentity is linked to a service and cannot retrieve an access
token by the caller," this indicates the workload identity is managed by Runtime or Gateway and

Obtain credentials 470


cannot retrieve tokens directly. This restriction helps maintain security boundaries and prevents
unauthorized token access.

For additional security controls, you can implement fine-grained access policies to restrict which
workload identities can access specific credential providers. For more information, see Scope down
access to credential providers by workload identity.

**Obtain OAuth 2.0 access token**

AgentCore Identity enables developers to obtain OAuth tokens for either user-delegated access
or machine-to-machine authentication based on the configured OAuth 2.0 credential providers.
The service will orchestrate the authentication process between the user or application to the
downstream authorization server, and it will retrieve and store the resulting token. Once the token
is available in the AgentCore Identity vault, authorized agents can retrieve it and use it to authorize
calls to resource servers. For example, the sample code below will retrieve a token to interact with
Google Drive on behalf of an end user. For more information, see Integrate with Google Drive using
OAuth2 for the complete example.

Injects Google Access Token
@requires_access_token(# Uses the same credential provider name created above
#provider_name= "google-provider",

Requires Google OAuth2 scope to access Google Drive
#scopes= ["https://www.googleapis.com/auth/drive.metadata.readonly"],

Sets to OAuth 2.0 Authorization Code flow
#auth_flow= "USER_FEDERATION",

Prints authorization URL to console
#on_auth_url= lambda x: print("\nPlease copy and paste this URL in your browser:\n" +
x),

If false, caches obtained access token
#force_authentication= False,)async#def#write_to_google_drive(*, access_token: str):

Use the token to call Google Drive
asyncio.run(write_to_google_drive(access_token= ""))

The process is similar to obtain a token for machine-to-machine calls, as shown in the following
example:

import#asyncio
from#bedrock_agentcore.identity.auth#import#requires_access_token, requires_api_key
@requires_access_token(provider_name= " my-api-key-provider ", # replace with your own
credential provider name
#scopes= [],

Obtain credentials 471


#auth_flow= 'M2M',)async#def#need_token_2LO_async(*, access_token: str):

Use the access token
asyncio.run(need_token_2LO_async(access_token= ""))

**Topics**

- Automatic refresh token storage and usage
- Streaming authorization URLs to application callers
- Resource indicators in AgentCore OAuth2 flows

**Automatic refresh token storage and usage**

AgentCore automatically stores and uses refresh tokens when available from OAuth2 providers,
reducing the frequency of user reauthorization prompts. When users initially grant consent
through a standard OAuth2 authorization code flow, the system stores both access tokens and
refresh tokens (if provided) in the secure token vault. This enables agents to obtain fresh access
tokens automatically when the original tokens expire, improving user experience by minimizing
repeated consent requests.

Important
Access tokens returned by AgentCore are not guaranteed to be valid. Tokens can be
revoked by customers on the federated provider side, which AgentCore cannot detect. If a
token is invalid, use forceAuthentication: true to force a new authentication flow
and obtain a valid access token.

Refresh tokens typically have longer lifespans than access tokens, with a default validity period
of approximately 30 days compared to the shorter lifespan of access tokens (often 1-2 hours).
When an access token expires, AgentCore automatically uses the stored refresh token to request a
new access token from the provider. **If a valid refresh token is stored, AgentCore skips the user
federation flow and directly returns a new access token**. If the refresh token is also expired or
invalid, the system falls back to prompting the user for full reauthorization.

This feature requires no configuration within AgentCore - it operates automatically when refresh
tokens are present in the OAuth2 provider's token response. However, you must configure your
OAuth2 provider to include refresh tokens in the authorization flow. The specific configuration
depends on your provider:

Obtain credentials 472


Provider Configuration Required

Google Include access_type=offline in customParameters when
calling GetResourceOauth2Token

"customParameters": { "access_type": " offline " }

Microsoft Include offline_access in scopes parameter when calling
GetResourceOauth2Token

"scopes": ["openid", "profile", " offline_access "]

Salesforce Include refresh_token in scopes parameter when calling
GetResourceOauth2Token

"scopes": ["api", " refresh_token "]

Atlassian Include offline_access in scopes parameter when calling
GetResourceOauth2Token

"scopes": ["read:jira-user", " offline_access "]

GitHub No extra AgentCore configuration required. Enable User-to-server
token expiration feature in your GitHub app settings. Refresh tokens
are stored automatically when this feature is enabled.

Slack No extra AgentCore configuration required. Enable "token rotation"
feature in your Slack app settings. Refresh tokens are returned
automatically when this feature is enabled.

LinkedIn No extra AgentCore configuration required. Enable refresh token
settings in your LinkedIn app configuration.

Other providers Some providers require configuration in their provider settings rather
than API parameters. Consult your provider's documentation for
refresh token requirements.

Obtain credentials 473


If your provider supports refresh tokens and is properly configured, AgentCore will automatically
store and manage them without additional setup. To clear stored refresh tokens and force users to
reauthenticate, set forceAuthentication=true when calling GetResourceOauth2Token. This
clears the refresh token and forces a complete federation flow. For information about configuring
OAuth2 providers, see Provider setup and configuration.

**Streaming authorization URLs to application callers**

For three-legged OAuth (3LO) flows, your agent needs to provide the authorization URL to the
calling application so users can complete the consent flow. While the examples above show
printing the URL to the console, production applications require streaming the URL back to the
caller through your application's response mechanism.

**Common implementation patterns**

**Streaming response pattern** â€“ For applications that support streaming responses, you can send
the authorization URL as part of the response stream:

import asyncio
from bedrock_agentcore.identity.auth import requires_access_token

@requires_access_token(
provider_name="google-provider",
scopes=["https://www.googleapis.com/auth/drive.metadata.readonly"],
auth_flow="USER_FEDERATION",

Stream URL back to caller instead of printing
on_auth_url=lambda url: stream_to_caller({
"type": "authorization_required",
"authorization_url": url,
"message": "Please visit this URL to authorize access"
}),
force_authentication=False,
)
async def agent_with_streaming_auth(*, access_token: str):

Agent logic continues after user completes authorization
return {"status": "success", "token_received": True}

def stream_to_caller(data):

Implementation depends on your streaming mechanism
Examples: WebSocket, Server-Sent Events, HTTP chunked response
response_stream.send(json.dumps(data))

Obtain credentials 474


**Callback pattern** â€“ For applications using callbacks or webhooks, store the authorization URL and
notify the caller:

import asyncio
from bedrock_agentcore.identity.auth import requires_access_token

@requires_access_token(
provider_name="google-provider",
scopes=["https://www.googleapis.com/auth/drive.metadata.readonly"],
auth_flow="USER_FEDERATION",

Store URL and trigger callback
on_auth_url=lambda url: handle_auth_callback(url),
force_authentication=False,
)
async def agent_with_callback_auth(*, access_token: str):
return {"status": "success", "data": "processed"}

def handle_auth_callback(authorization_url):

Store the URL associated with the request
auth_store.save(request_id, {
"authorization_url": authorization_url,
"status": "pending_authorization"
})

Notify the calling application
callback_service.notify(callback_url, {
"request_id": request_id,
"authorization_url": authorization_url,
"action_required": "user_authorization"
})

**Polling pattern** â€“ For applications that prefer polling, store the authorization URL in a retrievable
location:

import asyncio
from bedrock_agentcore.identity.auth import requires_access_token

@requires_access_token(
provider_name="google-provider",
scopes=["https://www.googleapis.com/auth/drive.metadata.readonly"],
auth_flow="USER_FEDERATION",

Store URL for polling retrieval
on_auth_url=lambda url: store_auth_url_for_polling(url),

Obtain credentials 475


force_authentication=False,
)
async def agent_with_polling_auth(*, access_token: str):
return {"status": "success", "data": "processed"}

def store_auth_url_for_polling(authorization_url):

Store in database, cache, or session store
session_store.set(f"auth_url:{session_id}", {
"authorization_url": authorization_url,
"created_at": datetime.utcnow(),
"status": "pending"
}, ttl=300) # 5 minute expiration

Choose the pattern that best fits your application architecture. Streaming responses provide the
best user experience for real-time applications, while callback and polling patterns work well for
asynchronous or batch processing scenarios.

**Resource indicators in AgentCore OAuth2 flows**

Resource indicators provide a standardized way to specify which resource server should accept an
OAuth2 access token. AgentCore uses Cognito as its authentication provider, which supports RFC
8707-compliant resource indicators that allow you to specify the intended resource server during
token requests. To use resource indicators, you must first configure the authorization server to
recognize specific resource servers using Cognito's CreateResourceServer API. Once configured,
when you specify a resource indicator in your token request, Cognito includes the corresponding
resource server identifier in the aud claim of the resulting token, enabling the resource server
to verify that the token is intended for its specific use. This provides several important benefits:
resource servers can validate that tokens are specifically intended for them (principle of least
privilege), improved auditability by clearly identifying which resource server each token targets,
and reduced risk of token misuse across different services within your application environment.

Through Cognito's RFC 8707 implementation, AgentCore enables clients to specify a resource
server directly in authorization and token requests, overriding the default audience parameter.
In Cognito, the 'resource indicator' referred to in the RFC corresponds to the ResourceServer's
'identifier' value. Resource indicators are particularly important for Model Context Protocol (MCP)
implementations, where they help mitigate specific security risks outlined in the MCP authorization
specification. The resource indicator corresponds to the RFC 9728 resource parameter, ensuring
proper token scoping for MCP server interactions. Note that the current implementation supports
single-resource binding, meaning you can specify one resource server per token request.

Obtain credentials 476


Use resource indicators when your agents need to access resource servers with specific security
requirements, or when you need fine-grained control over token audience validation. Resource
indicators are particularly useful for multi-tenant applications where tokens should be restricted to
specific customer resources.

**OAuth 2.0 authorization URL session binding**

AgentCore Identity provides OAuth 2.0 access token retrievals for your agent applications to access
third-party application vendors or resources protected by identity providers / authorization servers.
If an application or a resource requires a user to authorize explicitly with an OAuth authorization
code flow, AgentCore Identity generates an authorization URL for the user to navigate to and
consent access. Then, upon user giving consent, AgentCore Identity fetches the access token from
the application or resource on behalf of users, and stores it in the AgentCore Identity Token Vault.

However, since a user may accidentally send the authorization URL to another user and gain access
to that user's application or resource, your application must verify that the user who initiates an
authorization request is still the same as the user who has granted consent to the application or
resource. To do that, you need to register a publicly available HTTPS application endpoint with
AgentCore Identity that handles user verification.

**How session binding works**

The following flow diagram and corresponding steps show the OAuth 2.0 authorization URL
session binding process:

Obtain credentials 477


1. **Invoke agent** â€“ Your agent code invokes GetResourceOauth2Token API to retrieve an
    authorization URL, when an originating agent user wants to access some application or resource
    that he/she owns.
2. **Generate authorization URL** â€“ AgentCore Identity generates an authorization URL and session
    URI for the user to navigate to and consent access.
3. **Authorize and obtain access token** â€“ The user navigates to the authorization URL and grants
    consent for your agent to access his/her resource. After that, AgentCore Identity redirects the
    user's browser to your HTTPS application endpoint with information containing the originating
    user of the authorization request. At this point, your HTTPS application endpoint determines if
    the originating agent user is still the same as the currently logged in user of your application.
    If they match, your application endpoint invokes CompleteResourceTokenAuth so that
    AgentCore Identity can fetch and store the access token.

Obtain credentials 478


4. **Re-invoke agent to obtain access token** â€“ Once the application returns a valid response, your
    agent application will be able to retrieve the OAuth2.0 access tokens that were originally
    requested for the user. If the users do not match, your application simply does nothing or logs
    the attempt.

By allowing your application endpoint to verify the user identity, AgentCore Identity allows your
agent application to ensure that it is always the same user who initiated the authorization request
and the one who consented access.

**Implementation details**

When calling the CompleteResourceTokenAuth API, your application must present the original
inbound identity provider Oauth token or static user identifier that was used to generate the
workload access token to represent the user and the agent application involved in the OAuth2.0
authorization flow. Additionally, each authorization URL that gets generated by AgentCore Identity
is uniquely identified with its own session URI. This session URI must also be presented alongside
the user identifier in order to bind the session with the intended user.

Important
Prior to your application calling the CompleteResourceTokenAuth API, your application
must verify that the current user has an active, valid session with your application. By doing
so your application can associate the intended user with the Authorization session.

Once the application returns a valid response, your agent application will be able to retrieve the
OAuth2.0 access tokens that were originally requested for the user.

Important
When you are using the Amazon Bedrock AgentCore Starter Toolkit in a local environment,
the toolkit hosts the callback endpoint and calls the CompleteResourceTokenAuth API
on your behalf to verify the user session to get OAuth2.0 access tokens. This is to simplify
your local development and testing.
However, when deploying your agent code to AgentCore Runtime, your web
application that connects to the agent runtime must host a publicly accessible
HTTPS callback endpoint itself, the callback endpoint must be registered
against the workload identity as an AllowedResourceOAuth2ReturnUrl by calling

Obtain credentials 479


UpdateWorkloadIdentity using the agent ID provided by AgentCore Runtime, and then
call the CompleteResourceTokenAuth API after verifying the current user's browser
session in order to secure your Oauth2.0 authorization flows.

**Additional considerations**

When implementing OAuth 2.0 authorization URL session binding, keep the following
considerations in mind:

- Each authorization URL and its corresponding session identifier are only valid for 10 minutes.
- In order to secure your application callback endpoint against CSRF attacks, we
    highly recommend that you generate an opaque state to include in your API call to
    GetResourceOAuth2Token. Your application should be able to parse this value in order to
    ensure it's serving requests that were initiated by your agent application.

**Scope down access to credential providers by workload identity**

You can use IAM policies to control which workload identities have access to specific credential
providers. This enables fine-grained access control, ensuring that only authorized agents can
retrieve credentials for particular services.

**Access control mechanisms**

- **Workload identity-based restrictions** â€“ Limit credential provider access to specific workload
    identities
- **Resource-level permissions** â€“ Control access to individual credential providers using ARN-based
    policies
- **Directory-level controls** â€“ Manage access at the workload identity directory level

**Topics**

- IAM policy examples
- Implementation steps

Obtain credentials 480


**IAM policy examples**

The following examples demonstrate how to create IAM policies that restrict credential provider
access based on workload identity:

**Restrict API key provider access**

{
"Version": "2012-10-17",
"Statement": [
{
"Sid": "GetResourceApiKey",
"Effect": "Allow",
"Action": [
"bedrock-agentcore:GetResourceApiKey"
],
"Resource": [
"arn:aws:bedrock-agentcore:us-east-1:<account_id>:workload-identity-directory/
default",
"arn:aws:bedrock-agentcore:us-east-1:<account_id>:workload-identity-directory/
default/workload-identity/<workload-identity-name>",
"arn:aws:bedrock-agentcore:us-east-1:<account_id>:token-vault/default"
]
}
]
}

**Restrict OAuth2 credential provider access**

{
"Version": "2012-10-17",
"Statement": [
{
"Sid": "GetResourceOauth2Token",
"Effect": "Allow",
"Action": [
"bedrock-agentcore:GetResourceOauth2Token"
],
"Resource": [
"arn:aws:bedrock-agentcore:us-east-1:<account_id>:workload-identity-directory/
default",
"arn:aws:bedrock-agentcore:us-east-1:<account_id>:workload-identity-directory/
default/workload-identity/<workload-identity-name>",

Obtain credentials 481


"arn:aws:bedrock-agentcore:us-east-1:<account_id>:token-vault/default"
]
}
]
}

**Allow multiple workload identities access to a credential provider**

{
"Version": "2012-10-17",
"Statement": [
{
"Sid": "GetResourceApiKeyMultipleIdentities",
"Effect": "Allow",
"Action": [
"bedrock-agentcore:GetResourceApiKey"
],
"Resource": [
"arn:aws:bedrock-agentcore:us-east-1:<account_id>:workload-identity-directory/
default",
"arn:aws:bedrock-agentcore:us-east-1:<account_id>:workload-identity-directory/
default/workload-identity/agent-1",
"arn:aws:bedrock-agentcore:us-east-1:<account_id>:workload-identity-directory/
default/workload-identity/agent-2",
"arn:aws:bedrock-agentcore:us-east-1:<account_id>:workload-identity-directory/
default/workload-identity/agent-3",
"arn:aws:bedrock-agentcore:us-east-1:<account_id>:token-vault/default"
]
}
]
}

**Implementation steps**

To implement workload identity-based access control for credential providers:

1. **Identify your workload identities** â€“ Use aws bedrock-agentcore-control list-
    workload-identities to list all workload identities in your account. For information about
    creating and managing workload identities, see Manage workload identities with AgentCore
    Identity.
2. **Determine credential provider ARNs** â€“ Identify the specific credential providers you want to
    control access to

Obtain credentials 482


3. **Create IAM policies** â€“ Write IAM policies that specify which workload identities can access which
    credential providers
4. **Attach policies to roles** â€“ Attach the policies to the IAM roles used by your agents or
    applications
5. **Test access controls** â€“ Verify that only authorized workload identities can access the specified
    credential providers

**Best practices**

- Use descriptive names for workload identities to make policy management easier
- Regularly audit and review access policies to ensure they align with your security requirements
- Consider using IAM policy conditions for additional access controls based on time, IP address, or
    other factors
- Test policies in a development environment before applying them to production workloads

**Obtain API key**

Once you have stored your API keys in the AgentCore Identity vault, you can retrieve them directly
in your agent using the AgentCore SDK and the @requires_api_key annotation. For example, the
code below will retrieve the API key from the â€œyour-service-nameâ€ API key provider so that you can
use it in the need_api_key function.

import asyncio
from bedrock_agentcore.identity.auth import requires_api_key
@requires_api_key(provider_name= " your-service-name" # replace with your own
credential provider name)async def need_api_key(*, api_key: str):

Use the key in api_key
asyncio.run(need_api_key(api_key= ""))

### Provider setup and configuration

Amazon Bedrock AgentCore Identity provides managed OAuth 2.0 supported providers for both
inbound and outbound authentication. Each provider encapsulates the specific authentication
protocols, endpoint configurations, and credential formats required for a particular service or
identity system. The service provides built-in providers for popular services including Google,
GitHub, Slack, and Salesforce with authorization server endpoints and provider-specific parameters

Provider setup 483


pre-configured to reduce development effort. The providers abstract away the complexity of
different OAuth 2.0 implementations, API authentication schemes, and token formats, presenting a
unified interface to agents while handling the underlying protocol variations and edge cases.

Built-in providers are maintained by the AgentCore Identity team and automatically updated to
handle changes in external service APIs, security requirements, and best practices.

Supported providers include:

**Topics**

- Amazon Cognito
- Auth0 by Okta
- Atlassian
- CyberArk
- Dropbox
- Facebook
- FusionAuth
- GitHub
- Google
- HubSpot
- LinkedIn
- Microsoft
- Notion
- Okta
- OneLogin
- PingOne
- Reddit
- Salesforce
- Slack
- Spotify
- Twitch
- X
- Yandex

Provider setup 484


- Zoom

#### Amazon Cognito.................................................................................................................................

Amazon Cognito can be configured as an identity provider for accessing AgentCore Gateway
and Runtime, or an AgentCore Identity credential provider for outbound resource access. This
allows your agents to authenticate and authorize agent users with Cognito as the identity provider
and authorization server, or your agents to obtain credentials to access resources authorized by
Cognito.

**Inbound**

To add Cognito as an identity provider and authorization server for accessing AgentCore Gateway
and Runtime, you must:

- Configure discovery URL from your IDP directory. This helps AgentCore Identity get the metadata
    related to your OAuth authorization server and token verification keys.
- Enter valid clientId or aud claims for the token. This helps validate the tokens coming from
    your IDP and allow access for tokens that contain expected claims.

Use the following procedure to create a Cognito user pool as an inbound identity provider for user
authentication with AgentCore Runtime. The following steps will create a Cognito user pool, a user
pool client, add a user, and generate a bearer token for the user. The token is valid for 60 minutes
by default.

**To create a Cognito user pool as an inbound identity provider for Runtime authentication**

1. Create a file named setup_cognito.sh with the following content:

Note
The following script is only meant as an example. You should customize the user pool
settings and user credentials as needed for your application. Do not use this script
directly in production environments.

#!/bin/bash

Amazon Cognito 485


Create User Pool and capture Pool ID directly
export POOL_ID=$(aws cognito-idp create-user-pool
--pool-name "MyUserPool"
--policies '{"PasswordPolicy":{"MinimumLength":8}}'
--region us-east-1 | jq -r '.UserPool.Id')

Create App Client and capture Client ID directly
export CLIENT_ID=$(aws cognito-idp create-user-pool-client
--user-pool-id $POOL_ID
--client-name "MyClient"
--no-generate-secret
--explicit-auth-flows "ALLOW_USER_PASSWORD_AUTH" "ALLOW_REFRESH_TOKEN_AUTH"
--region us-east-1 | jq -r '.UserPoolClient.ClientId')

Create User
aws cognito-idp admin-create-user
--user-pool-id $POOL_ID
--username "testuser"
--temporary-password "${temp-password}"
--region us-east-1
--message-action SUPPRESS > /dev/null

Set Permanent Password
aws cognito-idp admin-set-user-password
--user-pool-id $POOL_ID
--username "testuser"
--password "${permanent-user-password}"
--region us-east-1
--permanent > /dev/null

Authenticate User and capture Access Token
export BEARER_TOKEN=$(aws cognito-idp initiate-auth
--client-id "$CLIENT_ID"
--auth-flow USER_PASSWORD_AUTH
--auth-parameters USERNAME='testuser',PASSWORD='${permanent-user-password}'
--region us-east-1 | jq -r '.AuthenticationResult.AccessToken')

Output the required values
echo "Pool id: $POOL_ID"
echo "Discovery URL: https://cognito-idp.us-east-1.amazonaws.com/$POOL_ID/.well-
known/openid-configuration"
echo "Client ID: $CLIENT_ID"
echo "Bearer Token: $BEARER_TOKEN"

Amazon Cognito 486


2. Run the script to create the Cognito resources:

source setup_cognito.sh

3. Record the output values, which will look similar to:

Pool id: us-east-1_poolid
Discovery URL: https://cognito-idp.us-east-1.amazonaws.com/us-
east-1_userpoolid/.well-known/openid-configuration
Client ID: clientid
Bearer Token: bearertoken

You'll need these values in the next steps.

Use the following procedure to create a Cognito user pool as an inbound identity provider for
machine-to-machine authentication with AgentCore Gateway. The following steps will create a user
pool, resource server, client credentials, and discovery URL configuration. This setup enables M2M
authentication flows for Gateway access.

**To create a Cognito user pool as an inbound identity provider for Gateway authentication**

1. Create a user pool:

aws cognito-idp create-user-pool
--region us-west-2
--pool-name "gateway-user-pool"

2. Record the user pool ID from the response or retrieve it using:

aws cognito-idp list-user-pools
--region us-west-2
--max-results 60

3. Create a resource server for the user pool:

aws cognito-idp create-resource-server
--region us-west-2
--user-pool-id
--identifier "gateway-resource-server"
--name "GatewayResourceServer" \

Amazon Cognito 487


--scopes '[{"ScopeName":"read","ScopeDescription":"Read access"},
{"ScopeName":"write","ScopeDescription":"Write access"}]'

4. Create a client for the user pool:

aws cognito-idp create-user-pool-client
--region us-west-2
--user-pool-id
--client-name "gateway-client"
--generate-secret
--allowed-o-auth-flows client_credentials
--allowed-o-auth-scopes "gateway-resource-server/read" "gateway-resource-server/
write"
--allowed-o-auth-flows-user-pool-client
--supported-identity-providers "COGNITO"

Record the client ID and client secret from the response. You'll need these values to configure
the Cognito provider in AgentCore Identity.

5. If needed, create a domain for your user pool:

aws cognito-idp create-user-pool-domain
--domain
--user-pool-id
--region us-west-2

Note
Remove any underscore from the UserPoolId when creating the domain. For
example, if your user pool ID is "us-west-2_gmSGKKGr9", use "us-west-2gmSGKKGr9"
as the domain.

6. Construct the discovery URL for your Cognito user pool:

https://cognito-idp.us-west-2.amazonaws.com//.well-known/openid-
configuration

7. Configure the Gateway Inbound Auth with the following values:

a. Discovery URL : The URL constructed in the previous step
b. Allowed clients : The client ID obtained when creating the user pool client

Amazon Cognito 488


**Outbound**

To configure Cognito user pools as an outbound resource provider, use the following configuration:

{
"name": "Cognito",
"credentialProviderVendor": "CognitoOauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {
"clientId": "your-client-id",
"clientSecret": "your-client-secret",
"authorizeEndpoint": "https://{your-cognito-domain}.auth.us-
east-1.amazoncognito.com/oauth2/authorize",
"tokenEndpoint": "https://{your-cognito-domain}.auth.us-east-1.amazoncognito.com/
oauth2/token",
"issuer": "https://cognito-idp.us-east-1.amazonaws.com/{your-user-pool-id}"
}
}
}

#### Auth0 by Okta....................................................................................................................................

Auth0 can be configured as an identity provider for accessing AgentCore Gateway and Runtime, or
an AgentCore Identity credential provider for outbound resource access. This allows your agents
to authenticate and authorize agent users with Auth0 as the identity provider and authorization
server, or your agents to obtain credentials to access resources authorized by Auth0.

**Inbound**

To add Auth0 as an identity provider and authorization server for accessing AgentCore Gateway
and Runtime, you must:

- Configure discovery URL from your IDP directory. This helps AgentCore Identity get the metadata
    related to your OAuth authorization server and token verification keys.
- Enter valid aud claims for the token. This helps validate the tokens coming from your IDP and
    allows access for tokens that contain expected claims.

Use the following procedure to set up Auth0 and obtain the necessary configuration values for
Gateway authentication.

Auth0 by Okta 489


**To configure Auth0 for inbound authentication**

1. Create an API in Auth0:

a. Sign in to your Auth0 dashboard.
b. Open APIs and choose Create API.
c. Enter a name and identifier for your API (e.g., "gateway-api").
d. Select the signing algorithm (RS256 recommended).
e. Choose Create.

2. Configure API scopes:

a. In the API settings, go to the Scopes tab.
b. Add scopes such as "invoke:gateway" and "read:gateway".

3. Create an application:

a. Open Applications and choose Create Application.
b. Select Machine to Machine Application.
c. Select the API you created in step 1.
d. Authorize the application for the scopes you created.
e. Choose Create.

4. Record the client ID and client secret from the application settings. You'll need these values to
    configure the Auth0 provider in AgentCore Identity.
5. Construct the discovery URL for your Auth0 tenant:

https:// your-domain /.well-known/openid-configuration

Where your-domain is your Auth0 tenant domain (e.g., "dev-example.us.auth0.com").

6. Configure Inbound Auth with the following values:

a. Discovery URL : The URL constructed in the previous step
b. Allowed audiences : The API identifier you created in step 1

**Outbound**

To configure Auth0 as an outbound resource provider, use the following:
Auth0 by Okta 490


{
"name": "NAME",
"credentialProviderVendor": "Auth0Oauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret ",
"authorizeEndpoint": "https:// your-auth0-tenant .auth0.com/authorize",
"tokenEndpoint": "https:// your-auth0-tenant .auth0.com/oauth/token",
"issuer": "https:// your-auth0-tenant .auth0.com"
}
}
}

#### Atlassian................................................................................................................................................

Atlassian can be configured as an AgentCore Identity credential provider for outbound resource
access. This allows your agents to authenticate users through Atlassian's OAuth2 service and obtain
access tokens for Atlassian API resources.

**Outbound**

**Step 1**

Use the following procedure to set up an Atlassian OAuth2 application and obtain the necessary
client credentials for AgentCore Identity.

**To configure an Atlassian OAuth2 application**

1. Open Atlassian's developer console and register for a developer account.
2. Create a new application.
3. Select authorization and next to **OAuth 2.0 (3LO)** select **Configure**.
4. Enter the following as a callback URL for the app:

https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/callback

5. Choose **Save changes**.
6. Select **Permissions** and choose the permissions relevant to your application.

For more details, refer to Atlassian's OAuth 2.0 (3LO) apps documentation.

Atlassian 491


**Step 2**

To configure Atlassian as an outbound resource provider, use the following:

{
"name": "NAME",
"credentialProviderVendor": "AtlassianOAuth2",
"oauth2ProviderConfigInput": {
"atlassianOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret "
}
}
}

#### CyberArk...............................................................................................................................................

CyberArk can be configured as an AgentCore Identity credential provider for outbound resource
access. This allows your agents to authenticate users through CyberArk's OAuth2 service and obtain
access tokens for CyberArk API resources.

**Outbound**

**Step 1**

Use the following procedure to set up a CyberArk OpenID Connect application and obtain the
necessary client credentials for AgentCore Identity.

**To configure a CyberArk OAuth2 application**

1. Open the developer console for CyberArk.
2. Open **Identity Administration** and then choose **Web Apps**.
3. Open the **Custom** tab.
4. Create a custom **OpenID Connect** application.
5. Open the **Trust** page, and use the following in the **Authorized Redirect URIs** :

https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/callback

6. Record the client ID and client secret generated as you'll need this information to configure the
    CyberArk resource provider in AgentCore Identity.

CyberArk 492


7. Configure any scopes necessary for your application.
8. Deploy the application by setting the appropriate permissions by opening the **Permissions**
    page and adding the relevant permissions.

For more details, refer to CyberArk's OpenID Connect documentation.

**Step 2**

To configure CyberArk as an outbound resource provider, use the following:

{
"name": "CyberArk",
"credentialProviderVendor": "CyberArkOauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret ",
"authorizeEndpoint": "https:// your-tenant-id .id.cyberark.cloud/OAuth2/Authorize/
__idaptive_cybr_user_oidc",
"tokenEndpoint": "https:// your-tenant-id .id.cyberark.cloud/OAuth2/Token/
__idaptive_cybr_user_oidc",
"issuer": "https:// your-tenant-id .id.cyberark.cloud/__idaptive_cybr_user_oidc"
}
}
}

#### Dropbox................................................................................................................................................

Dropbox can be configured as an AgentCore Identity credential provider for outbound resource
access. This allows your agents to authenticate users through Dropbox's OAuth2 service and obtain
access tokens for Dropbox API resources.

Note
Dropbox does not support the M2M/Client Credentials flow.

**Outbound**

**Step 1**

Dropbox 493


Use the following procedure to set up a Dropbox OAuth2 application and obtain the necessary
client credentials for AgentCore Identity.

**To configure a Dropbox OAuth2 application**

1. Open the developer **App Console** for Dropbox.
2. Choose **Create app**.
3. Choose **Scoped access**.
4. For the access type, choose the access type appropriate for your application.
5. Provide a name for your application.
6. Choose **Create app**.
7. On the app overview page, open the OAuth2 section and add the following as a redirect URI:

https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/callback

8. In the same section choose the dropdown below **Allow public clients (Implicit Grant & PKCE)**
    and choose **Disallow** in the options.
9. Record the app key and app secret as you'll need the information to configure the Dropbox
    resource provider in AgentCore Identity.
10. In the **Permissions** tab for the application, select the scopes that are needed for your
    application.

For more details, refer to Dropbox's OAuth implementation guide.

**Step 2**

To configure Dropbox as an outbound resource provider, use the following:

{
"name": "DropBox",
"credentialProviderVendor": "DropboxOauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret "
}
}
}

Dropbox 494


#### Facebook...............................................................................................................................................

Facebook can be configured as an AgentCore Identity credential provider for outbound resource
access. This allows your agents to authenticate users through Facebook's OAuth2 service and
obtain access tokens for Facebook API resources.

**Outbound**

**Step 1**

Use the following procedure to set up a Facebook OAuth2 application and obtain the necessary
client credentials for AgentCore Identity.

**To configure a Facebook OAuth2 application**

1. Create a developer account with Facebook.
2. Sign in with your Facebook credentials.
3. From the **My Apps** menu, choose **Create New App**.

Note
If you don't have an existing Facebook app, you will see a different option. Choose
Create App.

4. On the **Create an app** page, choose a use case for your app, and then choose **Next**.
5. Enter a name for your Facebook app and choose **Create App**.
6. On the left navigation bar, choose **App Settings** , and then choose **Basic**.
7. Record the **App ID** and the **App Secret**. You will use them for configuring the Facebook
    provider in AgentCore Identity.
8. Choose **+ Add platform** from the bottom of the page.
9. On the **Select Platform** screen, select your platforms, and then choose **Next**.
10. Choose **Save changes**.
11. For **App Domains** , enter the domain of your application and bedrock-
    agentcore. _region_ .amazonaws.com.
12. Choose **Save changes**.
13. From the navigation bar, choose **Products** , and then choose **Configure** from **Facebook Login**.
14. From the **Facebook Login Configure** menu, choose **Settings**.

Facebook 495


15. Enter the following redirect URL into **Valid OAuth Redirect URIs** :

https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/callback

16. Choose **Save changes**.

**Step 2**

To configure Facebook as an outbound resource provider, use the following:

{
"name": "Facebook",
"credentialProviderVendor": "FacebookOauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret "
}
}
}

#### FusionAuth...........................................................................................................................................

FusionAuth can be configured as an outbound resource credential provider for AgentCore Identity.
This allows your agents to authenticate users through FusionAuth's OAuth2 service and obtain
access tokens for FusionAuth API resources.

**Outbound**

**Step 1**

Use the following procedure to set up a FusionAuth OAuth2 application and obtain the necessary
client credentials for AgentCore Identity.

**To configure a FusionAuth OAuth2 application**

1. Open the developer console for FusionAuth.
2. In the main navigation bar, choose **Applications**.
3. Choose **Add** to create a new application.
4. Enter a name for your application.

FusionAuth 496


5. In the form mark the following as required: **Client Authentication** , **PKCE**.
6. For authorized redirect URLs, add the following:

https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/callback

7. Add the necessary scopes for your application.
8. Record the client ID and client secret. You'll need this information to configure the FusionAuth
    resource provider in AgentCore Identity.

For more details, refer to FusionAuth's OAuth documentation.

**Step 2**

To configure FusionAuth as an outbound resource provider, use the following:

{
"name": "FusionAuth",
"credentialProviderVendor": "FusionAuthOauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret ",
"authorizeEndpoint": "https:// your-tenant-authorization-url ",
"tokenEndpoint": "https:// your-tenant-token-endpoint ",
"issuer": "https:// your-tenant-token-issuer "
}
}
}

#### GitHub...................................................................................................................................................

GitHub can be configured as an AgentCore Identity credential provider for outbound resource
access. This allows your agents to authenticate users through GitHub's OAuth2 service and obtain
access tokens for GitHub API resources.

**Outbound**

**Step 1**

Use the following procedure to set up a GitHub OAuth2 application and obtain the necessary client
credentials for AgentCore Identity.

GitHub 497


**To configure a GitHub OAuth2 application**

1. Choose the profile picture of your github account and choose **Settings**.
2. Choose **Developer settings**.
3. Choose **OAuth Apps**.
4. On the OAuth2 apps page choose **New OAuth App**.
5. Enter the necessary details specific to your application. For authorization callback URL enter
    the following:
    - https://bedrock-agentcore. _region_ .amazonaws.com/identities/oauth2/
       callback
6. Choose **Register application** to create your Github OAuth app.
7. On Github's OAuth Apps page, go to your newly created provider.
8. Under the client secrets section, choose **Generate a new client secret**.
9. Make a note of the newly created client secret. You'll need this to configure your Github
    application with AgentCore Identity.

Note
Github only returns the full secret when it is created. If you lose track of it you'll need
to recreate the client secret to configure the provider in AgentCore Identity.

For more details, refer to Github's documentation Creating an OAuth app.

**Step 2**

To configure the outbound GitHub resource provider, use the following:

{
"name": "NAME",
"credentialProviderVendor": "GithubOauth2",
"oauth2ProviderConfigInput": {
"GithubOauth2ProviderConfigInput": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret ",
}
},

GitHub 498


}

#### Google...................................................................................................................................................

Google can be configured as an AgentCore Identity credential provider for outbound resource
access. This allows your agents to authenticate users through Google's OAuth2 service and obtain
access tokens for Google API resources.

**Outbound**

**Step 1**

Use the following procedure to set up a Google OAuth2 application and obtain the necessary client
credentials for AgentCore Identity.

**To configure a Google OAuth2 application**

1. Create a developer account with Google.
2. Sign in to the Google Cloud Platform console.
3. From the top navigation bar, choose **Select a project**. If you already have a project in the
    Google platform, this menu displays your default project instead.
4. Choose **NEW PROJECT**.
5. Enter a name for your product and then choose **CREATE**.
6. On the left navigation bar, choose **APIs and Services** , and then choose **OAuth consent screen**.
7. Enter the app information, an **App domain** , **Authorized domains** , and **Developer**
    **contact information**. Your **Authorized domains** must include bedrock-
    agentcore. _region_ .amazonaws.com. Choose **SAVE AND CONTINUE**.
8. Under **Scopes** , choose **Add or remove scopes** , and then choose the scopes necessary for your
    application.
9. Expand the left navigation bar again, choose **APIs and Services** , and then choose **Credentials**.
10. Choose **CREATE CREDENTIALS** , and then choose **OAuth client ID**.
11. Choose an **Application type** and give your client a **Name**.
12. Under **Authorized redirect URIs** , choose **ADD URI**. Enter the following:
    - https://bedrock-agentcore. _region_ .amazonaws.com/identities/oauth2/
       callback

Google 499


13. Choose **CREATE**.
14. Securely store the values that Google displays under **Your client ID** and **Your client secret**.
    Provide these values to AgentCore Identity when you add a Google credential provider.

**Step 2**

To configure the outbound Google resource provider, use the following:

{
"name": "NAME",
"credentialProviderVendor": "GoogleOauth2",
"oauth2ProviderConfigInput": {
"GoogleOauth2ProviderConfigInput": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret ",
}
},
}

#### HubSpot................................................................................................................................................

HubSpot can be configured as an AgentCore Identity credential provider for outbound resource
access. This allows your agents to authenticate users through HubSpot's OAuth2 service and obtain
access tokens for HubSpot API resources.

Note
HubSpot does not support the M2M/Client Credentials flow.

**Outbound**

**Step 1**

Use the following procedure to set up a HubSpot OAuth2 application and obtain the necessary
client credentials for AgentCore Identity.

**To configure a HubSpot OAuth2 application**

1. Open the developer console for HubSpot.

HubSpot 500


2. In the main navigation bar, choose **Apps**.
3. Choose **Create App**.
4. Enter a name for your application.
5. Choose the **Auth** tab and enter the following as a Redirect URL:

https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/callback

6. Configure any scopes that are required for your application.
7. Once your app has been created, go back to the **Auth** tab for your application.
8. Record the client ID and client secret, you'll need these when creating the HubSpot resource
    provider in AgentCore Identity.

For more details, refer to HubSpot's OAuth quickstart guide.

**Step 2**

To configure HubSpot as an outbound resource provider, use the following:

{
"name": "Hubspot",
"credentialProviderVendor": "HubspotOauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret "
}
}
}

Note
When calling GetResourceOAuth2Token, the scopes must include oauth.

#### LinkedIn................................................................................................................................................

LinkedIn can be configured as an AgentCore Identity credential provider for outbound resource
access. This allows your agents to authenticate users through LinkedIn's OAuth2 service and obtain
access tokens for LinkedIn API resources.

LinkedIn 501


**Outbound**

**Step 1**

Use the following procedure to set up a LinkedIn OAuth2 application and obtain the necessary
client credentials for AgentCore Identity.

**To configure a LinkedIn OAuth2 application**

1. Open LinkedIn's developer portal and create an application.
2. In the Auth tab, note the client ID and client secret as you'll need this information to configure
    LinkedIn as a provider in AgentCore Identity.
3. Under the OAuth2 settings section, add the following as an authorized redirect URL for the
    application:

https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/callback

4. Configure any scopes that are necessary for your application.

For more information about LinkedIn authentication, see Authentication overview on the Microsoft
website.

**Step 2**

To configure LinkedIn as an outbound resource provider, use the following configuration:

{
"name": "NAME",
"credentialProviderVendor": "LinkedInOAuth2",
"oauth2ProviderConfigInput": {
"linkedInOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret "
}
}
}

#### Microsoft...............................................................................................................................................

Microsoft Entra ID can be configured as an identity provider for accessing AgentCore Gateway
and Runtime, or an AgentCore Identity credential provider for outbound resource access. This

Microsoft 502


allows your agents to authenticate and authorize agent users with Microsoft Entra ID as the
identity provider and authorization server, or your agents to obtain credentials to access resources
authorized by Microsoft Entra ID.

**Inbound**

To add Microsoft Entra ID as an identity provider and authorization server for accessing AgentCore
Gateway and Runtime, you must:

- Configure discovery URL for your Microsoft Entra ID Tenant. This helps AgentCore Identity get
    the metadata related to your OAuth authorization server and token verification keys.
- Enter valid aud claims for the token. This helps validate the tokens coming from your IDP and
    allows access for tokens that contain the expected claims.

You can configure these as part of configuration of Gateway and Runtime inbound configuration.

Before configuring Microsoft Entra ID as your identity provider, we recommend completing
the basic setup steps outlined in Integrate with Google Drive using OAuth2. This ensures your
development environment and SDK are properly configured before adding identity provider
integration.

We support Microsoft Entra ID for v1.0 and v2.0 Access and ID tokens that do not have any custom
claims. You can determine which token versions your entra application is issuing by parsing the
JWT and looking at the ver claim.

Note
Multi-tenant application requirement: AgentCore currently supports only multi-tenant
Microsoft Entra applications. Single-tenant applications are not supported at this time.
When configuring your Microsoft Entra application, ensure that it is set up as a multi-
tenant application to work with AgentCore identity services.

For all token types, in your custom authorizer:

- **Discovery URL** : Discovery URL should be one of the following:
    - For v1.0 tokens use: https://login.microsoftonline.com/ _tenantId_ /.well-known/
       openid-configuration

Microsoft 503


- For v2.0 tokens use: https://login.microsoftonline.com/ _tenantId_ /v2.0/.well-
    known/openid-configuration
- **Allowed audiences** : aud should be the Application Id.

**Configurations specific for v1.0 Access Tokens**

When fetching the token from Microsoft Entra:

- Include in authorization URL a scope like _entra-application-id_ /.default alongside any
    other scopes your application might require. This allows Microsoft to know that you intend to
    use the access token against resources other than Microsoft's Graph API and will result in a token
    that can be validated by AgentCore Identity.

**Configurations Specific for v2.0 AccessTokens**

On Microsoft Entra:

- While configuring the application, go to the Application Manifest and add
    accessTokenAcceptedVersion=2.
- On the application, expose an API. The application ID URI and scopes can be whatever is
    necessary for your application; but, the scope must be included in the authorization URL when
    retrieving the access token.

**Configurations Specific for v1.0 and v2.0 Id Tokens**

On Microsoft Entra:

- While configuring the application, Enable ID Token Issuance in Application Registration.
- Include mandatory openid scope while calling the authorize and token endpoint for Microsoft
    Entra Id during Ingress Flows.

**Outbound**

To configure the outbound Microsoft resource provider, use the following:

{
"name": "NAME",

Microsoft 504


"credentialProviderVendor": "MicrosoftOAuth2",
"oauth2ProviderConfigInput": {
"microsoftOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret ",
"tenantId": " your-microsoft-entra-tenant "
}
}
}

#### Notion...................................................................................................................................................

Notion can be configured as an AgentCore Identity credential provider for outbound resource
access. This allows your agents to authenticate users through Notion's OAuth2 service and obtain
access tokens for Notion API resources.

**Outbound**

**Step 1**

Use the following procedure to set up a Notion OAuth2 application and obtain the necessary client
credentials for AgentCore Identity.

**To configure a Notion OAuth2 application**

1. Open https://www.notion.so/my-integrations.
2. Choose **+ New integration**.
3. Choose **Public integration**.
4. Provide a name for your integration.
5. Choose **Submit**.
6. On the integration details page, open the **OAuth Domain & URIs** section and add the
    following as a redirect URI:

https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/callback

7. Record the OAuth client ID and OAuth client secret as you'll need this information to configure
    the Notion resource provider in AgentCore Identity.

For more details, refer to Notion's authorization documentation.

Notion 505


**Step 2**

To configure Notion as an outbound resource provider, use the following:

{
"name": "Notion",
"credentialProviderVendor": "NotionOauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret "
}
}
}

#### Okta.......................................................................................................................................................

Okta can be configured as an AgentCore Identity credential provider for outbound resource access.
This allows your agents to authenticate users through Okta's OAuth2 service and obtain access
tokens for Okta API resources.

**Outbound**

**Step 1**

Use the following procedure to set up an Okta OAuth2 application and obtain the necessary client
credentials for AgentCore Identity.

**To configure an Okta OAuth2 application**

1. Open the Okta developer console.
2. In the left navigation bar, choose **Applications**.
3. Choose on **Create App Integration**.
4. Choose **OIDC - OpenID Connect** as the sign-in method for your application.
5. Choose **Web Application** as your application type.
6. Provide a name for your application.
7. Select **Authorization Code** and/or **Client Credentials** depending on your needs.
8. For **Sign-in redirect URIs** add the following:

Okta 506


https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/callback

9. Adjust the **Assignments** section as necessary depending on your needs.
10. Choose **Save**.
11. Record the client ID and client secret of your application, you'll need this information to
    configure the Okta resource provider in AgentCore Identity.
12. For Client credential flows the following must be performed (this can optionally be done for
    applications only being used for user federation):
    - In the left navigation bar, choose **Security**.
    - Open **API** and choose **Add Authorization Server**.
    - Follow the flow to create an authorization server dedicated to your Okta tenant.
    - Once the authorization server has been created choose the **Access Policies** tab on the
       overview page to configure an appropriate access policy.
    - Define the necessary custom scopes for the authorization server that is needed for your
       application.

For more details, refer to Okta's OAuth and OpenID Connect documentation.

**Step 2**

To configure Okta as an outbound resource provider, use the following:

{
"name": "Okta",
"credentialProviderVendor": "OktaOauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret ",
"authorizeEndpoint": "https:// your-tenant .okta.com/oauth2/ your-authorization-
server /v1/authorize",
"tokenEndpoint": "https:// your-tenant .okta.com/oauth2/ your-authorization-server /
v1/token",
"issuer": "https:// your-tenant .okta.com/oauth2/ your-authorization-server "
}
}
}

Okta 507


#### OneLogin..............................................................................................................................................

OneLogin can be configured as an AgentCore Identity credential provider for outbound resource
access. This allows your agents to authenticate users through OneLogin's OAuth2 service and
obtain access tokens for OneLogin API resources.

**Outbound**

**Step 1**

Use the following procedure to set up a OneLogin OAuth2 application and obtain the necessary
client credentials for AgentCore Identity.

**To configure a OneLogin OAuth2 application**

1. Open the OneLogin Administration panel.
2. Add a new app.
3. Search for OIDC and select the OpenId Connect app.
4. Choose a name for your application and choose **Save**.
5. On the page for the app, go to the **Configuration** tab and add the following as a redirect URI:

https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/callback

6. Open the **SSO** tab and note the client ID and client secret as you'll need these to configure the
    OneLogin app in AgentCore Identity.
7. Change the Token endpoint authentication method to **POST**.
8. Choose **Save**.

**Step 2**

To configure OneLogin as an outbound resource provider use the following:

{
"name": "OneLogin",
"credentialProviderVendor": "OneLoginOauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {
"clientId": " your-client-id ",

OneLogin 508


"clientSecret": " your-client-secret ",
"authorizeEndpoint": "https:// your-tenant .onelogin.com/oidc/2/auth",
"tokenEndpoint": "https:// your-tenant .onelogin.com/oidc/2/token",
"issuer": "https:// your-tenant .onelogin.com/oidc/2"
}
}
}

#### PingOne................................................................................................................................................

PingOne can be configured as an AgentCore Identity credential provider for outbound resource
access. This allows your agents to authenticate users through PingOne's OAuth2 service and obtain
access tokens for PingOne API resources.

**Outbound**

Note
You can only configure a PingOne OAuth2 application as either a user federation or M2M
OAuth2 client but not both.

**Step 1**

Use the following procedure to set up a PingOne OAuth2 application and obtain the necessary
client credentials for AgentCore Identity.

**To configure a PingOne OAuth2 application**

1. Sign onto the PingOne admin console.
2. In the left navigation bar, under **Applications** , choose **Application**.
3. On the page, choose the **+** icon next to **Applications** to create a new application.
4. To configure your application as a M2M OAuth2 client:
    - Select **Client Credentials** for Grant Type.
    - Select **Client Secret Post** for Token Endpoint Authentication Method.
    - Create a custom resource under Applicationsâ†’Resources in the tabs on the left side
       of the page, including a scope. Then, add that scope to the application under its

PingOne 509


personal Resources tab. Then, make sure that scope is present in the 'scopes' field of
GetResourceOauth2AccessToken.

5. To configure your application as a user federation Oauth2 client:
    - Select **Code** for Response Type.
    - Select **Authorization Code** for Grant Type.
    - Select **Client Secret Basic** for Token Endpoint Authentication Method.

For more details, refer to PingOne's API documentation.

**Step 2**

To configure PingOne as an outbound resource provider use the following:

{
"name": "PingOne",
"credentialProviderVendor": "PingOneOauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret ",
"authorizeEndpoint": "https://auth.pingone.com/ your-env-id /as/authorize",
"tokenEndpoint": "https://auth.pingone.com/ your-env-id /as/token",
"issuer": "https://auth.pingone.com/ your-env-id /as"
}
}
}

#### Reddit....................................................................................................................................................

Reddit can be configured as an AgentCore Identity credential provider for outbound resource
access. This allows your agents to authenticate users through Reddit's OAuth2 service and obtain
access tokens for Reddit API resources.

**Outbound**

**Step 1**

Use the following procedure to set up a Reddit OAuth2 application and obtain the necessary client
credentials for AgentCore Identity.

Reddit 510


**To configure a Reddit OAuth2 application**

1. Open Reddit's developer console: https://www.reddit.com/prefs/apps.
2. Choose on **create an app**.
3. Select **web app** as the application type.
4. Configure the following as the redirect URI for the application:

https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/callback

5. The client ID for the application is below the high-level summary of the application and the
    client secret is labelled **secret**. Note these values as you'll need it to configure the Reddit
    provider in AgentCore Identity.

For more details, refer to Reddit's OAuth2 documentation.

**Step 2**

To configure Reddit as an outbound resource provider, use the following:

{
"name": "Reddit",
"credentialProviderVendor": "RedditOauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret "
}
}
}

#### Salesforce.............................................................................................................................................

Salesforce can be configured as an AgentCore Identity credential provider for outbound resource
access. This allows your agents to authenticate users through Salesforce's OAuth2 service and
obtain access tokens for Salesforce API resources.

**Outbound**

**Step 1**

Salesforce 511


Use the following procedure to set up a Salesforce OAuth2 application and obtain the necessary
client credentials for AgentCore Identity.

**To configure a Salesforce OAuth2 application**

1. In the developer portal for Salesforce, create a connected app and enter the name and other
    requested information specific to your application.
2. Enable and configure the OAuth settings for the application, providing the following as the
    callback URL:
    - https://bedrock-agentcore. _region_ .amazonaws.com/identities/oauth2/
       callback
3. Choose the necessary scopes and permissions your application will need.
4. Choose **Require Proof Key for Code Exchange (PKCE) Extension for Supported Authorization**
    **Flows**.
5. Choose **Require Secret for the Web Server Flow**.
6. Choose **Enable Authorization Code and Credentials Flow**.
7. If you wish to use Salesforce as a ClientCredentials/M2M provider then choose **Enable Client**
    **Credentials Flow** and follow the prompts.
8. Save your application and copy the client ID and client secret that is issued for the application.
    You will need these to configure Salesforce in AgentCore Identity.

For more details, refer to Salesforce's documentation Define an OpenID Connect Provider.

**Step 2**

To configure the outbound Salesforce resource provider, use the following:

{
"name": "NAME",
"credentialProviderVendor": "SalesforceOauth2",
"oauth2ProviderConfigInput": {
"SalesforceOauth2ProviderConfigInput": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret ",
}
},
}

Salesforce 512


#### Slack......................................................................................................................................................

Slack can be configured as an AgentCore Identity credential provider for outbound resource access.
This allows your agents to authenticate users through Slack's OAuth2 service and obtain access
tokens for Slack API resources.

**Outbound**

**Step 1**

Use the following procedure to set up a Slack OAuth2 application and obtain the necessary client
credentials for AgentCore Identity.

**To configure a Slack OAuth2 application**

1. Create a Slack application, enter an app name, and choose the development workspace where
    the app will be built.
2. Choose the **OAuth & Permissions** section and set the following as the redirect URL for the
    application:
    - https://bedrock-agentcore. _region_ .amazonaws.com/identities/oauth2/
       callback
3. Copy the client ID and client secret that Slack issues for your application. You will need them
    for configuring the provider in AgentCore Identity.

For more details, refer to Slack's documentation Sign in with Slack.

**Step 2**

To configure the outbound Slack resource provider, use the following:

{
"name": "NAME",
"credentialProviderVendor": "SlackOauth2",
"oauth2ProviderConfigInput": {
"SlackOauth2ProviderConfigInput": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret ",
}
},

Slack 513


}

#### Spotify...................................................................................................................................................

Spotify can be configured as an AgentCore Identity credential provider for outbound resource
access. This allows your agents to authenticate users through Spotify's OAuth2 service and obtain
access tokens for Spotify API resources.

**Outbound**

**Step 1**

Use the following procedure to set up a Spotify OAuth2 application and obtain the necessary client
credentials for AgentCore Identity.

**To configure a Spotify OAuth2 application**

1. Open the developer dashboard for Spotify.
2. Choose **Create an App**.
3. Provide a name and description for your application.
4. Use the following as the **Redirect URI** for your application:

https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/callback

5. Select **Web API** for the API/SDKs that you intend to use for Spotify.
6. Choose **Save**.
7. On the application overview page, choose **Settings**.
8. On the **Basic Information** tab, record the client ID and client secret. You'll need these values
    for configuring the Spotify resource provider in AgentCore Identity.

**Step 2**

To configure Spotify as an outbound resource provider, use the following:

{
"name": "Spotify",
"credentialProviderVendor": "SpotifyOauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {

Spotify 514


"clientId": " your-client-id ",
"clientSecret": " your-client-secret "
}
}
}

#### Twitch....................................................................................................................................................

Twitch can be configured as an AgentCore Identity credential provider for outbound resource
access. This allows your agents to authenticate users through Twitch's OAuth2 service and obtain
access tokens for Twitch API resources.

**Outbound**

**Step 1**

Use the following procedure to set up a Twitch OAuth2 application and obtain the necessary client
credentials for AgentCore Identity.

**To configure a Twitch OAuth2 application**

1. Sign in to the Twitch developer console.
2. Choose the **Applications** tab and then choose **Register your Application**.
3. Set a name for your application.
4. For the **OAuth Redirect URLs** field, use the following:

https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/callback

5. Select the application category that is appropriate for the application you're developing (most
    likely this will be **Chat bot** ).
6. Set **Client Type** as **Confidential**.
7. Choose **Create**.
8. On the application details page, record the client ID and client secret as you'll need this
    information for configuring the Twitch resource provider in AgentCore Identity.

For more details, refer to Twitch's app registration documentation.

**Step 2**

Twitch 515


To configure Twitch as an outbound resource provider, use the following:

{
"name": "Twitch",
"credentialProviderVendor": "TwitchOauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret "
}
}
}

#### X.............................................................................................................................................................

X can be configured as an AgentCore Identity credential provider for outbound resource access.
This allows your agents to authenticate users through X's OAuth2 service and obtain access tokens
for X API resources.

**Outbound**

**Step 1**

Use the following procedure to set up a X OAuth2 application and obtain the necessary client
credentials for AgentCore Identity.

**To configure an X OAuth2 application**

1. Open the X developer portal.
2. In the left navigation bar, choose **Project & Apps**.
3. Choose on the X project you've created for the application.
4. Under the **Apps** header choose **Add an App**.
5. Choose **Create new**.
6. Provide a name and description for your application.
7. In the left navigation bar, choose the application that was just generated.
8. On the app details page for your new app, choose **Edit** in the User Authentication settings.
9. Select the **App permissions** necessary for your application.
10. For **Type of App** select **Web App, Automated App or Bot**.

X 516


11. Under **App Info** enter the following as the callback URL:

https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/callback

12. For **Website URL** enter the URL for your application.
13. Choose **Save**.
14. Under the **Keys and token** tab for your application, go to the **OAuth 2.0 Client ID and Client**
    **Secret**.
15. Choose **Generate** and note the client ID and secret that get generated as you'll need this
    information to configure the X resource provider in AgentCore Identity.

Note
X only displays the full client secret when it is generated, if you lose this information you'll
need to re-generate the client secret in the X developer portal.

For more details, refer to X's OAuth 2.0 documentation.

**Step 2**

To configure X as an outbound resource provider, use the following:

{
"name": "X",
"credentialProviderVendor": "XOauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret "
}
}
}

#### Yandex...................................................................................................................................................

Yandex can be configured as an AgentCore Identity credential provider for outbound resource
access. This allows your agents to authenticate users through Yandex's OAuth2 service and obtain
access tokens for Yandex API resources.

Yandex 517


**Outbound**

**Step 1**

Use the following procedure to set up a Yandex OAuth2 application and obtain the necessary client
credentials for AgentCore Identity.

**To configure a Yandex OAuth2 application**

1. Open the developer console for Yandex at https://oauth.yandex.com/.
2. Choose **Create app**.
3. Provide a name for your application.
4. For platforms, select **Web services**.
5. Choose **Save and Continue**.
6. Select the permissions necessary for your application and then choose **Save and Continue**.
7. Configure the following as the redirect URI for the application:

https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/callback

8. Choose **Save and Continue**.
9. Once the client has been created, note the client ID and client secret assigned to your
    application as you'll need them for configuring the Yandex provider in AgentCore Identity.

For more details, refer to Yandex's OAuth documentation.

**Step 2**

To configure Yandex as an outbound resource provider, use the following:

{
"name": "Yandex",
"credentialProviderVendor": "YandexOauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret "
}
}

Yandex 518


}

#### Zoom.....................................................................................................................................................

Zoom can be configured as an AgentCore Identity credential provider for outbound resource access.
This allows your agents to authenticate users through Zoom's OAuth2 service and obtain access
tokens for Zoom API resources.

**Outbound**

Note
You can only configure a Zoom OAuth2 application as either a user federation or M2M
OAuth2 client but not both.

**Step 1**

Use the following procedure to set up a Zoom OAuth2 application and obtain the necessary client
credentials for AgentCore Identity.

**To configure a Zoom OAuth2 application**

1. Sign in to the Zoom App Marketplace.
2. Choose **Develop** > **Build App**.
3. For a user federation app, select **General app** and choose **Create**.
    - On the app details page, add a name for your application and select how your application
       will be managed.
    - In the **OAuth Information** section, for both the OAuth Redirect URL and OAuth Allow Lists
       sections, use the following as the redirect URL for the application:

https://bedrock-agentcore. region .amazonaws.com/identities/oauth2/callback

4. For a M2M app, select **Server to Server OAuth App** and choose **Create**.
    - Add a name for your application.
    - On the app details page, choose **Scopes** and add the necessary scopes for your application.

Zoom 519


- Open **Information** and provide a company name, and developer contact information.
5. Record the client ID and client secret that have been generated for your application. You'll
need these values to configure the Zoom credential provider in AgentCore Identity.

For more details, refer to Zoom's integration documentation.

**Step 2**

To configure Zoom as an outbound resource provider, use the following:

{
"name": "Zoom",
"credentialProviderVendor": "ZoomOauth2",
"oauth2ProviderConfigInput" : {
"includedOauth2ProviderConfig": {
"clientId": " your-client-id ",
"clientSecret": " your-client-secret "
}
}
}

### Data protection in Amazon Bedrock AgentCore Identity

The AWS shared responsibility model applies to data protection in Amazon Bedrock AgentCore
Identity. As described in this model, AWS is responsible for protecting the global infrastructure that
runs all of the AWS Cloud. You are responsible for maintaining control over your content that is
hosted on this infrastructure. This content includes the security configuration and management
tasks for the AWS services that you use. For more information about data privacy, see the Data
Privacy FAQ.

For data protection purposes, we recommend that you protect AWS account credentials and set up
individual user accounts with IAM. That way each user is given only the permissions necessary to
fulfill their job duties. We also recommend that you secure your data in the following ways:

- Use multi-factor authentication (MFA) with each account.
- Use SSL/TLS to communicate with AWS resources.
- Set up API and user activity logging with AWS CloudTrail.
- Use AWS encryption solutions, along with all default security controls within AWS services.

Data protection 520


- Use advanced managed security services such as Amazon Macie, which assists in discovering and
    securing personal data that is stored in Amazon S3.

We strongly recommend that you never put sensitive identifying information, such as your
customers' account numbers, into free-form fields such as a **Name** field. This includes when you
work with Amazon Bedrock AgentCore Identity or other AWS services using the console, API,
AWS CLI, or AWS SDKs. Any data that you enter into Amazon Bedrock AgentCore Identity or
other services might get picked up for inclusion in diagnostic logs. When you provide a URL to an
external server, don't include credentials information in the URL to validate your request to that
server.

**Topics**

- Data encryption
- Set customer managed key policy
- Configure with API operations or an AWS SDK

#### Data encryption..................................................................................................................................

Data encryption typically falls into two categories: encryption at rest and encryption in transit.

**Encryption at rest**

Data within Amazon Bedrock AgentCore Identity is encrypted at rest in accordance with industry
standards.

By default, Amazon Bedrock AgentCore Identity encrypts customer data in token vaults with AWS
owned keys. You can also configure your token vaults to instead encrypt your information with
customer managed keys.

**AWS owned key**

Amazon Bedrock AgentCore Identity encrypts the data in your token vault with an AWS owned
KMS key. Keys of this type aren't visible in AWS KMS.

**Customer managed key**

Amazon Bedrock AgentCore Identity encrypts the data in your token vault with a customer
managed key. You own the administration of customer managed key policies, rotation, and
scheduled deletion.

Data encryption 521


**Things to know about token vault encryption with customer managed keys**

- Data in your token vault (access tokens) are encrypted at rest with the customer managed key
    you configure. The token vault ARN is captured in the EncryptionContext.
- All customer data in your token vault is encrypted at rest, even if you take no action to configure
    encryption settings.
- You can't configure token vault encryption at rest with multi-Region keys or asymmetric keys.
    Amazon Bedrock AgentCore Identity supports only single-region symmetric KMS keys for token
    vault encryption at rest.
- You can configure token vault encryption only with a KMS key ARN, not an alias.
- You can configure CMK for credential provider secrets using AWS Secrets Manager. Learn more.

The following procedures configure encryption at rest in your token vault. For more information
about KMS key policies that delegate access to AWS services like Amazon Cognito, see Permissions
for AWS services in key policies.

#### Set customer managed key policy..................................................................................................

Note
Currently we don't support configuring CMK on token vault through console.

To use a customer managed key, your key must trust an Amazon Bedrock AgentCore Identity
service principal to perform encryption and decryption operations on the key. Configure the key
policy of your KMS key as shown in the following example. The IAM principal that writes this policy
must have write access to your KMS key, with kms:PutKeyPolicy permission.

#### Configure with API operations or an AWS SDK...........................................................................

Set your key configuration in a SetTokenVaultCMK API request. The following partial example
request body sets the token vault to use the provided customer managed key.

"KmsConfiguration": {
"KeyType": "CUSTOMER_MANAGED_KEY",
"KmsKeyArn": "arn:aws:kms:us-east-1:111122223333:key/a1b2c3d4-5678-90ab-cdef-
EXAMPLE22222"

Set customer managed key policy 522


}

The following partial example request body sets a token vault to use an AWS owned key.

"KmsConfiguration": {
"KeyType": "AWS_OWNED_KEY"
}

If your GetTokenVault response doesn't include a KmsConfiguration parameter, your token
vault is configured to encrypt data at rest with an AWS owned key.

### Tagging AgentCore Identity resources

Amazon Bedrock AgentCore Identity supports comprehensive tagging capabilities across its
resource hierarchy to enable better resource management, cost allocation, access control, and
operational visibility. For general information about tags, including syntax and usage, see Tagging
AgentCore resources.

#### Benefits of tagging AgentCore Identity resources.......................................................................

Tags help you accomplish the following key objectives with your AgentCore Identity resources:

**Identify and organize AWS resources**

Many AWS services support tagging, allowing you to assign the same tag to resources from
different services. This helps indicate which resources are related. You could assign the same tag
to a workload identity that you assign to an DynamoDB table or Lambda function that uses those
credentials.

**Example scenario** : Tag all resources for a customer service application with
Application=customer-service-bot to easily identify and manage related resources across
different AWS services, as shown in the following sample code.

{
"name": "customer-service-workload-identity",
"tags": {
"Application": "customer-service-bot",
"Component": "authentication",
"Owner": "customer-experience-team"

Identity resource tagging 523


}
}

**Track AWS costs**

You can activate cost allocation tags on the AWS Billing and Cost Management dashboard. AWS
uses these tags to categorize your costs and deliver a monthly cost allocation report. This enables
you to:

- Allocate identity service costs to specific projects or teams
- Track spending patterns across different environments
- Optimize costs based on usage analysis

**Example scenario** : Use CostCenter=ai-platform and Project=bedrock-agents tags to
track how much your AI platform team spends on identity services for the Bedrock agents project,
as shown in the following sample code.

{
"name": "customer-service-workload-identity",
"tags": {
"CostCenter": "ai-platform",
"Project": "bedrock-agents",
"Environment": "production",
"Team": "customer-experience"
}
}

**Control access based on tags**

You can control access by specifying tag keys and values in the conditions for IAM policies. This
enables attribute-based access control (ABAC) where permissions are granted based on resource
tags.

**Example scenario** : Allow a user to access workload identities only if they have an Owner tag with a
value matching the user's team name, or restrict access to production credential providers based on
Environment=production tags, as shown in the following sample code.

{
"Version": "2012-10-17",

Benefits of tagging AgentCore Identity resources 524


"Statement": [
{
"Effect": "Allow",
"Action": [
"bedrock-agentcore:GetWorkloadIdentity",
"bedrock-agentcore:UpdateWorkloadIdentity"
],
"Resource": "*",
"Condition": {
"StringEquals": {
"bedrock-agentcore:ResourceTag/Owner": "${aws:PrincipalTag/Team}"
}
}
}
]
}

#### Resource architecture........................................................................................................................

Amazon Bedrock AgentCore Identity manages five distinct resource types organized in a
hierarchical structure:

**Primary resources**

The following are the primary resources in the AgentCore Identity service hierarchy:

- **Workload Identity Directory** : arn:aws:bedrock-agentcore:${Region}:
    ${Account}:workload-identity-directory/default
- **Token Vault** : arn:aws:bedrock-agentcore:${Region}:${Account}:token-vault/
    default

**Sub-resources**

The following are the sub-resources that exist within the primary resource hierarchy:

- **Workload Identity** : arn:aws:bedrock-agentcore:${Region}:${Account}:workload-
    identity-directory/default/workload-identity/${workload identity name}
- **OAuth2 Credential Provider** : arn:aws:bedrock-agentcore:${Region}:
    ${Account}:token-vault/default/oauth2credentialprovider/
    ${oauth2CredentialProviderName}

Resource architecture 525


- **API Key Credential Provider** : arn:${Partition}:bedrock-agentcore:
    ${Region}:${Account}:token-vault/default/apikeycredentialprovider/
    ${APIkeyCredentialproviderName}

#### Tagging support matrix.....................................................................................................................

The following table shows the tagging capabilities for each AgentCore Identity resource type:

**Tagging support for AgentCore Identity resources**

Resource Type Tag on Create Basic Tagging TBAC Support

Workload Identity # # #

OAuth2 Credential Provider # # #

API Key Credential Provider # # #

Workload Identity Directory # # #

Token Vault # # #

Note
TBAC (Tag-Based Access Control) support means you can use resource tags in IAM policy
conditions to control access to these resources.

Tagging support matrix 526


## Use Amazon Bedrock AgentCore built-in tools to interact

## with your applications

Amazon Bedrock AgentCore provides several built-in tools to enhance your development and
testing experience. These tools are designed to help you interact with your application in various
ways, providing capabilities for code execution and web browsing within the Amazon Bedrock
AgentCore environment.

Built-in tools are a key component of Amazon Bedrock AgentCore, allowing you to enhance agents
by adding hosted capabilities such as browser use and code execution. You can execute your code
in a secure environment. This is critical in Agentic AI applications where the agents may execute
arbitrary code that can lead to data compromise or security risks.

These tools are fully managed by Amazon Bedrock AgentCore, eliminating the need to set up and
maintain your own tool infrastructure.

### Built-in Tools Overview..........................................................................................................................

Amazon Bedrock AgentCore offers the following built-in tools:

Code Interpreter

A secure environment for executing code and analyzing data. The Amazon Bedrock AgentCore
Code Interpreter supports multiple programming languages including Python, TypeScript,
and JavaScript, allowing you to process data and perform calculations within the AgentCore
environment.

Browser Tool

A secure, isolated browser environment that allows you to interact with and test web
applications while minimizing potential risks to your system, access online resources, and
perform web-based tasks.

These built-in tools are part of AgentCore's build phase, alongside other components such as
Memory, Gateways, and Identity. They provide secure, managed capabilities that can be integrated
into your agents without requiring additional infrastructure setup.

Built-in Tools Overview 527


#### Security and Access Control.............................................................................................................

Built-in tools in Amazon Bedrock AgentCore are designed with security in mind. They provide:

- Isolated execution environments to help prevent cross-contamination
- Configurable session timeouts to limit resource usage
- Integration with IAM for access control
- Network security controls to help restrict external access

#### Key components.................................................................................................................................

The built-in tools are designed with a secure, scalable architecture that integrates with the broader
AgentCore services. Each tool operates within its own isolated environment to support security and
resource management.

Tool Resources

The base configuration for a tool, including network settings, permissions, and feature
configuration. Tool resources are created once and can be used for multiple sessions.

Sessions

Temporary runtime environments created from tool resources. Sessions have a defined lifecycle
and timeout period, and they maintain state during their lifetime.

APIs

Each tool provides APIs for creating and managing tool resources, starting and stopping
sessions, and interacting with the tool's functionality.

#### Integrating built-in tools with Agents...........................................................................................

Built-in tools can be integrated with your agents to enhance their capabilities. The integration
process involves:

1.Creating a tool resource (Code Interpreter or Browser Tool) or using a system resource

2.Creating a session to interact with the tool

3.Using the tool's API to perform operations

4.Terminating the session when finished

Security and Access Control 528


### Execute code and analyze data using Amazon Bedrock

### AgentCore Code Interpreter

The Amazon Bedrock AgentCore Code Interpreter enables AI agents to write and execute code
securely in sandbox environments, enhancing their accuracy and expanding their ability to solve
complex end-to-end tasks. This is critical in Agentic AI applications where the agents may execute
arbitrary code that can lead to data compromise or security risks. The AgentCore Code Interpreter
tool provides secure code execution, which helps you avoid running into these issues.

The Code Interpreter comes with pre-built runtimes for multiple languages and advanced features,
including large file support and internet access, and CloudTrail logging capabilities. For inline
upload, the file size can be up to 100 MB. And for uploading to Amazon S3 through terminal
commands, the file size can be as large as 5 GB.

Developers can customize environments with session properties and network modes to meet their
enterprise and security requirements. The AgentCore Code Interpreter reduces manual intervention
while enabling sophisticated AI development without compromising security or performance.

#### Overview...............................................................................................................................................

The AgentCore Code Interpreter is a capability that allows AI agents to write, execute, and
debug code securely in sandbox environments. It provides a bridge between natural language
understanding and computational execution, enabling agents to manipulate data and perform
calculations programmatically.

The AgentCore Code Interpreter runs in a containerized environment within Amazon Bedrock
AgentCore, ensuring that code execution remains isolated and secure.

AgentCore Code Interpreter: Execute code and analyze data 529


#### Why use Code Interpreter in agent development.......................................................................

The AgentCore Code Interpreter enhances agent development in the following ways:

- Execute code securely: Develop agents that can perform complex workflows and data analysis in
    isolated sandbox environments, while accessing internal data sources without exposing sensitive
    data or compromising security.
- Multiple programming languages: The Code Interpreter supports various programming
    languages including Python, JavaScript, and TypeScript, making it versatile for different use
    cases.
- Monitoring and large-scale data processing: Track and troubleshoot code execution. When
    working with large datasets, you can easily reference files stored in Amazon S3, enabling
    efficient processing of gigabyte-scale data without API limitations.
- Ease of use: Use a fully managed default mode with pre-built execution runtimes that support
    popular programming languages with common libraries pre-installed.
- Extends problem-solving capabilities: Allows agents to solve computational problems that are
    difficult to address through reasoning alone and enables precise mathematical calculations and
    data processing at scale.
- Long execution duration support: The Code Interpreter tool provides support for a default
    execution time of 15 minutes, which can be extended for up to eight hours.
- Handles structured data: Processes CSV, Excel, JSON, and other data formats, and performs data
    cleaning, and analysis.
- Enables complex workflows: Allows multi-step problem solving that combines reasoning with
    computation and facilitates iterative development and debugging.

The AgentCore Code Interpreter makes agents more powerful by complementing their reasoning
abilities with computational execution, allowing them to tackle a much wider range of tasks
effectively.

#### Best practices......................................................................................................................................

To get the most out of the AgentCore Code Interpreter:

- Keep code snippets concise and focused on specific tasks
- Use comments to document your code

Why use Code Interpreter in agent development 530


- Optimize code for performance when working with large datasets
- Save intermediate results when performing complex operations
- Use the code_session context manager to ensure proper cleanup
- Include try/except blocks in code to handle errors gracefully
- Code execution results are returned and processed as streams
- Clean up temporary files when no longer needed
- Close sessions when you're done to release resources

#### Pre-installed libraries.........................................................................................................................

The AgentCore Code Interpreter comes with a comprehensive set of pre-installed Python libraries
to support various data analysis, machine learning, and development tasks. These libraries are
available immediately without requiring additional installation.

**Data Analysis and Visualization**

**Data Analysis and Visualization libraries**

Library Description

pandas Data manipulation and analysis

numpy Numerical computing

matplotlib Plotting and visualization

matplotlib-inline Matplotlib backend for Jupyter

matplotlib-venn Venn diagram plotting

plotly Interactive visualizations

bokeh Interactive visualization library

scipy Scientific computing

statsmodels Statistical modeling

sympy Symbolic mathematics

Pre-installed libraries 531


Library Description

numba Just-in-time compilation for numerical functions

pyarrow Columnar data processing

numexpr Fast numerical expression evaluator

mizani Scales for Python graphics

contourpy Contour line generation

cycler Composable style cycles

fonttools Font manipulation library

kiwisolver Constraint solver

pyparsing Parsing library

python-dateutil Date/time utilities

pytz Timezone definitions

tzdata Timezone data

patsy Statistical model specification

threadpoolctl Thread pool control

joblib Parallel computing utilities

mpmath Arbitrary-precision arithmetic

llvmlite LLVM binding for Numba

Pre-installed libraries 532


**Machine Learning and AI**

**Machine Learning and AI libraries**

Library Description

scikit-learn Machine learning algorithms

scikit-image Image processing

torch PyTorch deep learning framework

torchvision Computer vision for PyTorch

torchaudio Audio processing for PyTorch

xgboost Gradient boosting framework

openai OpenAI API client

spacy Natural language processing

spacy-legacy Legacy components for spaCy

spacy-loggers Logging utilities for spaCy

nltk Natural language toolkit

textblob Text processing

catalogue Tiny library for function registries

confection Configuration system

cymem Memory management for Cython

murmurhash Cython bindings for MurmurHash

preshed Cython hash tables

srsly Serialization utilities

Pre-installed libraries 533


Library Description

thinc Machine learning library

wasabi Lightweight console printing

weasel Command-line interface for spaCy projects

blis BLAS-like linear algebra library

langcodes Language code utilities

language_data Language data for langcodes

marisa-trie Trie data structure

absl-py Abseil Python common libraries

mcp Model Context Protocol

**Mathematical and Optimization**

**Mathematical and Optimization libraries**

Library Description

cvxpy Convex optimization

ortools Operations research tools

pulp Linear programming

galois Galois field arithmetic

z3-solver Theorem prover

python_constraint2 Constraint satisfaction problems

gapstatistics Gap statistic for clustering

oeis Online Encyclopedia of Integer Sequences

Pre-installed libraries 534


Library Description

networkx Network analysis

igraph Graph analysis and visualization

**Web and API Development**

**Web and API Development libraries**

Library Description

requests HTTP library

beautifulsoup4 Web scraping

fastapi Modern web framework

Flask Lightweight web framework

Flask-Cors Cross-origin resource sharing for Flask

Flask-Login User session management for Flask

Django Full-featured web framework

httpx Async HTTP client

httpcore HTTP core library

starlette ASGI framework

uvicorn ASGI server

gunicorn WSGI HTTP server

Hypercorn ASGI server

asgiref ASGI reference implementation

Werkzeug WSGI utility library

Pre-installed libraries 535


Library Description

Jinja2 Template engine

MarkupSafe Safe string handling

itsdangerous Cryptographic signing

blinker Signal/event dispatching

click-plugins Click plugin system

tornado Web framework and async networking

sqlparse SQL parser

greenlet Lightweight coroutines

aiosignal Async signal dispatching

anyio Async compatibility layer

certifi Certificate bundle

dnspython DNS toolkit

email_validator Email validation

frozenlist Immutable list implementation

h11 HTTP/1.1 protocol implementation

h2 HTTP/2 protocol implementation

hpack HTTP/2 header compression

httptools Fast HTTP parsing

hyperframe HTTP/2 framing layer

idna Internationalized domain names

Pre-installed libraries 536


Library Description

multidict Multi-value dictionary

priority HTTP/2 priority tree

python-dotenv Environment variable management

python-multipart Multipart form data parser

shellingham Shell detection library

sniffio Async library detection

sse-starlette Server-sent events for Starlette

urllib3 HTTP client library

uvloop Fast event loop for asyncio

watchfiles File watching library

wsproto WebSocket protocol implementation

yarl URL parsing library

**Cloud and Database**

**Cloud and Database libraries**

Library Description

boto3 AWS SDK for Python (boto3)

duckdb In-process SQL database

SQLAlchemy SQL toolkit and ORM

pymongo MongoDB driver

redis Redis client

Pre-installed libraries 537


Library Description

psycopg2-binary PostgreSQL adapter

**File Processing and Documents**

**File Processing and Documents libraries**

Library Description

openpyxl Excel file processing

xlrd Excel file reading

XlsxWriter Excel file writing

pyxlsb Excel binary format reader

et-xmlfile XML file handling for openpyxl

PyPDF2 PDF processing

pdfplumber PDF text extraction

pdf2image PDF to image conversion

pdfkit HTML to PDF conversion

pypdfium2 PDF processing library

pdfminer.six PDF text extraction

pdfrw PDF reader/writer

python-docx Word document processing

docx2txt Word document text extraction

reportlab PDF generation

fpdf Simple PDF generation

Pre-installed libraries 538


Library Description

rarfile RAR archive processing

xml-python XML processing

svglib SVG to PDF/bitmap conversion

svgwrite SVG creation library

proglog Progress logging

lazy_loader Lazy module loading

**Image and Media Processing**

**Image and Media Processing libraries**

Library Description

pillow Image processing

opencv-python Computer vision

imageio Image I/O

imageio-ffmpeg FFmpeg plugin for imageio

moviepy Video editing

ffmpeg-python FFmpeg wrapper

ffmpy FFmpeg wrapper

pydub Audio manipulation

gtts Google Text-to-Speech

mutagen Audio metadata handling

Wand ImageMagick binding

Pre-installed libraries 539


Library Description

imgkit HTML to image conversion

pypng PNG image processing

PyWavelets Wavelet transforms

tifffile TIFF file processing

**Development Tools and Utilities**

**Development Tools and Utilities libraries**

Library Description

pydantic Data validation using type hints

pydantic-settings Settings management for Pydantic

pydantic_core Core validation logic for Pydantic

jsonschema JSON schema validation

PyYAML YAML processing

orjson Fast JSON library

ujson Ultra fast JSON encoder/decoder

click Command line interface creation

typer Modern CLI framework

tqdm Progress bars

loguru Logging library

rich Rich text and beautiful formatting

ipython Interactive Python shell

Pre-installed libraries 540


Library Description

Faker Fake data generation

qrcode QR code generation

retrying Retry decorator

tenacity Retry library

backoff Backoff and retry

more_itertools Additional iterator tools

cryptography Cryptographic recipes and primitives

bcrypt Password hashing

PyNaCl Networking and Cryptography library

pyOpenSSL OpenSSL wrapper

cffi C Foreign Function Interface

pycparser C parser in Python

annotated-types Reusable constraint types

typing_extensions Backported typing features

typing_inspection Runtime inspection of typing

astor AST to source code converter

asttokens Annotate AST with source tokens

executing Get currently executing AST node

pure-eval Safe evaluation of expressions

stack-data Extract data from stack frames

Pre-installed libraries 541


Library Description

decorator Decorator utilities

entrypoints Discover entry points

jedi Code completion library

parso Python parser

prompt_toolkit Interactive command line toolkit

traitlets Configuration system

wcwidth Terminal width calculation

Pygments Syntax highlighting

mdurl URL utilities for Markdown

texttable Text table formatting

xyzservices Source of XYZ tile services

attrs Classes without boilerplate

cachetools Extensible memoizing collections

cloudpathlib Cloud storage path library

cloudpickle Pickle for cloud computing

distro Linux distribution information

filelock Platform independent file locking

fsspec Filesystem specification

future Python 2/3 compatibility

httpx-sse Server-sent events for HTTPX

Pre-installed libraries 542


Library Description

importlib_metadata Library metadata access

importlib_resource
s

Resource access for packages

jsonschema-specifi
cations

JSON Schema specifications

packaging Core utilities for Python packages

pexpect Expect-like subprocess control

platformdirs Platform-specific directories

ptyprocess Pseudoterminal utilities

referencing JSON reference resolution

rpds-py Persistent data structures

six Python 2/3 compatibility utilities

smart-open Utils for streaming large files

zipp Backport of pathlib-compatible object wrapper

**Text and Markup Processing**

**Text and Markup Processing libraries**

Library Description

markdown-it-py Markdown parser

markdown2 Markdown processor

markdownify HTML to Markdown converter

Pre-installed libraries 543


Library Description

lxml XML and HTML processing

cssselect2 CSS selector implementation

tinycss2 CSS parser

webencodings Character encoding for web

soupsieve CSS selector library

regex Alternative regular expression module

chardet Character encoding detection

charset-normalizer Character encoding detection

**Geospatial and Mapping**

**Geospatial and Mapping libraries**

Library Description

shapely Geometric objects manipulation

pyshp Shapefile library

branca HTML/JS template library for maps

For a complete list of all pre-installed libraries with their specific versions, you can run the
following code in your Code Interpreter session:

import pkg_resources
installed_packages = [d for d in pkg_resources.working_set]
for package in sorted(installed_packages, key=lambda x: x.project_name.lower()):
print(f"{package.project_name}=={package.version}")

Pre-installed libraries 544


#### Get started with AgentCore Code Interpreter..............................................................................

AgentCore Code Interpreter enables your agents to execute Python code in a secure, managed
environment. The agent can perform calculations, analyze data, generate visualizations, and
validate answers through code execution.

This page covers the prerequisites and provides two approaches to get started:

- **Using AWS Strands** - A high-level agent framework that simplifies building AI agents with built-
    in tool integration, conversation management, and automatic session handling.
- **Direct usage** - SDK and Boto3 approaches that provide more control over session management
    and code execution for custom implementations.

**Topics**

- Prerequisites
- Configuring your credentials
- Using AgentCore Code Interpreter via AWS Strands
- Using AgentCore Code Interpreter directly

**Prerequisites**

Before you start, ensure you have:

- AWS account with credentials configured. See Configuring your credentials.
- Python 3.10+ installed
- Boto3 installed. See Boto3 documentation.
- IAM execution role with the required permissions. See Configuring your credentials.
- Model access: Anthropic Claude Sonnet 4.0 enabled in the Amazon Bedrock console. For
    information about using a different model with the Strands Agents see the _Model Providers_
    section in the Strands Agents SDK documentation.
- AWS Region where Amazon Bedrock AgentCore is available. See AWS Regions.

Get started with AgentCore Code Interpreter 545


**Configuring your credentials**

Perform the following steps to configure your AWS credentials and attach the required
permissions.

1. **Verify your AWS credentials**

Confirm your AWS credentials are configured:

aws sts get-caller-identity

Note
Take note of the user or credentials returned here, as you'll be using it when attaching
the required permissions.

If this command fails, configure your credentials. For more information, see Configuration and
credential file settings in the AWS CLI.

2. **Attach required permissions**

Your IAM user or role needs permissions to use AgentCore Code Interpreter. Attach this policy
to your IAM identity:

Note
Replace with your chosen region (for example, us-west-2) and
<account_id> with your AWS account ID in the policy below:

{
"Version":"2012-10-17", &TCX5-2025-waiver;
"Statement": [
{
"Sid": "BedrockAgentCoreCodeInterpreterFullAccess",
"Effect": "Allow",
"Action": [
"bedrock-agentcore:CreateCodeInterpreter",
Get started with AgentCore Code Interpreter 546


"bedrock-agentcore:StartCodeInterpreterSession",
"bedrock-agentcore:InvokeCodeInterpreter",
"bedrock-agentcore:StopCodeInterpreterSession",
"bedrock-agentcore:DeleteCodeInterpreter",
"bedrock-agentcore:ListCodeInterpreters",
"bedrock-agentcore:GetCodeInterpreter",
"bedrock-agentcore:GetCodeInterpreterSession",
"bedrock-agentcore:ListCodeInterpreterSessions"
],
"Resource": "arn:aws:bedrock-agentcore::<account_id>:code-
interpreter/*"
}
]
}

**To attach this policy**

Follow these steps:

1. Go to the IAM console.
2. Find your user or role from the response returned for the get-caller-identity API
    operation.
3. Choose **Add permissions** and then choose **Create inline policy**
4. Switch to JSON view and paste the policy above
5. Name it AgentCoreCodeInterpreterAccess and save

Note
If you're deploying agents to Amazon Bedrock AgentCore Runtime, you'll also eed to create
an IAM execution role with a service trust policy. For more information, see Get started with
AgentCore Runtime.

The following sections show you how to use the Amazon Bedrock AgentCore Code Interpreter with
and without the agent framework. Using the Code Interpeter directly without an agent framework
is especially useful when you want to execute specific code snippets programmatically.

**Topics**

Get started with AgentCore Code Interpreter 547


- Using AgentCore Code Interpreter via AWS Strands
- Using AgentCore Code Interpreter directly

**Using AgentCore Code Interpreter via AWS Strands**

The following sections show you how to use the Amazon Bedrock AgentCore Code Interpreter with
the Strands SDK. Before you go through the examples in this section, see Prerequisites.

**Topics**

- Step 1: Install dependencies
- Step 2: Create your agent with AgentCore Code Interpreter
- Step 3: Run the agent

**Step 1: Install dependencies**

Create a project folder and install the required packages:

Note
On Windows, use: .venv\Scripts\activate

mkdir agentcore-tools-quickstart
cd agentcore-tools-quickstart
python3 -m venv .venv
source .venv/bin/activate

Install the required packages:

pip install bedrock-agentcore strands-agents strands-agents-tools

These packages provide:

- bedrock-agentcore: The SDK for Amazon Bedrock AgentCore tools including AgentCore Code
    Interpreter
- strands-agents: The Strands agent framework
- strands-agents-tools: The tools that the Strands agent framework offers

Get started with AgentCore Code Interpreter 548


**Step 2: Create your agent with AgentCore Code Interpreter**

Create a file named code_interpreter_agent.py and add the following code:

from strands import Agent
from strands_tools.code_interpreter import AgentCoreCodeInterpreter

Initialize the Code Interpreter tool
code_interpreter_tool = AgentCoreCodeInterpreter(region="")

Define the agent's system prompt
SYSTEM_PROMPT = """You are an AI assistant that validates answers through code
execution.
When asked about code, algorithms, or calculations, write Python code to verify your
answers."""

Create an agent with the Code Interpreter tool
agent = Agent(
tools=[code_interpreter_tool.code_interpreter],
system_prompt=SYSTEM_PROMPT
)

Test the agent with a sample prompt
prompt = "Calculate the first 10 Fibonacci numbers."
print(f"\n\nPrompt: {prompt}\n\n")

response = agent(prompt)
print(response.message["content"][0]["text"])

This code:

- Initializes the AgentCore Code Interpreter tool for your region
- Creates an agent configured to use code execution for validation
- Sends a prompt asking the agent to calculate Fibonacci numbers
- Prints the agent's response

**Step 3: Run the agent**

Execute the script:

python code_interpreter_agent.py

Get started with AgentCore Code Interpreter 549


**Expected output**

You should see the agent's response containing the first 10 Fibonacci numbers. The agent will write
Python code to calculate the sequence and return both the code and the results.

If you encounter errors, verify:

- Your IAM role has the correct permissions and trust policy
- You have model access enabled in the Amazon Bedrock console
- Your AWS credentials are properly configured

**Using AgentCore Code Interpreter directly**

The following sections show you how to use the Amazon Bedrock AgentCore Code Interpreter
directly without an agent framework. This is especially useful when you want to execute specific
code snippets programmatically. Before you go through the examples in this section, see
Prerequisites.

**Topics**

- Step 1: Choose your approach and install dependencies
- Step 2: Execute code

**Step 1: Choose your approach and install dependencies**

Amazon Bedrock AgentCore provides two ways to interact with AgentCore Code Interpreter: using
the high-level SDK client or using boto3 directly.

- **SDK Client** : The bedrock_agentcore SDK provides a simplified interface that handles session
    management details. Use this approach for most applications.
- **Boto3 Client** : The AWS SDK gives you direct access to the AgentCore Code Interpreter API
    operations. Use this approach when you need fine-grained control over session configuration or
    want to integrate with existing boto3-based applications.

Create a project folder (if you didn't create one before) and install the required packages:

mkdir agentcore-tools-quickstart
cd agentcore-tools-quickstart
python3 -m venv .venv

Get started with AgentCore Code Interpreter 550


source .venv/bin/activate

On Windows, use: .venv\Scripts\activate

Install the required packages:

pip install bedrock-agentcore boto3

These packages provide:

- bedrock-agentcore: The SDK for Amazon Bedrock AgentCore tools including AgentCore Code
    Interpreter
- boto3: AWS SDK for Python (Boto3) to create, configure, and manage AWS services

**Step 2: Execute code**

Choose one of the following approaches to execute code with AgentCore Code Interpreter:

Note
Replace with your actual AWS Region (for example, us-east-1 or us-west-2).

SDK Client

Create a file named direct_code_execution_sdk.py and add the following code:

from bedrock_agentcore.tools.code_interpreter_client import CodeInterpreter
import json

Initialize the Code Interpreter client for your region
code_client = CodeInterpreter('')

Start a Code Interpreter session
code_client.start()

try:

Execute Python code
response = code_client.invoke("executeCode", {
"language": "python",
"code": 'print("Hello World!!!")'

Get started with AgentCore Code Interpreter 551


})

Process and print the response
for event in response["stream"]:
print(json.dumps(event["result"], indent=2))

finally:

Always clean up the session
code_client.stop()

This code:

- Creates a AgentCore Code Interpreter client for your region
- Starts a session (required before executing code)
- Executes Python code and streams the results with full event details
- Stops the session to clean up resources

Run the script

Execute the following command:

python direct_code_execution_sdk.py

Expected output

You should see a JSON response containing the execution result with Hello World!!! in the
output content.

Boto3

Create a file named direct_code_execution_boto3.py and add the following code:

import boto3
import json

Code to execute
code_to_execute = """
print("Hello World!!!")
"""

Initialize the bedrock-agentcore client
client = boto3.client(

Get started with AgentCore Code Interpreter 552


"bedrock-agentcore",
region_name=""
)

Start a Code Interpreter session
session_response = client.start_code_interpreter_session(
codeInterpreterIdentifier="aws.codeinterpreter.v1",
name="my-code-session",
sessionTimeoutSeconds=900
)
session_id = session_response["sessionId"]

print(f"Started session: {session_id}\n\n")

try:

Execute code in the session
execute_response = client.invoke_code_interpreter(
codeInterpreterIdentifier="aws.codeinterpreter.v1",
sessionId=session_id,
name="executeCode",
arguments={
"language": "python",
"code": code_to_execute
}
)

Extract and print the text output from the stream
for event in execute_response['stream']:
if 'result' in event:
result = event['result']
if 'content' in result:
for content_item in result['content']:
if content_item['type'] == 'text':
print(content_item['text'])

finally:

Stop the session when done
client.stop_code_interpreter_session(
codeInterpreterIdentifier="aws.codeinterpreter.v1",
sessionId=session_id
)
print(f"\n\nStopped session: {session_id}")

Get started with AgentCore Code Interpreter 553


This code:

- Creates a boto3 client for the bedrock-agentcore service
- Starts a AgentCore Code Interpreter session with a 900-second timeout
- Executes Python code using the session ID
- Parses the streaming response to extract text output
- Properly stops the session to release resources

The boto3 approach requires explicit session management. You must
call start_code_interpreter_session before executing code and
stop_code_interpreter_session when finished.

Run the script

Execute the following command:

python direct_code_execution_boto3.py

Expected output

You should see Hello World!!! printed as the result of the code execution, along with the
session ID information.

#### Run code in Code Interpreter from Agents

You can build agents that use the Code Interpreter tool to execute code and analyze data. This
section demonstrates how to build agents using different frameworks.

Strands

You can build an agent that uses the Code Interpreter tool using the Strands framework:

Install dependencies

Run the following commands to install the required packages:

pip install strands-agents
pip install bedrock-agentcore

Run code from agents 554


Write an agent with Code Interpreter tool

The following Python code shows how to write an agent using Strands with the Code
Interpreter tool:

strands_ci_agent.py
import json
from strands import Agent, tool
from bedrock_agentcore.tools.code_interpreter_client import code_session
import asyncio

#Define the detailed system prompt for the assistant
SYSTEM_PROMPT = """You are a helpful AI assistant that validates all answers through
code execution.

VALIDATION PRINCIPLES:

1. When making claims about code, algorithms, or calculations - write code to verify
them
2. Use execute_python to test mathematical calculations, algorithms, and logic
3. Create test scripts to validate your understanding before giving answers
4. Always show your work with actual code execution
5. If uncertain, explicitly state limitations and validate what you can

APPROACH:

- If asked about a programming concept, implement it in code to demonstrate
- If asked for calculations, compute them programmatically AND show the code
- If implementing algorithms, include test cases to prove correctness
- Document your validation process for transparency
- The state is maintained between executions, so you can refer to previous results

TOOL AVAILABLE:

- execute_python: Run Python code and see output

RESPONSE FORMAT: The execute_python tool returns a JSON response with:

- sessionId: The code interpreter session ID
- id: Request ID
- isError: Boolean indicating if there was an error
- content: Array of content objects with type and text/data
- structuredContent: For code execution, includes stdout, stderr, exitCode,
executionTime

For successful code execution, the output will be in content[0].text and also in
structuredContent.stdout.

Run code from agents 555


Check isError field to see if there was an error.

Be thorough, accurate, and always validate your answers when possible."""

#Define and configure the code interpreter tool
@tool
def execute_python(code: str, description: str = "") -> str:
"""Execute Python code"""

if description:
code = f"# {description}\n{code}"

#Print code to be executed
print(f"\n Code: {code}")

Call the Invoke method and execute the generated code, within the initialized
code interpreter session
with code_session("") as code_client:
response = code_client.invoke("executeCode", {
"code": code,
"language": "python",
"clearContext": False
})

for event in response["stream"]:
return json.dumps(event["result"])

#configure the strands agent including the tool(s)
agent=Agent(
tools=[execute_python],
system_prompt=SYSTEM_PROMPT,
callback_handler=None)

query="Can all the planets in the solar system fit between the earth and moon?"

Invoke the agent asynchcronously and stream the response
async def main():
response_text = ""
async for event in agent.stream_async(query):
if "data" in event:

Run code from agents 556


Stream text response
chunk = event["data"]
response_text += chunk
print(chunk, end="")

asyncio.run(main())

LangChain

You can build an agent that uses the Code Interpreter tool using the LangChain framework:

Install dependencies

Run the following commands to install the required packages:

pip install langchain
pip install langchain_aws
pip install bedrock-agentcore

Write an agent with Code Interpreter tool

The following Python code shows how to write an agent using LangChain with the Code
Interpreter tool:

langchain_ci_agent.py
#Please ensure that the latest Bedrock-AgentCore and Boto SDKs are installed
#Import Bedrock-AgentCore and other libraries

import json
from bedrock_agentcore.tools.code_interpreter_client import code_session
from langchain.agents import AgentExecutor, create_tool_calling_agent,
initialize_agent, tool
from langchain_aws import ChatBedrockConverse
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

#Define and configure the code interpreter tool
@tool
def execute_python(code: str, description: str = "") -> str:
"""Execute Python code"""

Run code from agents 557


if description:
code = f"# {description}\n{code}"

#Print the code to be executed
print(f"\nGenerated Code: \n{code}")

Call the Invoke method and execute the generated code, within the initialized code
interpreter session
with code_session("") as code_client:
response = code_client.invoke("executeCode", {
"code": code,
"language": "python",
"clearContext": False
})
for event in response["stream"]:
return json.dumps(event["result"])

Initialize the language model
Please ensure access to anthropic.claude-3-5-sonnet model in Amazon Bedrock
llm = ChatBedrockConverse(
model_id="anthropic.claude-3-5-sonnet-20240620-v1:0",
region_name=""
)

#Define the detailed system prompt for the assistant
SYSTEM_PROMPT = """You are a helpful AI assistant that validates all answers through
code execution.

VALIDATION PRINCIPLES:

1. When making claims about code, algorithms, or calculations - write code to verify
them
2. Use execute_python to test mathematical calculations, algorithms, and logic
3. Create test scripts to validate your understanding before giving answers
4. Always show your work with actual code execution
5. If uncertain, explicitly state limitations and validate what you can

APPROACH:

- If asked about a programming concept, implement it in code to demonstrate
- If asked for calculations, compute them programmatically AND show the code

Run code from agents 558


- If implementing algorithms, include test cases to prove correctness
- Document your validation process for transparency
- The code interpreter maintains state between executions, so you can refer to
previous results

TOOL AVAILABLE:

- execute_python: Run Python code and see output

RESPONSE FORMAT: The execute_python tool returns a JSON response with:

- sessionId: The code interpreter session ID
- id: Request ID
- isError: Boolean indicating if there was an error
- content: Array of content objects with type and text/data
- structuredContent: For code execution, includes stdout, stderr, exitCode,
executionTime

For successful code execution, the output will be in content[0].text and also in
structuredContent.stdout.
Check isError field to see if there was an error.

Be thorough, accurate, and always validate your answers when possible."""

Create a list of our custom tools
tools = [execute_python]

Define the prompt template
prompt = ChatPromptTemplate.from_messages([
("system", SYSTEM_PROMPT),
("user", "{input}"),
MessagesPlaceholder(variable_name="agent_scratchpad"),
])

Create the agent
agent = create_tool_calling_agent(llm, tools, prompt)

Create the agent executor
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

query="Can all the planets in the solar system fit between the earth and moon?"
resp=agent_executor.invoke({"input": query})

#print the result

Run code from agents 559


print(resp['output'][0]['text'])

#### Write files to a session......................................................................................................................

You can use the Code Interpreter to read and write files in the sandbox environment. This allows
you to upload data files, process them with code, and retrieve the results.

**Install dependencies**

Run the following command to install the required package:

pip install bedrock-agentcore

**Upload Code and Data using the file tool**

The following Python code shows how to upload files to the Code Interpreter session and execute
code that processes those files. The files that are required are data.csv and stats.py that are
available in this package.

file_mgmt_ci_agent.py
from bedrock_agentcore.tools.code_interpreter_client import CodeInterpreter
import json
from typing import Dict, Any, List

#Configure and Start the code interpreter session
code_client = CodeInterpreter('')
code_client.start()

#read the content of the sample data file
data_file = "data.csv"

try:
with open(data_file, 'r', encoding='utf-8') as data_file_content:
data_file_content = data_file_content.read()
#print(data_file_content)
except FileNotFoundError:
print(f"Error: The file '{data_file}' was not found.")
except Exception as e:
print(f"An error occurred: {e}")

Write files to a session 560


#read the content of the python script to analyze the sample file
code_file = "stats.py"
try:
with open(code_file, 'r', encoding='utf-8') as code_file_content:
code_file_content = code_file_content.read()
#print(code_file_content)
except FileNotFoundError:
print(f"Error: The file '{code_file}' was not found.")
except Exception as e:
print(f"An error occurred: {e}")

files_to_create = [
{
"path": "data.csv",
"text": data_file_content
},
{
"path": "stats.py",
"text": code_file_content
}]

#define the method to call the invoke API
def call_tool(tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:

response = code_client.invoke(tool_name, arguments)
for event in response["stream"]:
return json.dumps(event["result"], indent=2)

#write the sample data and analysis script into the code interpreter session
writing_files = call_tool("writeFiles", {"content": files_to_create})
print(f"writing files: {writing_files}")

#List and validate that the files were written successfully
listing_files = call_tool("listFiles", {"path": ""})
print(f"listing files: {listing_files}")

#Run the python script to analyze the sample data file
execute_code = call_tool("executeCode", {

Write files to a session 561


"code": files_to_create[1]['text'],
"language": "python",
"clearContext": True})
print(f"code execution result: {execute_code}")

#Clean up and stop the code interpreter session
code_client.stop()

#### Using Terminal Commands with an execution role.....................................................................

You can create a custom Code Interpreter tool with an execution role to upload/download files
from Amazon S3. This allows your code to interact with S3 buckets for storing and retrieving data.

**Prerequisites**

Before creating a custom Code Interpreter with S3 access, you need to:

1.Create an S3 bucket (e.g., codeinterpreterartifacts-<awsaccountid>)

2.Create a folder within the bucket (e.g., output_artifacts)

3.Create an IAM role with the following trust policy:

JSON

{
"Version":"2012-10-17",
"Statement": [
{
"Effect": "Allow",
"Principal": {
"Service": "bedrock-agentcore.amazonaws.com"
},
"Action": "sts:AssumeRole"
}
]
}

4.Add the following permissions to the role:

Using Terminal Commands with an execution role 562


##### JSON

{
"Version":"2012-10-17",
"Statement": [
{
"Sid": "VisualEditor0",
"Effect": "Allow",
"Action": [
"s3:PutObject",
"s3:GetObject"
],
"Resource": "arn:aws:s3:::codeinterpreterartifacts- 111122223333 /*"
}
]
}

**Sample Python code**

You can implement S3 integration using boto3 (AWS SDK for Python). The following example
uses boto3 to create a custom Code Interpreter with an execution role that can upload files to or
download files from Amazon S3.

Note
Before running this code, make sure to replace REGION and with your
AWS Region and AWS account number.

import boto3
import json
import time

REGION = ""
CP_ENDPOINT_URL = f"https://bedrock-agentcore-control.{REGION}.amazonaws.com"
DP_ENDPOINT_URL = f"https://bedrock-agentcore.{REGION}.amazonaws.com"

Update the accountId to reflect the correct S3 path.
Using Terminal Commands with an execution role 563


S3_BUCKET_NAME = "codeinterpreterartifacts-"

bedrock_agentcore_control_client = boto3.client(
'bedrock-agentcore-control',
region_name=REGION,
endpoint_url=CP_ENDPOINT_URL
)
bedrock_agentcore_client = boto3.client(
'bedrock-agentcore',
region_name=REGION,
endpoint_url=DP_ENDPOINT_URL
)

unique_name = f"s3InteractionEnv_{int(time.time())}"
create_response = bedrock_agentcore_control_client.create_code_interpreter(
name=unique_name,
description="Combined test code sandbox",
executionRoleArn="arn:aws:iam::123456789012:role/S3InteractionRole",
networkConfiguration={
"networkMode": "SANDBOX"
}
)
code_interpreter_id = create_response['codeInterpreterId']
print(f"Created custom interpreter ID: {code_interpreter_id}")

session_response = bedrock_agentcore_client.start_code_interpreter_session(
codeInterpreterIdentifier=code_interpreter_id,
name="combined-test-session",
sessionTimeoutSeconds=1800
)
session_id = session_response['sessionId']
print(f"Created session ID: {session_id}")

print(f"Downloading CSV generation script from S3")
command_to_execute = f"aws s3 cp s3://{S3_BUCKET_NAME}/generate_csv.py ."
response = bedrock_agentcore_client.invoke_code_interpreter(
codeInterpreterIdentifier=code_interpreter_id,
sessionId=session_id,
name="executeCommand",
arguments={
"command": command_to_execute
}
)

Using Terminal Commands with an execution role 564


for event in response["stream"]:
print(json.dumps(event["result"], default=str, indent=2))

print(f"Executing the CSV generation script")
response = bedrock_agentcore_client.invoke_code_interpreter(
codeInterpreterIdentifier=code_interpreter_id,
sessionId=session_id,
name="executeCommand",
arguments={
"command": "python generate_csv.py 5 10"
}
)

for event in response["stream"]:
print(json.dumps(event["result"], default=str, indent=2))

print(f"Uploading generated artifact to S3")
command_to_execute = f"aws s3 cp generated_data.csv s3://{S3_BUCKET_NAME}/
output_artifacts/"
response = bedrock_agentcore_client.invoke_code_interpreter(
codeInterpreterIdentifier=code_interpreter_id,
sessionId=session_id,
name="executeCommand",
arguments={
"command": command_to_execute
}
)

for event in response["stream"]:
print(json.dumps(event["result"], default=str, indent=2))

print(f"Stopping the code interpreter session")
stop_response = bedrock_agentcore_client.stop_code_interpreter_session(
codeInterpreterIdentifier=code_interpreter_id,
sessionId=session_id
)

print(f"Deleting the code interpreter")
delete_response = bedrock_agentcore_control_client.delete_code_interpreter(
codeInterpreterId=code_interpreter_id
)
print(f"Code interpreter status from response: {delete_response['status']}")

Using Terminal Commands with an execution role 565


print(f"Clean up completed, script run successful")

This example shows you how to:

- Create a custom Code Interpreter with an execution role
- Configure network access - Choose PUBLIC mode if your Code Interpreter needs to connect to
    the public internet. If your Code Interpreter supports connection to Amazon S3, and if you want
    your Code Interpreter session to remain isolated from the public internet, choose SANDBOX
    mode.
- Upload and download files between the Code Interpreter environment and S3
- Execute commands and scripts within the Code Interpreter environment
- Clean up resources when finished

#### Resource and session management................................................................................................

The following topics show how the Amazon Bedrock AgentCore Code Interpreter works and how
you can create the resources and manage sessions.

**IAM permissions**

The following IAM policy provides the necessary permissions for using the AgentCore Code
Interpreter:

JSON

{
"Version":"2012-10-17",
"Statement": [
{
"Effect": "Allow",
"Action": [
"bedrock-agentcore:CreateCodeInterpreter",
"bedrock-agentcore:StartCodeInterpreterSession",
"bedrock-agentcore:InvokeCodeInterpreter",
"bedrock-agentcore:StopCodeInterpreterSession",
"bedrock-agentcore:DeleteCodeInterpreter",
"bedrock-agentcore:ListCodeInterpreters",

Resource and session management 566


"bedrock-agentcore:GetCodeInterpreter",
"bedrock-agentcore:GetCodeInterpreterSession",
"bedrock-agentcore:ListCodeInterpreterSessions"
],
"Resource": "arn:aws:bedrock-agentcore: us-east-1 : 111122223333 :code-
interpreter/*"
}
]
}

You should also add the following trust policy to the execution role:

JSON

{
"Version":"2012-10-17",
"Statement": [{
"Sid": "BedrockAgentCoreBuiltInTools",
"Effect": "Allow",
"Principal": {
"Service": "bedrock-agentcore.amazonaws.com"
},
"Action": "sts:AssumeRole",
"Condition": {
"StringEquals": {
"aws:SourceAccount": "111122223333"
},
"ArnLike": {
"aws:SourceArn": "arn:aws:bedrock-agentcore:us-
east-1:111122223333:*"
}
}
}]
}

**How it works**

1. **Create a Code Interpreter**

Resource and session management 567


Build your own Code Interpreter or use the System Code Interpreter to enable capabilities such
as writing and running code or performing complex calculations. The Code Interpreter allows
you to augment your agent runtime to securely execute code in a fully managed environment
with low latency.

2. **Integrate it within an agent to invoke**

Copy the built-in tool resource ID into your runtime agent code to invoke it as part of your
session. For Code Interpreter tools, you can execute code and view the results in real-time.

3. **Assess performance using observability**

Monitor key metrics for each tool in CloudWatch to get real-time performance insights.

**Creating a Code Interpreter and starting a session**

1. **Create a Code Interpreter**

When configuring a Code Interpreter, you can choose network settings (Sandbox or Public), and
the execution role role that defines what AWS resources the Code Interpreter can access.

2. **Start a session**

The Code Interpreter uses a session-based model. After creating a Code Interpreter, you start
a session with a configurable timeout period (default is 15 minutes). Sessions automatically
terminate after the timeout period. Multiple sessions can be active simultaneously for a single
Code Interpreter, with each session maintaining its own state and environment.

3. **Execute code**

Within an active session, you can execute code in supported languages (Python, JavaScript,
TypeScript), and maintain state between executions. You can also perform file upload/download
operations, and use the support provided for the shell commands and AWS CLI commands.

4. **Stop session and clean up**

When you're finished using a session, you should stop it to release resources and avoid
unnecessary charges. You can also delete the Code Interpreter if you no longer intend to use it.

**Resource management**

The AgentCore Code Interpreter provides two types of resources:

Resource and session management 568


System ARNs

System ARNs are default resources pre-created for ease of use. These ARNs have default
configuration with the most restrictive options and are available for all regions where Amazon
Bedrock AgentCore is available.

Field Value

ID aws.codeinterpreter.v1

ARN arn:aws:bedrock-agentcore::a
ws:code-interpreter/aws.codeinterpreter.v1

Name Amazon Bedrock AgentCore Code Interpreter

Description AWS built-in code interpreter for secure code
execution

Status READY

Custom ARNs

Custom ARNs allow you to configure a code interpreter with your own settings. You can choose
network settings (Sandbox or Public), and the execution role that defines what AWS resources
the code interpreter can access.

**Network settings**

The AgentCore Code Interpreter supports the following network modes:

Sandbox mode

Provides complete isolation with no external network access. This is the most secure option but
limits the tool's ability to access external resources. S3 access is available in Sandbox mode.

Public network mode

Allows the tool to access public internet resources. This option enables integration with external
APIs and services but introduces potential security considerations.

Resource and session management 569


VPC mode

Connects the tool to your Virtual Private Cloud (VPC), allowing access to private resources
within your AWS environment such as databases, internal APIs, and other services while
maintaining network isolation from the public internet. This option requires additional VPC
configuration.

The following topics show you how to create and manage Code Interpreters, start and stop
sessions, and how to execute code.

**Topics**

- Creating an AgentCore Code Interpreter
- Listing AgentCore Code Interpreter tools
- Deleting an AgentCore Code Interpreter

**Creating an AgentCore Code Interpreter**

You can create a Code Interpreter using the Amazon Bedrock AgentCore console, AWS CLI, or AWS
SDK.

Console

To create a Code Interpreter using the console

1. Open the AgentCore console at https://console.aws.amazon.com/bedrock-agentcore/
    home#.
2. In the navigation pane, choose **Built-in tools**.
3. Choose **Create Code Interpreter tool**.
4. Provide a unique **Tool name** and optional **Description**.
5. Under **Network settings** , choose one of the following options:
    - **Sandbox** - Isolated environment with no external network access (most secure)
    - **Public network** - Allows access to public internet resources
6. Under **Permissions** , specify an IAM runtime role that defines what AWS resources the Code
    Interpreter can access.
7. Choose **Create**.

Resource and session management 570


After creating a Code Interpreter tool, the console displays important details about the tool:

Tool Resource ARN

The Amazon Resource Name (ARN) that uniquely identifies the Code Interpreter tool
resource (e.g., arn:aws:bedrock-agentcore::123456789012:code-interpreter/code-
interpreter-custom).
Code Interpreter Tool ID

The unique identifier for the Code Interpreter tool, used in API calls (e.g., code-interpreter-
custom-abc123).
IAM Role

The IAM role that the Code Interpreter assumes when executing code, determining what
AWS resources it can access.
Network Mode

The network configuration for the Code Interpreter (Sandbox or Public).
Creation Time

The date and time when the Code Interpreter tool was created.

##### AWS CLI

To create a Code Interpreter using the AWS CLI, use the create-code-interpreter
command:

aws bedrock-agentcore create-code-interpreter
--region
--name "my-code-interpreter"
--description "My Code Interpreter for data analysis"
--network-configuration '{
"networkMode": "PUBLIC"
}'
--execution-role-arn "arn:aws:iam::123456789012:role/my-execution-role"

Boto3

To create a Code Interpreter using the AWS SDK for Python, use the
create_code_interpreter method:

Resource and session management 571


import boto3

Initialize the boto3 client
cp_client = boto3.client(
'bedrock-agentcore-control',
region_name="",
endpoint_url="https://bedrock-agentcore-control..amazonaws.com"
)

Create a Code Interpreter
response = cp_client.create_code_interpreter(
name="myTestSandbox1",
description="Test code sandbox for development",
executionRoleArn="arn:aws:iam::123456789012:role/my-execution-role",
networkConfiguration={
"networkMode": "PUBLIC"
}
)

Print the Code Interpreter ID
code_interpreter_id = response["codeInterpreterId"]
print(f"Code Interpreter ID: {code_interpreter_id}")

##### API

To create a new Code Interpreter instance using the API, use the following call:

Using awscurl
awscurl -X PUT "https://bedrock-agentcore-control..amazonaws.com/code-
interpreters"
-H "Content-Type: application/json"
--region
--service bedrock-agentcore
-d '{
"name": "codeinterpreter'$(date +%m%d%H%M%S)'",
"description": "Test code sandbox for development",
"executionRoleArn": "'${ROLE_ARN}'",
"networkConfiguration": {
"networkMode": "PUBLIC"
}
}'

Resource and session management 572


**Listing AgentCore Code Interpreter tools**

You can view a list of all your Code Interpreter tools to manage and monitor them.

Console

To list code interpreters using the console

1. Open the AgentCore console at https://console.aws.amazon.com/bedrock-agentcore/
    home#.
2. In the navigation pane, choose **Built-in tools**.
3. The console displays a list of all your Code Interpreter tools, including their names, IDs,
    creation dates, and status.
4. You can use the search box to filter the list by name or other attributes.
5. Select a Code Interpreter to view its details, including active sessions and configuration
    settings.

##### AWS CLI

To list Code Interpreters using the AWS CLI, use the list-code-interpreters command:

aws bedrock-agentcore list-code-interpreters
--region
--max-results 10

You can use the --next-token parameter for pagination if you have more than the maximum
results:

aws bedrock-agentcore list-code-interpreters
--region
--max-results 10
--next-token "<your-pagination-token>"

Boto3

To list Code Interpreters using the AWS SDK for Python, use the list_code_interpreters
method:

import boto3

Resource and session management 573


Initialize the boto3 client
cp_client = boto3.client(
'bedrock-agentcore-control',
region_name="",
endpoint_url="https://bedrock-agentcore-control..amazonaws.com"
)

List Code Interpreters
response = cp_client.list_code_interpreters()

Print the Code Interpreters
for interpreter in response.get('codeInterpreterSummaries', []):
print(f"Name: {interpreter.get('name')}")
print(f"ID: {interpreter.get('codeInterpreterId')}")
print(f"Creation Time: {interpreter.get('createdAt')}")
print(f"Status: {interpreter.get('status')}")
print("---")

If there are more results, get the next page using the next_token
if 'nextToken' in response:
next_page = cp_client.list_code_interpreters(
nextToken=response['nextToken']
)

Process next_page...
##### API

To list Code Interpreter instances using the API, use the following call:

Note
For pagination, include the nextToken parameter.

Using awscurl
awscurl -X POST "https://bedrock-agentcore-control..amazonaws.com/code-
interpreters"
-H "Accept: application/json"
--service bedrock-agentcore
--region

Resource and session management 574


**Deleting an AgentCore Code Interpreter**

When you no longer need a Code Interpreter, you can delete it to free up resources and avoid
unnecessary charges.

Important
Deleting a Code Interpreter permanently removes it and all its configuration. This action
cannot be undone. Make sure all active sessions are stopped before deleting a Code
Interpreter.

Console

To delete a Code Interpreter using the console

1. Open the AgentCore console at https://console.aws.amazon.com/bedrock-agentcore/
    home#.
2. In the navigation pane, choose **Built-in tools**.
3. From the list of code interpreter tools, select the tool you want to delete.
4. Choose **Delete**.
5. In the confirmation dialog, enter the name of the code interpreter to confirm deletion.
6. Choose **Delete** to permanently delete the Code Interpreter.

##### AWS CLI

To delete a Code Interpreter using the AWS CLI, use the delete-code-interpreter
command:

aws bedrock-agentcore delete-code-interpreter
--region
--code-interpreter-id "<your-code-interpreter-id>"

Boto3

To delete a Code Interpreter using the AWS SDK for Python, use the
delete_code_interpreter method:

import boto3

Resource and session management 575


Initialize the boto3 client
cp_client = boto3.client(
'bedrock-agentcore-control',
region_name="",
endpoint_url="https://bedrock-agentcore-control..amazonaws.com"
)

Delete a Code Interpreter
response = cp_client.delete_code_interpreter(
codeInterpreterId="<your-code-interpreter-id>"
)

print("Code Interpreter deleted successfully")

API

To delete a Code Interpreter instance using the API, use the following call:

Using awscurl
awscurl -X DELETE "https://bedrock-agentcore-control..amazonaws.com/code-
interpreters/<your-code-interpreter-id>"
-H "Accept: application/json"
--service bedrock-agentcore
--region

**Session management**

The AgentCore Code Interpreter sessions have the following characteristics:

Session timeout

Default: 900 seconds (15 minutes)

Configurable: Can be adjusted when creating sessions, up to 8 hours

Session persistence

Files and data created during a session are available throughout the session's lifetime. When the
session is terminated, the session no longer persists and the data is cleaned up.

Automatic termination

Sessions automatically terminate after the configured timeout period

Resource and session management 576


Multiple sessions

Multiple sessions can be active simultaneously for a single code interpreter. Each session
maintains its own state and environment

Retention policy

The time to live (TTL) retention policy for the session data is 30 days.

**Using isolated sessions**

AgentCore Tools enable isolation of each user session to ensure secure and consistent reuse of
context across multiple tool invocations. Session isolation is especially important for AI agent
workloads due to their dynamic and multi-step execution patterns.

Each tool session runs in a dedicated microVM with isolated CPU, memory, and filesystem
resources. This architecture guarantees that one user's tool invocation cannot access data from
another user's session. Upon session completion, the microVM is fully terminated, and its memory
is sanitized, thereby eliminating any risk of cross-session data leakage.

**Starting a AgentCore Code Interpreter session**

After creating a Code Interpreter, you can start a session to execute code.

AWS CLI

To start a Code Interpreter session using the AWS CLI, use the start-code-interpreter-
session command:

aws bedrock-agentcore start-code-interpreter-session
--region
--code-interpreter-id "<your-code-interpreter-id>"
--name "my-code-session"
--description "My Code Interpreter session for data analysis"
--session-timeout-seconds 900

Boto3

To start a Code Interpreter session using the AWS SDK for Python, use the
start_code_interpreter_session method:

import boto3

Resource and session management 577


Initialize the boto3 client
dp_client = boto3.client(
'bedrock-agentcore',
region_name="",
endpoint_url="https://bedrock-agentcore..amazonaws.com"
)

Start a Code Interpreter session
response = dp_client.start_code_interpreter_session(
codeInterpreterIdentifier="aws.codeinterpreter.v1",
name="sandbox-session-1",
sessionTimeoutSeconds=3600
)

Print the session ID
session_id = response["sessionId"]
print(f"Session created: {session_id}")

##### API

To start a new Code Interpreter session using the API, use the following call:

Using awscurl
awscurl -X PUT
"https://bedrock-agentcore..amazonaws.com/code-interpreters/
aws.codeinterpreter.v1/sessions/start"
-H "Content-Type: application/json"
-H "Accept: application/json"
--service bedrock-agentcore
--region
-d '{
"name": "code-session-abc12345",
"description": "code sandbox session",
"sessionTimeoutSeconds": 900
}'

Note
You can use the managed resource ID aws.codeinterpreter.v1 or a resource ID you
get by creating a code interpreter with CreateCodeInterpreter.

Resource and session management 578


**Executing code**

Once you have started a Code Interpreter session, you can execute code in the session.

Boto3

To execute code using the AWS SDK for Python, use the invoke_code_interpreter method:

import boto3
import json

Initialize the boto3 client
dp_client = boto3.client(
'bedrock-agentcore',
region_name="",
endpoint_url="https://bedrock-agentcore..amazonaws.com"
)

Execute code in the Code Interpreter session
response = dp_client.invoke_code_interpreter(
codeInterpreterIdentifier="aws.codeinterpreter.v1",
sessionId="<your-session-id>",
name="executeCode",
arguments={
"language": "python",
"code": 'print("Hello World!!!")'
}
)

Process the event stream
for event in response["stream"]:
if "result" in event:
result = event["result"]
if "content" in result:
for content_item in result["content"]:
if content_item["type"] == "text":
print(content_item["text"])

API

To execute code in a code interpreter session using the API, use the following call:

Using awscurl
awscurl -X POST \

Resource and session management 579


"https://bedrock-agentcore..amazonaws.com/code-interpreters/
aws.codeinterpreter.v1/tools/invoke"
-H "Content-Type: application/json"
-H "Accept: application/json"
-H "x-amzn-code-interpreter-session-id: your-session-id"
--service bedrock-agentcore
--region
-d '{
"id": "1",
"name": "executeCode",
"arguments": {
"language": "python",
"code": "print("Hello, world!")"
}
}'

**Stopping a AgentCore Code Interpreter session**

When you are finished using a Code Interpreter session, you should stop it to release resources and
avoid unnecessary charges.

AWS CLI

To stop a code interpreter session using the AWS CLI, use the stop-code-interpreter-
session command:

aws bedrock-agentcore stop-code-interpreter-session
--region
--code-interpreter-id "<your-code-interpreter-id>"
--session-id "<your-session-id>"

Boto3

To stop a Code Interpreter session using the AWS SDK for Python, use the
stop_code_interpreter_session method:

import boto3

Initialize the boto3 client
dp_client = boto3.client(
'bedrock-agentcore',
region_name="",

Resource and session management 580


endpoint_url="https://bedrock-agentcore..amazonaws.com"
)

Stop the Code Interpreter session
response = dp_client.stop_code_interpreter_session(
codeInterpreterIdentifier="aws.codeinterpreter.v1",
sessionId="<your-session-id>"
)

print("Session stopped successfully")

API

To stop a code interpreter session using the API, use the following call:

Using awscurl
awscurl -X PUT
"https://bedrock-agentcore..amazonaws.com/code-interpreters/
aws.codeinterpreter.v1/sessions/stop?sessionId=<your-session-id>"
-H "Content-Type: application/json"
-H "Accept: application/json"
--service bedrock-agentcore
--region

#### Code Interpreter API Reference Examples

This section provides reference examples for common Code Interpreter operations using different
approaches. Each example shows how to perform the same operation using AWS CLI, Boto3 SDK,
and direct API calls.

**Code Execution**

These examples demonstrate how to execute code in a Code Interpreter session.

Boto3

params = {
"language": "python",
"code": "print("Hello, world!")"
}

client.invoke_code_interpreter(

API Reference Examples 581


**{
"codeInterpreterIdentifier": "aws.codeinterpreter.v1",
"sessionId": "<your-session-id>",
"name": "executeCode",
"arguments": params
})

API

Using awscurl
awscurl -X POST
"https://bedrock-agentcore..amazonaws.com/code-interpreters/
aws.codeinterpreter.v1/tools/invoke"
-H "Content-Type: application/json"
-H "Accept: application/json"
-H "x-amzn-code-interpreter-session-id: your-session-id"
--service bedrock-agentcore
--region
-d '{
"name": "executeCode",
"arguments": {
"language": "python",
"code": "print("Hello, world!")"
}
}'

**Terminal Commands**

These examples demonstrate how to execute terminal commands in a Code Interpreter session.

**Execute Command**

Boto3

params = {
"command": "ls -l"
}

client.invoke_code_interpreter(
**{
"codeInterpreterIdentifier": "aws.codeinterpreter.v1",
"sessionId": "<your-session-id>",

API Reference Examples 582


"name": "executeCommand",
"arguments": params
})

API

Using awscurl
awscurl -X POST
"https://bedrock-agentcore..amazonaws.com/code-interpreters/
aws.codeinterpreter.v1/tools/invoke"
-H "Content-Type: application/json"
-H "Accept: application/json"
-H "x-amzn-code-interpreter-session-id: your-session-id"
--service bedrock-agentcore
--region
-d '{
"name": "executeCommand",
"arguments": {
"command": "ls -l"
}
}'

**Start Command Execution**

Boto3

params = {
"command": "sleep 15 && echo Task completed successfully"
}

client.invoke_code_interpreter(
**{
"codeInterpreterIdentifier": "aws.codeinterpreter.v1",
"sessionId": "<your-session-id>",
"name": "startCommandExecution",
"arguments": params
})

API

Using awscurl
awscurl -X POST \

API Reference Examples 583


"https://bedrock-agentcore..amazonaws.com/code-interpreters/
aws.codeinterpreter.v1/tools/invoke"
-H "Content-Type: application/json"
-H "Accept: application/json"
-H "x-amzn-code-interpreter-session-id: your-session-id"
--service bedrock-agentcore
--region
-d '{
"name": "startCommandExecution",
"arguments": {
"command": "sleep 15 && echo Task completed successfully"
}
}'

**Get Task**

Boto3

params = {
"taskId": "<your-task-id>"
}

client.invoke_code_interpreter(
**{
"codeInterpreterIdentifier": "aws.codeinterpreter.v1",
"sessionId": "<your-session-id>",
"name": "getTask",
"arguments": params
})

API

Using awscurl
awscurl -X POST
"https://bedrock-agentcore..amazonaws.com/code-interpreters/
aws.codeinterpreter.v1/tools/invoke"
-H "Content-Type: application/json"
-H "Accept: application/json"
-H "x-amzn-code-interpreter-session-id: your-session-id"
--service bedrock-agentcore
--region
-d '{

API Reference Examples 584


"name": "getTask",
"arguments": {
"taskId": "<your-task-id>"
}
}'

**Stop Command Execution Task**

Boto3

params = {
"taskId": "<your-task-id>"
}

client.invoke_code_interpreter(
**{
"codeInterpreterIdentifier": "aws.codeinterpreter.v1",
"sessionId": "<your-session-id>",
"name": "stopTask",
"arguments": params
})

##### API

Using awscurl
awscurl -X POST
"https://bedrock-agentcore..amazonaws.com/code-interpreters/
aws.codeinterpreter.v1/tools/invoke"
-H "Content-Type: application/json"
-H "Accept: application/json"
-H "x-amzn-code-interpreter-session-id: your-session-id"
--service bedrock-agentcore
--region
-d '{
"name": "stopTask",
"arguments": {
"taskId": "<your-task-id>"
}
}'

API Reference Examples 585


**File Management**

These examples demonstrate how to manage files in a Code Interpreter session.

**Write Files**

Boto3

params = {
"content": [{"path": "dir1/samename.txt", "text": "File in dir1"}]
}

client.invoke_code_interpreter(
**{
"codeInterpreterIdentifier": "aws.codeinterpreter.v1",
"sessionId": "<your-session-id>",
"name": "writeFiles",
"arguments": params
})

##### API

Using awscurl
awscurl -X POST
"https://bedrock-agentcore..amazonaws.com/code-interpreters/
aws.codeinterpreter.v1/tools/invoke"
-H "Content-Type: application/json"
-H "Accept: application/json"
-H "x-amzn-code-interpreter-session-id: your-session-id"
--service bedrock-agentcore
--region
-d '{
"name": "writeFiles",
"arguments": {
"content": [{"path": "dir1/samename.txt", "text": "File in dir1"}]
}
}'

API Reference Examples 586


**Read Files**

Boto3

params = {
"paths": ["tmp.txt"]
}

client.invoke_code_interpreter(
**{
"codeInterpreterIdentifier": "aws.codeinterpreter.v1",
"sessionId": "<your-session-id>",
"name": "readFiles",
"arguments": params
})

API

Using awscurl
awscurl -X POST
"https://bedrock-agentcore..amazonaws.com/code-interpreters/
aws.codeinterpreter.v1/tools/invoke"
-H "Content-Type: application/json"
-H "Accept: application/json"
-H "x-amzn-code-interpreter-session-id: your-session-id"
--service bedrock-agentcore
--region
-d '{
"name": "readFiles",
"arguments": {
"paths": ["tmp.txt"]
}
}'

**Remove Files**

Boto3

params = {
"paths": ["tmp.txt"]
}

API Reference Examples 587


client.invoke_code_interpreter(
**{
"codeInterpreterIdentifier": "aws.codeinterpreter.v1",
"sessionId": "<your-session-id>",
"name": "removeFiles",
"arguments": params
})

API

Using awscurl
awscurl -X POST
"https://bedrock-agentcore..amazonaws.com/code-interpreters/
aws.codeinterpreter.v1/tools/invoke"
-H "Content-Type: application/json"
-H "Accept: application/json"
-H "x-amzn-code-interpreter-session-id: your-session-id"
--service bedrock-agentcore
--region
-d '{
"name": "removeFiles",
"arguments": {
"paths": ["tmp.txt"]
}
}'

**List Files**

Boto3

params = {
"directoryPath": ""
}

client.invoke_code_interpreter(
**{
"codeInterpreterIdentifier": "aws.codeinterpreter.v1",
"sessionId": "<your-session-id>",
"name": "listFiles",
"arguments": params
})

API Reference Examples 588


##### API

Using awscurl
awscurl -X POST
"https://bedrock-agentcore..amazonaws.com/code-interpreters/
aws.codeinterpreter.v1/tools/invoke"
-H "Content-Type: application/json"
-H "Accept: application/json"
-H "x-amzn-code-interpreter-session-id: your-session-id"
--service bedrock-agentcore
--region
-d '{
"name": "listFiles",
"arguments": {
"directoryPath": ""
}
}'

#### Observability........................................................................................................................................

The AgentCore Code Interpreter provides the following observability features:

Execution logs

Code interpreter execution console logs are not available in CloudWatch, but stdout/stderr
details are directly available in each invocation.

Metrics

You can view the following metrics in Amazon CloudWatch:

- Session counts: The number of sessions that Code Interpreter session has been requested
- Duration: The duration of sessions that Code Interpreter is running
- Invocations: The total number of times for each tool has been invoked
- Request latency: The latency of each request
- Throttles: The number of times requests to the tool have been throttled due to exceeding
    limits, with percentage change compared to the previous week
- User errors/system errors: The number of times requests failed due to either user error or
    system error

Observability 589


These metrics can be used to monitor the usage and performance of your code interpreter sessions,
set up alarms for abnormal behavior, and optimize your resource allocation.

For more information, see AgentCore generated built-in tools observability data.

### Interact with web applications using Amazon Bedrock

### AgentCore Browser

The Amazon Bedrock AgentCore Browser provides a secure, cloud-based browser that enables
AI agents to interact with websites. It includes security features such as session isolation, built-in
observability through live viewing, CloudTrail logging, and session replay capabilities.

#### Overview...............................................................................................................................................

The Amazon Bedrock AgentCore Browser provides a secure, isolated browser environment that
allows you to interact with web applications while minimizing potential risks to your system. It runs
in a containerized environment within AgentCore, and isolates web activity from your local system.

#### Why use remote browsers for agent development?...................................................................

A remote browser runs in a separate environment rather than on the local machine. For agent
development, remote browsers allow AI agents to interact with the web as humans do.

Remote browsers provide the following capabilities for agent development:

AgentCore Browser: interact with web applications 590


- Web interaction capabilities for navigating websites, filling forms, clicking buttons, and parsing
    dynamic content
- Serverless browser infrastructure that automatically scales without infrastructure overhead
- Visual understanding through screenshots that allow agents to interpret websites as humans do
- Human intervention with live interactive view capabilities
- Isolation and security by running web interactions for each session in a separate environment
- Complex web application navigation for interfaces that require browser capabilities
- Security through session isolation and audit capabilities
- Observability with real-time visibility and recorded history of browser interactions

Remote browsers bridge the gap between AI agents and the human web, allowing agents to
interact with websites designed for human users rather than being limited to APIs or static content.

#### Security Features................................................................................................................................

The Browser Tool includes several security features to help protect your environment:

- Isolation: The browser runs in a containerized environment, isolated from your local system
- Ephemeral sessions: Browser sessions are temporary and reset after each use
- Session timeouts: Sessions are terminated either by client or when the time to live (ttl) expires

#### How it works.......................................................................................................................................

The Amazon Bedrock AgentCore Browser provides a session-based model for secure web browsing
with comprehensive observability features. Here's how the complete workflow operates:

1. **Create a Browser Tool**

Create a Browser Tool to enable web browsing capabilities. You can choose between the
AWS managed Browser (aws.browser.v1) for quick setup, or create a custom browser with
advanced features like session recording, custom network settings, and specific IAM execution
roles. The Browser Tool allows you to augment your agent runtime to securely interact with
web applications, fill forms, navigate websites, and extract information in a fully managed
environment.

2. **Start a browser session**

Security Features 591


The Browser Tool uses a session-based model where each session runs in an isolated
environment. After creating a Browser Tool, you start a session with a configurable timeout
period (default is 15 minutes, extendable up to 8 hours). Sessions automatically terminate after
the timeout period, and multiple sessions can be active simultaneously for a single Browser Tool.

3. **Interact with the browser**

Once a session is started, you can interact with the browser using WebSocket-based streaming
APIs. The Automation endpoint enables your agent to perform browser actions such as
navigating to websites, clicking elements, filling out forms, taking screenshots, and more.
Libraries like Strands, Nova Act, or Playwright can be used to simplify these interactions.
Meanwhile, the Live View endpoint allows an end user to watch the browser session in real time
and interact with it directly through the live stream.

4. **Monitor and record sessions**

All browser sessions provide built-in observability through live viewing capabilities and
optional session recording. Live view allows real-time monitoring of browser activity, while
session recording (available for custom browsers) captures comprehensive interaction data
including DOM changes, user actions, console logs, and network events. Recorded sessions are
stored in your Amazon S3 bucket and can be replayed through the AWS Console or accessed
programmatically for debugging and analysis.

5. **Assess performance using observability**

Monitor key metrics for each tool in CloudWatch to get real-time performance insights. Session
recordings provide detailed analysis capabilities including video playback, timeline navigation,
user action tracking, and comprehensive logs for troubleshooting and optimization.

#### Use cases..............................................................................................................................................

The AgentCore Browser can be used for a wide range of use cases, enabling AI agents to interact
with web applications just as humans do. This section describes common use cases.

With the AgentCore Browser, you can:

- Test web applications in a secure environment
- Access online resources and services
- Perform web-based tasks and workflows

Use cases 592


- Interact with web interfaces
- Capture screenshots and record browser sessions
- Build AI agents that can navigate the web
- Automate form submissions and data entry
- Extract information from websites
- Perform e-commerce transactions
- Monitor website changes and updates

#### Get started with AgentCore Browser.............................................................................................

AgentCore Browser enables your agents to interact with web pages through a managed Chrome
browser. The agent can navigate websites, search for information, extract content, and interact
with web elements in a secure, managed environment.

This page covers the prerequisites and helps you get started using _AWS Strands_. Strands provides
a high-level agent framework that simplifies building AI agents with built-in tool integration,
conversation management, and automatic session handling.

**Topics**

- Prerequisites
- Using AgentCore Browser via AWS Strands
- Find your resources
- Next steps

**Prerequisites**

Before you start, ensure you have:

- AWS account with credentials configured. See Configuring your credentials.
- Python 3.10+ installed
- Boto3 installed. See Boto3 documentation.
- IAM execution role with the required permissions. See Configuring your credentials.
- Model access: Anthropic Claude Sonnet 4.0 enabled in the Amazon Bedrock console. For
    information about using a different model with the Strands Agents see the _Model Providers_
    section in the Strands Agents SDK documentation.

Get started with AgentCore Browser 593


- AWS Region where Amazon Bedrock AgentCore is available. See AWS Regions.
- Your network allows secure WebSocket connections

**Configuring your credentials**

Perform the following steps to configure your AWS credentials and attach the required permissions
to use AgentCore Browser.

1. **Verify your AWS credentials**

Confirm your AWS credentials are configured:

aws sts get-caller-identity

Take note of the user or credentials returned here, as you'll be attaching permissions to this
identity in the next step.

If this command fails, configure your credentials. For more information, see Configuration and
credential file settings in the AWS CLI documentation.

2. **Attach required permissions**

Your IAM user or role needs permissions to use AgentCore Browser. Attach this policy to your
IAM identity:

{
"Version":"2012-10-17",
"Statement": [
{
"Sid": "BedrockAgentCoreBrowserFullAccess",
"Effect": "Allow",
"Action": [
"bedrock-agentcore:CreateBrowser",
"bedrock-agentcore:ListBrowsers",
"bedrock-agentcore:GetBrowser",
"bedrock-agentcore:DeleteBrowser",
"bedrock-agentcore:StartBrowserSession",
"bedrock-agentcore:ListBrowserSessions",
"bedrock-agentcore:GetBrowserSession",
"bedrock-agentcore:StopBrowserSession",
"bedrock-agentcore:UpdateBrowserStream",

Get started with AgentCore Browser 594


"bedrock-agentcore:ConnectBrowserAutomationStream",
"bedrock-agentcore:ConnectBrowserLiveViewStream"
],
"Resource": "arn:aws:bedrock-agentcore::<account_id>:browser/*"

},
{
"Sid": "BedrockModelAccess",
"Effect": "Allow",
"Action": [
"bedrock:InvokeModel",
"bedrock:InvokeModelWithResponseStream"
],
"Resource": [
"*"
]
}
]
}

To attach this policy :

- Navigate to the IAM Console
- Find your user or role (the one returned by aws sts get-caller-identity)
- Click **Add permissions** â†’ **Create inline policy**
- Switch to JSON view and paste the policy above
- Name it AgentCoreBrowserAccess and save

Note
Replace with your actual AWS Region and <account_id> with your AWS
account ID.

3. **Verify your setup**

Confirm your setup is correct by checking:

- Your AWS credentials are properly configured
- The IAM policy is attached to your user or role

Get started with AgentCore Browser 595


- Model access is enabled in the Amazon Bedrock console

The following sections show you how to use the Amazon Bedrock AgentCore Browser with and
without the agent framework. Using the Browser directly without an agent framework is especially
useful when you want to execute specific browser automation tasks programmatically.

#### Using AgentCore Browser with other libraries.............................................................................

The following sections show you how to use the Amazon Bedrock AgentCore Browser with the
Strands SDK. Before you go through the examples in this section, see Prerequisites.

**Topics**

- Step 1: Install dependencies
- Step 2: Create your agent with AgentCore Browser
- Step 3: Run the agent
- Step 4: View the browser session live

**Step 1: Install dependencies**

Create a project folder and install the required packages:

Note
On Windows, use: .venv\Scripts\activate

mkdir agentcore-browser-quickstart
cd agentcore-browser-quickstart
python3 -m venv .venv
source .venv/bin/activate

Install the required packages:

pip install bedrock-agentcore strands-agents strands-agents-tools playwright nest-
asyncio

These packages provide:

Get started with AgentCore Browser 596


- bedrock-agentcore: The SDK for Amazon Bedrock AgentCore tools including AgentCore
    Browser
- strands-agents: The Strands agent framework
- strands-agents-tools: The tools that the Strands agent framework offers including Browser
    tool
- playwright: Python library for browser automation. Strands uses playwright for browser
    automation
- nest-asyncio: Allows running asyncio event loops within existing event loops

**Step 2: Create your agent with AgentCore Browser**

Create a file named browser_agent.py and add the following code:

Note
Replace with your actual AWS Region (for example, us-west-2 or us-east-1).

from strands import Agent
from strands_tools.browser import AgentCoreBrowser

Initialize the Browser tool
browser_tool = AgentCoreBrowser(region="")

Create an agent with the Browser tool
agent = Agent(tools=[browser_tool.browser])

Test the agent with a web search prompt
prompt = "what are the services offered by Bedrock AgentCore? Use the documentation
link if needed: https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/what-is-
bedrock-agentcore.html"
print(f"\n\nPrompt: {prompt}\n\n")

response = agent(prompt)
print("\n\nAgent Response:")
print(response.message["content"][0]["text"])

This code:

Get started with AgentCore Browser 597


- Initializes the Browser tool for your region
- Creates an agent that can use the browser to interact with websites
- Sends a prompt asking the agent to search AgentCore documentation and answer question
- Prints the agent's response with the information found

**Step 3: Run the agent**

Execute the following command:

python browser_agent.py

**Expected output**

You should see the agent's response containing details about AgentCore services from the
documentation. The agent navigates the website and extracts the requested information.

If you encounter errors, verify:

- Your IAM role/user has the correct permissions
- You have model access enabled in the Amazon Bedrock console
- Your AWS credentials are properly configured

**Step 4: View the browser session live**

While your browser script is running, you can view the session in real-time through the AWS
Console:

1. Open the AgentCore Browser Console
2. Navigate to **Built-in tools** in the left navigation
3. Select the Browser tool (for example, AgentCore Browser Tool, or your custom browser)
4. In the **Browser sessions** section, find your active session with status **Ready**
5. In the **Live view / recording** column, click the provided "View live session" URL
6. The live view opens in a new browser window, displaying the real-time browser session

The live view interface provides:

Get started with AgentCore Browser 598


- Real-time video stream of the browser session
- Interactive controls to take over or release control from automation
- Ability to terminate the session

This example:

- Creates a browser session using the browser_session client
- Retrieve the WebSocket connection details required for automation and live view.
- Start the viewer server, which launches a browser window to display the remote browser session
    via Live View.
- Connect Playwright to the remote browser via automation endpoint and navigate to
    Amazon.com.
- Keep the session alive until manually interrupted.
- Handle cleanup gracefully by terminating the session and releasing resources when the program
    exits.

The BrowserViewerServer component provides a local web server that connects to the remote
browser session and displays it in a browser window, allowing you to see and interact with the
browser in real-time.

**Find your resources**

After using AgentCore Browser, view your resources in the AWS Console:

Resource Location
1 Live View Browser Console > Tool Name

View live session

2 Session Recordings Browser Console > Tool Name

View recording

3 Browser Logs CloudWatch > Log groups

/aws/bedrock-agent
core/browser/

Get started with AgentCore Browser 599


Resource Location
4 Recording Files S3 > Your bucket > browser-
recordings/ prefix

5 Custom Browsers AgentCore Console > Built-in
tools > Your custom browser

6 IAM Roles IAM > Roles > Search for your
execution role

**Next steps**

Now that you have AgentCore Browser working, explore these advanced features:

- Browser session recording and replay - Record and replay sessions for debugging
- Using AgentCore Browser with other Browser libraries and tools - Use other frameworks like
    Nova Act or Playwright
- Use cases - See real-world implementation examples
- Resource and session management - Learn about API operations and custom browsers

#### Using AgentCore Browser with other Browser libraries and tools

You can build browser agents using various frameworks and libraries to automate web interactions.
This section demonstrates how to build browser agents using different frameworks.

Nova Act

You can build a browser agent using Nova Act to automate web interactions:

Step 1: Install dependencies

Create a project folder (if you have not already):

mkdir agentcore-browser-quickstart
cd agentcore-browser-quickstart
python3 -m venv .venv
source .venv/bin/activate

Using AgentCore Browser with other libraries 600


Note
On Windows, use: .venv\Scripts\activate

Install the required packages:

pip install bedrock-agentcore nova-act rich boto3

These packages provide:

- bedrock-agentcore: The SDK for Amazon Bedrock AgentCore tools including AgentCore
    Browser
- nova-act: The SDK for Nova Act which includes the model and orchestrator for browser
    automation
- rich: Library for rich text and beautiful formatting in the terminal
- boto3: AWS SDK for Python (Boto3) to create, configure, and manage AWS services

Step 2: Get Nova Act API Key

Navigate to Nova Act page and generate an API key using your amazon.com credentials. (Note
this currently works only for US based amazon.com accounts)

Create a file named nova_act_browser_agent.py and add the following code:

Write a browser agent using Nova Act

The following Python code shows how to write a browser agent using Nova Act. For information
about obtaining the API key for Nova Act, see Amazon Nova Act documentation.

from bedrock_agentcore.tools.browser_client import browser_session
from nova_act import NovaAct
from rich.console import Console
import argparse
import json
import boto3

Using AgentCore Browser with other libraries 601


console = Console()

from boto3.session import Session

boto_session = Session()
region = boto_session.region_name
print("using region", region)

def browser_with_nova_act(prompt, starting_page, nova_act_key, region="us-west-2"):
result = None
with browser_session(region) as client:
ws_url, headers = client.generate_ws_headers()
try:
with NovaAct(
cdp_endpoint_url=ws_url,
cdp_headers=headers,
nova_act_api_key=nova_act_key,
starting_page=starting_page,
) as nova_act:
result = nova_act.act(prompt)
except Exception as e:
console.print(f"NovaAct error: {e}")
finally:
return result

if name == "main":
parser = argparse.ArgumentParser()
parser.add_argument("--prompt", required=True, help="Browser Search
instruction")
parser.add_argument("--starting-page", required=True, help="Starting URL")
parser.add_argument("--nova-act-key", required=True, help="Nova Act API key")
parser.add_argument("--region", default="us-west-2", help="AWS region")
args = parser.parse_args()

result = browser_with_nova_act(
args.prompt, args.starting_page, args.nova_act_key, args.region
)
console.print(f"\n[cyan] Response[/cyan] {result.response}")
console.print(f"\n[bold green]Nova Act Result:[/bold green] {result}")

Step 3: Run the agent

Execute the script (Replace with your Nova Act API key in the command):

Using AgentCore Browser with other libraries 602


python nova_act_browser_agent.py --prompt "What are the common usecases of Bedrock
AgentCore?" --starting-page "https://docs.aws.amazon.com/bedrock-agentcore/latest/
devguide/what-is-bedrock-agentcore.html" --nova-act-key "your-nova-act-API-key"

Expected output

You should see the agent's response containing details of the common usecases of Amazon
Bedrock AgentCore. The agent navigates the website, performs the search, and extracts the
requested information.

If you encounter errors, verify:

- Your IAM role/user has the correct permissions
- Your Nova Act API key is correct
- Your AWS credentials are properly configured

Step 4: View the browser session live

While your browser script is running, you can view the session in real-time through the AWS
Console:

1. Open the Amazon Bedrock AgentCore Browser Console
2. Navigate to **Built-in tools** in the left navigation
3. Select the Browser tool (for example, AgentCore Browser Tool, or your custom
    browser)
4. In the **Browser sessions** section, find your active session with status **Ready**
5. In the **Live view / recording** column, click the provided "View live session" URL
6. The live view opens in a new browser window, displaying the real-time browser session

The live view interface provides:

- Real-time video stream of the browser session
- Interactive controls to take over or release control from automation
- Ability to terminate the session

Using AgentCore Browser with other libraries 603


Strands

You can build an agent that uses the Browser Tool as one of its tools using the Strands
framework:

Step 1: Install dependencies

Create a project folder (if you have not already):

mkdir agentcore-browser-quickstart
cd agentcore-browser-quickstart
python3 -m venv .venv
source .venv/bin/activate

Note
On Windows, use: .venv\Scripts\activate

Install the required packages:

pip install bedrock-agentcore strands-agents strands-agents-tools playwright nest-
asyncio

These packages provide:

- bedrock-agentcore: The SDK for Amazon Bedrock AgentCore tools including AgentCore
    Browser
- strands-agents: The Strands agent framework
- strands-agents-tools: The tools that the Strands agent framework offers including
    Browser tool
- playwright: Python library for browser automation. Strands uses playwright for browser
    automation
- nest-asyncio: Allows running asyncio event loops within existing event loops

Step 2: Create your agent with AgentCore Browser

Create a file named browser_agent.py and add the following code:

Using AgentCore Browser with other libraries 604


from strands import Agent
from strands_tools.browser import AgentCoreBrowser

Initialize the Browser tool
browser_tool = AgentCoreBrowser(region="us-west-2")

Create an agent with the Browser tool
agent = Agent(tools=[browser_tool.browser])

Test the agent with a web search prompt
prompt = "what are the services offered by Bedrock AgentCore? Use the documentation
link if needed: https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/what-
is-bedrock-agentcore.html"
print(f"\n\nPrompt: {prompt}\n\n")

response = agent(prompt)
print("\n\nAgent Response:")
print(response.message["content"][0]["text"])

This code:

- Initializes the Browser tool for your region
- Creates an agent that can use the browser to interact with websites
- Sends a prompt asking the agent to search AgentCore documentation and answer question
- Prints the agent's response with the information found

Step 3: Run the agent

Execute the script:

python browser_agent.py

Expected output

You should see the agent's response containing details about AgentCore services from the
documentation. The agent navigates the website and extracts the requested information.

If you encounter errors, verify:

Using AgentCore Browser with other libraries 605


- Your IAM role/user has the correct permissions
- You have model access enabled in the Amazon Bedrock console
- Your AWS credentials are properly configured

Step 4: View the browser session live

While your browser script is running, you can view the session in real-time through the AWS
Console:

1. Open the Amazon Bedrock AgentCore Browser Console
2. Navigate to **Built-in tools** in the left navigation
3. Select the Browser tool (for example, AgentCore Browser Tool, or your custom
    browser)
4. In the **Browser sessions** section, find your active session with status **Ready**
5. In the **Live view / recording** column, click the provided "View live session" URL
6. The live view opens in a new browser window, displaying the real-time browser session

The live view interface provides:

- Real-time video stream of the browser session
- Interactive controls to take over or release control from automation
- Ability to terminate the session

Playwright

You can use the Playwright automation framework with the Browser Tool:

Step 1: Install dependencies

Create a project folder (if you didn't create one before) and install the required packages:

mkdir agentcore-browser-quickstart
cd agentcore-browser-quickstart
python3 -m venv .venv
source .venv/bin/activate

Using AgentCore Browser with other libraries 606


Note
On Windows, use: .venv\Scripts\activate

Install the required packages:

pip install bedrock-agentcore playwright boto3 nest-asyncio

These packages provide:

- bedrock-agentcore: The SDK for Amazon Bedrock AgentCore tools including AgentCore
    Browser
- playwright: Python library for browser automation
- boto3: AWS SDK for Python (Boto3) to create, configure, and manage AWS services
- nest-asyncio: Allows running asyncio event loops within existing event loops

Step 2: Control browser with Playwright

You can use Browser directly without an agent framework or an LLM. This is useful when you
want programmatic control over browser automation. Amazon Bedrock AgentCore provides
integration with Playwright for browser automation.

Async Playwright example

Create a file named direct_browser_playwright.py and add the following code:

from playwright.async_api import async_playwright, Playwright, BrowserType
from bedrock_agentcore.tools.browser_client import browser_session
import asyncio

async def run(playwright: Playwright):

Create and maintain a browser session
with browser_session('us-west-2') as client:

Get WebSocket URL and authentication headers
ws_url, headers = client.generate_ws_headers()

Connect to the remote browser
chromium: BrowserType = playwright.chromium

Using AgentCore Browser with other libraries 607


browser = await chromium.connect_over_cdp(
ws_url,
headers=headers
)

Get the browser context and page
context = browser.contexts[0]
page = context.pages[0]

try:

Navigate to a website
await page.goto("https://docs.aws.amazon.com/bedrock-agentcore/latest/
devguide/what-is-bedrock-agentcore.html")

Print the page title
title = await page.title()
print(f"Page title: {title}")

Keep the session alive for 2 minutes to allow viewing
print("\n\nBrowser session is active. Check the AWS Console for live
view.")
await asyncio.sleep(120)

finally:

Clean up resources
await page.close()
await browser.close()

async def main():
async with async_playwright() as playwright:
await run(playwright)

Run the async function
if name == "main":
asyncio.run(main())

Sync Playwright example with live view

Alternatively, you can use the sync API with integrated live view server:

from playwright.sync_api import sync_playwright, Playwright, BrowserType
from bedrock_agentcore.tools.browser_client import browser_session
from browser_viewer import BrowserViewerServer

Using AgentCore Browser with other libraries 608


import time

def run(playwright: Playwright):

Create the browser session and keep it alive
with browser_session('us-west-2') as client:
ws_url, headers = client.generate_ws_headers()

Start viewer server
viewer = BrowserViewerServer(client, port=8005)
viewer_url = viewer.start(open_browser=True)

Connect using headers
chromium: BrowserType = playwright.chromium
browser = chromium.connect_over_cdp(
ws_url,
headers=headers
)

context = browser.contexts[0]
page = context.pages[0]

try:
page.goto("https://amazon.com/")
print(page.title())
time.sleep(120)
finally:
page.close()
browser.close()

with sync_playwright() as playwright:
run(playwright)

Run the script

Execute either script:

python direct_browser_playwright.py

Expected output

You should see the page title printed (for example, Page title: What is Amazon
Bedrock AgentCore? - Amazon Bedrock AgentCore). The script keeps the browser
session active for 2 minutes before closing.

Using AgentCore Browser with other libraries 609


Both examples:

- Create a managed browser session using Amazon Bedrock AgentCore Browser
- Connect to the remote Chrome browser using Playwright's Chrome DevTools Protocol (CDP)
- Navigate to AgentCore documentation and print the page title
- Keep the session alive for 2 minutes, allowing you to view it in the AWS Console
- Properly close the browser and clean up resources

#### Resource and session management................................................................................................

The following topics show how the Amazon Bedrock AgentCore Browser works and how you can
create the resources and manage sessions.

**Permissions**

To use the Amazon Bedrock AgentCore Browser, you need the following permissions in your IAM
policy:

JSON

{
"Version":"2012-10-17",
"Statement": [
{
"Sid": "BedrockAgentCoreInBuiltToolsFullAccess",
"Effect": "Allow",
"Action": [
"bedrock-agentcore:CreateBrowser",
"bedrock-agentcore:ListBrowsers",
"bedrock-agentcore:GetBrowser",
"bedrock-agentcore:DeleteBrowser",
"bedrock-agentcore:StartBrowserSession",
"bedrock-agentcore:ListBrowserSessions",
"bedrock-agentcore:GetBrowserSession",
"bedrock-agentcore:StopBrowserSession",
"bedrock-agentcore:UpdateBrowserStream",
"bedrock-agentcore:ConnectBrowserAutomationStream",
"bedrock-agentcore:ConnectBrowserLiveViewStream"
],

Resource and session management 610


"Resource": "arn:aws:bedrock-agentcore: us-
east-1 : 111122223333 :browser/*"
}
]
}

If you're using session recording with S3, the execution role you provide when creating a browser
needs the following permissions:

{
"Sid": "BedrockAgentCoreBuiltInToolsS3Policy",
"Effect": "Allow",
"Action": [
"s3:PutObject",
"s3:ListMultipartUploadParts",
"s3:AbortMultipartUpload"
],
"Resource": "arn:aws:s3:::example-s3-bucket/example-prefix/*",
"Condition": {
"StringEquals": {
"aws:ResourceAccount": "{{accountId}}"
}
}
}

You should also add the following trust policy to the execution role:

JSON

{
"Version":"2012-10-17",
"Statement": [{
"Sid": "BedrockAgentCoreBuiltInTools",
"Effect": "Allow",
"Principal": {
"Service": "bedrock-agentcore.amazonaws.com"
},
"Action": "sts:AssumeRole",
"Condition": {
"StringEquals": {
"aws:SourceAccount": " 111122223333 "

Resource and session management 611


},
"ArnLike": {
"aws:SourceArn": "arn:aws:bedrock-agentcore: us-
east-1 : 111122223333 :*"
}
}
}]
}

**Browser setup for API operations**

Run the following commands to set up your Browser Tool that is common to all control plane and
data plane API operations.

import boto3
import uuid

REGION = ""
CP_ENDPOINT_URL = f"https://bedrock-agentcore-control.{REGION}.amazonaws.com"
DP_ENDPOINT_URL = f"https://bedrock-agentcore.{REGION}.amazonaws.com"

cp_client = boto3.client(
'bedrock-agentcore-control',
region_name=REGION,
endpoint_url=CP_ENDPOINT_URL
)

dp_client = boto3.client(
'bedrock-agentcore',
region_name=REGION,
endpoint_url=DP_ENDPOINT_URL
)

**Creating a Browser Tool and starting a session**

1. **Create a Browser Tool**

When configuring a Browser Tool, choose the public network setting, recording configuration for
session replay, and permissions through an IAM runtime role that defines what AWS resources
the Browser Tool can access.

2. **Start a session**

Resource and session management 612


The Browser Tool uses a session-based model. After creating a Browser Tool, you start a session
with a configurable timeout period (default is 15 minutes). Sessions automatically terminate
after the timeout period. Multiple sessions can be active simultaneously for a single Browser
Tool, with each session maintaining its own state and environment.

3. **Interact with the browser**

Once a session is started, you can interact with the browser using WebSocket-based streaming
APIs. The Automation endpoint enables your agent to perform browser actions such as
navigating to websites, clicking elements, filling out forms, taking screenshots, and more.
Libraries like browser-use or Playwright can be used to simplify these interactions.

Meanwhile, the Live View endpoint allows an end user to watch the browser session in real time
and interact with it directly through the live stream.

4. **Stop the session**

When you're finished using the browser session, you should stop it to release resources and
avoid unnecessary charges. Sessions can be stopped manually or will automatically terminate
after the configured timeout period.

**Resource management**

The AgentCore Browser provides two types of resources:

System ARNs

System ARNs are default resources pre-created for ease of use. These ARNs have default
configuration with the most restrictive options and are available for all regions where Amazon
Bedrock AgentCore is available.

Field Value

ID aws.browser.v1

ARN arn:aws:bedrock-agentcore:us-east-1:
aws:browser/aws.browser.v1

Name Amazon Bedrock AgentCore Browser Tool

Resource and session management 613


Field Value

Description AWS built-in browser for secure web
browsing

Status READY

Custom ARNs

Custom ARNs allow you to configure a browser tool with your own settings. You can choose the
public network setting, recording configuration, security settings, and permissions through an
IAM runtime role that defines what AWS resources the browser tool can access.

**Network settings**

The AgentCore Browser supports the public network mode. This mode allows the tool to access
public internet resources. This option enables integration with external APIs and services.

**Creating an AgentCore Browser**

You can create a Browser Tool using the Amazon Bedrock AgentCore console, AWS CLI, or AWS
SDK.

Console

To create a Browser Tool using the console

1. Open the AgentCore console at https://console.aws.amazon.com/bedrock-agentcore/
    home#.
2. In the navigation pane, choose **Built-in tools**.
3. Choose **Create browser tool**.
4. Provide a unique **Tool name** and optional **Description**.
5. Under **Network settings** , choose **Public network** which allows access to public internet
    resources. VPC is not supported.
6. Under **Session recording** , you can enable recording of browser sessions to an S3 bucket for
    later review.

Resource and session management 614


7. Under **Permissions** , specify an IAM execution role that defines what AWS resources the
    Browser Tool can access.
8. Choose **Create**.

##### AWS CLI

To create a Browser Tool using the AWS CLI, use the create-browser command:

aws bedrock-agentcore-control create-browser
--region
--name "my-browser"
--description "My browser for web interaction"
--network-configuration '{
"networkMode": "PUBLIC"
}'
--recording '{
"enabled": true,
"s3Location": {
"bucket": "my-bucket-name",
"prefix": "sessionreplay"
}
}'
--execution-role-arn "arn:aws:iam::123456789012:role/my-execution-role"

Boto3

To create a Browser Tool using the AWS SDK for Python (Boto3), use the create_browser
method:

Request Syntax

The following shows the request syntax:

response = cp_client.create_browser(
name="my_custom_browser",
description="Test browser for development",
networkConfiguration={
"networkMode": "PUBLIC"
},
executionRoleArn="arn:aws:iam::123456789012:role/Sessionreplay",

Resource and session management 615


clientToken=str(uuid.uuid4()),
recording={
"enabled": True,
"s3Location": {
"bucket": "session-record-123456789012",
"prefix": "replay-data"
}
}
)

API

To create a new browser instance using the API, use the following call:

Using awscurl
awscurl -X PUT
"https://bedrock-agentcore-control..amazonaws.com/browsers"
-H "Content-Type: application/json"
-H "Accept: application/json"
--service bedrock-agentcore
--region
-d '{
"name": "test_browser_1",
"description": "Test sandbox for development",
"networkConfiguration": {
"networkMode": "PUBLIC"
},
"recording": {
"enabled": true,
"s3Location": {
"bucket": "<your-bucket-name>",
"prefix": "sessionreplay"
}
},
"executionRoleArn": "arn:aws:iam::123456789012:role/my-execution-role"
}'

**Get AgentCore Browser tool**

You can get information about the Browser tool in your account and view their details, status, and
configurations.

Resource and session management 616


Console

To get information about the Browser tool using the console

1. Open the AgentCore console at https://console.aws.amazon.com/bedrock-agentcore/
    home#.
2. In the navigation pane, choose **Built-in tools**.
3. The browser tools are listed in the **Browser tools** section.
4. You can choose a tool that you created to view it's details such as name, ID, status, and
    creation date for each browser tool.

##### AWS CLI

To get information about a Browser tool using the AWS CLI, use the get-browser command:

aws bedrock-agentcore-control get-browser
--region
--browser-id "<your-browser-id>"

Boto3

To get information about the Browser tool using the AWS SDK for Python (Boto3), use the
get_browser method:

Request Syntax

The following shows the request syntax:

response = cp_client.get_browser(
browserId="<your-browser-id>"
)

API

To get the browser tool using the API, use the following call:

Using awscurl
awscurl -X GET \

Resource and session management 617


"https://bedrock-agentcore-control..amazonaws.com/browsers/<your-browser-
id>"
-H "Content-Type: application/json"
-H "Accept: application/json"
--service bedrock-agentcore
--region

**Listing AgentCore Browser tools**

You can list all browser tools in your account to view their details, status, and configurations.

Console

To list browser tools using the console

1. Open the AgentCore console at https://console.aws.amazon.com/bedrock-agentcore/
    home#.
2. In the navigation pane, choose **Built-in tools**.
3. The browser tools are listed in the **Browser tools** section.
4. You can view details such as name, ID, status, and creation date for each browser tool.

##### AWS CLI

To list browser tools using the AWS CLI, use the list-browsers command:

aws bedrock-agentcore-control list-browsers
--region

You can filter the results by type:

aws bedrock-agentcore-control list-browsers
--region
--type SYSTEM

You can also limit the number of results and use pagination:

Resource and session management 618


aws bedrock-agentcore-control list-browsers
--region
--max-results 10
--next-token "<your-pagination-token>"

Boto3

To list browser tools using the AWS SDK for Python (Boto3), use the list_browsers method:

Request Syntax

The following shows the request syntax:

response = cp_client.list_browsers(type="CUSTOM")

API

To list browser tools using the API, use the following call:

Using awscurl
awscurl -X POST
"https://bedrock-agentcore-control..amazonaws.com/browsers"
-H "Content-Type: application/json"
-H "Accept: application/json"
--service bedrock-agentcore
--region

You can filter the results by type:

awscurl -X POST
"https://bedrock-agentcore-control..amazonaws.com/browsers?type=SYSTEM"
-H "Content-Type: application/json"
-H "Accept: application/json"
--service bedrock-agentcore
--region

You can also limit the number of results and use pagination:

Resource and session management 619


awscurl -X POST
"https://bedrock-agentcore-control..amazonaws.com/browsers?
maxResults=1&nextToken=<your-pagination-token>"
-H "Content-Type: application/json"
-H "Accept: application/json"
--service bedrock-agentcore
--region

**Deleting an AgentCore Browser**

When you no longer need a browser tool, you can delete it to free up resources. Before deleting a
browser tool, make sure to stop all active sessions associated with it.

Console

To delete a Browser tool using the console

1. Open the AgentCore console at https://console.aws.amazon.com/bedrock-agentcore/
    home#.
2. Navigate to **Built-in tools** and select your browser tool.
3. Choose **Delete** from the **Actions** menu.
4. Confirm the deletion by typing the browser tool name in the confirmation dialog.
5. Choose **Delete**.

Note
You cannot delete a browser tool that has active sessions. Stop all sessions before
attempting to delete the tool.

##### AWS CLI

To delete a Browser tool using the AWS CLI, use the delete-browser command:

aws bedrock-agentcore-control delete-browser
--region
--browser-id "<your-browser-id>"

Resource and session management 620


Boto3

To delete a Browser tool using the AWS SDK for Python (Boto3), use the delete_browser
method:

Request Syntax

The following shows the request syntax:

response = cp_client.delete_browser(
browserId="<your-browser-id>"
)

API

To delete a browser tool using the API, use the following call:

Using awscurl
awscurl -X DELETE
"https://bedrock-agentcore-control..amazonaws.com/browsers/<your-browser-
id>"
-H "Content-Type: application/json"
-H "Accept: application/json"
--service bedrock-agentcore-control
--region

**Session management**

The AgentCore Browser sessions have the following characteristics:

Session timeout

Default: 900 seconds (15 minutes)

Configurable: Can be adjusted when creating sessions, up to 8 hours

Session recording

Browser sessions can be recorded for later review

Recordings include network traffic and console logs

Resource and session management 621


Recordings are stored in an S3 bucket specified during browser creation

Live view

Sessions can be viewed in real-time using the live view feature

Live view is available at: /browser-streams/aws.browser.v1/sessions/{session_id}/live-view

Automatic termination

Sessions automatically terminate after the configured timeout period

Multiple sessions

Multiple sessions can be active simultaneously for a single browser tool. Each session maintains
its own state and environment. There can be up to a maximum of 500 sessions.

Retention policy

The time to live (TTL) retention policy for the session data is 30 days.

**Using isolated sessions**

AgentCore Tools enable isolation of each user session to ensure secure and consistent reuse of
context across multiple tool invocations. Session isolation is especially important for AI agent
workloads due to their dynamic and multi-step execution patterns.

Each tool session runs in a dedicated microVM with isolated CPU, memory, and filesystem
resources. This architecture guarantees that one user's tool invocation cannot access data from
another user's session. Upon session completion, the microVM is fully terminated, and its memory
is sanitized, thereby eliminating any risk of cross-session data leakage.

**Starting a browser session**

After creating a browser, you can start a session to interact with web applications.

AWS CLI

To start a Browser session using the AWS CLI, use the start-browser-session command:

aws bedrock-agentcore start-browser-session
--region
--browser-identifier "my-browser"
--name "my-browser-session" \

Resource and session management 622


--session-timeout-seconds 900
--view-port width=1456,height=819

Boto3

To start a Browser session using the AWS SDK for Python (Boto3), use the
start_browser_session method:

Request Syntax

The following shows the request syntax:

response = dp_client.start_browser_session(
browserIdentifier="aws.browser.v1",
name="browser-session-1",
sessionTimeoutSeconds=3600,
viewPort={
'height': 819,
'width': 1456
}
)

BrowserClient

To start a browser session using the BrowserClient class for more control over the session
lifecycle:

from bedrock_agentcore.tools.browser_client import BrowserClient

Create a browser client
client = BrowserClient(region="us-west-2")

Start a browser session
client.start()
print(f"Session ID: {client.session_id}")

try:

Generate WebSocket URL and headers
url, headers = client.generate_ws_headers()

Perform browser operations with your preferred automation tool
Resource and session management 623


finally:

Always close the session when done
client.stop()

API

To create a new browser session using the API, use the following call:

Using awscurl
awscurl -X PUT
"https://bedrock-agentcore..amazonaws.com/browsers/aws.browser.v1/
sessions/start"
-H "Content-Type: application/json"
-H "Accept: application/json"
--service bedrock-agentcore
--region
-d '{
"name": "browser-session-abc12345",
"description": "browser sandbox session",
"sessionTimeoutSeconds": 300,
"viewPort": {
"height": 819,
"width": 1456
}
}'

**Get Browser session**

You can get information about a browser session that you have created.

AWS CLI

To get information about a browser session using the AWS CLI, use the get-browser-
session command:

aws bedrock-agentcore get-browser-session
--region
--browser-identifier "aws.browser.v1"
--session-id "<your-session-id>"

Resource and session management 624


Boto3

To get information about a browser session using the AWS SDK for Python (Boto3), use the
get_browser_session method:

Request Syntax

The following shows the request syntax:

response = dp_client.get_browser_session(
browserIdentifier="aws.browser.v1",
sessionId="<your-session-id>"
)

API

To get information about a browser session using the API, use the following call:

Using awscurl
awscurl -X GET
"https://bedrock-agentcore..amazonaws.com/browsers/aws.browser.v1/
sessions/get?sessionId=<your-session-id>"
-H "Content-Type: application/json"
-H "Accept: application/json"
--service bedrock-agentcore
--region

{
"browserIdentifier": "aws.browser.v1",
"createdAt": "2025-07-14T22:16:40.713152248Z",
"lastUpdatedAt": "2025-07-14T22:16:40.713152248Z",
"name": "testBrowserSession1752531400",
"sessionId": "<your-session-id>",
"sessionReplayArtifact": null,
"sessionTimeoutSeconds": 900,
"status": "TERMINATED",
"streams": {
"automationStream": {
"streamEndpoint": "wss://bedrock-agentcore..amazonaws.com/browser-
streams/aws.browser.v1/sessions/<your-session-id>/automation",
"streamStatus": "ENABLED"

Resource and session management 625


},
"liveViewStream": {
"streamEndpoint": "https://bedrock-agentcore..amazonaws.com/browser-
streams/aws.browser.v1/sessions/<your-session-id>/live-view"
}
},
"viewPort": {
"height": 819,
"width": 1456
}
}

**Interacting with a browser session**

Once you have started a Browser session, you can interact with it using the WebSocket API.

Console

To interact with a Browser session using the console

1. Navigate to your active Browser session.
2. Use the browser interface to navigate to websites, interact with web elements, and perform
    other browser actions.
3. You can view the browser activity in real-time through the live view feature.

##### SDK

To interact with a Browser session programmatically, use the WebSocket-based streaming API
with the following URL format:

https://bedrock-agentcore..amazonaws.com/browser-streams/{browser_id}/
sessions/{session_id}/automation

You can use libraries like Playwright to establish a connection with the WebSocket and control
the browser. Here's an example:

from playwright.sync_api import sync_playwright, Playwright, BrowserType
import os

Resource and session management 626


import base64
from bedrock_agentcore.tools.browser_client import browser_session

def main(playwright: Playwright):

Keep browser session alive during usage
with browser_session('us-west-2') as client:

Generate CDP endpoint and headers
ws_url, headers = client.generate_ws_headers()

Connect to browser using headers
chromium: BrowserType = playwright.chromium
browser = chromium.connect_over_cdp(ws_url, headers=headers)

Use the first available context or create one
context = browser.contexts[0] if browser.contexts else browser.new_context()
page = context.pages[0] if context.pages else context.new_page()

page.goto("https://amazon.com/")
print("Navigated to Amazon")

Create CDP session for screenshot
cdp_client = context.new_cdp_session(page)
screenshot_data = cdp_client.send("Page.captureScreenshot", {
"format": "jpeg",
"quality": 80,
"captureBeyondViewport": True
})

Decode and save screenshot
image_data = base64.b64decode(screenshot_data['data'])
with open("screenshot.jpeg", "wb") as f:
f.write(image_data)

print("# Screenshot saved as screenshot.jpeg")
page.close()
browser.close()

with sync_playwright() as p:
main(p)

The following example code shows how you can perform live view using the WebSocket-based
streaming API.

Resource and session management 627


https://bedrock-agentcore..amazonaws.com/browser-streams/{browser_id}/
sessions/{session_id}/live-view

Below is the code.

import time
from rich.console import Console
from bedrock_agentcore.tools.browser_client import browser_session
from browser_viewer import BrowserViewerServer

console = Console()

def main():
try:

Step 1: Create browser session
with browser_session('us-west-2') as client:
print("\r # Browser ready! ")
ws_url, headers = client.generate_ws_headers()

Step 2: Start viewer server
console.print("\n[cyan]Step 3: Starting viewer server...[/cyan]")
viewer = BrowserViewerServer(client, port=8005)
viewer_url = viewer.start(open_browser=True)

Keep running
while True:
time.sleep(1)

except KeyboardInterrupt:
console.print("\n\n[yellow]Shutting down...[/yellow]")
if 'client' in locals():
client.stop()
console.print("# Browser session terminated")
except Exception as e:
console.print(f"\n[red]Error: {e}[/red]")
import traceback
traceback.print_exc()

if name == "main":
main()

Resource and session management 628


**Listing browser sessions**

You can list all active browser sessions to monitor and manage your resources. This is useful for
tracking active sessions, identifying long-running sessions, or finding sessions that need to be
stopped.

AWS CLI

To list Browser sessions using the AWS CLI, use the list-browser-sessions command:

aws bedrock-agentcore list-browser-sessions
--region
--browser-id "<your-browser-id>"
--max-results 10

You can also filter sessions by status:

aws bedrock-agentcore list-browser-sessions
--region
--browser-id "<your-browser-id>"
--status "READY"

Boto3

To list Browser sessions using the AWS SDK for Python (Boto3), use the
list_browser_sessions method:

Request Syntax

The following shows the request syntax:

response = dp_client.list_browser_sessions(
browserIdentifier="aws.browser.v1"
)

You can also filter sessions by status:

Resource and session management 629


List only active sessions
filtered_response = dp_client.list_browser_sessions(
browserIdentifier="aws.browser.v1",
status="READY"
)

Print filtered session information
for session in filtered_response['items']:
print(f"Ready Session ID: {session['sessionId']}")
print(f"Name: {session['name']}")
print("---")

API

To list browser sessions using the API, use the following call:

Using awscurl
awscurl -X POST
"https://bedrock-agentcore..amazonaws.com/browsers/<your-browser-id>/
sessions/list"
-H "Content-Type: application/json"
-H "Accept: application/json"
--service bedrock-agentcore
--region
-d '{
"maxResults": 10
}'

You can also filter sessions by status:

Using awscurl
awscurl -X POST
"https://bedrock-agentcore..amazonaws.com/browsers/aws.browser.v1/
sessions/list"
-H "Content-Type: application/json"
-H "Accept: application/json"
--service bedrock-agentcore
--region
-d '{
"maxResults": 10,

Resource and session management 630


"status": "READY"
}'

**Stopping a browser session**

When you are finished using a Browser session, you should stop it to release resources and avoid
unnecessary charges.

AWS CLI

To stop a Browser session using the AWS CLI, use the stop-browser-session command:

aws bedrock-agentcore stop-browser-session
--region
--browser-id "<your-browser-id>"
--session-id "<your-session-id>"

Boto3

To stop a Browser session using the AWS SDK for Python (Boto3), use the
stop_browser_session method:

Request Syntax

The following shows the request syntax:

response = dp_client.stop_browser_session(
browserIdentifier="aws.browser.v1",
sessionId="<your-session-id>",
)

API

To stop a browser session using the API, use the following call:

Using awscurl
awscurl -X PUT
"https://bedrock-agentcore..amazonaws.com/browsers/aws.browser.v1/
sessions/stop?sessionId=<your-session-id>" \

Resource and session management 631


-H "Content-Type: application/json"
-H "Accept: application/json"
--service bedrock-agentcore
--region

**Updating browser streams**

You can update browser streams to enable or disable automation. This is useful when you need to
enter sensitive information like login credentials that you don't want the agent to see.

Boto3

response = dp_client.update_browser_stream(
browserIdentifier="aws.browser.v1",
sessionId="<your-session-id>",
streamUpdate={
"automationStreamUpdate": {
"streamStatus": "DISABLED" # or "ENABLED"
}
}
)

API

awscurl -X PUT
"https://bedrock-agentcore..amazonaws.com/browsers/aws.browser.v1/
sessions/streams/update?sessionId=<your-session-id>"
-H "Content-Type: application/json"
-H "Accept: application/json"
--service bedrock-agentcore
--region
-d '{
"streamUpdate": {
"automationStreamUpdate": {
"streamStatus": "ENABLED"
}
}
}'

CLI

aws bedrock-agentcore update-browser-stream \

Resource and session management 632


--region
--browser-id "<your-browser-id>"
--session-id "<your-session-id>"
--stream-update automationStreamUpdate={streamStatus=ENABLED}

#### Rendering live view using AWS DCV Web Client

Amazon Bedrock AgentCore's live view is powered by **AWS DCV**. Each browser session launches a
dedicated DCV server that streams the browser interface and enables real-time user interaction.

To render the live view, you must use the **AWS DCV Web Client** , which supports interactive display
within a browser. Authentication is handled via **IAM SigV4-signed query parameters** , which must
be appended to the live view URL to authorize access.

The example SDK includes a lightweight **web server** that hosts the DCV Web Client and connects to
the live view, enabling an end-to-end interactive experience out of the box.

If you want to directly integrate the live view experience into their own web applications, they
can embed the **DCV Web Client** and generate the signed connection URL using the SDK's helper
methods. This allows full customization of the UI while leveraging Amazon Bedrock AgentCore's
Browser Tool capabilities.

**Using Callbacks to Customize URL Parameters**

The DCV Web SDK supports custom callbacks that you can use to modify the URLs used during
authentication and session establishment. This feature enables advanced integration scenarios,
including the ability to append custom query parameters and add AWS Signature Version 4 (SigV4)
signed values to secure and authorize connections through external systems.

**Customizing Authentication and connection URL:httpExtraSearchParamsCallback**

The authenticate method supports a callback parameter,
httpExtraSearchParamsCallback. Before initiating the request, you can use this callback to
inject custom query parameters into the authentication URL.

When establishing a WebSocket connection to the DCV server, you can use the
httpExtraSearchParamsCallback in the connect method to customize the URL used.

Example:

Rendering live view using DCV client 633


**Example**

The following shows a sample code:

async function startAndConnect() {
const response = await fetch('/presigned-url');
const { sessionId, presignedUrl: url } = await response.json();
presignedUrl = url; // Set global variable

dcv.setLogLevel(dcv.LogLevel.INFO);
auth = dcv.authenticate(presignedUrl, {
promptCredentials: onPromptCredentials,
error: onError,
success: (auth, result) => {
const { sessionId, authToken } = result[0];
connect(presignedUrl, sessionId, authToken);
},
httpExtraSearchParams: httpExtraSearchParamsCb
});
}

function connect(serverUrl, sessionId, authToken) {
dcv.connect({
url: serverUrl,
sessionId,
authToken,
divId: 'dcv-display',
observers: {
httpExtraSearchParams: httpExtraSearchParamsCb,
displayLayout: displayLayoutCallbackCb,
}
})
.then((conn) => {
console.log('Connection established');
connection = conn;
})
.catch((error) => {
console.error('Connection failed:', error.message);
});
}

function httpExtraSearchParamsCb(method, url, body) {

Rendering live view using DCV client 634


const presignedUrl = getPresignedUrlForLiveViewEndpoint();
const searchParams = new URL(presignedUrl).searchParams;

return searchParams;
}

These callbacks offer fine-grained control over the URL and headers used by the SDK during key
stages of session negotiation and connection, supporting advanced use cases and integration with
existing security infrastructure.

#### Observability and session replay....................................................................................................

The AgentCore Browser provides the following observability features:

Session replay

You can replay browser sessions using the Amazon Bedrock AgentCore SDK to view session
recordings stored in Amazon S3. This feature enables you to review past browser interactions
for debugging, auditing, or training purposes. The recordings in S3 include DOM change events,
browser network activity, and console logs for comprehensive session analysis.

Metrics

You can view browser session metrics in Amazon CloudWatch, including session counts,
durations, and error rates to monitor usage and performance.

**Topics**

- CloudWatch Metrics for AgentCore Browser
- Browser session recording and replay

**CloudWatch Metrics for AgentCore Browser**

You can view the following metrics in Amazon CloudWatch:

- Session counts: The number of browser sessions that have been requested
- Session duration: The length of time browser sessions are active
- Error rates: The frequency of errors encountered during browser sessions
- Resource utilization: CPU, memory, and network usage by browser sessions

Observability and session replay 635


These metrics can be used to monitor the usage and performance of your browser sessions, set up
alarms for abnormal behavior, and optimize your resource allocation.

For more information, see AgentCore generated built-in tools observability data.

**Browser session recording and replay**

Browser session recording and replay provides comprehensive observability for debugging,
auditing, or training purposes. When you create a browser with session recording enabled, Amazon
Bedrock AgentCore automatically captures browser interactions and stores them in your specified
Amazon S3 bucket for later analysis.

Session replay captures comprehensive browser interaction data that enables you to view replays
and understand the actions that occurred during browser sessions. This functionality helps you
resolve errors and improve future invocations by providing detailed insights into browser behavior.

Information collected during session replay includes:

- Session DOM changes and mutations
- User actions including clicks, scrolls, and form interactions
- Console logs and error messages
- Chrome DevTools Protocol (CDP) events
- Network events and HTTP requests

**Prerequisites for session recording**

To enable session recording, you need:

- An Amazon S3 bucket to store recording data
- An IAM execution role with permissions to write to your Amazon S3 bucket
- A custom browser tool configured with recording enabled

**Configure IAM role for recording**

To enable session recording, you need an IAM execution role with permissions to write recording
data to Amazon S3 and log activity to CloudWatch. For detailed instructions on setting up
permissions, see Permissions.

The execution role requires additional permissions beyond the standard browser permissions:

Observability and session replay 636


{
"Sid": "S3Permissions",
"Effect": "Allow",
"Action": [
"s3:PutObject",
"s3:GetObject",
"s3:ListBucket",
"s3:ListMultipartUploadParts",
"s3:AbortMultipartUpload"
],
"Resource": [
"arn:aws:s3:::your-recording-bucket",
"arn:aws:s3:::your-recording-bucket/"
]
},
{
"Sid": "CloudWatchLogsPermissions",
"Effect": "Allow",
"Action": [
"logs:CreateLogGroup",
"logs:CreateLogStream",
"logs:PutLogEvents",
"logs:DescribeLogStreams"
],
"Resource": ""
}

Replace your-recording-bucket with your actual Amazon S3 bucket name.

The following sections show you how to use session replay and some programmatic examples.

**Topics**

- How to use session replay
- Session replay programmatic examples

**How to use session replay**

Session recording captures all browser interactions and allows you to replay sessions for
debugging, analysis, and monitoring. This feature requires a custom browser tool with recording
enabled.

Observability and session replay 637


Note

- Session replay captures DOM mutations and reconstructs them during playback. The
    browser may make cross-origin HTTP requests to fetch external assets during replay.
- Session replay is not available in the AWS managed Browser (aws.browser.v1).

Session replay in AgentCore Browser involves the following steps:

1. **Create a Browser Tool with Recording** - Create a custom browser with recording enabled and
    specify your Amazon S3 bucket for storage
2. **Use the Recording-Enabled Browser** - Start browser sessions and perform browsing activities
    through automation or live view
3. **Replay and Inspect Recorded Sessions** - Access recordings through the AWS Console with
    comprehensive analysis tools
4. **Access Recordings Programmatically** - Retrieve and analyze recording data directly from
    Amazon S3 for custom workflows

Important
Before you perform these steps, make sure that you've configured the IAM Role for
recording. You must set up permissions for Amazon Bedrock AgentCore to write recording
data to Amazon S3 and log activity to CloudWatch. For more information, see Configure
IAM role for recording.

**Step 1: Create a browser tool with recording**

Create a custom browser tool with recording enabled. For detailed instructions on creating browser
tools, see Creating an AgentCore Browser.

When creating your browser tool, ensure you:

- Enable session recording in the configuration
- Specify your Amazon S3 bucket and prefix for storing recordings
- Use the IAM execution role from Step 1

Observability and session replay 638


Example using Python SDK:

import boto3
import uuid

region = "us-west-2"
bucket = "your-recording-bucket"

client = boto3.client("bedrock-agentcore-control", region_name=region)

response = client.create_browser(
name="MyRecordingBrowser",
description="Browser with session recording enabled",
networkConfiguration={"networkMode": "PUBLIC"},
executionRoleArn="arn:aws:iam::123456789012:role/AgentCoreBrowserRecordingRole",
clientToken=str(uuid.uuid4()),
recording={
"enabled": True,
"s3Location": {
"bucket": bucket,
"prefix": "browser-recordings"
}
}
)

browser_identifier = response.get("browserId") or response.get("browserIdentifier")
print(f"Created browser with recording: {browser_identifier}")
print(f"Recordings will be stored at: s3://{bucket}/browser-recordings/")

**Step 2: Use the recording-enabled browser**

Use your recording-enabled browser with any automation framework. All browser interactions will
be automatically recorded. Example using Strands:

from strands import Agent
from strands_tools.browser import AgentCoreBrowser

Use the browser created with recording
browser_identifier = "your-browser-identifier"
region = "us-west-2"
browser_tool = AgentCoreBrowser(region=region, identifier=browser_identifier)

agent = Agent(tools=[browser_tool.browser])

Observability and session replay 639


prompt = (
"Navigate to https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/what-is-
bedrock-agentcore.html "
"and summarize the key features of AgentCore."
)

response = agent(prompt)
print("Agent Response:")
print(response.message["content"][0]["text"])

All interactions during this session will be automatically recorded and uploaded to your Amazon S3
bucket when the session ends.

**Step 3: Monitor live sessions and replay recordings**

The AWS Console provides comprehensive tools for both real-time monitoring and recorded
session analysis.

**Live view monitoring**

Monitor browser sessions in real-time and interact with active sessions:

**To access live view in the console**

1. Open the Amazon Bedrock AgentCore console and navigate to **Built-in tools**
2. Select your browser tool from the list (for example, MyRecordingBrowser)
3. In the **Browser sessions** section, locate an active session with status **Ready** or **In progress**
4. In the **Live view / recording** column, click the provided "View live session" URL
5. The live view opens in a new browser window, displaying the real-time browser session

The live view interface provides:

- Real-time video stream of the browser session
- Interactive controls to take over or release control from automation
- Session status indicators and connection information
- Ability to interact directly with the browser when control is enabled

Observability and session replay 640


**Session replay and analysis**

Access detailed session recordings and analysis through the console replay interface:

**To access session replay in the console**

1. Navigate to your browser tool and select a completed session with **Terminated** status
2. Click **View Recording** for the session you want to analyze
3. The session replay page displays with comprehensive analysis tools

**Session analysis features**

The console provides multiple analysis tools:

- **Video Player** : Interactive playback with timeline scrubber for navigation
- **Pages Navigation** : Panel showing all visited pages with time ranges
- **User Actions** : All user interactions with timestamps, methods, and details
- **Page DOM** : DOM structure and HTML content for each page
- **Console Logs** : Browser console output, errors, and log messages
- **CDP Events** : Chrome DevTools Protocol events with parameters and results
- **Network Events** : HTTP requests, responses, status codes, and timing

**Navigate recordings**

Use these methods to navigate through recordings:

- Click on pages in the Pages panel to jump to specific moments
- Click on user actions to see where they occurred in the timeline
- Use the video timeline scrubber for precise navigation
- Choose **View recording** links in action tables to jump to specific interactions

**Step 4: Access recordings programmatically**

Access live view and recording insights programmatically using the Amazon Bedrock AgentCore
SDK and APIs for custom integration and automated analysis.

Observability and session replay 641


**Programmatic live view access**

Connect to live browser sessions using the browser client and viewer server:

import time
from rich.console import Console
from bedrock_agentcore.tools.browser_client import browser_session
from browser_viewer import BrowserViewerServer

console = Console()

def main():
try:

Create browser session
with browser_session('us-west-2') as client:
print("# Browser ready!")
ws_url, headers = client.generate_ws_headers()

Start viewer server
console.print("[cyan]Starting viewer server...[/cyan]")
viewer = BrowserViewerServer(client, port=8005)
viewer_url = viewer.start(open_browser=True)

Keep running
while True:
time.sleep(1)

except KeyboardInterrupt:
console.print("[yellow]Shutting down...[/yellow]")
if 'client' in locals():
client.stop()
console.print("# Browser session terminated")

if name == "main":
main()

**Programmatic recording access**

Access recording data directly from Amazon S3 for custom analysis workflows:

import boto3

s3_client = boto3.client('s3', region_name='us-west-2')

Observability and session replay 642


List recordings in your bucket
bucket_name = "your-recording-bucket"
prefix = "browser-recordings/"

response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)

print(f"Recordings in s3://{bucket_name}/{prefix}:")
for obj in response.get('Contents', []):
print(f" {obj['Key']} ({obj['Size']} bytes)")
print(f" Last Modified: {obj['LastModified']}")
print()

Recording data structure:

s3://your-recording-bucket/browser-recordings/

session-id/
batch_1.ndjson.gz
batch_2.ndjson.gz
batch_3.ndjson.gz
Each session creates a folder with the session ID, and recording data is uploaded in chunks as the
session progresses.

**Session replay programmatic examples**

For advanced use cases, you can build custom session replay viewers and integrate recording data
into your own analysis workflows.

The following GitHub examples show a standalone session replay viewer and what the complete
browser experience looks like when using the browser session replay feature.

For additional examples, see AgentCore Browser examples on GitHub.

**Standalone Session Replay Viewer**

The standalone session replay viewer is a separate tool for viewing recorded browser sessions
directly from Amazon S3 without creating a new browser.

- Connect directly to S3 to view recordings
- View any past recording by specifying its session ID

Observability and session replay 643


- Display error messages when artifacts are missing from S3, with console replay URLs specific to
    session ID
- Interactive video playback interface with timeline navigation
- Action markers on timeline showing form fills, clicks, and navigation events
- Observability table displaying pages traveled with duration and URL details
- Console events, CDP logs, and network logs for each page interaction
- Session duration tracking integrated at page level
- Real-time action verification with visual correlation between video and action data

View the latest recording in a bucket
python view_recordings.py --bucket session-record-test-123456789012 --prefix replay-
data

View a specific recording
python view_recordings.py --bucket session-record-test-123456789012 --prefix replay-
data --session 01JZVDG02M8MXZY2N7P3PKDQ74

Use a specific AWS profile
python view_recordings.py --bucket session-record-test-123456789012 --prefix replay-
data --profile my-profile

For reference, see Standalone session replay viewer on GitHub.

**Complete Browser Experience with Recording and Replay**

A comprehensive tool for creating browser sessions with recording capabilities and advanced replay
features.

- Create browser sessions with automatic recording to S3
- Live view with interactive control (take/release)
- Adjust display resolution on the fly
- Automatic session recording to S3
- Integrated session replay viewer with video player interface
- Timeline scrubbing with precise action location tracking
- Page-by-page analysis with navigation timeline and URL copying
- Form filling action verification with click location details

Observability and session replay 644


- Session duration tracking integrated at page level
- Real-time action verification with visual correlation between video and action data

View the latest recording in a bucket
python -m live_view_sessionreplay.browser_interactive_session

For reference, see Interactive browser session on GitHub.

### Troubleshoot AgentCore built-in tools

This section provides solutions to common issues you might encounter when using Amazon
Bedrock AgentCore built-in tools.

#### Browser tool issues............................................................................................................................

**Permission denied errors**

**Symptom:** Errors mentioning access denied or insufficient permissions.

**Solution:**

- Verify your IAM user or role has the required Browser permissions
- Check your AWS credentials: aws sts get-caller-identity
- For recording: Verify the execution role has Amazon S3 write permissions
- For recording: Confirm the trust policy allows bedrock-agentcore.amazonaws.com to
    assume the role

**Model access denied**

**Symptom:** Errors about model access or authorization when running agents.

**Solution:**

- Navigate to the Amazon Bedrock console
- Go to **Model access** in the left navigation
- Enable **Anthropic Claude Sonnet 4**

Troubleshoot built-in tools 645


- Verify you're in the correct region (match the region in your code)

**Browser session timeout**

**Symptom:** Browser sessions end unexpectedly or timeout errors occur.

**Solution:**

- Check the sessionTimeoutSeconds parameter when starting sessions
- Default timeout is 900 seconds (15 minutes)
- Increase timeout for longer sessions: sessionTimeoutSeconds=1800
- Sessions automatically stop after the timeout period

**Recording not appearing in Amazon S3**

**Symptom:** No recording files in your Amazon S3 bucket after session completes.

**Solution:**

- Verify the execution role has correct Amazon S3 permissions
- Confirm the Amazon S3 bucket name and prefix are correct
- Check the execution role trust policy includes bedrock-agentcore service
- Review CloudWatch Logs for Amazon S3 upload errors
- Ensure the session ran for at least a few seconds (very short sessions may not generate
    recordings)

**Playwright connection errors**

**Symptom:** Cannot connect to browser with Playwright or WebSocket errors.

**Solution:**

- Verify you installed playwright: pip install playwright
- Confirm the browser session started successfully before connecting
- Check that the session is still active (not timed out)
- Verify your network allows WebSocket connections

Browser tool issues 646


**Agent cannot make progress due to CAPTCHA checks**

**Issue:** Your agent gets blocked by CAPTCHA verification when using the Browser tool to interact
with websites.

**Cause:** Anti-bot measures on popular websites detect automated browsing and require human
verification.

**Solution:** Structure your agent to avoid search engines and implement the following architecture
pattern:

- Use the Browser tool only for specific page actions, not general web searching
- Use non-browser MCP tools like Tavily search for general web search operations
- Consider adding a live view feature to your agent application that allows end users to take
    control and solve CAPTCHAs when needed

**CORS errors when integrating with browser applications**

**Issue:** Cross-Origin Resource Sharing (CORS) errors occur when building browser-based web
applications that call a custom Amazon Bedrock AgentCore runtime server.

**Cause:** Browser security policies block cross-origin requests to your runtime server during local
development or self-hosted deployment.

**Solution:** Add CORS middleware to your BedrockAgentCoreApp to handle cross-origin requests
from your frontend:

from bedrock_agentcore.runtime import BedrockAgentCoreApp
from fastapi.middleware.cors import CORSMiddleware

app = BedrockAgentCoreApp()

Add CORS middleware to allow browser requests
app.add_middleware(
CORSMiddleware,
allow_origins=[""], # Customize in production
allow_credentials=True,
allow_methods=[""],
allow_headers=["*"],

Browser tool issues 647


)

Handle browser preflight requests to /invocations
@app.options("/invocations")
async def options_handler():
return {"message": "OK"}

@app.entrypoint
def my_agent(payload):
return {"response": "Hello from agent"}

Important
In production environments, replace allow_origins=["*"] with specific domain origins
for better security.

#### Code Interpreter issues.....................................................................................................................

For general Code Interpreter troubleshooting, see the specific documentation for the section called
â€œAgentCore Code Interpreter: Execute code and analyze dataâ€.

Common issues with Code Interpreter typically relate to:

- Code execution timeouts
- Memory limitations during data processing
- Package installation restrictions

For detailed troubleshooting steps, refer to the Code Interpreter tool documentation.

Code Interpreter issues 648


## Observe your agent applications on Amazon Bedrock

## AgentCore Observability

With AgentCore, you can trace, debug, and monitor AI agents' performance in production
environments.

AgentCore Observability helps you trace, debug, and monitor agent performance in production
environments. It offers detailed visualizations of each step in the agent workflow, enabling you to
inspect an agent's execution path, audit intermediate outputs, and debug performance bottlenecks
and failures.

AgentCore Observability gives you real-time visibility into agent operational performance through
access to dashboards powered by Amazon CloudWatch and telemetry for key metrics such as
session count, latency, duration, token usage, and error rates. Rich metadata tagging and filtering
simplify issue investigation and quality maintenance at scale. AgentCore emits telemetry data in
standardized OpenTelemetry (OTEL)-compatible format, enabling you to easily integrate it with
your existing monitoring and observability stack.

By default, AgentCore outputs a set of key built-in metrics for agents, gateway resources, and
memory resources. For memory resources, AgentCore also outputs spans and log data if you enable
it. You can also instrument your agent code to provide additional span and trace data and custom
metrics and logs. See the section called â€œAdd observability to your agentsâ€ to learn more.

All of the metrics, spans, and logs output by AgentCore are stored in Amazon CloudWatch, and can
be viewed in the CloudWatch console or downloaded from CloudWatch using the AWS CLI or one
of the AWS SDKs.

In addition to the raw data stored in CloudWatch Logs, for agent runtime data only, the
CloudWatch console provides an observability dashboard containing trace visualizations, graphs
for custom span metrics, error breakdowns, and more. To learn more about viewing your agents'
observability data, see the section called â€œView metrics for your agentsâ€

**Topics**

- Get started with AgentCore Observability
- Add observability to your Amazon Bedrock AgentCore resources
- Understand observability for agentic resources in AgentCore

649


- Amazon Bedrock AgentCore generated observability data
- View observability data for your Amazon Bedrock AgentCore agents

### Get started with AgentCore Observability.........................................................................................

Amazon Bedrock Amazon Bedrock AgentCore Observability helps you trace, debug, and monitor
agent performance in production environments. This guide helps you implement observability
features in your agent applications.

**Topics**

- Prerequisites
- Step 1: Enable transaction search on CloudWatch
- Step 2: Enable observability for Amazon Bedrock AgentCore Runtime hosted agents
- Step 3: Enable observability for non-Amazon Bedrock AgentCore-hosted agents
- Step 4: Observe your agent with GenAI observability on Amazon CloudWatch
- Best practices

#### Prerequisites

Before starting, make sure you have:

- **AWS Account** with credentials configured (aws configure) with model access enabled to the
    Foundation Model you would like to use.
- **Python 3.10+** installed
- **Enable transaction search** on Amazon CloudWatch. Only once, first-time users must enable
    CloudWatch Transaction Search to view Bedrock Amazon Bedrock AgentCore spans and traces
- **Add the OpenTelemetry library** Include aws-opentelemetry-distro (ADOT) in your
    requirements.txt file.
- Make sure that your framework is configured to emit traces (eg. strands-agents[otel]
    package), you may sometimes need to include <your-agent-framework-auto-
    instrumentor> # e.g., opentelemetry-instrumentation-langchain

Amazon Bedrock AgentCore Observability offers two ways to configure monitoring to match
different infrastructure needs:

Get started with AgentCore Observability 650


1.Amazon Bedrock AgentCore Runtime-hosted agents

2.Non-runtime hosted agents

As a one time setup per AWS account, first time users need to enable Transaction Search on
Amazon CloudWatch. There are two ways to do this, via the API and via the CloudWatch Console.

#### Step 1: Enable transaction search on CloudWatch......................................................................

After you enable Transaction Search, it can take ten minutes for spans to become available for
search and analysis. Choose one of the options below:

**Option 1: Enable transaction search using an API**

**To enable transaction search using the API**

1. Create a policy that grants access to ingest spans in CloudWatch Logs using AWS CLI.

An example is shown below on how to format your AWS CLI command with
PutResourcePolicy.

aws logs put-resource-policy --policy-name MyResourcePolicy --policy-
document '{ "Version": "2012-10-17" , "Statement": [ { "Sid":
"TransactionSearchXRayAccess", "Effect": "Allow", "Principal": { "Service":
"xray.amazonaws.com" }, "Action": "logs:PutLogEvents", "Resource":
[ "arn:partition:logs:region:account-id:log-group:aws/spans:",
"arn:partition:logs:region:account-id:log-group:/aws/application-
signals/data:" ], "Condition": { "ArnLike": { "aws:SourceArn":
"arn:partition:xray:region:account-id:*" }, "StringEquals": { "aws:SourceAccount":
"account-id" } } } ]}'

2. Configure the destination of trace segments.

An example is shown below on how to format your AWS CLI command with
UpdateTraceSegmentDestination.

aws xray update-trace-segment-destination --destination CloudWatchLogs

3. **Optional** Configure the amount of spans to index.

Configure your desired sampling percentage with UpdateIndexingRule.

Step 1: Enable transaction search on CloudWatch 651


aws xray update-indexing-rule --name "Default" --rule '{"Probabilistic":
{"DesiredSamplingPercentage": number}}'

**Option 2: Enable transaction search in the CloudWatch console**

**To enable transaction search in the CloudWatch console**

1. Open the CloudWatch console at https://console.aws.amazon.com/cloudwatch/.
2. From the navigation pane, under **Application Signals** , choose **Transaction Search**.
3. Choose **Enable Transaction Search**.
4. Select the box to ingest spans as structured logs, and enter a percentage of spans to be
    indexed. You can index spans at 1% for free and change the percentage later based on your
    requirements.

Now proceed to exploring the two ways to configure observability.

#### Step 2: Enable observability for Amazon Bedrock AgentCore Runtime hosted agents........

Amazon Bedrock AgentCore Runtime-hosted agents are deployed and executed directly within
the Amazon Bedrock AgentCore environment, providing automatic instrumentation with
minimal configuration. This approach offers the fastest path to deployment and is ideal for rapid
development and testing.

For a complete example, refer to this notebook

**Set up folder and virtual environment**

Create a new folder for your agent. Then create and initialize a new python virtual environment.

mkdir agentcore-observability-quickstart
cd agentcore-observability-quickstart
python3 -m venv .venv
source .venv/bin/activate

Step 2: Enable observability for Amazon Bedrock AgentCore Runtime hosted agents 652


**Create your agent**

The following is an example of using the Strands Agents SDK.

To enable OTEL exporting, install Strands Agents with otel extra dependencies:

pip install 'strands-agents[otel]'

Use the following steps to host a strands agent on an AgentCore Runtime:

Save this as strands_claude.py
from strands import Agent, tool
from strands_tools import calculator # Import the calculator tool
import argparse
import json
from bedrock_agentcore.runtime import BedrockAgentCoreApp
from strands.models import BedrockModel

app = BedrockAgentCoreApp()

Create a custom tool
@tool
def weather():
""" Get weather """ # Dummy implementation
return "sunny"

model_id = "us.anthropic.claude-3-7-sonnet-20250219-v1:0"
model = BedrockModel(
model_id=model_id,
)
agent = Agent(
model=model,
tools=[calculator, weather],
system_prompt="You're a helpful assistant. You can do simple math calculation, and
tell the weather."
)

@app.entrypoint
def strands_agent_bedrock(payload):
"""
Invoke the agent with a payload
"""

Step 2: Enable observability for Amazon Bedrock AgentCore Runtime hosted agents 653


user_input = payload.get("prompt")
print("User input:", user_input)
response = agent(user_input)
return response.message['content'][0]['text']

if name == "main":
app.run()

**Deploy and invoke your agent on Amazon Bedrock AgentCore Runtime**

Use the following code to deploy the agent to AgentCore Runtime by using the
bedrock_agentcore_starter_toolkit package.

from bedrock_agentcore_starter_toolkit import Runtime
from boto3.session import Session
boto_session = Session()
region = boto_session.region_name

agentcore_runtime = Runtime()
agent_name = "strands_claude_getting_started"
response = agentcore_runtime.configure(
entrypoint="strands_claude.py",
auto_create_execution_role=True,
auto_create_ecr=True,
requirements_file="requirements.txt", # make sure aws-opentelemetry-distro exists
along with your libraries required to run your agent
region=region,
agent_name=agent_name
)

launch_result = agentcore_runtime.launch()
launch_result

In these steps you deployed your strands agent to an AgentCore Runtime with the starter toolkit.
When you invoke your agent, it is automatically instrumented using Open Telemetry.

Invoke your agent using the following command and view the Traces, sessions and metrics on
GenAI Observability dashboard on Amazon CloudWatch.

invoke_response = agentcore_runtime.invoke({"prompt": "How is the weather now?"})
invoke_response

Step 2: Enable observability for Amazon Bedrock AgentCore Runtime hosted agents 654


#### Step 3: Enable observability for non-Amazon Bedrock AgentCore-hosted agents...............

For agents running outside of the Amazon Bedrock AgentCore runtime, you can deliver the same
monitoring capabilities for agents deployed on your own infrastructure. This allows consistent
observability regardless of where your agents run. Use the following steps to configure the
environment variables needed to observe your agents.

For a complete example, refer to this notebook

**Configure AWS environment variables**

export AWS_ACCOUNT_ID=
export AWS_DEFAULT_REGION=
export AWS_REGION=
export AWS_ACCESS_KEY_ID=
export AWS_SECRET_ACCESS_KEY=

**Configure CloudWatch logging**

Create a log group and log stream for your agent in Amazon CloudWatch which you can use to
configure below environment variables.

**Configure OpenTelemetry environment variables**

export AGENT_OBSERVABILITY_ENABLED=true # Activates the ADOT pipeline
export OTEL_PYTHON_DISTRO=aws_distro # Uses AWS Distro for OpenTelemetry
export OTEL_PYTHON_CONFIGURATOR=aws_configurator # Sets AWS configurator for ADOT SDK
export OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf # Configures export protocol
export OTEL_EXPORTER_OTLP_LOGS_HEADERS=x-aws-log-group=<YOUR-LOG-GROUP>,x-aws-log-
stream=<YOUR-LOG-STREAM>,x-aws- metric-namespace=<YOUR-NAMESPACE>

Directs logs to CloudWatch groups
export OTEL_RESOURCE_ATTRIBUTES=service.name= <YOUR-AGENT-NAME> # Identifies your agent
in observability data

Replace _<YOUR-AGENT-NAME>_ with a unique name to identify this agent in the GenAI
Observability dashboard and logs.

**Create an agent locally**

Create agent.py - Strands agent that is a weather assistant
Step 3: Enable observability for non-Amazon Bedrock AgentCore-hosted agents 655


from strands import Agent
from strands_tools import http_request

Define a weather-focused system prompt
WEATHER_SYSTEM_PROMPT = """You are a weather assistant with HTTP capabilities. You can:

1. Make HTTP requests to the National Weather Service API
2. Process and display weather forecast data
3. Provide weather information for locations in the United States

When retrieving weather information:

1. First get the coordinates or grid information using https://api.weather.gov/points/
{latitude},{longitude} or https://api.weather.gov/points/{zipcode}
2. Then use the returned forecast URL to get the actual forecast

When displaying responses:

- Format weather data in a human-readable way
- Highlight important information like temperature, precipitation, and alerts
- Handle errors appropriately
- Convert technical terms to user-friendly language

Always explain the weather conditions clearly and provide context for the forecast.
"""

Create an agent with HTTP capabilities
weather_agent = Agent(
system_prompt=WEATHER_SYSTEM_PROMPT,
tools=[http_request], # Explicitly enable http_request tool
)

response = weather_agent("What's the weather like in Seattle?")
print(response)

**Run your agent with automatic instrumentation command**

With aws-opentelemetry-distro in your requirements.txt, the opentelemetry-instrument
command will:

- Load your OTEL configuration from your environment variables
- Automatically instrument Strands, Amazon Bedrock calls, agent tool and databases, and other
    requests made by agent
- Send traces to CloudWatch

Step 3: Enable observability for non-Amazon Bedrock AgentCore-hosted agents 656


- Enable you to visualize the agent's decision-making process in the GenAI Observability
    dashboard

opentelemetry-instrument python agent.py

You can now view your traces, sessions and metrics on GenAI Observability Dashboard on Amazon
CloudWatch with the value of **YOUR-AGENT-NAME** that you configured in your environment
variables.

To correlate traces across multiple agent runs, you can associate a session ID with your telemetry
data using OpenTelemetry baggage:

from opentelemetry import baggage, context
ctx = baggage.set_baggage("session.id", session_id)

Run the session-enabled version following command, complete implementation provided in the
notebook:

opentelemetry-instrument python strands_travel_agent_with_session.py --session-id
"user-session-123"

#### Step 4: Observe your agent with GenAI observability on Amazon CloudWatch....................

After implementing observability, you can view the collected data in CloudWatch:

**Observe your agent**

1.Open the GenAI Observability on CloudWatch console

2.You can view the data related to model invocations and agents on Bedrock Amazon Bedrock
AgentCore on the dashboard.

3.In the Bedrock Agentcore tab you can view Agents View, Sessions View and Traces View.

4.Agents View lists all your Agents that are on and not on runtime, you can also choose an agent
and view further details like runtime metrics, sessions and traces specific to an agent.

5.In the **Sessions View** tab, you can navigate across all the sessions associated with agents.

Step 4: Observe your agent with GenAI observability on Amazon CloudWatch 657


6.In the **Trace View** tab, you can look into the traces and span information for agents. Also explore
the trace trajectory and timeline by choosing a trace.

**View logs in CloudWatch**

**To view logs in CloudWatch**

1. Open the CloudWatch console
2. In the left navigation pane, expand **Logs** and select **Log groups**
3. Search for your agent's log group:
    - Standard logs (stdout/stderr) Location: /aws/bedrock-agentcore/runtimes/
       <agent_id>-<endpoint_name>/[runtime-logs] <UUID>
    - OTEL structured logs: /aws/bedrock-agentcore/runtimes/<agent_id>-
       <endpoint_name>/runtime-logs

**View traces and spans**

**To view traces and spans**

1. Open the CloudWatch console
2. Select **Transaction Search** from the left navigation
3. Location: /aws/spans/default
4. Filter by service name or other criteria
5. Select a trace to view the detailed execution graph

**View metrics**

**To view metrics**

1. Open the CloudWatch console
2. Select **Metrics** from the left navigation
3. Browse to the bedrock-agentcore namespace
4. Explore the available metrics

Step 4: Observe your agent with GenAI observability on Amazon CloudWatch 658


#### Best practices

1. **Start simple, then expand** - The default observability provided by Amazon Bedrock AgentCore
    captures most critical metrics automatically, including model calls, token usage, and tool
    execution.
2. **Configure for development stage** - Tailor your observability configuration to match your
    current development phase and progressively adjust.
3. **Use consistent naming** - Establish naming conventions for services, spans, and attributes from
    the start
4. **Filter sensitive data** - Prevent exposure of confidential information by filtering sensitive data
    from observability attributes and payloads.
5. **Set up alerts** - Configure CloudWatch alarms to notify you of potential issues before they
    impact users

### Add observability to your Amazon Bedrock AgentCore

### resources

Amazon Bedrock AgentCore provides a number of built-in metrics to monitor the performance of
resources for the AgentCore runtime, memory, gateway, built-in tools, and identity resource types.
This default data is available in Amazon CloudWatch. To view the full range of observability data in
the CloudWatch console, or to output custom runtime metrics for agents, you need to instrument
your code using the AWS Distro for Open Telemetry (ADOT) SDK.

To view the observability dashboard in CloudWatch, open the Amazon CloudWatch GenAi
Observability page.

See the following sections to learn more about configuring your resources to view observability
metrics in the CloudWatch console generative AI observability page and in CloudWatch Logs.

Tip
Use of the ADOT SDK to output custom metrics is also supported for agents running
outside the AgentCore runtime. To learn how to enable observability for these agents, see
the section called â€œEnabling observability for agents hosted outside of AgentCoreâ€.

Best practices 659


**Topics**

- Enabling AgentCore observability
- Enabling observability in agent code for AgentCore-hosted agents
- Enabling observability for agents hosted outside of AgentCore
- Enabling observability for AgentCore runtime, memory, gateway, built-in tools, and identity
    resources
- Enhanced AgentCore runtime observability with custom headers
- Enhanced AgentCore built-in tools observability with custom headers
- Enhanced AgentCore identity observability with custom headers
- Observability best practices
- Using other observability platforms

#### Enabling AgentCore observability...................................................................................................

To view metrics, spans, and traces generated by the AgentCore service, you first need to complete a
one-time setup to turn on Amazon CloudWatch Transaction Search. To view service-provided spans
for memory resources, you also need to enable tracing when you create a memory. See the section
called â€œEnabling observability for AgentCore runtime, memory, gateway, built-in tools, and identity
resourcesâ€ to learn more.

The following sections describe how to perform these setup actions and to enable observability in
your agent code.

**Enabling CloudWatch Transaction Search**

You can enable CloudWatch Transaction Search either by using the CloudWatch console, or by
using an API through the AWS Command Line Interface (AWS CLI) or one of the AWS SDKs.

Use one of the following procedures to enable Transaction Search.

CloudWatch console

To enable CloudWatch Transaction Search in the CloudWatch console

1. Open the CloudWatch console.
2. In the navigation pane, expand **Application Signals (APM)** and choose **Transaction search**.
3. Choose **Enable Transaction Search**.

Enabling AgentCore observability 660


4. Select the checkbox to ingest spans as structured logs.
5. Choose **Save**.

##### API

To enable CloudWatch Transaction Search using an API

1. When using the AWS CLI or an AWS SDK to enable Transaction Search, first configure the
    necessary permissions to ingest spans in CloudWatch Logs by adding a resource-based
    policy with PutResourcePolicy.

The following AWS CLI command adds a resource policy that gives AWS X-Ray permissions
to send traces to CloudWatch Logs.

aws logs put-resource-policy --policy-name MyResourcePolicy --policy-
document '{ "Version": "2012-10-17", "Statement": [ { "Sid":
"TransactionSearchXRayAccess", "Effect": "Allow", "Principal": { "Service":
"xray.amazonaws.com" }, "Action": "logs:PutLogEvents", "Resource":
[ "arn:partition:logs:region:account-id:log-group:aws/spans:",
"arn:partition:logs:region:account-id:log-group:/aws/application-
signals/data:" ], "Condition": { "ArnLike": { "aws:SourceArn":
"arn:partition:logs:region:account-id:*" }, "StringEquals":
{ "aws:SourceAccount": "account-id" } } } ]}'

For clarity, the inline JSON policy in this command is shown expanded in the following
example:

{
"Version":"2012-10-17",
"Statement": [
{
"Sid": "TransactionSearchXRayAccess",
"Effect": "Allow",
"Principal": {
"Service": "xray.amazonaws.com"
},
"Action": "logs:PutLogEvents",
"Resource": [
"arn:aws:logs: us-east-1 : 123456789012 :log-group:aws/spans:*",

Enabling AgentCore observability 661


"arn:aws:logs: us-east-1 : 123456789012 :log-group:/aws/
application-signals/data:"
],
"Condition": {
"ArnLike": {
"aws:SourceArn": "arn:aws:xray: us-east-1 : 123456789012 :"
},
"StringEquals": {
"aws:SourceAccount": " 123456789012 "
}
}
}
]
}

2. Configure the destination of your trace segments using UpdateTraceSegmentDestination.

To use the AWS CLI, run the following command.

aws xray update-trace-segment-destination --destination CloudWatchLogs

3. (Optional) Configure your desired sampling percentage using UpdateIndexingRule.

To use the AWS CLI, run the following command.

aws xray update-indexing-rule --name "Default" --rule '{"Probabilistic":
{"DesiredSamplingPercentage": number}}'

#### Enabling observability in agent code for AgentCore-hosted agents.......................................

In addition to the service-generated metrics, with AgentCore you can also gather span and trace
data as well as custom metrics emitted from your agent code.

When you use agent frameworks like Strands, LangChain, or CrewAI with supported third-party
instrumentation libraries, the framework itself comes with built in support for OTEL and GenAI
semantic conventions, and it can also be instrumented with an auto-instrumentation package such
as opentelemetry-instrument-langchain. It is also possible to send Generative AI semantic
conventions telemetry and spans by defining a custom tracer. AgentCore supports use of the
following instrumentation libraries in your agent framework:

Enabling observability in agent code for AgentCore-hosted agents 662


- OpenInference
- Openllmetry
- OpenLit
- Traceloop

To view this data in the CloudWatch console generative AI observability page and in Amazon
CloudWatch, you need to add the AWS Distro for Open Telemetry (ADOT) SDK to your agent code.

Note
With AgentCore, you can also view metrics for agents that aren't running in the AgentCore
runtime. Additional setup steps are required to configure telemetry outputs for non-
AgentCore agents. See the instructions in the section called â€œEnabling observability for
agents hosted outside of AgentCoreâ€ to learn more.

To add ADOT support and enable AgentCore observability, follow the steps in the following
procedure.

**Add observability to your AgentCore agent**

1. Ensure that your framework is configured to emit traces. For example, in the Strands
    framework, the tracer object must be configured to instruct Strands to emit Open Telemetry
    (OTEL) logs.
2. Add the ADOT SDK and boto3 to your agent's dependencies. For Python, add the following to
    your requirements.txt file:

aws-opentelemetry-distro>=0.10.0
boto3

Alternatively, you can install the dependencies directly:

pip install aws-opentelemetry-distro>=0.10.0 boto3

3. Execute your agent code using the OpenTelemetry auto-instrumentation command:

opentelemetry-instrument python my_agent.py

Enabling observability in agent code for AgentCore-hosted agents 663


This auto-instrumentation approach automatically adds the SDK to the Python path. You may
already be using this approach as part of your standard OpenTelemetry implementation.

For containerized environment (such as docker) add the following command:

CMD ["opentelemetry-instrument", "python", "main.py"]

When using ADOT, in order to propagate session id correctly, define the X-Amzn-Bedrock-
AgentCore-Runtime-Session-Id in the request header. ADOT then sets the session_id
correctly in the downstream headers.

To propoagate a trace ID, invoke the AgentCore runtime with the parameter
traceId= set.

You can also invoke your agent with additional headers for additional observability options.
See the section called â€œEnhanced AgentCore runtime observability with custom headersâ€ to
learn more.

#### Enabling observability for agents hosted outside of AgentCore..............................................

To enable observability for agents hosted outside of the AgentCore runtime, first follow the steps
in the previous sections to enable CloudWatch Transaction Search and add the ADOT SDK to your
code.

For agents running outside of the AgentCore runtime, you also need to create an agent log-group
which you include in your environment variables.

Configure your AWS environment variables, and then set your Open Telemetry environment
variables as shown in the following.

AWS environment variables

AWS_ACCOUNT_ID=
AWS_DEFAULT_REGION=
AWS_REGION=
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=

OTEL environment variables

Enabling observability for agents hosted outside of AgentCore 664


AGENT_OBSERVABILITY_ENABLED=true
OTEL_PYTHON_DISTRO=aws_distro
OTEL_PYTHON_CONFIGURATOR=aws_configurator # required for ADOT Python only
OTEL_RESOURCE_ATTRIBUTES=service.name=<agent-name>,aws.log.group.names=/aws/bedrock-
agentcore/runtimes/<agent-id>,cloud.resource_id=<AgentEndpointArn:AgentEndpointName> #
endpoint is optional
OTEL_EXPORTER_OTLP_LOGS_HEADERS=x-aws-log-group=/aws/bedrock-agentcore/runtimes/<agent-
id>,x-aws-log-stream=runtime-logs,x-aws-metric-namespace=bedrock-agentcore
OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf
OTEL_TRACES_EXPORTER=otlp

Replace <agent-name> with your agent's name and <agent-id> with a unique identifier for your
agent.

Note
(Optional) For Agent Frameworks other than Strands, LangChain, CrewAI:
You may need to add an additional SDK and code to send Generative AI semantic
conventions telemetry and spans. CloudWatch AgentCore Observability supports use of the
following instrumentation libraries in your agent framework:

- OpenInference
- Openllmetry
- OpenLit
- Traceloop

**Session ID support**

To propagate session ID, you need to invoke using session identifier in the OTEL baggage:

from opentelemetry import baggage

ctx = baggage.set_baggage("session.id", session_id) # Set the session.id in baggage
attach(ctx) # Attach the context to make it active token

Enabling observability for agents hosted outside of AgentCore 665


#### Enabling observability for AgentCore runtime, memory, gateway, built-

#### in tools, and identity resources

When you create an AgentCore runtime resource (agent), by default, AgentCore runtime creates a
CloudWatch log group for the service-provided logs. However, for memory, gateway, and built-in
tool resources, AgentCore doesn't configure log destinations for you automatically.

For memory and gateway resources, you can configure log destinations either in the console or by
using an AWS SDK. If you use the console to configure a CloudWatch Logs destination, the default
log group name for memory and gateway resources has the form /aws/vendedlogs/bedrock-
agentcore/{resource-type}/APPLICATION_LOGS/{resource-id}, where {resource-
type} is either memory or gateway.

For memory and gateway logs, you can also configure log destinations in Amazon S3 logs or
Firehose stream logs using the AgentCore console. To learn more about storing logs in Amazon S3
or Firehose, see Uploading, downloading, and working with objects in Amazon S3 and Creating an
Amazon Data Firehose delivery stream.

To learn more about the log data output by AgentCore for memory and gateway resources see
Provided log data (memory) or Provided log data (gateway).

For built-in tool resources, the AgentCore service doesn't provide logs by default, but you can
output your own logs from your code. If you supply your own log outputs, you need to manually
configure log destinations to store this data.

To see what observability data AgentCore provides by default for each resource type, see the
section called â€œAgentCore generated observability dataâ€.

**Configure log destinations using the console**

To configure log destinations for memory or gateway logs in the AgentCore console, use the
following procedures.

Memory

To configure log delivery for memory resources (console)

1. Open the Memory page in the AgentCore console.
2. In the **Memory** pane, select the memory you want to configure a log destination for.
3. Scroll down to the **Log delivery** pane and choose **Add**.

Enabling observability for AgentCore runtime, memory, gateway, built-in tools, and identity resources 666


4. From the dropdown list, select the type of log destination you want to add (CloudWatch
    Logs group, Amazon S3 bucket, or Amazon Data Firehose).
5. For **Log type** , select **APPLICATION_LOGS**.
6. For Amazon S3 and Firehose destinations, enter a **Delivery destination ARN**. For
    CloudWatch Logs, the **Destination log group** is already populated with a default value.
7. (Optional) For CloudWatch Logs destinations, to change the default log group, enter a new
    log group name or select an existing log group under **Destination log group**.
8. (Optional) To change the fields that are captured in each log record or the logs' output
    format, expand **Additional settings -** **_optional_** , and modify the **Field selection** , **Output**
    **format** , and **Field delimiter** to your desired configuration.
9. Choose **Add**.

Gateway

To configure log delivery for gateway resources (console)

1. Open the Gateways page in the AgentCore console.
2. In the **Gateways** pane, select the gateway you want to configure a log destination for.
3. Scroll down to the **Log delivery** pane and choose **Add**.
4. From the dropdown list, select the type of log destination you want to add (CloudWatch
    Logs group, Amazon S3 bucket, or Amazon Data Firehose).
5. For Amazon S3 and Firehose destinations, enter a **Delivery destination ARN**. For
    CloudWatch Logs, the **Destination log group** is already populated with a default value.
6. (Optional) For CloudWatch Logs destinations, to change the default log group, enter a new
    log group name or select an existing log group under **Destination log group**.
7. (Optional) To change the fields that are captured in each log record or the logs' output
    format, expand **Additional settings -** **_optional_** , and modify the **Field selection** , **Output**
    **format** , and **Field delimiter** to your desired configuration.
8. Choose **Add**.

Runtime

To configure log delivery for agent runtime resources (console)

1. Open the Agent Runtime page in the AgentCore console.

Enabling observability for AgentCore runtime, memory, gateway, built-in tools, and identity resources 667


2. In the **Runtime agents** pane, select the runtime agent for which you want to configure a
    log destination.
3. Scroll down to the **Log delivery** pane and from the **Add** drop-down, choose the **Logging**
    **destination** - either Amazon CloudWatch Logs, Amazon S3, or Amazon Data Firehose.
4. Configure the following log delivery details and then choose **Add** :
    - For **Log type** , choose **APPLICATION_LOGS**.
    - If using Amazon CloudWatch Logs as the logging destination, specify the destination log
       group.
    - If using Amazon S3 as the logging destination, specify the destination Amazon S3
       bucket.
    - If using Amazon Data Firehose as the logging destination, specify a destination delivery
       stream.
5. Verify that the log delivery status is set to **Delivery active**.

Built-in tools

To configure log delivery for built-in tools resources (console)

1. Open the Built-in tools page in the AgentCore console.
2. In the **Built-in tools** pane, either in the **Code interperter tools** or the **Browser tools** tab,
    select the code interpreter tool or browser tool for which you want to configure a log
    destination.
3. Scroll down to the **Log delivery** pane and from the **Add** drop-down, choose the **Logging**
    **destination** - either Amazon CloudWatch Logs, Amazon S3, or Amazon Data Firehose.
4. Configure the following log delivery details and then choose **Add** :
    - For **Log type** , choose **APPLICATION_LOGS**.
    - If using Amazon CloudWatch Logs as the logging destination, specify the destination log
       group.
    - If using Amazon S3 as the logging destination, specify the destination Amazon S3
       bucket.
    - If using Amazon Data Firehose as the logging destination, specify a destination delivery
       stream.
5. Verify that the log delivery status is set to **Delivery active**.

Enabling observability for AgentCore runtime, memory, gateway, built-in tools, and identity resources 668


Identity

WorkloadIdentity log delivery enablement is handled at the associated resource level, including
agent runtime or agent gateway resources.

To configure WorkloadIdentity log delivery for associated resources (console)

1. Open either the Gateway or the Agent Runtime page in the AgentCore console and select
    an agent or a gateway for which you want to enable WorkloadIdentity logging.
2. In the **Identity** tab, scroll down to the **Log delivery** pane and from the **Add** drop-down,
    choose the **Logging destination** - either Amazon CloudWatch Logs, Amazon S3, or Amazon
    Data Firehose.
3. Configure the following log delivery details and then choose **Add** :
    - For **Log type** , choose **APPLICATION_LOGS**.
    - If using Amazon CloudWatch Logs as the logging destination, specify the destination log
       group.
    - If using Amazon S3 as the logging destination, specify the destination Amazon S3
       bucket.
    - If using Amazon Data Firehose as the logging destination, specify a destination delivery
       stream.
4. Verify that the log delivery status is set to **Delivery active**.

**Configure tracing delivery to CloudWatch using the console**

This section describes how to enable trace delivery to CloudWatch to track the flow of interactions
through your application allowing you to visualize requests, identify performance bottlenecks,
troubleshoot errors, and optimize performance.

Memory

To configure tracing for memory resources (console)

1. Open the Memory page in the AgentCore console.
2. In the **Memory** pane, select the memory resource for which you want to enable tracing.
3. In the **Tracing** pane, choose **Edit** , toggle the widget to **Enable** , and then choose **Save**.

Enabling observability for AgentCore runtime, memory, gateway, built-in tools, and identity resources 669


Runtime

To configure tracing for runtime resources (console)

1. Open the Agents runtime page in the AgentCore console.
2. In the **Runtime agents** pane, select the agent for which you want to enable tracing.
3. In the **Tracing** pane, choose **Edit** , toggle the widget to **Enable** , and then choose **Save**.

Tracing will be enabled for the selected agent and spans will be available in the aws/
spans log group.

To configure WorkloadIdentity tracing for runtime resources (console)

1. Open the Agents runtime page in the AgentCore console.
2. In the **Runtime agents** pane, choose the **Identity** tab, and then select the agent for which
    you want to enable WorkloadIdentity tracing.
3. In the **Tracing** pane, choose **Edit** , toggle the widget to **Enable** , and then choose **Save**.

WorkloadIdentity tracing will be enabled for the selected agent and spans will be available
in the aws/spans log group.

Built-in tools

To configure tracing for built-in tools (console)

1. Open the Built-in tools page in the AgentCore console.
2. In the **Built-in tools** pane, either in the **Code interperter tools** or the **Browser tools** tab,
    select the code interpreter tool or browser tool for which you want to enable tracing.
3. In the **Tracing** pane, choose **Edit** , toggle the widget to **Enable** , and then choose **Save**.

Tracing will be enabled for the selected code interperter or browser tool and spans will be
available in the aws/spans log group.

Gateway

To configure tracing for gateway resources (console)

1. Open the Gateways page in the AgentCore console.

Enabling observability for AgentCore runtime, memory, gateway, built-in tools, and identity resources 670


2. In the **Gateways** pane, select the gateway for which you want to enable tracing.
3. In the **Tracing** pane, choose **Edit** , toggle the widget to **Enable** , and then choose **Save**.

Tracing will be enabled for the selected gateway and spans will be available in the aws/
spans log group.

To configure WorkloadIdentity tracing for gateway resources (console)

1. Open the Gateways page in the AgentCore console.
2. In the **Gateways** pane, choose the **Identity** tab, and then select the gateway for which you
    want to enable WorkloadIdentity tracing.
3. In the **Tracing** pane, choose **Edit** , toggle the widget to **Enable** , and then choose **Save**.

WorkloadIdentity tracing will be enabled for the selected gateway and spans will be
available in the aws/spans log group.

Note
You must have CloudWatch Transaction Search enabled before you can enable tracing.

Identity

To configure tracing for identity resources (console)

1. Open the Identity page in the AgentCore console.
2. In the **Identity** pane, select the OAuth client or the API key for which you want to enable
    tracing.
3. In the **Tracing** pane, choose **Edit** , toggle the widget to **Enable** , and then choose **Save**.

**Configure CloudWatch resources using an AWS SDK**

**To configure a delivery source for logs and traces (SDK)**

- Run the following Python code to configure CloudWatch for your memory, gateway, and built-
    in tool resources. Note that delivery sources and destinations for tracing are only applicable for
    memory and gateway resources.

Enabling observability for AgentCore runtime, memory, gateway, built-in tools, and identity resources 671


import boto3

def enable_observability_for_resource(resource_arn, resource_id, account_id,
region='us-east-1'):
"""
Enable observability for a Bedrock AgentCore resource (e.g., Memory Store)
"""
logs_client = boto3.client('logs', region_name=region)

Step 0: Create new log group for vended log delivery
log_group_name = f'/aws/vendedlogs/bedrock-agentcore/{resource_id}'
logs_client.create_log_group(logGroupName=log_group_name)
log_group_arn = f'arn:aws:logs:{region}:{account_id}:log-group:{log_group_name}'

Step 1: Create delivery source for logs
logs_source_response = logs_client.put_delivery_source(
name=f"{resource_id}-logs-source",
logType="APPLICATION_LOGS",
resourceArn=resource_arn
)

Step 2: Create delivery source for traces
traces_source_response = logs_client.put_delivery_source(
name=f"{resource_id}-traces-source",
logType="TRACES",
resourceArn=resource_arn
)

Step 3: Create delivery destinations
logs_destination_response = logs_client.put_delivery_destination(
name=f"{resource_id}-logs-destination",
deliveryDestinationType='CWL',
deliveryDestinationConfiguration={
'destinationResourceArn': log_group_arn,
}
)

Traces required
traces_destination_response = logs_client.put_delivery_destination(
name=f"{resource_id}-traces-destination",
deliveryDestinationType='XRAY'
)

Enabling observability for AgentCore runtime, memory, gateway, built-in tools, and identity resources 672


Step 4: Create deliveries (connect sources to destinations)
logs_delivery = logs_client.create_delivery(
deliverySourceName=logs_source_response['deliverySource']['name'],
deliveryDestinationArn=logs_destination_response['deliveryDestination']['arn']
)

Traces required
traces_delivery = logs_client.create_delivery(
deliverySourceName=traces_source_response['deliverySource']['name'],
deliveryDestinationArn=traces_destination_response['deliveryDestination']
['arn']
)

print(f"Observability enabled for {resource_id}")
return {
'logs_delivery_id': logs_delivery['id'],
'traces_delivery_id': traces_delivery['id']
}

Usage example
resource_arn = "arn:aws:bedrock-agentcore:us-east-1:123456789012:memory/my-memory-id"
resource_id = "my-memory-id"
account_id = "123456789012"

delivery_ids = enable_observability_for_resource(resource_arn, resource_id, account_id)

#### Enhanced AgentCore runtime observability with custom headers..........................................

You can invoke your agent with additional HTTP headers to provide enhanced observability
options. The following example shows invocations including optional additional header requests
for agents hosted in the AgentCore runtime.

**Example Boto3 invocation**

def invoke_agent(agent_id, payload, session_id=None):
client = boto3.client("bedrock-agentcore", region="us-west-2")
response = client.invoke_agent_runtime(
agentRuntimeArn="arn:aws:bedrock-agentcore:us-west-2:111122223333:runtime/
test_agent_boto2-nIg2xk3VSR",
runtimeSessionId="12345678-1234-5678-9abc-123456789012",
payload='{"query": "Plan a weekend in Seattle"}',
)

Enhanced AgentCore runtime observability with custom headers 673


You can include the following optional headers when invoking your agent to enhance observability
and tracing capabilities:

**Optional request headers for observability**

Header Description Sample
Value

Technical Explanation

X-Amzn-Tr
ace-Id

Trace ID
for request
tracking (X-
Ray Format)

Root=1-57
59e988-bd
862e3fe1b
e46a99427
2793;Pare
nt=53995c
3f42cd8ad
8;Sampled=1

Used for distributed tracing across AWS
services. Contains root ID (request origin),
parent ID (previous service), and sampling
decision for tracing. Sampling=1 means 100%
sampling. Parent is X-Ray Trace format as
well. OTEL will auto-generate trace IDs if not
supplied.

traceparent W3C
standard
tracing
header

00-4bf92f
3577b34da
6a3ce929d
0e0e4736-
00f067aa0
ba902b7-01

W3C format that includes version, trace ID,
parent ID, and flags. Required for cross-service
trace correlation when using modern tracing
systems.

X-Amzn-Be
drock-Age
ntCore-Ru
ntime-Ses
sion-Id

AgentCore
session
identifier

a1b2c3d4-
5678-90ab
-cdef-EXA
MPLEaaaaa

Identifies a user session within the AgentCore
system. Helps with session-based analytics
and troubleshooting.

mcp-session-
id

MCP session
identifier

mcp-a1b2c
3d4-5678-
90ab-cdef-
EXAMPLEa
aaaa

Identifies a session in the Managed Cloud
Platform. Enables tracing of operations across
the MCP ecosystem.

tracestate Additional
tracing state
information

congo=t61
rcWkgMzE,
rojo=00f0

Vendor-specific tracing information. Conveys
additional context for tracing systems beyond
what's in traceparent.

Enhanced AgentCore runtime observability with custom headers 674


Header Description Sample
Value

Technical Explanation

67aa0ba90
2b7

baggage Context
propagation
for distribut
ed tracing

userId=al
ice,serve
rRegion=us-
east-1

Key-value pairs that propagate user-defi
ned properties across service boundaries for
contextual logging and analysis.

#### Enhanced AgentCore built-in tools observability with custom headers..................................

You can invoke your Build-in Tools with additional HTTP headers to provide enhanced observability
options. You can include the following optional headers when integrating following Build-in Tools
APIs to enhance observability and tracing capabilities:

The following APIs support custom headers:

- StartCodeInterpreterSession
- InvokeCodeInterpreter
- StopCodeInterpreterSession
- StartBrowserSession
- StopBrowserSession

**Optional request headers for observability**

Header Description Sample
Value

Technical Explanation

X-Amzn-Tr
ace-Id

Trace ID
for request
tracking (X-
Ray Format)

Root=1-57
59e988-bd
862e3fe1b
e46a99427
2793;Pare
nt=53995c

Used for distributed tracing across AWS
services. Contains root ID (request origin),
parent ID (previous service), and sampling
decision for tracing. Sampling=1 means 100%
sampling. Parent is X-Ray Trace format as
well. OTEL will auto-generate trace IDs if not
supplied.

Enhanced AgentCore built-in tools observability with custom headers 675


Header Description Sample
Value

Technical Explanation

3f42cd8ad
8;Sampled=1

traceparent W3C
standard
tracing
header

00-4bf92f
3577b34da
6a3ce929d
0e0e4736-
00f067aa0
ba902b7-01

W3C format that includes version, trace ID,
parent ID, and flags. Required for cross-service
trace correlation when using modern tracing
systems.

#### Enhanced AgentCore identity observability with custom headers...........................................

You can invoke your identity resources with additional HTTP headers to provide enhanced
observability options. You can include the following optional headers when integrating following
identity APIs to enhance observability and tracing capabilities:

The following APIs support custom headers:

- GetWorkloadAccessToken
- GetWorkloadAccessTokenForJWT
- GetWorkloadAccessTokenForUserId
- GetResourceOauth2Token
- GetResourceAPIKey

**Optional request headers for observability**

Header Description Sample
Value

Technical Explanation

X-Amzn-Tr
ace-Id

Trace ID
for request
tracking (X-
Ray Format)

Root=1-57
59e988-bd
862e3fe1b
e46a99427
2793;Pare

Used for distributed tracing across AWS
services. Contains root ID (request origin),
parent ID (previous service), and sampling
decision for tracing. Sampling=1 means 100%
sampling. Parent is X-Ray Trace format as

Enhanced AgentCore identity observability with custom headers 676


Header Description Sample
Value

Technical Explanation

nt=53995c
3f42cd8ad
8;Sampled=1

well. OTEL will auto-generate trace IDs if not
supplied.

#### Observability best practices.............................................................................................................

Consider the following best practices when implementing observability for agents in AgentCore:

- Use consistent session IDs - When possible, reuse the same session ID for related requests to
    maintain context across interactions.
- Implement distributed tracing - Use the provided headers to enable end-to-end tracing across
    your application components.
- Add custom attributes - Enhance your traces and metrics with custom attributes that provide
    additional context for troubleshooting and analysis.
- Monitor resource usage - Pay attention to memory usage metrics to optimize your agent's
    performance.
- Set up alerts - Configure CloudWatch alarms to help notify you of potential issues before they
    impact your users.

#### Using other observability platforms..............................................................................................

To integrate agents hosted in the AgentCore runtime with other observability platforms to capture
and view telemetry outputs, set the following environment variable:

DISABLE_ADOT_OBSERVABILITY=true

Setting this variable to true unsets the AgentCore runtime's default ADOT environment variables,
ensuring that none of the default ADOT configurations are set.

### Understand observability for agentic resources in AgentCore

This section defines the concepts of sessions, traces and spans as they relate to monitoring and
observability of agents.

Observability best practices 677


**Topics**

- Sessions
- Traces
- Spans
- Relationship Between Sessions, Traces, and Spans

#### Sessions.................................................................................................................................................

A session represents a complete interaction context between a user and an agent. Sessions
encapsulate the entire conversation or interaction flow, maintaining state and context across
multiple exchanges. Each session has a unique identifier and captures the full lifecycle of user
engagement with the agent, from initialization to termination.

Sessions provide the following capabilities for agents:

- Context persistence across multiple interactions within the same conversation
- State management for maintaining user-specific information
- Conversation history tracking for contextual understanding
- Resource allocation and management for the duration of the interaction
- Isolation between different user interactions with the same agent

From an observability perspective, sessions provide a high-level view of user engagement patterns,
allowing you to monitor agent performance across metrics, traces, and spans and to understand
how users interact with your agents over time and across different use cases.

By default, AgentCore provides a set of observability metrics at the session level for agents
that are running in the AgentCore runtime. You can view the runtime metrics in the Amazon
CloudWatch console on the generative AI observability page. This page offers a variety of graphs
and visualizations to help you interpret your agents' data. AgentCore also outputs a default set
of metrics for memory resources, gateway resources, and built-in tools. All of these metrics can
be viewed in CloudWatch. In addition to the provided metrics, logs and spans are provided by
default for memory resources, and by instrumenting your agent code, you can capture custom
metrics, logs, and spans for your agent which can also be viewed on the CloudWatch generative AI
observability page. See the following sections and the section called â€œView metrics for your agentsâ€
to learn more.

Sessions 678


#### Traces....................................................................................................................................................

A trace represents a detailed record of a single request-response cycle beginning from with an
agent invocation and may include additional calls to other agents. Traces capture the complete
execution path of a request, including all internal processing steps, external service calls, decision
points, and resource utilization. Each trace is associated with a specific session and provides
granular visibility into the agent's behavior for a particular interaction.

Traces include the following components for agents:

- Request details including timestamps, input parameters, and context
- Processing steps showing the sequence of operations performed
- Tool invocations with input/output parameters and execution times
- Resource utilization metrics such as processing time
- Error information including exception details and recovery attempts
- Response generation details and final output

From an observability perspective, traces provide deep insights into the internal workings of your
agents, allowing you to troubleshoot issues, optimize performance, and understand behavior
patterns. By analyzing trace data, you can identify bottlenecks, detect anomalies, and verify that
your agent is functioning as expected across different scenarios and inputs.

To gather trace data, you need to instrument your agent code using the AWS Distro for Open
Telemetry (ADOT). See the section called â€œEnabling observability in agent code for AgentCore-
hosted agentsâ€ and the section called â€œEnabling observability for agents hosted outside of
AgentCoreâ€ to learn more.

#### Spans

A span represents a discrete, measurable unit of work within an agent's execution flow. Spans
capture fine-grained operations that occur during request processing, providing detailed visibility
into the internal components and steps that make up a complete trace. Each span has a defined
start and end time, creating a precise timeline of agent activities and their durations.

Spans include the following essential attributes for agent observability:

- Operation name identifying the specific function or process being executed
- Timestamps marking the exact start and end times of the operation

Traces 679


- Parent-child relationships showing how operations nest within larger processes
- Tags and attributes providing contextual metadata about the operation
- Events marking significant occurrences within the span's lifetime
- Status information indicating success, failure, or other completion states
- Resource utilization metrics specific to the operation

Spans form a hierarchical structure within traces, with parent spans encompassing child spans that
represent more granular operations. For example, a high-level "process user query" span might
contain child spans for "parse input," "retrieve context," "generate response," and "format output."
This hierarchical organization creates a detailed execution tree that reveals the complete flow of
operations within the agent.

By default, AgentCore outputs a set of span data for memory resources only. This data can be
viewed in CloudWatch Logs and CloudWatch Application signals. To record span data for your
agents or gateway resources, you need to instrument your agent. See the section called â€œEnabling
observability in agent code for AgentCore-hosted agentsâ€ and the section called â€œEnabling
observability for agents hosted outside of AgentCoreâ€ to learn more.

#### Relationship Between Sessions, Traces, and Spans

Sessions, traces, and spans form a three-tiered hierarchical relationship in the observability
framework for agents. A session contains multiple traces, with each trace representing a discrete
interaction within the broader context of the session. Each trace, in turn, contains multiple spans
that capture the fine-grained operations and steps within that interaction. This hierarchical
structure allows you to analyze agent behavior at different levels of granularity, from high-level
session patterns to mid-level interaction flows to detailed execution paths for specific operations.

The relationship between these three observability components can be visualized as:

- Sessions (highest level) - Represent complete user conversations or interaction contexts
- Traces (middle level) - Represent individual request-response cycles within a session
- Spans (lowest level) - Represent specific operations or steps within a trace

This multi-tiered relationship enables several important observability capabilities:

- Contextual analysis of individual interactions within their broader conversation flow
- Correlation of related requests across a user's interaction journey

Relationship 680


- Progressive troubleshooting from session-level anomalies to trace-level patterns to span-level
    root causes
- Comprehensive performance profiling across different temporal and functional dimensions
- Holistic understanding of agent behavior patterns and evolution throughout a conversation
- Precise identification of performance bottlenecks at the operation level through span analysis

While traces provide visibility into complete request-response cycles, spans offer deeper insights
into the internal workings of those cycles. Spans reveal exactly which operations consume the
most time, where errors originate, and how different components interact within a single trace.
This granularity is particularly valuable when troubleshooting complex issues or optimizing
performance in sophisticated agent implementations.

By leveraging session, trace, and span data in your observability strategy, you can gain
comprehensive insights into your agent's behavior, performance, and effectiveness at multiple
levels of detail. This multi-layered approach to observability supports continuous improvement,
robust troubleshooting, and informed optimization of your agent implementations, from high-
level conversation patterns down to individual operation performance.

### AgentCore generated observability data............................................................................................

For agents running in the AgentCore runtime, AgentCore automatically generates a set of session
metrics which you can view in the Amazon CloudWatch Logs generative AI observability page. You
can also use AgentCore observability to monitor the performance of memory, gateway, and built-
in tool resources, even if you're not using the AgentCore runtime to host your agents. For memory,
gateway, and built-in tool resources, AgentCore outputs a default set of data to CloudWatch.

The following table summarizes the default data provided for each resource type, and where the
data is available.

Resource type Service-provided
data

Available in
CloudWatch gen AI
observability

Available in
CloudWatch (Logs or
metrics)

Agent Metrics Yes Yes

Memory Metrics, Spans, Logs No Yes

AgentCore generated observability data 681


Resource type Service-provided
data

Available in
CloudWatch gen AI
observability

Available in
CloudWatch (Logs or
metrics)

Gateway Metrics No Yes

Tools Metrics No Yes

* memory spans and logs require enablement. See the section called â€œAdd observability to your
agentsâ€ to learn more.

Note
To view metrics, spans, and traces for AgentCore, you need to perform a one-time setup
process to enable CloudWatch Transaction Search. To learn more see the section called
â€œEnabling AgentCore observabilityâ€.

Refer to the following topics to learn about the default service-provided observability metrics for
AgentCore runtime, memory, and gateway resources.

**Topics**

- AgentCore generated runtime observability data
- AgentCore generate memory observability data
- AgentCore generated gateway observability data
- AgentCore generated built-in tools observability data
- AgentCore generated identity observability data

By instrumenting your agent code, you can also gather more detailed trace and span data as well
as custom metrics. See the section called â€œEnabling observability in agent code for AgentCore-
hosted agentsâ€ to learn more.

AgentCore generated observability data 682


#### AgentCore generated runtime observability data

The runtime metrics provided by AgentCore give you visibility into your agent execution activity
levels, processing latency, resource utilization, and error rates. AgentCore also provides aggregated
metrics for total invocations and sessions.

**Topics**

- Observability runtime metrics
- Resource usage metrics and logs
- Provided span data
- Application log data
- Error types

#### Runtime observability data..............................................................................................................

The following list describes the runtime metrics provided by AgentCore. Runtime metrics are
batched at one minute intervals. To learn more about viewing runtime metrics, see the section
called â€œView metrics for your agentsâ€.

Invocations

Shows the total number of requests made to the Data Plane API. Each API call counts as one
invocation, regardless of the request payload size or response status.

Invocations (aggregated)

Shows the total number of invocations across all resources

Throttles

Displays the number of requests throttled by the service due to exceeding allowed TPS
(Transactions Per Second) or quota limits. These requests return ThrottlingException with HTTP
status code 429. Monitor this metric to determine if you need to review your service quotas or
optimize request patterns.

System Errors

Shows the number of server-side errors encountered by AgentCore during request processing.
High levels of server-side errors can indicate potential infrastructure or service issues that
require investigation. See the section called â€œError typesâ€ for a list of possible error codes.

Runtime observability data 683


User Errors

Represents the number of client-side errors resulting from invalid requests. These require user
action to resolve. High levels of client-side errors can indicate issues with request formatting or
permissions that need to be addressed. See the section called â€œError typesâ€ for a list of possible
error codes.

Latency

The total time elapsed between receiving the request and sending the final response token.
Represents complete end-to-end processing time of the request.

Total Errors

The total number of system and user errors. In the Amazon Bedrock AgentCore console, this
metric displays the number of errors as a percentage of the total number of invocations.

Session Count

Shows the total number of agent sessions. Useful for monitoring overall platform usage,
capacity planning, and understanding user engagement patterns.

Sessions (aggregated)

Shows the total number of sessions across all resources.

**Resource usage metrics and logs**

Amazon Bedrock AgentCore runtime provides comprehensive resource usage telemetry, including
CPU and memory consumption metrics for your runtime resources.

Note
Resource usage data may be delayed by up to 60 minutes and precision might differ across
metrics.

**Vended metrics**

Amazon Bedrock AgentCore runtime automatically provides resource usage metrics at account,
agent runtime, and agent endpoint levels. These metrics are published at 1-minute resolution.

Runtime observability data 684


Amazon CloudWatch aggregation and metric data retention will follow standard Amazon
CloudWatch data retention polices. For more information, see https://docs.aws.amazon.com/
AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Metric.

Here are the dimension sets and metrics available for monitoring your resources:

Name Dimensions Description

CPUUsed-vCPUHours Service; Service, Resource;
Service, Resource, Name

The total amount of virtual
CPU consumed in vCPU-Hours
unit, available at the resource
and account levels. Useful
for resource tracking and
estimated billing visibility.

MemoryUsed-GBHours Service; Service, Resource;
Service, Resource, Name

The total amount of memory
consumed in GB-Hours unit,
available at the resource
and account levels. Useful
for resource tracking and
estimated billing visibility.

Dimension explanation

- **Service** - AgentCore.Runtime
- **Resource** - Agent Arn
- **Name** - Agent Endpoint name, in the format of AgentName::EndpointName

Account level metrics are available in Amazon CloudWatch Bedrock AgentCore Observability
Console under the **Runtime** tab. The dashboard displays Memory and CPU usage graphs generated
from these metrics, representing total resource usage across all agents in your account within the
region.

Agent Endpoint level metrics are available in AgentEndpoint page of Amazon CloudWatch
Bedrock AgentCore Observability Console. The dashboard displays Memory and CPU usage graphs
generated from these metrics, representing total resource usage across all sessions invoked by the
specified Agent Endpoint.

Runtime observability data 685


Note
Telemetry data is provided for monitoring purposes. Actual billing is calculated based
on metered usage data and may differ from telemetry values due to aggregation timing,
reconciliation processes, and measurement precision. Refer to your AWS billing statement
for authoritative charges.

**Vended logs**

Bedrock AgentCore Runtime provides vended logs for session-level usage metrics
at 1-second granularity. Each log record contains resource consumption data
including CPU usage (agent.runtime.vcpu.hours.used) and memory consumption
(agent.runtime.memory.gb_hours.used).

Each log record will have following schema:

Log type Log fields Description

USAGE_LOGS event_timestamp, resource_
arn, service.name, cloud.pro
vider, cloud.region, account.i
d, region, resource.id,
session.id, agent.name,
elapsed_time_seconds,
agent.runtime.vcpu.hours.us
ed, agent.runtime.memo
ry.gb_hours.used

Resource Usage Logs for
session-level resource
tracking.

To enable USAGE_LOG log type for your agents, see Add observability to your Amazon Bedrock
AgentCore resources. The logs are then displayed in the configured destination (AWS LogGroup,
Amazon S3 or Amazon Kinesis Firehose) as configured.

In the Agent Session page of the Amazon CloudWatch Bedrock AgentCore Observability Console,
you can see resource usage metrics generated from these logs. To optimize your metric viewing
experience, select your desired time range using the selector in the top right to focus on specific
CPU and Memory Usage data.

Runtime observability data 686


Note
Telemetry data is provided for monitoring purposes. Actual billing is calculated based
on metered usage data and may differ from telemetry values due to aggregation timing,
reconciliation processes, and measurement precision. Refer to your AWS billing statement
for authoritative charges.

**Provided span data**

To enhance observability, AgentCore provides structured spans that provide visibility into agent
runtime invocations. To enable this span data, you need to enable observability on your agent
resource. See Add observability to your Amazon Bedrock AgentCore resources for steps and details.
This span data is available in AWS CloudWatch Logs aws/spans log group. The following table
defines the operation for which spans are created and the attributes for each captured span.

Operation name Span attributes Description

InvokeAgentRuntime aws.operation.name,
aws.resource.arn, aws.reque
st_id, aws.agent.id, aws.endpo
int.name, aws.account.id,
session.id, latency_ms,
error_type, aws.resource.type,
aws.xray.origin, aws.region

Invokes the agent runtime.

- aws.operation.name - the operation name (InvokeAgentRuntime)
- aws.resource.arn - the Amazon resource name for the agent runtime
- aws.request_id - request ID for the invocation
- aws.agent.id - the unique identifier for the agent runtime
- aws.endpoint.name - the name of the endpoint used to invoke the agent runtime
- aws.account.id - customerâ€™s account id
- session.id - the session ID for the invocation
- latency_ms - the latency of the request in milliseconds
- error_type - either throttle, system, or user (only present if error)

Runtime observability data 687


- aws.resource.type - the CFN resource type
- aws.xray.origin - the CFN resource type used by x-ray to identify the service
- aws.region - the region the customer resource exists in

**Application log data**

AgentCore provides structured Application logs that help you gain visibility into your agent
runtime invocations and session-level resource consumption. This log data is provided when
enabling observability on your agent resource. See Add observability to your Amazon Bedrock
AgentCore resources for steps and details. AgentCore can output logs to CloudWatch Logs, Amazon
S3, or Firehose stream. If you use a CloudWatch Logs destination, these logs are stored under your
agentâ€™s application logs or under your own custom log group.

Log type Log fields Description

APPLICATION_LOGS timestamp, resource_arn,
event_timestamp, account_i
d, request_id, session_id,
trace_id, span_id, service_n
ame, operation, request_p
ayload, response_payload

Application logs for
InvokeRuntimeOperation with
tracing fields, request, and
response payloads

- request_payload - the request payload of the agent invocation
- response_payload - the response from the agent invocation

**Error types**

The following list defines the possible error types for user, system, and throttling errors.

**User error codes**

- InvocationError.Validation - Client provided invalid input (400)
- InvocationError.ResourceNotFound - Requested resource doesn't exist (404)
- InvocationError.AccessDenied - Client lacks permissions (403)
- InvocationError.Conflict - Resource conflict (409)

Runtime observability data 688


**System error codes**

- InvocationError.Internal - Internal server error (500)

**Throttling error codes**

- InvocationError.Throttling - Rate limiting (429)
- InvocationError.ServiceQuota - Service-side quota/limit reached (402)

#### AgentCore generate memory observability data

For the AgentCore memory resource type, AgentCore outputs metrics to Amazon CloudWatch by
default. AgentCore also outputs a default set of spans and logs, if you enable these. See the section
called â€œEnabling observability for AgentCore runtime, memory, gateway, built-in tools, and identity
resourcesâ€ to learn more about enabling spans and logs.

Refer to the following sections to learn more about the provided observability data for your agent
memory stores.

**Provided memory metrics**

The AgentCore memory resource type provides the following metrics by default.

Latency

The total time elapsed between receiving the request and sending the final response token.
Represents complete end-to-end processing of the request.

Invocations

The total number of API requests made to the data plane and control plane. This metric also
tracks the number of memory ingestion events.

System Errors

Number of invocations that result in AWS server-side errors.

User Errors

Number of invocations that result in client-side errors.

Memory observability data 689


Errors

Total number of errors that occur while processing API requests in the data plane and control
plane. This metric also tracks the total errors that occur during memory ingestion.

Throttles

Number of invocations that the system throttled. Throttled requests count as invocations,
errors, and user errors.

Creation Count

Counts the number of created memory events and memory records.

**Provided span data**

To enhance observability, AgentCore provides structured spans that trace the relationship between
events and the memories they generate or access. To enable this span data, you need to instrument
your agent code. See the section called â€œAdd observability to your agentsâ€ to learn more.

This span data is available in full in CloudWatch Logs and CloudWatch Application Signals. To learn
more about viewing observability data, see the section called â€œView metrics for your agentsâ€.

The following table defines the operations for which spans are created and the attributes for each
captured span.

Operation name Span attributes Description

CreateEvent memory.id , session.i
d , event.id, actor.id,
throttled , error, fault

Creates a new event within a
memory session

GetEvent memory.id , session.i
d , event.id, actor.id,
throttled , error, fault

Retrieves an existing memory
event

ListEvents memory.id , session.i
d , event.id, actor.id,
throttled , error, fault

Lists events within a session

Memory observability data 690


Operation name Span attributes Description

DeleteEvent memory.id , session.i
d , event.id, actor.id,
throttled , error, fault

Deletes an event from
memory

RetrieveMemoryRecords memory.id , namespace ,
throttled , error, fault

Retrieves memory records for
a given namespace

ListMemoryRecords memory.id , namespace ,
throttled , error, fault

Lists available memory
records

**Provided log data**

AgentCore provides structured logs that help you monitor and troubleshoot key AgentCore
Memory resource processes. To enable this log data, you need to instrument your agent code. See
the section called â€œAdd observability to your agentsâ€ to learn more.

AgentCore can output logs to CloudWatch Logs, Amazon S3, or Firehose stream. If you use
a CloudWatch Logs destination, these logs are stored under the default log group /aws/
vendedlogs/bedrock-agentcore/memory/APPLICATION_LOGS/{memory_id} or under
a custom log group starting with /aws/vendedlogs/. See the section called â€œEnabling
observability for AgentCore runtime, memory, gateway, built-in tools, and identity resourcesâ€ to
learn more.

When the DeleteMemory operation is called, logs are generated for the start and completion of
the deletion process. Any corresponding deletion error logs will be provided with insights into why
the call failed.

We also provide logs for various stages in the long-term memory creation process, namely
extraction and consolidation. When new short term memory events are provided, AgentCore
extracts key concepts from responses to begin the formation of new long-term memory records.
Once these have been created, they are integrated with existing memory records to create a unified
store of distinct memories.

See the following breakdown to learn how each workflow helps you monitor the formation of new
memories:

Memory observability data 691


**Extraction logs**

- Start and completion of extraction processing
- Number of memories successfully extracted
- Any errors in deserializing or processing input events

**Consolidation logs:**

- Start and completion of consolidation processing
- Number of memories requiring consolidation
- Success/failure of memory additions and updates
- Related memory retrieval status

The following table provides a more detailed breakdown of how different memory resource
workflows use log fields alongside the log body itself to provide request-specific information.

Workflow name Log fields Description

Extraction resource_arn, event_tim
estamp, memory_strategy_id
, namespace, actor_id,
session_id, event_id,
requestId, isError

Analyzes incoming conversat
ions to generate new
memories

Consolidation resource_arn, event_tim
estamp, memory_strategy_id
, namespace, session_id,
requestId, isError

Combines extracted
memories with existing
memories

#### AgentCore generated gateway observability data

The following sections describe the gateway metrics, logs, and spans output by AgentCore to
Amazon CloudWatch. These metrics aren't available on the CloudWatch generative AI observability
page. Gateway metrics are batched at one minute intervals. To learn more about viewing gateway
metrics, see the section called â€œView metrics for your agentsâ€.

Gateway observability data 692


Note
To enable service-provided logs for AgentCore gateways, you need to configure the
necessary CloudWatch resources. See the section called â€œEnabling observability for
AgentCore runtime, memory, gateway, built-in tools, and identity resourcesâ€ to learn more.

**Topics**

- Provided metrics
- Provided log data
- Provided spans

**Provided metrics**

Gateway publishes invocation and usage metrics to CloudWatch. You can view these metrics and
also set up alarms to alert you when certain metrics exceed thresholds. To learn more, select a
topic:

**Topics**

- Invocation metrics
- Usage metrics
- View gateway CloudWatch metrics
- Setting up CloudWatch alarms

**Invocation metrics**

These metrics provide information about API invocations, performance, and errors.

For these metrics, the following dimensions are used:

- **Operation** â€“ The name of the API operation (ex. InvokeGateway).
- **Protocol** â€“ The name of the protocol (ex. MCP).
- **Method** â€“ Represents the MCP operation being invoked (ex. tools/list).
- **Resource** â€“ Represents the identifier of the resource (ex. gateway ARN).
- **Name** â€“ Represents the name of the tool.

Gateway observability data 693


Metric Description Statistics Units

Invocations The total number of requests made
to each Data Plane API. Each API call
counts as one invocation regardless of
the response status.

Sum Count

Throttles The number of requests throttled (status
code 429) by the service.

Sum Count

SystemErrors The number of requests which failed
with 5xx status code.

Sum Count

UserErrors The number of requests which failed
with 4xx status code except 429.

Sum Count

Latency The time elapsed between when the
service receives the request and when it
begins sending the first response token.
In other words, initial response time.

Average,
Minimum,
Maximum, p50,
p90, p99

Milliseconds

Duration The total time elapsed between receiving
the request and sending the final
response token. Represents complete
end-to-end processing time of the
request.

Average,
Minimum,
Maximum, p50,
p90, p99

Milliseconds

TargetExe
cutionTime

The total time taken to execute the
target over Lambda / OpenAPI / etc. This
helps determine the contribution of the
target to the total Latency.

Average,
Minimum,
Maximum, p50,
p90, p99

Milliseconds

**Usage metrics**

These metrics provide information about how your gateway is being used.

Gateway observability data 694


Metric Description Statistics Units

TargetType The total number of requests served
by each type of target (MCP, Lambda,
OpenAPI).

Sum Count

**View gateway CloudWatch metrics**

For more information about viewing CloudWatch metrics, see View available metrics in the
Amazon CloudWatch User Guide. The following procedure shows you how to view metrics for your
gateways:

**To view gateway metrics in the console**

1. Open the CloudWatch console at https://console.aws.amazon.com/cloudwatch/.
2. In the left navigation pane, choose **All metrics** under the **Metrics** section.
3. Under **Browse** , from the dropdown menu that displays the current AWS Region, select the
    Region for which you want metrics.
4. Choose the **Bedrock-AgentCore** namespace.
5. Choose a dimension (ex. **Operation** ) or combination of dimensions (ex. **Method, Operation,**
    **Protocol** ) to view the metrics for it.
6. To add a metric to the CloudWatch graph, select the checkbox next to it.

**Setting up CloudWatch alarms**

You can use the PutMetricAlarm API operation to set up CloudWatch alarms to alert you when
certain metrics exceed thresholds. For example, you might want to be notified when the error rate
exceeds 5% or when the latency exceeds 1 second.

The following example shows you how to create an alarm for high error rates using the AWS CLI:

aws cloudwatch put-metric-alarm
--alarm-name "HighErrorRate"
--alarm-description "Alarm when error rate exceeds 5%"
--metric-name "SystemErrors"
--namespace "Bedrock-AgentCore"
--statistic "Sum" \

Gateway observability data 695


--dimensions "Name=Resource,Value=my-gateway-arn"
--period 300
--evaluation-periods 1
--threshold 5
--comparison-operator "GreaterThanThreshold"
--alarm-actions "arn:aws:sns:us-west-2:123456789012:my-topic"

This alarm will trigger when the number of system errors exceeds 5 in a 5-minute period. When the
alarm triggers, it will send a notification to the specified SNS topic.

**Provided log data**

AgentCore provides logs that help you monitor and troubleshoot key AgentCore gateway resource
processes. To enable this log data, you need to create a log destination.

AgentCore can output logs to CloudWatch Logs, Amazon S3, or Firehose stream. If you use
a CloudWatch Logs destination, these logs are stored under the default log group /aws/
vendedlogs/bedrock-agentcore/gateway/APPLICATION_LOGS/{gateway_id} or
under a custom log group starting with /aws/vendedlogs/. See the section called â€œEnabling
observability for AgentCore runtime, memory, gateway, built-in tools, and identity resourcesâ€ to
learn more.

AgentCore logs the following information for gateway resources:

- Start and completion of gateway requests processing
- Error messages for Target configurations
- MCP Requests with missing or incorrect authorization headers
- MCP Requests with incorrect request parameters (tools, method)

You can also see request and response bodies as part of your Vended Logs integration when any
of the MCP Operations are performed on the Gateway. They can do further analysis on these logs,
using the span_id and trace_id fields to connect the vended spans and logs being emitted.
For more information about encrypting your gateways with customer-managed KMS keys, see
Advanced features and topics for Amazon Bedrock AgentCore Gateway.

Sample log:

{

Gateway observability data 696


"resource_arn": "arn:aws:bedrock-agentcore:us-
east-1:123456789012:gateway/ ",
"event_timestamp": 1759370851622,
"body": {
"isError": false,
"log": "Started processing request with requestId: 1",
"requestBody": "{id=1, jsonrpc=2.0, method=tools/call, params={name=target-
quick-start-f9scus___LocationTool, arguments={location=seattle}}}",
"id": "1"
},
"account_id": "123456789012",
"request_id": "12345678-1234-1234-1234-123456789012",
"trace_id": "160fc209c3befef4857ab1007d041db0",
"span_id": "81346de89c725310"
}

Sample log with response body:

{
"resource_arn": "arn:aws:bedrock-agentcore:us-
east-1:123456789012:gateway/ ",
"event_timestamp": 1759370853807,
"body": {
"isError": false,
"responseBody": "{jsonrpc=2.0, id=1, result={isError=false,
content=[{type=text, text="good"}]}}",
"log": "Successfully processed request with requestId: 2",
"id": "1"
},
"account_id": "123456789012",
"request_id": "12345678-1234-1234-1234-123456789012",
"trace_id": "160fc209c3befef4857ab1007d041db0",
"span_id": "81346de89c725310"
}

**Provided spans**

AgentCore supports OTEL compliant vended spans that you can use to track invocations across
different primitives that are being used.

Sample vended Spans for Tool Invocation:

Gateway observability data 697


- kind:SERVER - tracks the overall execution details, tool invoked, gateway details, AWS request
    ID, trace and span ID.
- kind:CLIENT - covers the specific target that was invoked and details around it like target type,
    target execution time, target execution start and end times, etc.

For other MCP method invocations, only the kind:SERVER span is emitted.

While these spans emit metrics, to investigate why a failure occurred for a specific span, a
Gateway user must check the logs that are vended. Various fields, for example, spanId or
aws.request.id can help in stitching these spans and logs together.

Operation Span attributes Description

List Tools aws.operation.name,
aws.resource.arn, aws.reque
st.id, aws.account.id,
gateway.id, aws.xray.origin,
aws.resource.type, aws.regio
n, latency_ms, error_type,
jsonrpc.error.code, http.meth
od, http.response.stat
us_code, gateway.name,
url.path, overhead_latency_m
s

List tools attached to a
gateway

Call Tool aws.operation.name,
aws.resource.arn, aws.reque
st.id, aws.account.id,
gateway.id, aws.xray.origin,
aws.resource.type, aws.regio
n, latency_ms, error_type,
jsonrpc.error.code, http.meth
od, http.response.stat
us_code, gateway.name,
url.path, overhead_latency_m
s, tool.name

Call a specific tool. Two spans
are emmited: 1. kind:SERV
ER which tracks the overall
execution details (success /
not) , tool invoked, gateway
details, AWS request ID, trace
and span ID. 2. kind:CLIE
NT which covers the specific
target that was invoked and
details around it like target
type, target execution time,

Gateway observability data 698


Operation Span attributes Description
target execution start and
end times, etc.

Search Tools aws.operation.name,
aws.resource.arn, aws.reque
st.id, aws.account.id,
gateway.id, aws.xray.origin,
aws.resource.type, aws.regio
n, latency_ms, error_type,
jsonrpc.error.code, http.meth
od, http.response.stat
us_code, gateway.name,
url.path, overhead_latency_m
s, tool.name

Search for ten most relevant
tools given an input query

#### Built-in tools observability data......................................................................................................

**Topics**

- Observability tools metrics
- Resource usage metrics and logs
- Provided span data
- Application log data

**Observability tools metrics**

AgentCore provides the following built-in metrics for the code interpreter and browser tools. Built-
in tool metrics are batched at one minute intervals. To learn more about AgentCore tools, see
_AgentCore Built-in Tools: Interact with your applications using built-in tools_.

**Invoke tool:**

Invocations

The total number of requests made to the Data Plane API. Each API call counts as one
invocation, regardless of the request payload size or response status.

Built-in tools observability data 699


Throttles

The number of requests throttled by the service due to exceeding allowed TPS (Transactions Per
Second) or quota limits. These requests return ThrottlingException with HTTP status code 429.

SystemErrors

The number of server-side errors encountered during request processing.

UserErrors

The number of client-side errors resulting from invalid requests. This require user action in
order to resolve.

Latency

The time elapsed between when the service receives the request and when it begins sending
the first response token. Important for measuring initial response time.

**Create tool session:**

Invocations

The total number of requests made to the Data Plane API. Each API call counts as one
invocation, regardless of the request payload size or response status.

Throttles

The number of requests throttled by the service due to exceeding allowed TPS (Transactions Per
Second) or quota limits. These requests return ThrottlingException with HTTP status code 429.

SystemErrors

The number of server-side errors encountered during request processing.

UserErrors

The number of client-side errors resulting from invalid requests. This require user action in
order to resolve.

Latency

The time elapsed between when the service receives the request and when it begins sending
the first response token. Important for measuring initial response time.

Duration

The duration of tool session (Operation becomes CodeInterpreterSession/BrowserSession).

Built-in tools observability data 700


**Browser user takeover:**

TakerOverCount

The total number of user taking over

TakerOverReleaseCount

The total number of user releasing control

TakerOverDuration

The duration of user taking over

**Resource usage metrics and logs**

Amazon Bedrock AgentCore Built-in Tools provides comprehensive resource usage telemetry,
including CPU and memory consumption metrics for your runtime resources.

Note
Resource usage data may be delayed by up to 60 minutes and precision might differ across
metrics.

**Vended metrics**

By default, Bedrock AgentCore Built-in Tools vends metrics for Account level and Tool level
at 1-minute resolution. Amazon CloudWatch aggregation and metric data retention follow
standard Amazon CloudWatch data retention polices. For more information, see https://
docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Metric.

Name Dimensions Description

CPUUsed-vCPUHours Service; Service, Resource The total amount of virtual
CPU consumed in vCPU-Hours
unit, available at the resource
and account level. Useful
for resource tracking and
estimated billing visibility.

Built-in tools observability data 701


Name Dimensions Description

MemoryUsed-GBHours Service; Service, Resource The total amount of memory
consumed in GB-Hours unit,
available at the resource
and account levels. Useful
for resource tracking and
estimated billing visibility.

Dimension explanation

- **Service** - AgentCore.CodeInterpreter or AgentCore.Browser
- **Resource** - Built-in tool Id

Account level metrics are available in the Amazon CloudWatch Bedrock AgentCore Observability
Console under **Built-in Tools** tab. The dashboard on the console will contain a Memory usage
graph and a CPU usage graph generated from the usage metrics. These graphs represent the total
resource usage across all tools of the selected tool type in the account in the region.

Tool level metrics are available in **Tools** page of the Amazon CloudWatch Bedrock AgentCore
Observability Console. The dashboard on the console will contain a Memory usage graph and a
CPU usage graph generated from the usage metrics. The graphs represent the total resource usage
across all sessions of the selected tool.

Note
Telemetry data is provided for monitoring purposes. Actual billing is calculated based
on metered usage data and may differ from telemetry values due to aggregation timing,
reconciliation processes, and measurement precision. Refer to your AWS billing statement
for authoritative charges.

**Vended Logs**

Amazon Bedrock AgentCore Built-in Tools provides the ability to enabled vended logs for session
level usage telemetry at 1-second granularity. Each log record contains 1 second Resource Usage
datum. Currently supported metrics include:

Built-in tools observability data 702


- Code Interprefer codeInterpreter.vcpu.hours.used and codeInterpreter.memory.gb_hours.used
- Browser browser.vcpu.hours.used and browser.memory.gb_hours.used

Each resource usage datum will use the following schema in the log record.

**Code Interpreter**

Log type Log fields Description

USAGE_LOGS event_timestamp, resource_
arn, service.name, cloud.pro
vider, cloud.region, account.i
d, region, resource.id, session.i
d, elapsed_time_seconds,
codeInterpreter.vcpu.hours.
used, codeInterpreter.me
mory.gb_hours.used

Resource Usage Logs for
session-level resource
tracking.

**Browser**

Log type Log fields Description

USAGE_LOGS event_timestamp, resource_
arn, service.name, cloud.pro
vider, cloud.region, account.i
d, region, resource.id, session.i
d, elapsed_time_secon
ds, browser.vcpu.hours
.used, browser.memory.gb_
hours.used

Resource Usage Logs for
session-level resource
tracking.

For more information about enabling logs, see Add observability to your Amazon Bedrock
AgentCore resources. These logs are theyn displayed in the destination as configured (AWS
LogGroup, Amazon S3, or Amazon Kinesis Firehose.

Built-in tools observability data 703


In the Built-in Tools Session page of the Amazon CloudWatch Bedrock AgentCore Observability
Console, you can see resource usage metrics generated from these logs. To optimize your metric
viewing experience, select your desired time range using the selector in the top right to focus on
specific CPU and Memory Usage data.

Note
Telemetry data is provided for monitoring purposes. Actual billing is calculated based
on metered usage data and may differ from telemetry values due to aggregation timing,
reconciliation processes, and measurement precision. Refer to your AWS billing statement
for authoritative charges.

**Provided span data**

To enhance observability, AgentCore provides structured spans that provide visibility into built-
in tools APIs. To enable this span data, you need to enable observability on your built-in tool
resource. See Add observability to your Amazon Bedrock AgentCore resources for steps and
details. This span data is available in full in AWS CloudWatch Logs in the aws/spans log group.
The following table defines the operation for which spans are created and the attributes for each
captured span.

**Code interpreter**

Operation name Span attributes Description

StartCodeInterpreterSession aws.operation.name,
aws.resource.arn, aws.reque
st.id, aws.account.id, toolsessi
on.id, aws.xray.origin,
aws.resource.type, aws.region,
latency_ms, error_type

Starts a code interpreter
session.

StopCodeInterpreterSession aws.operation.name,
aws.resource.arn, aws.reque
st.id, aws.account.id, toolsessi
on.id, aws.xray.origin,
aws.resource.type, aws.regio

Stops a code interpreter
session.

Built-in tools observability data 704


Operation name Span attributes Description
n, latency_ms, error_type,
session_duration_s

InvokeCodeInterpreter aws.operation.name,
aws.resource.arn, aws.reque
st.id, aws.account.id, toolsessi
on.id, aws.xray.origin,
aws.resource.type, aws.region,
latency_ms, error_type

Invokes a code interpreter
with input code.

CodeInterpreterSessionExpire aws.operation.name,
aws.resource.arn, aws.reque
st.id, aws.account.id, toolsessi
on.id, aws.xray.origin,
aws.resource.type, aws.regio
n, latency_ms, error_type,
session_duration_s

Expires a code interpreter
session if StopCodeInterprete
rSession is not called and the
session times out.

- toolsession.id - the id of the tool session
- session_duration_s - the duration of the session in seconds before it ended

**Browser**

Operation name Span attributes Description

StartBrowserSession aws.operation.name,
aws.resource.arn, aws.reque
st.id, aws.account.id, toolsessi
on.id, aws.xray.origin,
aws.resource.type, aws.region,
latency_ms, error_type

Starts a browser session.

StopBrowserSession aws.operation.name,
aws.resource.arn, aws.reque
st.id, aws.account.id, toolsessi

Stops a browsersession.

Built-in tools observability data 705


Operation name Span attributes Description
on.id, aws.xray.origin,
aws.resource.type, aws.regio
n, latency_ms, error_type,
session_duration_s

ConnectBrowserAuto
mationStream

aws.operation.name,
aws.resource.arn, aws.reque
st.id, aws.account.id, toolsessi
on.id, aws.xray.origin,
aws.resource.type, aws.region,
latency_ms, error_type

Connect to a browser
automation stream.

BrowserSessionExpire aws.operation.name,
aws.resource.arn, aws.reque
st.id, aws.account.id, toolsessi
on.id, aws.xray.origin,
aws.resource.type, aws.regio
n, latency_ms, error_type,
session_duration_s

Expires a code interpreter
session if StopBrowserSession
is not called and the session
times out.

**Application log data**

AgentCore provides structured Application logs that help you gain visibility into your agent
runtime invocations and session-level resource consumption. This log data is provided when
enabling observability on your agent resource. See Add observability to your Amazon Bedrock
AgentCore resources for steps and details. AgentCore can output logs to CloudWatch Logs, Amazon
S3, or Firehose stream. If you use a CloudWatch Logs destination, these logs are stored under your
agentâ€™s application logs or under your own custom log group.

Log type Log fields Description

APPLICATION_LOGS timestamp, resource_arn,
event_timestamp, account_i
d, request_id, session_id,
trace_id, span_id, service_n

Application logs for
InvokeCodeInterpreter with
tracing fields, request, and
response payloads

Built-in tools observability data 706


Log type Log fields Description
ame, operation, request_p
ayload, response_payload

#### AgentCore generated identity observability data

This document described observability data emitted by the Bedrock AgentCore Identity Service.
This data provides visibility into the performance, usage, and operational health of the service,
allowing your to monitor authorization activities for your AI agents and workloads.

You can use the identity observability data described in this section in the following ways:

- Monitor usage: track API call volume and throttling events across workload identities and
    credential providers
- Track inbound authorization: monitor success/failure rates for workload access token operations
- Analyze Resource Access Patterns: gain insights into OAuth2 providers and API key usage
    patterns by provider type and flow
- Troubleshoot issues: identify and diagnose errors by type, operation, and resource
- Capacity planning: use metrics to understand usage patterns and plan for scaling

These metrics can be viewed in the Amazon CloudWatch console, retrieved via the Amazon
CloudWatch API, or incorporated into Amazon CloudWatch dashboards and alarms for proactive
monitoring.

**Topics**

- Usage, authorization, and resource access metrics
- Provided span data
- Provided log data

**Usage, authorization, and resource access metrics**

The following dimensions reference applies to the metrics described in this section:

- WorkloadIdentity: the workload identity name making the request.

Identity observability data 707


- WorkloadIdentityDirectory: the directory containing the workload identity (typically default).
- TokenVault: the token vault being accessed (typically default).
- ProviderName: the name of the credential provider (for example, MyGoogleProvider,
    MySlackProvider).
- FlowType: the OAuth2 flow type (USER_FEDERATION, M2M).
- ExceptionType: the specific error type (ValidationException, ThrottlingException, etc.)

**Usage metrics**

These metrics are emitted in the AWS/Usage namespace and track service usage at the AWS
account level.

Metric name Dimensions Description

CallCount Service, Type,
Class, Resource

Tracks the
number of
calls made to
Identity Service
operations. This
can be used for
service quotas.

ThrottleCount Service, Type,
Class, Resource

Tracks the
number of
throttled
calls for
Identity Service
operations.

**Authorization metrics**

These metrics are emitted in the AWS/Bedrock-AgentCore namespace and provide insights into
authentication and authorization operations.

Identity observability data 708


Metric name Dimensions Description

WorkloadA
ccessToke
nFetchSuccess

WorkloadI
dentity,
WorkloadI
dentityDirectory,
Operation

Tracks successful
workload access
token fetch
operations.

WorkloadA
ccessToke
nFetchFailures

WorkloadI
dentity,
WorkloadI
dentityDirectory,
Operation,
ExceptionType

Tracks failed
workload access
token fetch
operations by
exception type.

WorkloadA
ccessToke
nFetchThrottles

WorkloadI
dentity,
WorkloadI
dentityDirectory,
Operation

Tracks throttled
workload access
token fetch
operations.

**Resource access metrics**

These metrics track credential provider operations for accessing external resources.

Metric name Dimensions Description

ResourceA
ccessToke
nFetchSuccess

WorkloadI
dentity,
WorkloadI
dentityDirectory,
TokenVault,
ProviderName,
Type

Tracks successfu
l OAuth2 token
fetch operation
s from credentia
l providers.

Identity observability data 709


Metric name Dimensions Description

ResourceA
ccessToke
nFetchFailures

WorkloadI
dentity,
WorkloadI
dentityDirectory,
TokenVault,
ProviderName,
Type, Exception
Type

Tracks failed
OAuth2 token
fetch operation
s by exception
type.

ResourceA
ccessToke
nFetchThrottles

WorkloadI
dentity,
WorkloadI
dentityDirectory,
TokenVault,
ProviderName,
Type

Tracks throttled
OAuth2 token
fetch operations.

ApiKeyFet
chSuccess

WorkloadI
dentity,
WorkloadI
dentityDirectory,
TokenVault,
ProviderName

Tracks successfu
l API key fetch
operations.

ApiKeyFet
chFailures

WorkloadI
dentity,
WorkloadI
dentityDirectory,
TokenVault,
ProviderName,
ExceptionType

Tracks failed
API key fetch
operations by
exception type.

Identity observability data 710


Metric name Dimensions Description

ApiKeyFet
chThrottles

WorkloadI
dentity,
WorkloadI
dentityDirectory,
TokenVault,
ProviderName

Tracks throttled
API key fetch
operations.

**Provided span data**

To enhance observability, AgentCore Identity provides structured spans that give visibility into
identity service operations. To enable span data, you need to enable observability on your
workload identity or credential provider resource.

This span data is available in Amazon CloudWatch Logs aws/spans log group. The following table
defines operations for which spans are created and their attributes.

The following attribute explanations apply to the information in the tables below:

- aws.operation.name - the operation name being performed
- aws.resource.arn - the Amazon Resource Name for the identity resource
- aws.request_id - unique request ID for the operation
- aws.account.id - user's AWS account ID
- workload.identity.id - the workload identity name
- workload.identity.directory - the workload identity directory
- credential.provider.name - name of the credential provider
- credential.provider.type - type of credential provider (OAuth2, API Key)
- token.vault.name - token vault name
- oauth2.flow - OAuth2 flow type (USER_FEDERATION, M2M)
- latency_ms - operation latency in milliseconds
- error_type - error classification (throttle, system, user, null if successful)
- aws.region - AWS region where the operation occurred

**Workload Identity Operations**

Identity observability data 711


Operation Span attributes Description

GetWorkloadAccessToken aws.operation.name,
aws.resource.arn, aws.reque
st_id, aws.account.id,
workload.identity.id,
workload.identity.directory
, aws.region, latency_ms,
error_type

Fetches workload access
token for machine-to-
machine authentication

GetWorkloadAccessT
okenForJWT

aws.operation.name,
aws.resource.arn, aws.reque
st_id, aws.account.id,
workload.identity.id,
workload.identity.directory,
issuer, user_sub, aws.region,
latency_ms, error_type

Fetches workload access
token using JWT user token

GetWorkloadAccessT
okenForUserId

aws.operation.name,
aws.resource.arn, aws.reque
st_id, aws.account.id,
workload.identity.id,
workload.identity.directory
, aws.region, latency_ms,
error_type

Fetches workload access
token for specific user ID

**Credential Provider Operations**

Operation Span attributes Description

GetResourceOAuth2Token aws.operation.name,
aws.resource.arn, aws.reque
st_id, aws.account.id,
workload.identity.id,
credential.provider.name,
credential.provider.type,

Fetches OAuth2 access token
from credential provider

Identity observability data 712


Operation Span attributes Description
token.vault.name, oauth2.fl
ow, aws.region, latency_ms,
error_type

GetResourceAPIKey aws.operation.name,
aws.resource.arn, aws.reque
st_id, aws.account.id,
workload.identity.id,
credential.provider.name,
token.vault.name, aws.region,
latency_ms, error_type

Fetches API key from
credential provider

**Provided log data**

AgentCore Identity provides structured application logs that help you gain visibility into identity
service operations. This log data is provided when enabling observability on your identity
resources.

AgentCore can output logs to Amazon CloudWatch Logs, Amazon S3, or Amazon Kinesis Firehose
stream. If you use a CloudWatch Logs destination, these logs are stored under your resource's
application logs or under your own custom log group.

Log type Log fields Description

Application Logs timestamp, resource_arn,
event_timestamp, account_id,
request_id, trace_id, span_id,
service_name, operation,
request_payload, response_
payload

Application logs for Identity
Service operations with
tracing fields, request, and
response payloads

Log field explanations:

- timestamp - Unix timestamp of the log event
- resource_arn - ARN of the identity resource

Identity observability data 713


- event_timestamp - ISO 8601 timestamp string
- account_id - AWS account ID
- request_id - unique request identifier
- trace_id - distributed tracing ID
- span_id - span identifier for the operation
- service_name - service name (BedrockAgentCore.Identity)
- operation - pperation name (GetWorkloadAccessToken, etc.)
- request_payload - request payload
- response_payload - response payload

### View observability data for your Amazon Bedrock AgentCore

### agents

After implementing observability in your agent, you can view the collected metrics and traces in
both the CloudWatch console generative AI observability page and in CloudWatch Logs. Refer to
the following sections to learn how to view metrics for your agents.

#### View data using generative AI observability in Amazon CloudWatch.....................................

The CloudWatch generative AI observability page displays all of the service-provided metrics
output by the AgentCore agent runtime, as well as span- and trace-derived data if you have
enabled instrumentation in your agent code. To view the observability dashboard in CloudWatch,
open the Amazon CloudWatch GenAi Observability page.

With generative AI observability in CloudWatch, you can view tailored dashboards with graphs and
other visualizations of your data, as well as error breakdowns, trace visualizations and more. To
learn more about using generative AI observability in CloudWatch, including how to look at your
agents' individual session and trace data, see Amazon Bedrock AgentCore agents in the _Amazon
CloudWatch user guide_.

#### View other data in CloudWatch......................................................................................................

All of the service-provided metrics and spans can also be viewed in CloudWatch, along with any
metrics that your instrumented agent code outputs.

View metrics for your agents 714


To view this data, refer to the following sections.

**Logs**

1. Open the CloudWatch console.
2. In the left hand navigation pane, expand **Logs** and select **Log groups**
3. Use the search field to find the log group for your agent, memory, or gateway resource.

AgentCore agent log groups have the following format:

- **Standard logs** - stdout/stderr output
    - **Location** : /aws/bedrock-agentcore/runtimes/<agent_id>-<endpoint_name>/[runtime-
       logs] <UUID>
    - **Contains** : Runtime errors, application logs, debugging statements
    - **Example Usage** :
       - print("Processing request...") # Appears in standard logs
       - logging.info("Request processed successfully") # Appears in standard logs
- **OTEL structured logs** - Detailed operation information
    - **Location** : /aws/bedrock-agentcore/runtimes/<agent_id>-<endpoint_name>/otel-rt-logs
    - **Contains** : Execution details, error tracking, performance data
    - **Automatic collection** : No additional code required - generated by ADOT instrumentation
    - **Benefits** : Can include correlation IDs linking logs to relevant traces

**Traces and Spans**

Traces provide visibility into request execution paths through your agent:

- Location: /aws/spans/default
- Access via: CloudWatch Transaction Search console
- Requirements: CloudWatch Transaction Search must be enabled

Traces automatically capture:

- Agent invocation sequences
- Integration with framework components (LangChain, etc.)

View other data in CloudWatch 715


- LLM calls and responses
- Tool invocations and results
- Error paths and exceptions

For distributed tracing across services, you can use standard HTTP headers:

- AWS X-Ray format: X-Amzn-Trace-Id: Root=1-5759e988-
    bd862e3fe1be46a994272793;Parent=53995c3f42cd8ad8;Sampled=1
- W3C format: traceparent:
    00-4bf92f3577b34da6a3ce929d0e0e4736-00f067aa0ba902b7-01

To view traces:

- Navigate to CloudWatch console
- Select **Transaction Search** from the left navigation
- Filter by service name or other criteria
- Select a trace to view the detailed execution graph

**Metrics**

If you have enabled observability by instrumenting your agent code as described in the section
called â€œEnabling AgentCore observabilityâ€, your agent automatically generates OTEL metrics, which
are sent to CloudWatch using Enhanced Metric Format (EMF):

- Namespace: bedrock-agentcore
- Access via: CloudWatch Metrics console
- Contents: Custom metrics generated by your agent code and frameworks
- Automatic collection: No additional code required - generated by ADOT instrumentation

In addition to agent-emitted metrics, the AgentCore service publishes standard service metrics to
CloudWatch. Refer to the section called â€œRuntime observability dataâ€ for a list of these metrics.

View other data in CloudWatch 716


## Amazon Bedrock AgentCore MCP Server: Vibe coding

## with your coding assistant

The Amazon Bedrock AgentCore Model Context Protocol (MCP) server helps you transform, deploy,
and test Amazon Bedrock AgentCore-compatible agents directly from your preferred development
environment. With built-in support for runtime integration, gateway connectivity, and agent
lifecycle management, the MCP server simplifies moving from local development to production
deployment on Amazon Bedrock AgentCore services.

The MCP server works with popular MCP clients including Kiro, Cursor, Claude Code, and Amazon Q
CLI, providing conversational commands to automate complex agent development workflows.

**Topics**

- Prerequisites
- Step 1: Install the MCP server
- Step 2: Transform an existing agent for AgentCore runtime
- Step 3: Deploy your agent to AgentCore runtime
- Step 4: Test your deployed agent
- Next steps

### Prerequisites..............................................................................................................................................

Before you begin, verify that you have the following:

- An AWS account with Amazon Bedrock AgentCore permissions
- AWS CLI installed and configured with appropriate credentials. For setup instructions, see
    Installing or updating to the latest version of the AWS CLI.
- One of the supported MCP clients:
    - Kiro
    - Cursor
    - Claude Code
    - Amazon Q CLI

Prerequisites 717


- An existing AgentCore agent built with a supported framework (Strands Agents, LangGraph,
    CrewAI, or similar)

For more information about Amazon Bedrock AgentCore, see the Amazon Bedrock AgentCore
documentation.

#### Install required dependencies..........................................................................................................

Install the necessary packages for Amazon Bedrock AgentCore development.

To install the required packages, run the following commands:

Install AgentCore dependencies
pip install bedrock-agentcore
pip install bedrock-agentcore-starter-toolkit

### Step 1: Install the MCP server..............................................................................................................

To install the AgentCore MCP server, add it to your MCP client's configuration file. Each MCP client
stores this configuration in a different location.

#### Add MCP server configuration.........................................................................................................

Choose your MCP client and add the corresponding configuration:

**For Kiro**

Add to .kiro/settings/mcp.json (if it doesn't exist, see Creating Configuration Files ):

{
"mcpServers": {
"bedrock-agentcore-mcp-server": {
"command": "uvx",
"args": [
"awslabs.amazon-bedrock-agentcore-mcp-server@latest"
],
"env": {
"FASTMCP_LOG_LEVEL": "ERROR"

Install required dependencies 718


},
"disabled": false,
"autoApprove": [
"search_agentcore_docs",
"fetch_agentcore_doc"
]
}
}
}

**For Cursor**

Add to .cursor/mcp.json:

{
"mcpServers": {
"bedrock-agentcore-mcp-server": {
"command": "uvx",
"args": [
"awslabs.amazon-bedrock-agentcore-mcp-server@latest"
],
"env": {
"FASTMCP_LOG_LEVEL": "ERROR"
},
"disabled": false,
"autoApprove": [
"search_agentcore_docs",
"fetch_agentcore_doc"
]
}
}
}

**For Amazon Q**

The best practice is to configure MCP servers for individual Q CLI agents. For configuration
instructions, see Configuring MCP servers for Amazon Q CLI.

For Amazon Q in IDEs (VS Code and JetBrains), see Using MCP servers with Amazon Q in your IDE.

Add MCP server configuration 719


**For Claude Code**

Configuration depends on your installation:

- **Standalone app** : Add to ~/.claude/mcp.json
- **VS Code extension** : Configure MCP servers through the Claude Code CLI first, then the extension
    will automatically use them. See the Claude Code VS Code documentation for setup details.

For standalone Claude Code app:

{
"mcpServers": {
"bedrock-agentcore-mcp-server": {
"command": "uvx",
"args": [
"awslabs.amazon-bedrock-agentcore-mcp-server@latest"
],
"env": {
"FASTMCP_LOG_LEVEL": "ERROR"
},
"disabled": false,
"autoApprove": [
"search_agentcore_docs",
"fetch_agentcore_doc"
]
}
}
}

#### Verify MCP server installation.........................................................................................................

To verify that the MCP server is connected and working successfully, restart your MCP client after
adding the configuration and confirm that the following tools are available:

- search_agentcore_docs - Search Amazon Bedrock AgentCore documentation
- fetch_agentcore_doc - Fetch specific Amazon Bedrock AgentCore documentation pages

Verify MCP server installation 720


### Step 2: Transform an existing agent for AgentCore runtime.........................................................

To make your existing AgentCore agent code compatible with Amazon Bedrock AgentCore
Runtime, use the MCP server to guide the transformation process. For example, if you have a
Strands AgentCore agent, the transformation helps convert it to be Amazon Bedrock AgentCore-
compatible by updating imports, dependencies, and application structure.

#### Transform your agent code..............................................................................................................

The MCP server guides your MCP client to make the following changes to your AgentCore agent
code:

**Add runtime library imports**

The MCP server adds the required AgentCore imports:

from bedrock_agentcore.runtime import BedrockAgentCoreApp

**Update dependencies**

The MCP server updates your requirements.txt file:

bedrock-agentcore
strands-agents

**Initialize the AgentCore application**

The MCP server adds application initialization:

app = BedrockAgentCoreApp()

**Decorate the main entrypoint**

The MCP server converts your handler function:

Step 2: Transform an existing agent for AgentCore runtime 721


@app.entrypoint
def handler(event, context):

Your agent logic here
pass

**Add application runner**

The MCP server adds the application runner:

if name == "main":
app.run()

#### Transformation procedure................................................................................................................

To transform your AgentCore agent, open your existing AgentCore agent file (for example,
weather_agent.py) in your MCP client and use your MCP client's AI assistant with the following
prompt:

Transform this AgentCore agent code to be compatible with AgentCore runtime. Update the
imports, dependencies, and application structure as needed.

### Step 3: Deploy your agent to AgentCore runtime............................................................................

After you transform your AgentCore agent for AgentCore compatibility, deploy it using the
AgentCore CLI through your MCP client.

#### Deploy using the AgentCore CLI.....................................................................................................

The MCP server uses the AgentCore CLI to deploy your AgentCore agent. The deployment process
includes:

- Creating the deployment configuration
- Building and containerizing the AgentCore agent

Transformation procedure 722


- Deploying to Amazon Bedrock AgentCore Runtime
- Providing the deployment details and AgentCore agent ARN

To deploy your AgentCore agent, use your MCP client's AI assistant with the following prompt:

Deploy this AgentCore agent to AgentCore runtime using the AgentCore CLI.

The MCP server executes the necessary CLI commands automatically.

#### Verify deployment..............................................................................................................................

After deployment completes, you receive confirmation with the following details:

- AgentCore agent ARN
- Runtime configuration
- Deployment status

### Step 4: Test your deployed agent........................................................................................................

Test your deployed AgentCore agent by invoking it through Amazon Bedrock AgentCore Runtime.

#### Invoke the agent.................................................................................................................................

The MCP server uses the AgentCore CLI to invoke your AgentCore agent and display results
including:

- AgentCore agent response
- Execution logs
- Performance metrics

To test your deployed AgentCore agent, use your MCP client's AI assistant with the following
prompt:

Test the deployed AgentCore agent with a sample request.

Verify deployment 723


Review the invocation output:

AgentCore Agent Response: Hello! I can help you with weather information.
Execution Time: 1.2s
Status: Success

### Next steps..................................................................................................................................................

After you successfully deploy and test your first AgentCore agent with the AgentCore MCP server,
you can explore additional capabilities:

- _Tool integration_ - Connect your AgentCore agent to Amazon Bedrock AgentCore Gateway for
    external tool access
- _Memory integration_ - Add Amazon Bedrock AgentCore Memory for conversation context
- _Identity management_ - Implement Amazon Bedrock AgentCore Identity for secure access control
- _Advanced frameworks_ - Explore integration with LangGraph, CrewAI, and other frameworks

For more information, see the following:

- the section called â€œGet started with AgentCore Runtimeâ€
- the section called â€œGet started with AgentCore Gatewayâ€
- AgentCore CLI reference

Next steps 724


## Security in Amazon Bedrock AgentCore

Cloud security at AWS is the highest priority. As an AWS customer, you benefit from data centers
and network architectures that are are designed to help meet with the requirements of the most
security-sensitive organizations.

Security is a shared responsibility between AWS and you. The shared responsibility model describes
this as security _of_ the cloud and security _in_ the cloud:

- **Security of the cloud** â€“ AWS is responsible for protecting the infrastructure that runs AWS
    services in the AWS Cloud. AWS also provides you with services that you can use securely. Third-
    party auditors regularly test and verify the effectiveness of our security as part of the AWS
    Compliance Programs. To learn about the compliance programs that apply to Amazon Bedrock
    AgentCore, see AWS Services in Scope by Compliance Program.
- **Security in the cloud** â€“ Your responsibility is determined by the AWS service that you use. You
    are also responsible for other factors including the sensitivity of your data, your companyâ€™s
    requirements, and applicable laws and regulations.

This documentation helps you understand how to apply the shared responsibility model when
using AgentCore. The following topics show you how to configure AgentCore to help meet your
security and compliance objectives You also learn how to use other AWS services that help you to
monitor and secure your AgentCore resources.

**Topics**

- Data protection in Amazon Bedrock AgentCore
- Identity and access management for Amazon Bedrock AgentCore
- Compliance validation for Amazon Bedrock AgentCore
- Resilience in Amazon Bedrock AgentCore
- Cross-service confused deputy prevention

### Data protection in Amazon Bedrock AgentCore

The AWS shared responsibility model applies to data protection in Amazon Bedrock AgentCore. As
described in this model, AWS is responsible for protecting the global infrastructure that runs all
of the AWS Cloud. You are responsible for maintaining control over your content that is hosted on

Data protection 725


this infrastructure. You are also responsible for the security configuration and management tasks
for the AWS services that you use. For more information about data privacy, see the Data Privacy
FAQ. For information about data protection in Europe, see the AWS Shared Responsibility Model
and GDPR blog post on the _AWS Security Blog_.

For data protection purposes, we recommend that you protect AWS account credentials and set
up individual users with AWS IAM Identity Center or AWS Identity and Access Management (IAM).
That way, each user is given only the permissions necessary to fulfill their job duties. We also
recommend that you secure your data in the following ways:

- Use multi-factor authentication (MFA) with each account.
- Use SSL/TLS to communicate with AWS resources. We require TLS 1.2 and recommend TLS 1.3.
- Set up API and user activity logging with AWS CloudTrail. For information about using CloudTrail
    trails to capture AWS activities, see Working with CloudTrail trails in the _AWS CloudTrail User_
    _Guide_.
- Use AWS encryption solutions, along with all default security controls within AWS services.
- Use advanced managed security services such as Amazon Macie, which assists in discovering and
    securing sensitive data that is stored in Amazon S3.
- If you require FIPS 140-3 validated cryptographic modules when accessing AWS through a
    command line interface or an API, use a FIPS endpoint. For more information about the available
    FIPS endpoints, see Federal Information Processing Standard (FIPS) 140-3.

We strongly recommend that you never put confidential or sensitive information, such as your
customers' email addresses, into tags or free-form text fields such as a **Name** field. This includes
when you work with AgentCore or other AWS services using the console, API, AWS CLI, or AWS
SDKs. Any data that you enter into tags or free-form text fields used for names may be used for
billing or diagnostic logs. If you provide a URL to an external server, we strongly recommend that
you do not include credentials information in the URL to validate your request to that server.

**AgentCore Gateway-specific considerations**

- AgentCore Gateway accepts inputs from customers for tool definitions and service details, which
    can potentially contain personally identifiable information (PII).
- Customer data and metadata are stored in Amazon DynamoDB and Amazon Simple Storage
    Service and are encrypted either with a service key or a customer-managed KMS key.
- Customer content is not used to provide and maintain the AgentCore Gateway service.

Data protection 726


- Metadata doesn't include customer information (such as PII).
- Metrics and logs are stored in CloudWatch.

**Topics**

- Data encryption
- Protecting your data using VPC and AWS PrivateLink
- Cross-region inference in Amazon Bedrock AgentCore Memory

#### Data encryption..................................................................................................................................

**Encryption at rest**

Amazon Bedrock AgentCore stores data at rest using Amazon DynamoDB and Amazon Simple
Storage Service (Amazon S3). The data at rest is encrypted using AWS encryption solutions
by default. AgentCore encrypts your data using AWS owned encryption keys from AWS Key
Management Service. You donâ€™t have to take any action to protect the AWS managed keys that
encrypt your data. For more information, see AWS owned keys in the _AWS Key Management Service
Developer Guide_.

**Key considerations**

- The following data is not encrypted by default:
    - Gateway names
    - Gateway target names
    - Gateway tool names
    - Gateway CloudWatch logs
- Customers can encrypt the following resources with a customer-managed KMS key:
    - Gateways â€“ For more information, see Encrypt your AgentCore gateway with a customer-
       managed KMS key.

**Encryption in transit**

All communication between customers and Amazon Bedrock AgentCore and between AgentCore
and its downstream dependencies is protected using TLS 1.2 or higher connections.

Data encryption 727


Encryption in transit is configured by default for the following services:

**Key considerations**

- All outbound traffic for AgentCore Gateway is protected using TLS.
- When invoking a gateway, note the following about the data that is transferred:
    - During a _call tool_ request, the service transforms the data in the request and makes a call to
       the customer-configured web service. The response from the web service is transformed and
       returned as a _call tool_ response to the invoker.
    - During a _list tools_ request, the request is a standard MCP list/tools operation request and the
       response contains a list of tools configured on the gateway by the customer during control
       plane operations.

**Key management**

You can use AWS KMS customer managed keys for the following Amazon Bedrock AgentCore
resources:

**Resources that support AWS KMS customer managed keys**

- Memories. For more information, see Create an AgentCore Memory.
- Gateways. For more information, see Encrypt your AgentCore gateway with a customer-managed
    KMS key. Note the following:
    - For AgentCore Gateway resources, AWS managed keys are single-tenant use and different for
       each region.
    - If a key encrypting your gateway is compromised, you should rotate the key or delete the
       gateway and create a new one with a new key.
    - AgentCore Gateway integrates with AWS Certificate Manager. For more information, see AWS
       Certificate Manager User Guide

#### Protecting your data using VPC and AWS PrivateLink

You can use Amazon Virtual Private Cloud (Amazon VPC) and AWS PrivateLink to create private
connections between your VPC and Amazon Bedrock AgentCore.

**Topics**

VPC and AWS PrivateLink 728


- Use interface VPC endpoints (AWS PrivateLink) to create a private connection between your VPC
    and your Amazon Bedrock AgentCore resources
- Configure Amazon Bedrock AgentCore Runtime and tools for VPC

**Use interface VPC endpoints (AWS PrivateLink) to create a private connection**

**between your VPC and your Amazon Bedrock AgentCore resources**

You can use AWS PrivateLink to create a private connection between your VPC and Amazon
Bedrock AgentCore. You can access AgentCore as if it were in your VPC, without the use of an
internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. Instances in
your VPC don't need public IP addresses to access AgentCore.

You establish this private connection by creating an _interface endpoint_ , powered by AWS
PrivateLink. We create an endpoint network interface in each subnet that you enable for the
interface endpoint. These are requester-managed network interfaces that serve as the entry point
for traffic destined for AgentCore.

For more information, see Access AWS services through AWS PrivateLink in the _AWS PrivateLink
Guide_.

**Considerations for AgentCore**

Before you set up an interface endpoint for AgentCore, review Considerations in the _AWS
PrivateLink Guide_.

AgentCore supports the following primitives through the singular interface endpoint
com.amazonaws. _region_ .bedrock-agentcore:

- **Runtime** - Agent runtime operations
- **Built-in Tools** - Code Interpreter and Browser Tool operations
- **Memory** - Memory store operations
- **Identity** - Identity management operations

The following primitive uses a separate endpoint:

- **AgentCore Gateway** - Uses endpoint com.amazonaws. _region_ .bedrock-
    agentcore.gateway

VPC and AWS PrivateLink 729


Note
AWS PrivateLink is currently not supported for AgentCore control plane endpoints.

For a list of AWS Regions in which AgentCore interface endpoints are available, see AWS Regions.

Authorization considerations for data plane APIs
The data plane APIs support both AWS Signature Version 4 (SigV4) headers for
authentication and Bearer Token (OAuth) authentication. VPC endpoint policies can only
restrict callers based on IAM principals and not OAuth users. For OAuth-based requests to
succeed through the VPC endpoint, the principal must be set to * in the endpoint policy.
Otherwise, only SigV4 allowlisted callers can make successful calls over the VPC endpoint.

AWS IAM global condition context keys are supported. By default, full access to AgentCore is
allowed through the interface endpoint. You can control access by attaching an endpoint policy to
the interface endpoint or by associating a security group with the endpoint network interfaces.

**Create an interface endpoint for AgentCore**

You can create an interface endpoint for AgentCore using either the Amazon VPC console or the
AWS Command Line Interface (AWS CLI). For more information, see Create an interface endpoint in
the _AWS PrivateLink Guide_.

Create an interface endpoint for AgentCore using the following service name format:

- All primitives (Runtime, Built-in Tools, Memory, Identity): com.amazonaws. _region_ .bedrock-
    agentcore
- For AgentCore Gateway: com.amazonaws. _region_ .bedrock-agentcore.gateway

If you enable private DNS for the interface endpoint, you can make API requests to
AgentCore using its default Regional DNS name. For example, bedrock-agentcore.us-
east-1.amazonaws.com.

VPC and AWS PrivateLink 730


**Create an endpoint policy for your interface endpoint**

An endpoint policy is an IAM resource that you can attach to an interface endpoint. The default
endpoint policy allows full access to AgentCore through the interface endpoint. To control the
access allowed to AgentCore from your VPC, attach a custom endpoint policy to the interface
endpoint.

An endpoint policy specifies the following information:

- The principals that can perform actions (AWS accounts, IAM users, and IAM roles).
    - For AgentCore Gateway, if your gateway ingress isn't AWS Signature Version 4 (SigV4)-based
       (for example, if you use OAuth instead), you must specify the Principal field as the wildcard
       *. SigV4 -based authentication allows you to define the Principal as a specific AWS identity.
       This also applies to AgentCore Runtime.
- The actions that can be performed.
- The resources on which the actions can be performed.

For more information, see Control access to services using endpoint policies in the _AWS PrivateLink
Guide_.

**Endpoint policies for various primitives**

The following examples show endpoint policies for different AgentCore components:

Runtime

The following endpoint policy allows specific IAM principals to invoke agent runtime resources.

{
"Statement": [
{
"Effect": "Allow",
"Principal": {
"AWS": "arn:aws::iam:: ACCOUNT_ID :user/ USERNAME "
},
"Action": [
"bedrock-agentcore:InvokeAgentRuntime"
],
"Resource": "arn:aws::bedrock-agentcore:us-
east-1: ACCOUNT_ID :runtime/ RUNTIME_ID "

VPC and AWS PrivateLink 731


}
]
}

Mixed IAM and OAuth authentication

The InvokeAgentRuntime API supports two modes of VPC endpoint authorization. The
following example policy allows both IAM principals and OAuth callers to access different agent
runtime resources.

{
"Statement": [
{
"Effect": "Allow",
"Principal": {
"AWS": "arn:aws::iam:: ACCOUNT_ID :root"
},
"Action": [
"bedrock-agentcore:InvokeAgentRuntime"
],
"Resource": "arn:aws::bedrock-agentcore:us-
east-1: ACCOUNT_ID :runtime/ customAgent1 "
},
{
"Effect": "Allow",
"Principal": "*",
"Action": [
"bedrock-agentcore:InvokeAgentRuntime"
],
"Resource": "arn:aws::bedrock-agentcore:us-
east-1: ACCOUNT_ID :runtime/ customAgent2 "
}
]
}

The above policy allows only the IAM principal to make InvokeAgentRuntime calls
to customAgent1. It also allows both IAM principals and OAuth callers to make
InvokeAgentRuntime calls to customAgent2.

Code Interpreter Tool

The following endpoint policy allows specific IAM principals to invoke Code Interpreter
resources.

VPC and AWS PrivateLink 732


{
"Statement": [
{
"Effect": "Allow",
"Principal": {
"AWS": "arn:aws::iam:: ACCOUNT_ID :root"
},
"Action": [
"bedrock-agentcore:InvokeCodeInterpreter"
],
"Resource": "arn:aws::bedrock-agentcore:us-east-1: ACCOUNT_ID :code-
interpreter/ CODE_INTERPRETER_ID "
}
]
}

Memory

All data plane operations

The following endpoint policy allows specific IAM principals to access us-east-1 data plane
operations for a specific AgentCore Memory.

{
"Statement": [
{
"Effect": "Allow",
"Principal": {
"AWS": "arn:aws::iam:: ACCOUNT_ID :root"
},
"Action": [
"bedrock-agentcore:CreateEvent",
"bedrock-agentcore:DeleteEvent",
"bedrock-agentcore:GetEvent",
"bedrock-agentcore:ListEvents",
"bedrock-agentcore:DeleteMemoryRecord",
"bedrock-agentcore:GetMemoryRecord",
"bedrock-agentcore:ListMemoryRecords",
"bedrock-agentcore:RetrieveMemoryRecords",
"bedrock-agentcore:ListActors",
"bedrock-agentcore:ListSessions",
"bedrock-agentcore:BatchCreateMemoryRecords",
"bedrock-agentcore:BatchDeleteMemoryRecords",

VPC and AWS PrivateLink 733


"bedrock-agentcore:BatchUpdateMemoryRecords"
],
"Resource": "arn:aws::bedrock-agentcore:us-
east-1: ACCOUNT_ID :memory/ MEMORY_ID "
}
]
}

Access to all memories

The following endpoint policy allows specific IAM principals access to all memories.

{
"Statement": [
{
"Effect": "Allow",
"Principal": {
"AWS": "arn:aws::iam:: ACCOUNT_ID :root"
},
"Action": [
"bedrock-agentcore:CreateEvent",
"bedrock-agentcore:DeleteEvent",
"bedrock-agentcore:GetEvent",
"bedrock-agentcore:ListEvents",
"bedrock-agentcore:DeleteMemoryRecord",
"bedrock-agentcore:GetMemoryRecord",
"bedrock-agentcore:ListMemoryRecords",
"bedrock-agentcore:RetrieveMemoryRecords",
"bedrock-agentcore:ListActors",
"bedrock-agentcore:ListSessions",
"bedrock-agentcore:BatchCreateMemoryRecords",
"bedrock-agentcore:BatchDeleteMemoryRecords",
"bedrock-agentcore:BatchUpdateMemoryRecords"
],
"Resource": "arn:aws::bedrock-agentcore:us-east-1: ACCOUNT_ID :memory/*"
}
]
}

Access restriction by APIs

The following endpoint policy grants permission for a specific IAM principal to create events in a
specific AgentCore Memory resource.

VPC and AWS PrivateLink 734


{
"Statement": [
{
"Effect": "Allow",
"Principal": {
"AWS": "arn:aws::iam:: ACCOUNT_ID :root"
},
"Action": [
"bedrock-agentcore:CreateEvent"
],
"Resource": "arn:aws::bedrock-agentcore:us-
east-1: ACCOUNT_ID :memory/ MEMORY_ID "
}
]
}

Browser Tool

The following endpoint policy allows specific IAM principals to connect to Browser Tool
resources.

{
"Statement": [
{
"Effect": "Allow",
"Principal": {
"AWS": "arn:aws::iam:: ACCOUNT_ID :root"
},
"Action": [
"bedrock-agentcore:ConnectBrowserAutomationStream"
],
"Resource": "arn:aws::bedrock-agentcore:us-
east-1: ACCOUNT_ID :browser/ BROWSER_ID "
}
]
}

Gateway

The following is an example of a custom endpoint policy. When you attach this policy to your
interface endpoint, it allows all principals to invoke the gateway specified in the Resource
field.

VPC and AWS PrivateLink 735


{
"Statement": [
{
"Effect": "Allow",
"Principal": "*",
"Action": [
"bedrock:InvokeGateway"
],
"Resource": "arn:aws::bedrock-agentcore:us-east-1::gateway/ my-gateway "
}
]
}

Identity

The following endpoint policy allows access to Identity resources.

{
"Statement": [
{
"Effect": "Allow",
"Principal": "",
"Action": [
""
],
"Resource": "arn:aws:bedrock-agentcore:us-east-1: ACCOUNT_ID :workload-
identity-directory/default/workload-identity/ WORKLOAD_IDENTITY_ID "
}
]
}

**Configure Amazon Bedrock AgentCore Runtime and tools for VPC**

You can configure Amazon Bedrock AgentCore Runtime and built-in tools (Code Interpreter and
Browser Tool) to connect to resources in your Amazon Virtual Private Cloud (VPC). By configuring
VPC connectivity, you enable secure access to private resources such as databases, internal APIs,
and services within your VPC.

VPC and AWS PrivateLink 736


**VPC connectivity for Amazon Bedrock AgentCore Runtime and tools**

To enable Amazon Bedrock AgentCore Runtime and built-in tools to securely access resources
in your private VPC, AgentCore provides VPC connectivity capabilities. This feature allows your
runtime and tools to:

- Connect to private resources without exposing them to the internet
- Maintain secure communications within your organization's network boundaries
- Access enterprise data stores and internal services while preserving security

When you configure VPC connectivity for Amazon Bedrock AgentCore Runtime and tools:

- Amazon Bedrock creates elastic network interfaces (ENIs) in your VPC using the service-linked
    role AWSServiceRoleForBedrockAgentCoreNetwork
- These ENIs enable your Amazon Bedrock AgentCore Runtime and tools to securely communicate
    with resources in your VPC
- Each ENI is assigned a private IP address from the subnets you specify
- Security groups attached to the ENIs control which resources your runtime and tools can
    communicate with

Note
VPC connectivity impacts inbound and outbound network traffic from AgentCore services.
When you host your application in an AWS VPC, you can establish private connectivity
to the AgentCore Runtime and AgentCore Gateway APIs by adding the AgentCore VPC
endpoint to your VPC. This enables secure API calls, without internet traversal, through VPC
PrivateLink inbound connections.

**Prerequisites**

Before configuring Amazon Bedrock AgentCore Runtime and tools for VPC access, ensure you have:

- An Amazon VPC with appropriate subnets for your runtime and tool requirements. For example,
    to configure your subnets to have internet access, see Internet access considerations.
- Subnets located in supported Availability Zones for your region. For information about
    supported Availability Zones, see Supported Availability Zones.

VPC and AWS PrivateLink 737


- Appropriate security groups defined in your VPC for runtime and tool access patterns. For
    example, to configure your security groups to connect to Amazon RDS, see Example: Connecting
    to an Amazon RDS database.
- Required IAM permissions to create and manage the service-linked role (already included in the
    AWS managed policy BedrockAgentCoreFullAccess). For information about required permissions,
    see IAM permissions.
- Required VPC endpoints if your VPC doesn't have internet access. For example, to configure your
    VPC endpoints, see VPC endpoint configuration.
- Understanding of your runtime and tool network requirements (databases, APIs, web resources).
    If you need to use Browser tool which requires internet access, then your VPC should have
    internet access through NAT Gateway. For example, see Security group considerations.

Important
AgentCore creates a network interface in your account with a private IP address. Using a
public subnet does not provide internet connectivity. To enable internet access, place it in
private subnets with a route to a NAT Gateway.

**Supported Availability Zones**

AgentCore supports VPC connectivity in specific Availability Zones within each supported region.
When configuring subnets for your Amazon Bedrock AgentCore Runtime and built-in tools, ensure
that your subnets are located in the supported Availability Zones for your region.

The following table shows the supported Availability Zone IDs for each region:

Region Region Code Supported Availability Zones

US East (N. Virginia) us-east-1 â€¢ use1-az1

- use1-az2
- use1-az4

US East (Ohio) us-east-2 â€¢ use2-az1

- use2-az2
- use2-az3

VPC and AWS PrivateLink 738


Region Region Code Supported Availability Zones

US West (Oregon) us-west-2 â€¢ usw2-az1

- usw2-az2
- usw2-az3

Asia Pacific (Sydney) ap-southeast-2 â€¢ apse2-az1

- apse2-az2
- apse2-az3

Asia Pacific (Mumbai) ap-south-1 â€¢ aps1-az1

- aps1-az2
- aps1-az3

Asia Pacific (Singapor
e)

ap-southeast-1 â€¢ apse1-az1

- apse1-az2
- apse1-az3

Asia Pacific (Tokyo) ap-northeast-1 â€¢ apne1-az1

- apne1-az2
- apne1-az4

Europe (Ireland) eu-west-1 â€¢ euw1-az1

- euw1-az2
- euw1-az3

Europe (Frankfurt) eu-central-1 â€¢ euc1-az1

- euc1-az2
- euc1-az3

VPC and AWS PrivateLink 739


Important
Subnets must be located in the supported Availability Zones listed above. If you specify
subnets in unsupported Availability Zones, the configuration will fail during resource
creation.

To identify the Availability Zone ID of your subnets, you can use the following CLI command:

aws ec2 describe-subnets --subnet-ids subnet-12345678 --query
'Subnets[0].AvailabilityZoneId'

**IAM permissions**

AgentCore uses the service-linked role AWSServiceRoleForBedrockAgentCoreNetwork
to create and manage network interfaces in your VPC. This role is automatically created when
you first configure Amazon Bedrock AgentCore Runtime or AgentCore built-in tools to use VPC
connectivity.

If you need to create this role manually, your IAM entity needs the following permissions:

{
"Action": "iam:CreateServiceLinkedRole",
"Effect": "Allow",
"Resource": "arn:aws:iam::*:role/aws-service-role/network.bedrock-
agentcore.amazonaws.com/AWSServiceRoleForBedrockAgentCoreNetwork",
"Condition": {
"StringLike": {
"iam:AWSServiceName": "network.bedrock-agentcore.amazonaws.com"
}
}
}

This permission is already included in the AWS managed policy BedrockAgentCoreFullAccess.

**Best practices**

For optimal performance and security with VPC-connected Amazon Bedrock AgentCore Runtime
and built-in tools:

- **High Availability** :

VPC and AWS PrivateLink 740


- Configure at least two private subnets in different Availability Zones. For a list of supported
    Availability Zones, see Supported Availability Zones.
- Deploy dependent resources (such as databases or caches) with multi-AZ support to avoid
    single points of failure.
- **Network Performance** :
- Place Amazon Bedrock AgentCore Runtime or built-in tools subnets in the same Availability
Zones as the resources they connect to. This reduces cross-AZ latency and data transfer costs.
- Use VPC endpoints for AWS services whenever possible. Endpoints provide lower latency,
higher reliability, and avoid NAT gateway charges for supported services.
- **Security** :
- Apply the principle of least privilege when creating security group rules.
- Enable VPC Flow Logs for auditing and monitoring. Review logs regularly to identify
unexpected traffic patterns.
- **Internet Access** :
- To provide internet access from Amazon Bedrock AgentCore Runtime or built-in tools inside a
VPC, configure a NAT gateway in a public subnet. Update the route table for private subnets to
send outbound traffic (0.0.0.0/0) to the NAT gateway.
- We recommend using VPC endpoints for AWS services instead of internet routing to improve
security and reduce costs.

**Configuring VPC access for runtime and tools**

You can configure VPC access for Amazon Bedrock AgentCore Runtime and built-in tools using the
AWS Management Console, AWS CLI, or AWS SDKs.

**Runtime configuration**

AWS Management Console

1. Open the AgentCore console at https://console.aws.amazon.com/bedrock-agentcore/
    home#.
2. Navigate to the AgentCore section
3. Select or create an Amazon Bedrock AgentCore Runtime configuration
4. Choose your ECR image
5. Under the Network configuration section, choose **VPC**

VPC and AWS PrivateLink 741


6. Select your VPC from the dropdown list
7. Select the appropriate subnets for your application needs
8. Select one or more security groups to apply to the ENIs
9. Save your configuration

##### AWS CLI

aws bedrock-agentcore create-runtime
--runtime-name "MyAgentRuntime"
--network-configuration '{
"networkMode": "VPC",
"networkModeConfig": {
"subnets": ["subnet-0123456789abcdef0", "subnet-0123456789abcdef1"],
"securityGroups": ["sg-0123456789abcdef0"]
}
}'

AWS SDK (Python)

import boto3

client = boto3.client('bedrock-agentcore')

response = client.create_runtime(
runtimeName='MyAgentRuntime',
networkConfiguration={
'networkMode': 'VPC',
'networkModeConfig': {
'subnets': ['subnet-0123456789abcdef0', 'subnet-0123456789abcdef1'],
'securityGroups': ['sg-0123456789abcdef0']
}
}
)

**Code Interpreter configuration**

AWS Management Console

1. Open the AgentCore console at https://console.aws.amazon.com/bedrock-agentcore/
    home#.

VPC and AWS PrivateLink 742


2. Navigate to AgentCore â†’ Built-in Tools â†’ Code Interpreter
3. Select **Create Code Interpreter** or modify existing configuration
4. Provide a tool name (optional)
5. Configure execution role with necessary permissions
6. Under Network configuration, choose **VPC**
7. Select your VPC from the dropdown
8. Choose appropriate subnets (recommend private subnets across multiple AZs with NAT
    gateway)
9. Select security groups for ENI access control
10. Configure execution role with necessary permissions
11. Save your configuration

##### AWS CLI

aws bedrock-agentcore-control create-code-interpreter
--region
--name "my-code-interpreter"
--description "My Code Interpreter with VPC mode for data analysis"
--execution-role-arn "arn:aws:iam::123456789012:role/my-execution-role"
--network-configuration '{
"networkMode": "VPC",
"networkModeConfig": {
"subnets": ["subnet-0123456789abcdef0", "subnet-0123456789abcdef1"],
"securityGroups": ["sg-0123456789abcdef0"]
}
}'

AWS SDK (Python)

import boto3

Initialize the boto3 client
cp_client = boto3.client(
'bedrock-agentcore-control',
region_name="",
endpoint_url="https://bedrock-agentcore-control..amazonaws.com"
)

VPC and AWS PrivateLink 743


Create a Code Interpreter
response = cp_client.create_code_interpreter(
name="myTestVpcCodeInterpreter",
description="Test code sandbox for development",
executionRoleArn="arn:aws:iam::123456789012:role/my-execution-role",
networkConfiguration={
'networkMode': 'VPC',
'networkModeConfig': {
'subnets': ['subnet-0123456789abcdef0', 'subnet-0123456789abcdef1'],
'securityGroups': ['sg-0123456789abcdef0']
}
}
)

Print the Code Interpreter ID
code_interpreter_id = response["codeInterpreterId"]
print(f"Code Interpreter ID: {code_interpreter_id}")

**Browser Tool configuration**

AWS Management Console

1. Open the AgentCore console at https://console.aws.amazon.com/bedrock-agentcore/
    home#.
2. In the navigation pane, choose **Built-in tools**
3. Choose **Create Browser tool**
4. Provide a tool name (optional) and description (optional)
5. Set execution role permissions
6. Under the Network configuration section, choose **VPC** mode
7. Select your VPC and subnets
8. Configure security groups for web access requirements
9. Set execution role permissions
10. Save your configuration

##### AWS CLI

aws bedrock-agentcore-control create-browser \

VPC and AWS PrivateLink 744


--region
--name "my-browser"
--description "My browser for web interaction"
--network-configuration '{
"networkMode": "VPC",
"networkModeConfig": {
"subnets": ["subnet-0123456789abcdef0", "subnet-0123456789abcdef1"],
"securityGroups": ["sg-0123456789abcdef0"]
}
}'
--recording '{
"enabled": true,
"s3Location": {
"bucket": "my-bucket-name",
"prefix": "sessionreplay"
}
}'
--execution-role-arn "arn:aws:iam::123456789012:role/my-execution-role"

AWS SDK (Python)

import boto3

Initialize the boto3 client
cp_client = boto3.client(
'bedrock-agentcore-control',
region_name="",
endpoint_url="https://bedrock-agentcore-control..amazonaws.com"
)

Create a Browser
response = cp_client.create_browser(
name="myTestVpcBrowser",
description="Test browser with VPC mode for development",
networkConfiguration={
'networkMode': 'VPC',
'networkModeConfig': {
'subnets': ['subnet-0123456789abcdef0', 'subnet-0123456789abcdef1'],
'securityGroups': ['sg-0123456789abcdef0']
}
},
executionRoleArn="arn:aws:iam::123456789012:role/Sessionreplay",
recording={

VPC and AWS PrivateLink 745


"enabled": True,
"s3Location": {
"bucket": "session-record-123456789012",
"prefix": "replay-data"
}
}
)

**Security group considerations**

Security groups act as virtual firewalls for your Amazon Bedrock AgentCore Runtime or built-in
tool when connected to a VPC. They control inbound and outbound traffic at the instance level. To
configure security groups for your runtime:

- **Outbound rules** â€“ Define outbound rules to allow your Amazon Bedrock AgentCore Runtime to
    connect to required VPC resources.
- **Inbound rules** â€“ Ensure that the target resource's security group allows inbound connections
    from the security group associated with your Amazon Bedrock AgentCore Runtime.
- **Least privilege** â€“ Apply the principle of least privilege by allowing only the minimum required
    traffic.

**Example: Connecting to an Amazon RDS database**

When your Amazon Bedrock AgentCore Runtime connects to an Amazon RDS database, configure
the security groups as follows:

**Amazon Bedrock AgentCore Runtime security group**

- **Outbound** â€“ Allow TCP traffic to the RDS database's security group on port 3306 (MySQL).
- **Inbound** â€“ Not required. The runtime only initiates outbound connections.

**Amazon RDS database security group**

- **Inbound** â€“ Allow TCP traffic from the Amazon Bedrock AgentCore Runtime security group on
    port 3306.
- **Outbound** â€“ Not required. Return traffic is automatically allowed because security groups are
    stateful.

VPC and AWS PrivateLink 746


**VPC endpoint configuration**

When running Amazon Bedrock AgentCore Runtime in a private VPC without internet access, you
must configure the following VPC endpoints to ensure proper functionality:

**Required VPC endpoints**

- **Amazon ECR Requirements** :
    - Docker endpoint: com.amazonaws. _region_ .ecr.dkr
    - ECR API endpoint: com.amazonaws. _region_ .ecr.api
- **Amazon S3 Requirements** :
    - Gateway endpoint for ECR docker layer storage: com.amazonaws. _region_ .s3
- **CloudWatch Requirements** :
    - Logs endpoint: com.amazonaws. _region_ .logs

Note
Be sure to replace region with your specific region if different.

**Internet access considerations**

When you connect Amazon Bedrock AgentCore Runtime or a built-in tool to a Virtual Private Cloud
(VPC), it does not have internet access by default. By default, these resources can communicate
only with resources inside the same VPC. If your runtime or tool requires access to both VPC
resources and the internet, you must configure your VPC accordingly.

**Internet access architecture**

To enable internet access for your VPC-connected Amazon Bedrock AgentCore Runtime or built-in
tool, configure your VPC with the following components:

- **Private subnets** â€“ Place the Amazon Bedrock AgentCore Runtime or tool's network interfaces in
    private subnets.
- **Public subnets with a NAT gateway** â€“ Deploy a NAT gateway in one or more public subnets to
    provide outbound internet access for private resources.
- **Internet gateway (IGW)** â€“ Attach an internet gateway to your VPC to enable communication
    between the NAT gateway and the internet.

VPC and AWS PrivateLink 747


**Routing configuration**

Update your subnet route tables as follows:

- **Private subnet route table** â€“ Add a default route (0.0.0.0/0) that points to the NAT gateway. This
    allows outbound traffic from the runtime or tool to reach the internet.
- **Public subnet route table** â€“ Add a default route (0.0.0.0/0) that points to the internet gateway.
    This allows the NAT gateway to communicate with the internet.

Important
Connecting Amazon Bedrock AgentCore Runtime and built-in tools to public subnets does
not provide internet access. Always use private subnets with NAT gateways for internet
connectivity.

**Monitoring and troubleshooting**

To monitor and troubleshoot your VPC-connected Amazon Bedrock AgentCore Runtime and tools:

**CloudWatch Logs**

Enable CloudWatch Logs for your Amazon Bedrock AgentCore Runtime to identify any connectivity
issues:

- Check error messages related to VPC connectivity
- Look for timeout errors when connecting to VPC resources
- Monitor initialization times (VPC connectivity may increase session startup times)

**Common issues and solutions**

- **Connection timeouts** :
    - Verify security group rules are correct
    - Ensure route tables are properly configured
    - Check that the target resource is running and accepting connections
- **DNS resolution failures** :
    - Ensure that DNS resolution is enabled in your VPC

VPC and AWS PrivateLink 748


- Verify that your DHCP options are configured correctly
- **Missing ENIs** :
- Check the IAM permissions to ensure the service-linked role has appropriate permissions
- Look for any service quotas that may have been reached

**Code Interpreter issues**

- **Code Interpreter invoke call timeouts when trying to call a public endpoint** :
    - Verify that VPC is configured with NAT gateway for internet access
- **Invoke calls for a Code Interpreter with private VPC endpoints throw "AccessDenied" errors** :
    - Make sure the execution role passed during Code Interpreter creation has the right permissions
       for AWS service for which VPC endpoint was configured
- **Invoke calls for a Code Interpreter with some private VPC endpoints show "Unable to locate**
    **Credentials" error** :
    - Check that the execution role has been provided while creating the code interpreter

**Browser Tool issues**

- **Live-View/Connection Stream is unable to load webpages and fails with connection timeouts** :
    - Check if the browser was created with Private Subnet with NAT Gateway

**Testing VPC connectivity**

To verify that your AgentCore Runtime and tools have proper VPC connectivity, you can test
connections to your private resources and verify that network interfaces are created correctly in
your specified subnets.

To verify that your AgentCore tool has internet access, you can configure a Code Interpreter with
your VPC configuration and use the Invoke API with executeCommand that attempts to connect
to a public API or website using curl command and check the response. If the connection times
out, review your VPC configuration, particularly your route tables and NAT gateway setup.

Using awscurl
awscurl -X POST
"https://bedrock-agentcore..amazonaws.com/code-interpreters/
<code_interpreter_id>/tools/invoke" \

VPC and AWS PrivateLink 749


-H "Content-Type: application/json"
-H "Accept: application/json"
-H "x-amzn-code-interpreter-session-id: your-session-id"
--service bedrock-agentcore
--region
-d '{
"name": "executeCommand",
"arguments": {
"command": "curl amazon.com"
}
}'

#### Cross-region inference in Amazon Bedrock AgentCore Memory

With cross-region inference, Amazon Bedrock AgentCore Memory will automatically select the
optimal region within your geography (as described in more detail below) to process your inference
request, maximizing available compute resources and model availability, and providing the best
customer experience.

Cross-region inference requests are kept within the AWS Regions that are part of the geography
where the data originally resides. For example, a request made within the US is kept within the
AWS Regions in the US. Although the data remains stored only in the primary region, when using
cross-region inference, your input prompts and output results may move outside of your primary
region. All data will be transmitted encrypted across Amazon's secure network.

Note
There's no additional cost for using cross-region inference.
Amazon CloudWatch and AWS CloudTrail logs won't specify the AWS Region in which data
inference occurs.
If you don't want cross-region inference, you can manage your model selection using a
built-in with overrides strategy.

**Supported Regions for AgentCore Memory cross-region inference**

For a list of Region codes and endpoints supported in AgentCore, see the section called â€œAWS
Regionsâ€. For endpoints, see Amazon Bedrock AgentCore endpoints and quotas.

Cross-region inference in AgentCore Memory 750


Supported AgentCore Memory geography Inference regions

United States US East (N. Virginia) (us-east-1)

US East (Ohio) (us-east-2)

US West (Oregon) (us-west-2)

Europe Europe (Frankfurt) (eu-central-1)

Europe (Ireland) (eu-west-1)

Asia Pacific Asia Pacific (Tokyo) (ap-northeast-1)

Asia Pacific (Mumbai) (ap-south-1)

Asia Pacific (Singapore) (ap-southeast-1)

Asia Pacific (Sydney) (ap-southeast-2)

### Identity and access management for Amazon Bedrock

### AgentCore

AWS Identity and Access Management (IAM) is an AWS service that helps an administrator securely
control access to AWS resources. IAM administrators control who can be _authenticated_ (signed in)
and _authorized_ (have permissions) to use AgentCore resources. IAM is an AWS service that you can
use with no additional charge.

**Topics**

- Audience
- Authenticating with identities
- Managing access using policies
- How Amazon Bedrock AgentCore works with IAM
- Identity-based policy examples for Amazon Bedrock AgentCore
- AWS managed policies for Amazon Bedrock AgentCore
- Using service-linked roles for Amazon Bedrock AgentCore

Identity and access management 751


- Understanding Credentials Management in Amazon Bedrock AgentCore
- Troubleshooting Amazon Bedrock AgentCore identity and access

#### Audience...............................................................................................................................................

How you use AWS Identity and Access Management (IAM) differs based on your role:

- **Service user** - request permissions from your administrator if you cannot access features (see
    Troubleshooting Amazon Bedrock AgentCore identity and access)
- **Service administrator** - determine user access and submit permission requests (see How Amazon
    Bedrock AgentCore works with IAM)
- **IAM administrator** - write policies to manage access (see Identity-based policy examples for
    Amazon Bedrock AgentCore)

#### Authenticating with identities.........................................................................................................

Authentication is how you sign in to AWS using your identity credentials. You must be
authenticated as the AWS account root user, an IAM user, or by assuming an IAM role.

You can sign in as a federated identity using credentials from an identity source like AWS
IAM Identity Center (IAM Identity Center), single sign-on authentication, or Google/Facebook
credentials. For more information about signing in, see How to sign in to your AWS account in the
_AWS Sign-In User Guide_.

For programmatic access, AWS provides an SDK and CLI to cryptographically sign requests. For
more information, see AWS Signature Version 4 for API requests in the _IAM User Guide_.

**AWS account root user**

When you create an AWS account, you begin with one sign-in identity called the AWS account _root
user_ that has complete access to all AWS services and resources. We strongly recommend that you
don't use the root user for everyday tasks. For tasks that require root user credentials, see Tasks
that require root user credentials in the _IAM User Guide_.

**Federated identity**

As a best practice, require human users to use federation with an identity provider to access AWS
services using temporary credentials.

Audience 752


A _federated identity_ is a user from your enterprise directory, web identity provider, or AWS Directory
Service that accesses AWS services using credentials from an identity source. Federated identities
assume roles that provide temporary credentials.

For centralized access management, we recommend AWS IAM Identity Center. For more
information, see What is IAM Identity Center? in the _AWS IAM Identity Center User Guide_.

**IAM users and groups**

An _IAM user_ is an identity with specific permissions for a single person or application. We
recommend using temporary credentials instead of IAM users with long-term credentials. For more
information, see Require human users to use federation with an identity provider to access AWS
using temporary credentials in the _IAM User Guide_.

An _IAM group_ specifies a collection of IAM users and makes permissions easier to manage for large
sets of users. For more information, see Use cases for IAM users in the _IAM User Guide_.

**IAM roles**

An _IAM role_ is an identity with specific permissions that provides temporary credentials. You can
assume a role by switching from a user to an IAM role (console) or by calling an AWS CLI or AWS
API operation. For more information, see Methods to assume a role in the _IAM User Guide_.

IAM roles are useful for federated user access, temporary IAM user permissions, cross-account
access, cross-service access, and applications running on Amazon EC2. For more information, see
Cross account resource access in IAM in the _IAM User Guide_.

#### Managing access using policies.......................................................................................................

You control access in AWS by creating policies and attaching them to AWS identities or resources.
A policy defines permissions when associated with an identity or resource. AWS evaluates these
policies when a principal makes a request. Most policies are stored in AWS as JSON documents. For
more information about JSON policy documents, see Overview of JSON policies in the _IAM User
Guide_.

Using policies, administrators specify who has access to what by defining which **principal** can
perform **actions** on what **resources** , and under what **conditions**.

By default, users and roles have no permissions. An IAM administrator creates IAM policies and
adds them to roles, which users can then assume. IAM policies define permissions regardless of the
method used to perform the operation.

Managing access using policies 753


**Identity-based policies**

Identity-based policies are JSON permissions policy documents that you attach to an identity (user,
group, or role). These policies control what actions identities can perform, on which resources, and
under what conditions. To learn how to create an identity-based policy, see Define custom IAM
permissions with customer managed policies in the _IAM User Guide_.

Identity-based policies can be _inline policies_ (embedded directly into a single identity) or _managed
policies_ (standalone policies attached to multiple identities). To learn how to choose between
managed and inline policies, see Choose between managed policies and inline policies in the _IAM
User Guide_.

**Resource-based policies**

Resource-based policies are JSON policy documents that you attach to a resource. Examples
include IAM _role trust policies_ and Amazon S3 _bucket policies_. In services that support resource-
based policies, service administrators can use them to control access to a specific resource. You
must specify a principal in a resource-based policy.

Resource-based policies are inline policies that are located in that service. You can't use AWS
managed policies from IAM in a resource-based policy.

**Other policy types**

AWS supports additional policy types that can set the maximum permissions granted by more
common policy types:

- **Permissions boundaries** â€“ Set the maximum permissions that an identity-based policy can grant
    to an IAM entity. For more information, see Permissions boundaries for IAM entities in the _IAM_
    _User Guide_.
- **Service control policies (SCPs)** â€“ Specify the maximum permissions for an organization or
    organizational unit in AWS Organizations. For more information, see Service control policies in
    the _AWS Organizations User Guide_.
- **Resource control policies (RCPs)** â€“ Set the maximum available permissions for resources in your
    accounts. For more information, see Resource control policies (RCPs) in the _AWS Organizations_
    _User Guide_.
- **Session policies** â€“ Advanced policies passed as a parameter when creating a temporary session
    for a role or federated user. For more information, see Session policies in the _IAM User Guide_.

Managing access using policies 754


**Multiple policy types**

When multiple types of policies apply to a request, the resulting permissions are more complicated
to understand. To learn how AWS determines whether to allow a request when multiple policy
types are involved, see Policy evaluation logic in the _IAM User Guide_.

#### How Amazon Bedrock AgentCore works with IAM......................................................................

Before you use IAM to manage access to AgentCore, learn what IAM features are available to use
with AgentCore.

IAM feature AgentCore support

Identity-based policies Yes

Resource-based policies No

Policy actions Yes

Policy resources Yes

Policy condition keys Yes

ACLs No

ABAC (tags in policies) Partial

Temporary credentials Yes

Principal permissions Yes

Service roles Yes

Service-linked roles Yes

To get a high-level view of how AgentCore and other AWS services work with most IAM features,
see AWS services that work with IAM in the _IAM User Guide_.

How Amazon Bedrock AgentCore works with IAM 755


**Identity-based policies for AgentCore**

**Supports identity-based policies:** Yes

Identity-based policies are JSON permissions policy documents that you can attach to an identity,
such as an IAM user, group of users, or role. These policies control what actions users and roles can
perform, on which resources, and under what conditions. To learn how to create an identity-based
policy, see Define custom IAM permissions with customer managed policies in the _IAM User Guide_.

With IAM identity-based policies, you can specify allowed or denied actions and resources as well
as the conditions under which actions are allowed or denied. To learn about all of the elements
that you can use in a JSON policy, see IAM JSON policy elements reference in the _IAM User Guide_.

**Identity-based policy examples for AgentCore**

To view examples of AgentCore identity-based policies, see Identity-based policy examples for
Amazon Bedrock AgentCore.

**Resource-based policies within AgentCore**

**Supports resource-based policies:** No

Resource-based policies are JSON policy documents that you attach to a resource. Examples of
resource-based policies are IAM _role trust policies_ and Amazon S3 _bucket policies_. In services that
support resource-based policies, service administrators can use them to control access to a specific
resource. For the resource where the policy is attached, the policy defines what actions a specified
principal can perform on that resource and under what conditions. You must specify a principal
in a resource-based policy. Principals can include accounts, users, roles, federated users, or AWS
services.

To enable cross-account access, you can specify an entire account or IAM entities in another
account as the principal in a resource-based policy. For more information, see Cross account
resource access in IAM in the _IAM User Guide_.

**Policy actions for AgentCore**

**Supports policy actions:** Yes

Administrators can use AWS JSON policies to specify who has access to what. That is, which
**principal** can perform **actions** on what **resources** , and under what **conditions**.

How Amazon Bedrock AgentCore works with IAM 756


The Action element of a JSON policy describes the actions that you can use to allow or deny
access in a policy. Include actions in a policy to grant permissions to perform the associated
operation.

To see a list of AgentCore actions, see Actions Defined by Amazon Bedrock AgentCore in the
_Service Authorization Reference_.

Policy actions in AgentCore use the following prefix before the action:

bedrock-agentcore

To specify multiple actions in a single statement, separate them with commas.

"Action": [
"bedrock-agentcore: action1 ",
"bedrock-agentcore: action2 "
]

To view examples of AgentCore identity-based policies, see Identity-based policy examples for
Amazon Bedrock AgentCore.

**Policy resources for AgentCore**

**Supports policy resources:** Yes

Administrators can use AWS JSON policies to specify who has access to what. That is, which
**principal** can perform **actions** on what **resources** , and under what **conditions**.

The Resource JSON policy element specifies the object or objects to which the action applies. As
a best practice, specify a resource using its Amazon Resource Name (ARN). For actions that don't
support resource-level permissions, use a wildcard (*) to indicate that the statement applies to all
resources.

"Resource": "*"

To see a list of AgentCore resource types and their ARNs, see Resources Defined by Amazon
Bedrock AgentCore in the _Service Authorization Reference_. To learn with which actions you can
specify the ARN of each resource, see Actions Defined by Amazon Bedrock AgentCore.

How Amazon Bedrock AgentCore works with IAM 757


To view examples of AgentCore identity-based policies, see Identity-based policy examples for
Amazon Bedrock AgentCore.

**Policy condition keys for AgentCore**

**Supports service-specific policy condition keys:** Yes

Administrators can use AWS JSON policies to specify who has access to what. That is, which
**principal** can perform **actions** on what **resources** , and under what **conditions**.

The Condition element specifies when statements execute based on defined criteria. You can
create conditional expressions that use condition operators, such as equals or less than, to match
the condition in the policy with values in the request. To see all AWS global condition keys, see
AWS global condition context keys in the _IAM User Guide_.

To see a list of AgentCore condition keys, see Condition Keys for Amazon Bedrock AgentCore in the
_Service Authorization Reference_. To learn with which actions and resources you can use a condition
key, see Actions Defined by Amazon Bedrock AgentCore.

The following condition keys are especially useful when working with Amazon Bedrock AgentCore:

- bedrock-agentcore:InboundJwtClaim/iss - You can use this condition key to restrict
    access to APIs that accept a JWT representing an enduser to work with specific issuer (iss)
    claim values present in the JWT passed in the request. You can apply this condition key to the
    GetWorkloadAccessTokenForJwt and CompleteResourceTokenAuth operations.
- bedrock-agentcore:InboundJwtClaim/sub - You can use this condition key
    to restrict access to APIs that accept a JWT to work with specific subject (sub) claim
    values present in the JWT passed in the request. You can apply this condition key to the
    GetWorkloadAccessTokenForJwt and CompleteResourceTokenAuth operations.
- bedrock-agentcore:InboundJwtClaim/aud - You can use this condition key to
    restrict access to APIs that accept a JWT to work with specific audience (aud) claim
    values present in the JWT passed in the request. You can apply this condition key to the
    GetWorkloadAccessTokenForJwt and CompleteResourceTokenAuth operations.
- bedrock-agentcore:userid - You can use this condition key to restrict access to APIs
    that accept a static user ID to work only with the defined user ID values in your policy
    statement. You can apply this condition key to the GetWorkloadAccessTokenForUserId and
    CompleteResourceTokenAuth operations.
- bedrock-agentcore:InboundJwtClaim/scope - You can use this condition key to restrict
    access based on the scope claim in the JWT passed in the request.

How Amazon Bedrock AgentCore works with IAM 758


- bedrock-agentcore:InboundJwtClaim/client_id - You can use this condition key
    to restrict access to APIs that accept a JWT to work with specific client_id claim values
    present in the JWT passed in the request. This key is only available when the JWT has the
    client_id claim exactly and is not available when the information is communicated in other
    similar claims. You can apply this condition key to the GetWorkloadAccessTokenForJwt and
    CompleteResourceTokenAuth operations.

To view examples of AgentCore identity-based policies, see Identity-based policy examples for
Amazon Bedrock AgentCore.

**ACLs in AgentCore**

**Supports ACLs:** No

Access control lists (ACLs) control which principals (account members, users, or roles) have
permissions to access a resource. ACLs are similar to resource-based policies, although they do not
use the JSON policy document format.

**ABAC with AgentCore**

**Supports ABAC (tags in policies):** Partial

Attribute-based access control (ABAC) is an authorization strategy that defines permissions based
on attributes called tags. You can attach tags to IAM entities and AWS resources, then design ABAC
policies to allow operations when the principal's tag matches the tag on the resource.

To control access based on tags, you provide tag information in the condition element of a policy
using the aws:ResourceTag/ _key-name_ , aws:RequestTag/ _key-name_ , or aws:TagKeys
condition keys.

If a service supports all three condition keys for every resource type, then the value is **Yes** for the
service. If a service supports all three condition keys for only some resource types, then the value is
**Partial**.

For more information about ABAC, see Define permissions with ABAC authorization in the _IAM User
Guide_. To view a tutorial with steps for setting up ABAC, see Use attribute-based access control
(ABAC) in the _IAM User Guide_.

**Using temporary credentials with AgentCore**

**Supports temporary credentials:** Yes

How Amazon Bedrock AgentCore works with IAM 759


Temporary credentials provide short-term access to AWS resources and are automatically created
when you use federation or switch roles. AWS recommends that you dynamically generate
temporary credentials instead of using long-term access keys. For more information, see
Temporary security credentials in IAM and AWS services that work with IAM in the _IAM User Guide_.

**Cross-service principal permissions for AgentCore**

**Supports forward access sessions (FAS):** Yes

Forward access sessions (FAS) use the permissions of the principal calling an AWS service,
combined with the requesting AWS service to make requests to downstream services. For policy
details when making FAS requests, see Forward access sessions.

**Service roles for AgentCore**

**Supports service roles:** Yes

A service role is an IAM role that a service assumes to perform actions on your behalf. An IAM
administrator can create, modify, and delete a service role from within IAM. For more information,
see Create a role to delegate permissions to an AWS service in the _IAM User Guide_.

Warning
Changing the permissions for a service role might break AgentCore functionality. Edit
service roles only when AgentCore provides guidance to do so.

**Service-linked roles for AgentCore**

**Supports service-linked roles:** Yes

A service-linked role is a type of service role that is linked to an AWS service. The service can
assume the role to perform an action on your behalf. Service-linked roles appear in your AWS
account and are owned by the service. An IAM administrator can view, but not edit the permissions
for service-linked roles.

For details about creating or managing service-linked roles, see AWS services that work with IAM.
Find a service in the table that includes a Yes in the **Service-linked role** column. Choose the **Yes**
link to view the service-linked role documentation for that service.

How Amazon Bedrock AgentCore works with IAM 760


#### Identity-based policy examples for Amazon Bedrock AgentCore

By default, users and roles don't have permission to create or modify AgentCore resources. To grant
users permission to perform actions on the resources that they need, an IAM administrator can
create IAM policies.

To learn how to create an IAM identity-based policy by using these example JSON policy
documents, see Create IAM policies (console) in the _IAM User Guide_.

For details about actions and resource types defined by AgentCore, including the format of the
ARNs for each of the resource types, see Actions, Resources, and Condition Keys for Amazon
Bedrock AgentCore in the _Service Authorization Reference_.

**Topics**

- Policy best practices
- Using the AgentCore console
- Allow users to view their own permissions

**Policy best practices**

Identity-based policies determine whether someone can create, access, or delete AgentCore
resources in your account. These actions can incur costs for your AWS account. When you create or
edit identity-based policies, follow these guidelines and recommendations:

- **Get started with AWS managed policies and move toward least-privilege permissions** â€“ To
    get started granting permissions to your users and workloads, use the _AWS managed policies_
    that grant permissions for many common use cases. They are available in your AWS account. We
    recommend that you reduce permissions further by defining AWS customer managed policies
    that are specific to your use cases. For more information, see AWS managed policies or AWS
    managed policies for job functions in the _IAM User Guide_.
- **Apply least-privilege permissions** â€“ When you set permissions with IAM policies, grant only the
    permissions required to perform a task. You do this by defining the actions that can be taken on
    specific resources under specific conditions, also known as _least-privilege permissions_. For more
    information about using IAM to apply permissions, see Policies and permissions in IAM in the
    _IAM User Guide_.
- **Use conditions in IAM policies to further restrict access** â€“ You can add a condition to your
    policies to limit access to actions and resources. For example, you can write a policy condition to

Identity-based policy examples 761


specify that all requests must be sent using SSL. You can also use conditions to grant access to
service actions if they are used through a specific AWS service, such as AWS CloudFormation. For
more information, see IAM JSON policy elements: Condition in the IAM User Guide.

- **Use IAM Access Analyzer to validate your IAM policies to ensure secure and functional**
    **permissions** â€“ IAM Access Analyzer validates new and existing policies so that the policies
    adhere to the IAM policy language (JSON) and IAM best practices. IAM Access Analyzer provides
    more than 100 policy checks and actionable recommendations to help you author secure and
    functional policies. For more information, see Validate policies with IAM Access Analyzer in the
    _IAM User Guide_.
- **Require multi-factor authentication (MFA)** â€“ If you have a scenario that requires IAM users or
    a root user in your AWS account, turn on MFA for additional security. To require MFA when API
    operations are called, add MFA conditions to your policies. For more information, see Secure API
    access with MFA in the _IAM User Guide_.

For more information about best practices in IAM, see Security best practices in IAM in the _IAM User
Guide_.

**Using the AgentCore console**

To access the Amazon Bedrock AgentCore console, you must have a minimum set of permissions.
These permissions must allow you to list and view details about the AgentCore resources in your
AWS account. If you create an identity-based policy that is more restrictive than the minimum
required permissions, the console won't function as intended for entities (users or roles) with that
policy.

You don't need to allow minimum console permissions for users that are making calls only to the
AWS CLI or the AWS API. Instead, allow access to only the actions that match the API operation
that they're trying to perform.

To ensure that users and roles can still use the AgentCore console, also attach the AgentCore
_ConsoleAccess_ or _ReadOnly_ AWS managed policy to the entities. For more information, see
Adding permissions to a user in the _IAM User Guide_.

**Allow users to view their own permissions**

This example shows how you might create a policy that allows IAM users to view the inline and
managed policies that are attached to their user identity. This policy includes permissions to
complete this action on the console or programmatically using the AWS CLI or AWS API.

Identity-based policy examples 762


{
"Version": "2012-10-17",
"Statement": [
{
"Sid": "ViewOwnUserInfo",
"Effect": "Allow",
"Action": [
"iam:GetUserPolicy",
"iam:ListGroupsForUser",
"iam:ListAttachedUserPolicies",
"iam:ListUserPolicies",
"iam:GetUser"
],
"Resource": ["arn:aws:iam:::user/${aws:username}"]
},
{
"Sid": "NavigateInConsole",
"Effect": "Allow",
"Action": [
"iam:GetGroupPolicy",
"iam:GetPolicyVersion",
"iam:GetPolicy",
"iam:ListAttachedGroupPolicies",
"iam:ListGroupPolicies",
"iam:ListPolicyVersions",
"iam:ListPolicies",
"iam:ListUsers"
],
"Resource": ""
}
]
}

#### AWS managed policies for Amazon Bedrock AgentCore

An AWS managed policy is a standalone policy that is created and administered by AWS. AWS
managed policies are designed to provide permissions for many common use cases so that you can
start assigning permissions to users, groups, and roles.

AWS managed policies 763


Keep in mind that AWS managed policies might not grant least-privilege permissions for your
specific use cases because they're available for all AWS customers to use. We recommend that you
reduce permissions further by defining customer managed policies that are specific to your use
cases.

You cannot change the permissions defined in AWS managed policies. If AWS updates the
permissions defined in an AWS managed policy, the update affects all principal identities (users,
groups, and roles) that the policy is attached to. AWS is most likely to update an AWS managed
policy when a new AWS service is launched or new API operations become available for existing
services.

For more information, see AWS managed policies in the _IAM User Guide_.

#### AWS managed policies......................................................................................................................

You can attach BedrockAgentCoreFullAccess to your users, groups, and roles.

This policy grants permissions that allow full access to the Amazon Bedrock AgentCore.

**Permissions details**

This policy includes the following permissions:

- bedrock-agentcore (Amazon Bedrock Agent Core) â€“ Allows principals full access to all
    Amazon Bedrock Agent Core resources.
- iam (AWS Identity and Access Management) â€“ Allows principals to list and get information
    about roles and policies, and to pass roles with "BedrockAgentCore" in the name to the bedrock-
    agentcore service. Also allows creating service-linked roles for CloudWatch Application Signals,
    Amazon Bedrock AgentCore network, and Amazon Bedrock AgentCore runtime identity.
- secretsmanager (AWS Secrets Manager) â€“ Allows principals to create, update, retrieve, and
    delete secrets with names that begin with "bedrock-agentcore".
- kms (AWS Key Management Service) â€“ Allows principals to list and describe keys, and to decrypt
    data within the same AWS account when called via the Bedrock Agent Core service.

AWS managed policies 764


- s3 (Amazon Simple Storage Service) â€“ Allows principals to get objects from S3 buckets with
    names that begin with "bedrock-agentcore-gateway-" when called via the Bedrock Agent Core
    service.
- lambda (AWS Lambda) â€“ Allows principals to list Lambda functions.
- logs (Amazon CloudWatch Logs) â€“ Allows principals to access, query, and manage log data in
    log groups related to Bedrock Agent Core and Application Signals, including creating log groups
    and streams.
- application-autoscaling (Application Auto Scaling) â€“ Allows principals to describe scaling
    policies.
- application-signals (Amazon CloudWatch Application Signals) â€“ Allows principals to
    retrieve information about application signals and start discovery.
- autoscaling (Amazon EC2 Auto Scaling) â€“ Allows principals to describe Auto Scaling resources.
- cloudwatch (Amazon CloudWatch) â€“ Allows principals to retrieve and list metrics, generate
    queries, and access other CloudWatch resources.
- oam (Amazon CloudWatch Observability Access Manager) â€“ Allows principals to list sinks.
- rum (Amazon CloudWatch RUM) â€“ Allows principals to retrieve and list RUM resources.
- synthetics (Amazon CloudWatch Synthetics) â€“ Allows principals to describe and get
    information about Synthetics resources.
- xray (AWS X-Ray) â€“ Allows principals to retrieve trace information, manage trace segment
    destinations, and work with indexing rules.

**AWS managed policy: BedrockAgentCoreNetworkServiceRolePolicy**

This policy is attached to a service-linked role that allows the service to perform actions on your
behalf. You cannot attach this policy to your users, groups, or roles.

This policy grants permissions that allow AgentCore to create and manage network interfaces in
your VPC when running in VPC mode.

**Permissions details**

This policy includes the following permissions:

- ec2 (Amazon Elastic Compute Cloud) â€“ Allows the service to create, manage, and delete network
    interfaces in your VPC, assign and unassign private IP addresses, and describe VPC resources.

AWS managed policies 765


Network interfaces are tagged with "AmazonBedrockAgentCoreManaged" to ensure the service
only manages resources it creates.

You can view this policy at BedrockAgentCoreNetworkServiceRolePolicy.

For more information about the service-linked role that uses this policy, see Using service-linked
roles for Amazon Bedrock AgentCore.

**AWS managed policy:**

**AmazonBedrockAgentCoreMemoryBedrockModelInferenceExecutionRolePolicy**

You can attach AmazonBedrockAgentCoreMemoryBedrockModelInferenceExecutionRolePolicy to
your users, groups, and roles.

This policy grants permissions that allow full access to the Amazon Bedrock Agent Core Memory.

**Permissions details**

This policy includes the following permissions.

- bedrock â€“ Allows principals to call the Amazon Bedrock Invokemodel and
    InvokeModelWithResponseStream actions. This is required so that an agent can store
    memories.

**AWS managed policy: BedrockAgentCoreRuntimeIdentityServiceRolePolicy**

This policy is attached to a service-linked role that allows the service to perform actions on your
behalf. You cannot attach this policy to your users, groups, or roles.

This policy grants permissions that allow access to identity and token management resources that
are required for AgentCore Runtime authentication and authorization.

**Permissions details**

AWS managed policies 766


This policy includes the following permissions:

- bedrock-agentcore (Amazon Bedrock Agent Core) â€“ Allows the service to get workload
    access tokens for JWT authentication and user ID-based authentication. Specifically
    allows GetWorkloadAccessToken, GetWorkloadAccessTokenForJWT, and
    GetWorkloadAccessTokenForUserId actions on the default workload identity directory and
    its associated workload identities.

**Policy contents**

You can view the complete policy at BedrockAgentCoreRuntimeIdentityServiceRolePolicy.

For more information about the service-linked role that uses this policy, see Using service-linked
roles for Amazon Bedrock AgentCore.

**AgentCore updates to AWS managed policies**

View details about updates to AWS managed policies for AgentCore since this service began
tracking these changes. For automatic alerts about changes to this page, subscribe to the RSS feed
on the AgentCore Document history page.

Change Description Date

BedrockAgentCoreRu
ntimeIdentityServiceRolePol
icy â€“ New policy

Added a new AWS managed
policy that allows AgentCore
to manage workload identity
access tokens and OAuth
credentials for agent
runtimes.

October 10, 2025

BedrockAgentCoreFullAccess

- Updated policy

Added permission to create
the Amazon Bedrock
AgentCore runtime identity
service-linked role.

October 9, 2025

BedrockAgentCoreFullAccess

- Updated policy

Added permission to create
the Amazon Bedrock

October 8, 2025

AWS managed policies 767


Change Description Date
AgentCore runtime identity
service-linked role.

BedrockAgentCoreFullAccess

- Updated policy

Added permission to create
the Amazon Bedrock
AgentCore network service-l
inked role.

September 19, 2025

BedrockAgentCoreNe
tworkServiceRolePolicy â€“ New
policy

Added a new AWS managed
policy that allows AgentCore
to create and manage
network interfaces in your
VPC when running in VPC
mode.

September 19, 2025

AgentCore started tracking
changes

AgentCore started tracking
changes for its AWS managed
policies.

July 16, 2025

#### Using service-linked roles for Amazon Bedrock AgentCore

Amazon Bedrock AgentCore uses AWS Identity and Access Management (IAM) service-linked roles.
A service-linked role is a unique type of IAM role that is linked directly to AgentCore. Service-linked
roles are predefined by AgentCore and include all the permissions that the service requires to call
other AWS services on your behalf.

A service-linked role makes using AgentCore easier because you don't have to manually add the
necessary permissions. AgentCore defines the permissions of its service-linked roles, and unless
defined otherwise, only AgentCore can assume its roles. The defined permissions include the trust
policy and the permissions policy, and that permissions policy cannot be attached to any other IAM
entity.

You can delete the roles only after first deleting their related resources. This protects your
AgentCore resources because you can't inadvertently remove permission to access the resources.

AgentCore uses the following service-linked roles:

Service-linked roles 768


- AWSServiceRoleForBedrockAgentCoreNetwork - Manages network interfaces in your VPC
- AWSServiceRoleForBedrockAgentCoreRuntimeIdentity - Manages workload identity
    access tokens and OAuth credentials for agent runtimes

**AgentCore service-linked role permissions**

**Network service-linked role**

AgentCore uses the service-linked role named AWSServiceRoleForBedrockAgentCoreNetwork
to allow AgentCore to create and manage network interfaces in your VPC on your behalf.

The AWSServiceRoleForBedrockAgentCoreNetwork service-linked role trusts the following
services to assume the role:

- network.bedrock-agentcore.amazonaws.com

The role permissions policy allows AgentCore to complete the following actions on the specified
resources:

You can view the complete policy at BedrockAgentCoreNetworkServiceRolePolicy.

{
"Version": "2012-10-17",
"Statement": [
{
"Sid": "AllowCreateEniInAnySubnet",
"Effect": "Allow",
"Action": "ec2:CreateNetworkInterface",
"Resource": "arn:aws:ec2:::subnet/"
},
{
"Sid": "AllowCreateEniWithSecurityGroups",
"Effect": "Allow",
"Action": "ec2:CreateNetworkInterface",
"Resource": "arn:aws:ec2:::security-group/"
},
{
"Sid": "AllowCreateEniWithBedrockManagedRequestTag",
"Effect": "Allow",
"Action": "ec2:CreateNetworkInterface",
"Resource": "arn:aws:ec2:::network-interface/*",

Service-linked roles 769


"Condition": {
"ForAllValues:StringEquals": {
"aws:TagKeys": [
"AmazonBedrockAgentCoreManaged"
]
},
"StringEquals": {
"aws:RequestTag/AmazonBedrockAgentCoreManaged": "true"
}
}
},
{
"Sid": "AllowTagEniOnCreate",
"Effect": "Allow",
"Action": "ec2:CreateTags",
"Resource": "arn:aws:ec2:::network-interface/",
"Condition": {
"StringEquals": {
"ec2:CreateAction": "CreateNetworkInterface"
}
}
},
{
"Sid": "AllowManageEniWhenBedrockManaged",
"Effect": "Allow",
"Action": [
"ec2:DeleteNetworkInterface",
"ec2:AssignPrivateIpAddresses",
"ec2:UnassignPrivateIpAddresses",
"ec2:CreateNetworkInterfacePermission"
],
"Resource": "arn:aws:ec2:::network-interface/",
"Condition": {
"StringEquals": {
"aws:ResourceTag/AmazonBedrockAgentCoreManaged": "true"
}
}
},
{
"Sid": "AllowGetSecurityGroupsForVpc",
"Effect": "Allow",
"Action": [
"ec2:GetSecurityGroupsForVPC"
],

Service-linked roles 770


"Resource": "arn:aws:ec2:::vpc/"
},
{
"Sid": "AllowDescribeNetworkingResources",
"Effect": "Allow",
"Action": [
"ec2:DescribeNetworkInterfaces",
"ec2:DescribeSecurityGroups",
"ec2:DescribeSubnets",
"ec2:DescribeVpcs"
],
"Resource": ""
}
]
}

**Identity service-linked role**

AgentCore uses the service-linked role named
AWSServiceRoleForBedrockAgentCoreRuntimeIdentity to allow AgentCore to manage
workload identity access tokens and OAuth credentials on your behalf.

The AWSServiceRoleForBedrockAgentCoreRuntimeIdentity service-linked role trusts the
following services to assume the role:

- runtime-identity.bedrock-agentcore.amazonaws.com

The role permissions policy allows AgentCore to complete these actions on the specified resources.

You can view the complete policy at BedrockAgentCoreRuntimeIdentityServiceRolePolicy.

{
"Version": "2012-10-17",
"Statement": {
"Sid": "AllowWorkloadIdentityAccess",
"Effect": "Allow",
"Action": [
"bedrock-agentcore:GetWorkloadAccessToken",
"bedrock-agentcore:GetWorkloadAccessTokenForJWT",
"bedrock-agentcore:GetWorkloadAccessTokenForUserId"
],
"Resource": [

Service-linked roles 771


"arn:aws:bedrock-agentcore:::workload-identity-directory/default",
"arn:aws:bedrock-agentcore:::workload-identity-directory/default/
workload-identity/*"
]
}
}

For information about changes to this policy, see AgentCore updates to AWS managed policies.

**Understanding the Identity Feature**

The service-linked role is used to support OAuth authentication and JWT bearer token features for
AgentCore Runtime resources. This feature allows agent runtimes to securely manage workload
identities and access external OAuth providers on behalf of users.

**Key Benefits of Identity Management**

- **Simplified Permission Management** : Eliminates the need to manually configure IAM policies for
    workload identity access
- **Secure Token Management** : Provides secure access to workload access tokens for OAuth flows
- **User Federation** : Enables three-legged OAuth flows for accessing external services like Google
    Drive, Microsoft Graph, etc.
- **Automatic Provisioning** : Service-linked role is created automatically when needed

**How Identity Management Works**

When you invoke an AgentCore Runtime with OAuth authentication or JWT bearer tokens:

1.You configure JWT authorizer settings (discovery URL, allowed clients, allowed audiences) during
runtime creation

2.AgentCore creates the service-linked role automatically to manage workload identity
permissions

3.The runtime uses the service-linked role to exchange JWT tokens for workload access tokens

4.Your agent code can use these tokens to access external OAuth providers and services

5.All token management is handled securely through the AgentCore Identity service

**Migration from Legacy Approach**

Service-linked roles 772


For existing agents (created before October 13, 2025)

- Continue to use manual IAM policies attached to the agent execution role
- No automatic migration - existing behavior is preserved

For new agents (created on or after October 13, 2025)

- Automatically use the service-linked role approach
- No manual IAM policy configuration required
- Simplified setup and management

The service-linked role ensures that AgentCore can only access workload identity resources that
are explicitly associated with your agent runtimes, maintaining secure isolation and clear resource
attribution.

For implementation details, see Authenticate and authorize with Inbound Auth and Outbound
Auth.

**Creating a service-linked role for AgentCore**

You don't need to manually create service-linked roles. AgentCore creates them automatically
when needed:

- **Network service-linked role** : Created when you create an AgentCore Runtime, Code Interpreter,
    or Browser resources with VPC configuration
- **Identity service-linked role** : Created when you create or update an AgentCore Runtime on or
    after **October 13, 2025**

If you delete a service-linked role and then need to create it again, you can use the same process
to re-create the role in your account. When you create the appropriate AgentCore resources,
AgentCore creates the service-linked role for you again.

**Permissions required to create a service-linked role**

You must configure permissions to allow an IAM entity (such as a user, group, or role) to create,
edit, or delete a service-linked role. The IAM entity needs to have the following permissions:

**For the Network service-linked role**

Service-linked roles 773


{
"Action": "iam:CreateServiceLinkedRole",
"Effect": "Allow",
"Resource": "arn:aws:iam::*:role/aws-service-role/network.bedrock-
agentcore.amazonaws.com/AWSServiceRoleForBedrockAgentCoreNetwork",
"Condition": {
"StringLike": {
"iam:AWSServiceName": "network.bedrock-agentcore.amazonaws.com"
}
}
}

**For the Identity service-linked role**

{
"Sid": "CreateBedrockAgentCoreRuntimeIdentityServiceLinkedRolePermissions",
"Effect": "Allow",
"Action": "iam:CreateServiceLinkedRole",
"Resource": "arn:aws:iam::*:role/aws-service-role/runtime-identity.bedrock-
agentcore.amazonaws.com/AWSServiceRoleForBedrockAgentCoreRuntimeIdentity",
"Condition": {
"StringEquals": {
"iam:AWSServiceName": "runtime-identity.bedrock-agentcore.amazonaws.com"
}
}
}

These permissions are already included in the AWS managed policy BedrockAgentCoreFullAccess.

**Editing a service-linked role for AgentCore**

AgentCore does not allow you to edit the AWSServiceRoleForBedrockAgentCoreNetwork
or AWSServiceRoleForBedrockAgentCoreRuntimeIdentity service-linked roles. After
you create a service-linked role, you cannot change the name of the role because various entities
might reference the role. However, you can edit the description of the role using IAM. For more
information, see Editing a service-linked role.

**Deleting a service-linked role for AgentCore**

If you no longer need to use a feature or service that requires a service-linked role, we recommend
that you delete that role. That way you don't have an unused entity that is not actively monitored

Service-linked roles 774


or maintained. However, you must delete all your AgentCore resources that use the service-linked
role before you can delete the role:

- **Network service-linked role** : Delete all AgentCore Runtime, Code Interpreter, and Browser
    resources with VPC configuration
- **Identity service-linked role** : Delete all AgentCore Runtime resources

**Cleaning up a service-linked role**

Before you can use IAM to delete a service-linked role, you must first confirm that the role has no
active sessions and remove any resources used by the role.

**To check whether the service-linked role has an active session in the IAM console**

1.Sign in to the AWS Management Console and open the IAM console at https://
console.aws.amazon.com/iam/.

2.In the navigation pane of the IAM console, choose **Roles** , and then choose the name (not the
check box) of the AWSServiceRoleForBedrockAgentCoreNetwork role.

3.On the **Summary** page for the selected role, choose the **Access Advisor** tab.

4.On the **Access Advisor** tab, review the recent activity for the service-linked role.

Note
If you are unsure whether AgentCore is using a service-linked role, you can try to delete the
role. If the service is using the role, then the deletion fails and you can view the Regions
where the role is being used. If the role is being used, then you must wait for the session to
end before you can delete the role. You cannot revoke the session for a service-linked role.

If you want to remove a service-linked role, you must first delete the appropriate AgentCore
resources:

- AWSServiceRoleForBedrockAgentCoreNetwork: Delete all AgentCore Runtime, Code
    Interpreter, and Browser resources with VPC configuration
- AWSServiceRoleForBedrockAgentCoreRuntimeIdentity: Delete all AgentCore Runtime
    resources

Service-linked roles 775


**Manually delete the service-linked role**

Use the IAM console, the AWS CLI, or the IAM API to delete service-linked roles. For more
information, see Deleting a service-linked role.

#### Understanding Credentials Management in Amazon Bedrock AgentCore

**MicroVM Metadata Service (MMDS)**

When you configure an execution role with Amazon Bedrock AgentCore Browser, AgentCore Code
Interpreter, or AgentCore Runtime, the underlying compute uses MMDS to access credentials,
similar to how EC2 instances use the Instance Metadata Service (IMDS). This allows the service
within the VM to retrieve temporary AWS credentials for operations like S3 access. This is
independent of the network mode that the AgentCore Code Interpreter, AgentCore Browser, or
AgentCore Runtime is running in.

Important
When configuring the execution role permissions, use careful consideration since any
code or actor running inside the VM can access these credentials by calling the metadata
endpoint.

**Best Practices for Role Setup**

- Follow the principle of least privilege when setting up the execution role. Especially when using
    these tools with LLMs, that can generate arbitrary code, it's crucial to limit permissions to only
    what you intend.
- Avoid privilege escalation by ensuring that the execution role associated with your resource has
    equal or fewer privileges than the users who can invoke it.

The following shows an example of properly scoped permissions:

{
"Effect": "Allow",
"Action": ["s3:GetObject", "s3:PutObject"],
"Resource": "arn:aws:s3:::<your-specific-bucket>/*"
}

Credentials Management 776


#### Troubleshooting Amazon Bedrock AgentCore identity and access

Use the following information to help you diagnose and fix common issues that you might
encounter when working with AgentCore and IAM.

**Topics**

- I am not authorized to perform an action in AgentCore
- I am not authorized to perform iam:PassRole
- I want to allow people outside of my AWS account to access my AgentCore resources

**I am not authorized to perform an action in AgentCore**

If you receive an error that you're not authorized to perform an action, your policies must be
updated to allow you to perform the action.

The following example error occurs when the mateojackson IAM user tries to use the console
to view details about a fictional _my-example-widget_ resource but doesn't have the fictional
bedrock-agentcore: _GetWidget_ permissions.

User: arn:aws:iam::123456789012:user/mateojackson is not authorized to perform:
bedrock-agentcore: GetWidget on resource: my-example-widget

In this case, the policy for the mateojackson user must be updated to allow access to the _my-
example-widget_ resource by using the bedrock-agentcore: _GetWidget_ action.

If you need help, contact your AWS administrator. Your administrator is the person who provided
you with your sign-in credentials.

**I am not authorized to perform iam:PassRole**

If you receive an error that you're not authorized to perform the iam:PassRole action, your
policies must be updated to allow you to pass a role to AgentCore.

Some AWS services allow you to pass an existing role to that service instead of creating a new
service role or service-linked role. To do this, you must have permissions to pass the role to the
service.

Troubleshooting 777


The following example error occurs when an IAM user named marymajor tries to use the console
to perform an action in AgentCore. However, the action requires the service to have permissions
that are granted by a service role. Mary does not have permissions to pass the role to the service.

User: arn:aws:iam::123456789012:user/marymajor is not authorized to perform:
iam:PassRole

In this case, Mary's policies must be updated to allow her to perform the iam:PassRole action.

If you need help, contact your AWS administrator. Your administrator is the person who provided
you with your sign-in credentials.

**I want to allow people outside of my AWS account to access my AgentCore**

**resources**

You can create a role that users in other accounts or people outside of your organization can use to
access your resources. You can specify who is trusted to assume the role. For services that support
resource-based policies or access control lists (ACLs), you can use those policies to grant people
access to your resources.

To learn more, consult the following:

- To learn whether AgentCore supports these features, see How Amazon Bedrock AgentCore works
    with IAM.
- To learn how to provide access to your resources across AWS accounts that you own, see
    Providing access to an IAM user in another AWS account that you own in the _IAM User Guide_.
- To learn how to provide access to your resources to third-party AWS accounts, see Providing
    access to AWS accounts owned by third parties in the _IAM User Guide_.
- To learn how to provide access through identity federation, see Providing access to externally
    authenticated users (identity federation) in the _IAM User Guide_.
- To learn the difference between using roles and resource-based policies for cross-account access,
    see Cross account resource access in IAM in the _IAM User Guide_.

### Compliance validation for Amazon Bedrock AgentCore

AWS has completed its internal assessment to validate that Amazon Bedrock AgentCore aligns
with several of the AWS compliance programs. In addition, Amazon Bedrock AgentCore is pursuing

Compliance validation 778


FedRAMP compliance. Our third-party auditors will review and test Amazon Bedrock AgentCore
during the next audit cycles for these compliance programs.

To learn whether an AWS service is within the scope of specific compliance programs, see AWS
services in Scope by Compliance Program and choose the compliance program that you are
interested in. For general information, see AWS Compliance Programs.

You can download third-party audit reports using AWS Artifact. For more information, see
Downloading Reports in AWS Artifact.

Your compliance responsibility when using AWS services is determined by the sensitivity of your
data, your company's compliance objectives, and applicable laws and regulations. For more
information about your compliance responsibility when using AWS services, see AWS Security
Documentation.

### Resilience in Amazon Bedrock AgentCore

The AWS global infrastructure is built around AWS Regions and Availability Zones. AWS Regions
provide multiple physically separated and isolated Availability Zones, which are connected with
low-latency, high-throughput, and highly redundant networking. With Availability Zones, you
can design and operate applications and databases that automatically fail over between zones
without interruption. Availability Zones are more highly available, fault tolerant, and scalable than
traditional single or multiple data center infrastructures.

For more information about AWS Regions and Availability Zones, see AWS Global Infrastructure.

In addition to the AWS global infrastructure, AgentCore offers several features to help support your
data resiliency and backup needs.

### Cross-service confused deputy prevention.........................................................................................

The confused deputy problem is a security issue where an entity that doesn't have permission to
perform an action can coerce a more-privileged entity to perform the action. In AWS, cross-service
impersonation can result in the confused deputy problem. Cross-service impersonation can occur
when one service (the _calling service_ ) calls another service (the _called service_ ). The calling service
can be manipulated to use its permissions to act on another customer's resources in a way it should
not otherwise have permission to access. To prevent this, AWS provides tools that help you protect
your data for all services with service principals that have been given access to resources in your
account.

Resilience 779


We recommend using the aws:SourceArn and aws:SourceAccount global condition context
keys in resource policies to limit the permissions that Amazon Bedrock AgentCore gives another
service to the resource. Use aws:SourceArn if you want only one resource to be associated with
the cross-service access. Use aws:SourceAccount if you want to allow any resource in that
account to be associated with the cross-service use.

The most effective way to protect against the confused deputy problem is to use the
aws:SourceArn global condition context key with the full ARN of the resource. If you don't know
the full ARN of the resource or if you are specifying multiple resources, use the aws:SourceArn
global context condition key with wildcard characters (*) for the unknown portions of the ARN. For
example, arn:aws: _servicename_ :*: _123456789012_ :*.

If the aws:SourceArn value does not contain the account ID, such as an Amazon S3 bucket ARN,
you must use both global condition context keys to limit permissions.

The following example shows how you can use the aws:SourceArn and aws:SourceAccount
global condition context keys in AgentCore to prevent the confused deputy problem.

JSON

{
"Version":"2012-10-17",
"Statement": [
{
"Sid": "AssumeRolePolicy",
"Effect": "Allow",
"Principal": {
"Service": "bedrock-agentcore.amazonaws.com"
},
"Action": "sts:AssumeRole",
"Condition": {
"StringEquals": {
"aws:SourceAccount": " 123456789012 "
},
"ArnLike": {
"aws:SourceArn": "arn:aws:bedrock-agentcore: us-
east-1 : 123456789012 :*"
}
}
}
]

Cross-service confused deputy prevention 780


}

Cross-service confused deputy prevention 781


## Tagging AgentCore resources

A _tag_ is a label that you assign to an AWS resource. Each tag consists of a _key_ and an optional _value_ ,
both of which you define.

Tags enable you to categorize your AWS resources in different ways, for example, by purpose,
owner, or environment. This is useful when you have many resources of the same typeâ€”you can
quickly identify a specific resource based on the tags you've assigned to it.

### Tagging overview.....................................................................................................................................

Each tag consists of a key and an optional value. For example, you could define a set of tags for
your account's AgentCore resources that helps you track each resource's owner and stack level.

We recommend that you devise a set of tag keys that meets your needs for each resource type.
Using a consistent set of tag keys makes it easier for you to manage your resources. You can search
and filter the resources based on the tags you add.

Tags don't have any semantic meaning to AgentCore and are interpreted strictly as a string of
characters. Also, tags are not automatically assigned to your resources. You can edit tag keys and
values, and you can remove tags from a resource at any time. You can set the value of a tag to an
empty string, but you can't set the value of a tag to null. If you add a tag that has the same key as
an existing tag on that resource, the new value overwrites the old value. If you delete a resource,
any tags for the resource are also deleted.

### Resources that support tagging...........................................................................................................

The following AgentCore resources support tagging:

- Agent runtime
- Agent runtime endpoint
- Code interpreter
- Browser
- Gateway
- Workload identity
- OAuth2 credential provider

Tagging overview 782


- API key credential provider
- Workload identity directory
- Token vault
- AgentCore Memory

### Tag restrictions.........................................................................................................................................

The following basic restrictions apply to tags:

- Maximum number of tags per resource â€“ 50
- For each resource, each tag key must be unique, and each tag key can have only one value.
- Maximum key length â€“ 128 Unicode characters in UTF-8
- Maximum value length â€“ 256 Unicode characters in UTF-8
- If your tagging schema is used across multiple services and resources, remember that other
    services may have restrictions on allowed characters. Generally allowed characters are: letters,
    numbers, and spaces representable in UTF-8, and the following characters: + - =. _ : / @.
- Tag keys and values are case-sensitive.
- Don't use aws:, AWS:, or any upper or lowercase combination of such as a prefix for either keys
    or values as it is reserved for AWS use. You can't edit or delete tag keys or values with this prefix.
    Tags with this prefix do not count against your tags per resource limit.

### Working with tags...................................................................................................................................

You can add, edit, or delete tags for AgentCore resources using the console, API, or CLI.

#### Adding tags..........................................................................................................................................

Console

You can add tags when you create the following AgentCore resources:

- Agent runtime
- Agent runtime endpoint
- Code interpreter
- Browser

Tag restrictions 783


- Gateway
- Workload identity
- OAuth2 credential provider
- API key credential provider

To add tags when creating a resource

1.Open the AgentCore console.
2.Navigate to the resource type you want to create.
3.Follow the steps to create the resource. When you reach the Tags section, choose Add tag.
4.Enter a tag key and optionally a tag value.
5.To add more tags, choose Add tag again.
6.Complete the resource creation process.

To add tags to an existing resource

1.Open the AgentCore console.
2.Navigate to the resource type and select the specific resource.
3.Choose the Tags tab.
4.Choose Add tag , then enter a key and optionally a value.
5.Choose Save changes.

##### API

You can add tags when you create resources or to existing resources using the AgentCore API.

Adding tags when creating resources

You can add tags when you create resources using the following API operations:

- CreateAgentRuntime â€“ Include tags in the tags parameter.
- CreateAgentRuntimeEndpoint â€“ Include tags in the tags parameter.
- CreateCodeInterpreter â€“ Include tags in the tags parameter.

Adding tags 784


- CreateBrowser â€“ Include tags in the tags parameter.
- CreateGateway â€“ Include tags in the tags parameter.
- CreateWorkloadIdentity â€“ Include tags in the tags parameter.
- CreateOAuth2CredentialProvider â€“ Include tags in the tags parameter.
- CreateAPIKeyCredentialProvider â€“ Include tags in the tags parameter.

Adding tags to existing resources

Use the TagResource operation to add tags to existing resources.

CLI

You can use the CLI to add tags to AgentCore resources.

To add tags to a resource

Use the tag-resource command:

aws bedrock-agentcore tag-resource
--resource-arn arn:aws:bedrock-agentcore:us-east-1:123456789012:agent-runtime/
example-runtime
--tags Key=Environment,Value=Production Key=Team,Value=AI

#### Managing tags.....................................................................................................................................

Console

You can edit tag values for existing resources in the console.

To edit tags for an existing resource

1.Open the AgentCore console.
2.Navigate to the resource type and select the specific resource.
3.Choose the Tags tab.
4.To edit a tag, modify the key or value directly.
5.Choose Save changes.

Managing tags 785


##### API

You can use the AgentCore API to list and manage tags for resources.

Listing tags

Use the ListTagsForResource operation to list the tags for a resource.

Updating tags

Use the TagResource operation to update existing tags by adding new values for existing keys.

CLI

You can use the CLI to list and manage tags for AgentCore resources.

To list tags for a resource

Use the list-tags-for-resource command:

aws bedrock-agentcore list-tags-for-resource
--resource-arn arn:aws:bedrock-agentcore:us-east-1:123456789012:agent-runtime/
example-runtime

To update tags for a resource

Use the tag-resource command to update existing tags:

aws bedrock-agentcore tag-resource
--resource-arn arn:aws:bedrock-agentcore:us-east-1:123456789012:agent-runtime/
example-runtime
--tags Key=Environment,Value=Staging

#### Deleting tags.......................................................................................................................................

Console

You can remove tags from resources in the console.

Deleting tags 786


To delete tags from a resource

1.Open the AgentCore console.
2.Navigate to the resource type and select the specific resource.
3.Choose the Tags tab.
4.To delete a tag, choose Remove next to the tag.
5.Choose Save changes.

##### API

You can use the AgentCore API to remove tags from resources.

Removing tags

Use the UntagResource operation to remove tags from a resource.

CLI

You can use the CLI to remove tags from AgentCore resources.

To remove tags from a resource

Use the untag-resource command:

aws bedrock-agentcore untag-resource
--resource-arn arn:aws:bedrock-agentcore:us-east-1:123456789012:agent-runtime/
example-runtime
--tag-keys Environment Team

Deleting tags 787


## Quotas for Amazon Bedrock AgentCore

Your AWS account has default quotas, formerly referred to as limits, for each AWS service. Unless
otherwise noted, each quota is Region-specific. You can request increases for some quotas, and
other quotas cannot be increased.

To request a quota increase, contact AWS support.

**Topics**

- AgentCore Runtime Service Quotas
- AgentCore Memory Service Quotas
- AgentCore Identity Service Quotas
- AgentCore Gateway Service Quotas
- AgentCore Browser Service Quotas
- AgentCore Code Interpreter Service Quotas

### AgentCore Runtime Service Quotas....................................................................................................

When working with AgentCore Runtime, you need to be aware of the service limits that apply to
your account. These limits help ensure service stability and availability for all users.

#### Resource allocation limits.................................................................................................................

The following table describes the resource allocation limits for AgentCore Runtime:

**Resource allocation limits**

Limit Default Value Adjustable Notes

Active session
workloads per
account

1,000 in US East (N.
Virginia) and US West
(Oregon), and 500 in
other AWS Regions.

Yes Can be increased via support
ticket

Total agents per
account

1,000 Yes Can be increased via support
ticket

AgentCore Runtime Service Quotas 788


Limit Default Value Adjustable Notes

Versions per
agent

1,000 Yes Inactive versions deleted after
45 days

Endpoints
(aliases) per agent

10 Yes Can be increased via support
ticket

Maximum size for
a Docker image
in an AgentCore
Runtime

1 GB No

Maximum
hardware
allocation per
session

2vCPU/8GB No The maximum memory/CP
U usage and allocation per
Runtime session

#### Invocation limits.................................................................................................................................

The following table describes the invocation limits for AgentCore Runtime:

**Invocation limits**

Limit Value Adjustable Notes

Request timeout 15 minutes No Maximum time for synchronous
requests

Maximum payload
size

100 MB No Maximum size for request/response
payloads

Streaming chunk
size

10 MB No Maximum size for individual chunks

Streaming
maximum
duration

60 mins No Maximum time for streaming connectio
ns

Invocation limits 789


Limit Value Adjustable Notes

Asynchronous
job maximum
duration

8 hours No Maximum execution time for asynchron
ous jobs

Invocations per
second

25 per endpoint Yes Rate limit for API calls

#### Throttling limits..................................................................................................................................

The following table describes the rate limits for AgentCore Runtime after which you will be
throttled:

**Throttling limits**

Limit Value Adjustable Notes

InvokeAge
ntRuntime API
rate, per agent,
per account

25 TPS Yes Transactions per second

New sessions
created rate, per
endpoint

10 TPM No Transactions per minute

CreateAge
ntRuntime API
rate

5 TPS Yes Transactions per second

CreateAge
ntRuntime
Endpoint API rate

5 TPS Yes Transactions per second

GetAgentRuntime
API rate

50 TPS Yes Transactions per second

Throttling limits 790


Limit Value Adjustable Notes

GetAgentR
untimeEndpoint
API rate

50 TPS Yes Transactions per second

UpdateAge
ntRuntime API
rate

5 TPS Yes Transactions per second

UpdateAge
ntRuntime
Endpoint API rate

5 TPS Yes Transactions per second

DeleteAge
ntRuntime API
rate

5 TPS Yes Transactions per second

DeleteAge
ntRuntime
Endpoint API rate

5 TPS Yes Transactions per second

ListAgent
Runtimes API rate

5 TPS Yes Transactions per second

ListAgent
RuntimeEn
dpoints API rate

5 TPS Yes Transactions per second

ListAgent
RuntimeVersions
API rate

5 TPS Yes Transactions per second

#### Lifetime session lifecycle parameters............................................................................................

The following table describes the lifetime session lifecycle parameters for AgentCore Runtime:

Lifetime session lifecycle parameters 791


**Lifetime session lifecycle parameters**

Phase Timeout Adjustable Notes

Idle session
timeout

15 minutes of
inactivity

Yes,
through
the
idleRunti
meSession
Timeout
API
parameter
in the
Lifecycle
Configura
tion
data type

When this limit is reached, the
execution environment is terminate
d and a new one is created for the
session

Maximum session
duration

8 hrs Yes,
through
the
maxLifeti
me API
parameter
in the
Lifecycle
Configura
tion
data type

### AgentCore Memory Service Quotas.....................................................................................................

The following table describes the lifetime session lifecycle parameters for AgentCore Memory:

AgentCore Memory Service Quotas 792


**AgentCore Memory limits**

Limit Value Adjustable Notes

Maximum number of AgentCore
Memory resources per AWS
Region in an AWS account
account

50 Yes

Maximum number of memory
strategies per AgentCore Memory
resource

6 No

Minimum EventExpirationDur
ation days in a CreateEvent
operation

7 No

Maximum EventExpirationDur
ation days in a CreateEvent
operation

365 No

Maximum prompt size (AppendTo
Prompt) for custom memory
strategy (Extraction/Consol
idation)

30 KB No

Maximum number of messages
per CreateEvent operation

100 No

Maximum message size in a
CreateEvent operation

9 KB No

Maximum event size in a
CreateEvent operation

10 MB No

Maximum CreateEvent requests 10 Yes The
maximum
number
of
CreateEve

AgentCore Memory Service Quotas 793


Limit Value Adjustable Notes
nt
requests
per
second
that
you can
perform
in this
AWS
account
account
in the
current
AWS
Region.

AgentCore Memory Service Quotas 794


Limit Value Adjustable Notes

Maximum CreateEvent requests
per actor, per session, including
conversational payloads

0.25 No The
maximum
number
of
CreateEve
nt
requests
per
second,
per
actor, per
session,
including
conversat
ional
payloads
that
you can
perform
in this
AWS
account
account
in the
current
AWS
Region.

AgentCore Memory Service Quotas 795


Limit Value Adjustable Notes

Maximum CreateEvent requests
per actor, per session, not
including conversational payloads

10 No The
maximum
number
of
CreateEve
nt
requests
per
second,
per
actor, per
session,
not
including
conversat
ional
payloads
that
you can
perform
in this
AWS
account
account
in the
current
AWS
Region.

AgentCore Memory Service Quotas 796


Limit Value Adjustable Notes

Maximum RetrieveMemoryReco
rds requests

5 Yes The
maximum
number
of
RetrieveM
emoryReco
rds
requests
per
second
that
you can
perform
in this
AWS
account
account
in the
current
AWS
Region.

AgentCore Memory Service Quotas 797


Limit Value Adjustable Notes

Maximum requests for all other
AgentCore Memory APIs

20 Yes The
maximum
transacti
ons per
second
(TPS)
that
can be
processed
in this
AWS
account
account
in the
current
AWS
Region
for all
other
AgentCore
Memory
APIs.

AgentCore Memory Service Quotas 798


Limit Value Adjustable Notes

Maximum number of tokens per
minute for long-term memory
extraction

150,000 Yes The
maximum
number
of tokens
per
minute
that
can be
processed
for long-
term
memory
extractio
n for
built-in
strategie
s in this
AWS
account
in the
current
AWS
Region.
You can
monitor
token
use
through
the
Amazon
CloudWatc
h metric
named
TokenCoun

AgentCore Memory Service Quotas 799


Limit Value Adjustable Notes
t in the
Bedrock-
A
gentCore
namespace

. You can
request
an
increase
to this
limit
through
the
Service
Quotas
console.

### AgentCore Identity Service Quotas......................................................................................................

When working with AgentCore Identity, you need to be aware of the service limits that apply to
your account. These limits help ensure service stability and availability for all users.

**AgentCore Identity Limits**

Limit Value Adjustabl
e

Notes

Workload identities 1,000 No The maximum number of
workload identities that you
can create in this account in the
current Region.

Resource OAuth2 credential
providers

50 No The maximum number of OAuth2
credential providers for egress

AgentCore Identity Service Quotas 800


Limit Value Adjustabl
e

Notes

resources that you can create in
this account in the current Region.

Resource API key credential
providers

50 No The maximum number of API key
credential providers for egress
resources that you can create in
this account in the current Region.

### AgentCore Gateway Service Quotas....................................................................................................

This section provides information about Amazon Bedrock AgentCore Gateway endpoints and
service limits.

#### Endpoints..............................................................................................................................................

Amazon Bedrock AgentCore Gateway provides AWS Region-specific endpoints for management
operations and runtime access.

The Amazon Bedrock AgentCore Gateway control plane endpoints use the following format, where
you can replace _<region>_ with any of the AWS Regions listed in AWS Regions.

bedrock-agentcore-control. .amazonaws.com

The AgentCore Gateway URLs for runtime access have the following format:

https://{gateway-Id}.gateway.bedrock-agentcore.{Region}.amazonaws.com

Where:

- **{gateway-Id}** is the unique identifier for your gateway
- **{Region}** is the AWS Region where your gateway is deployed

Gateway ARNs have the following format:

arn:${Partition}:bedrock-agentcore:${Region}:${Account}:gateway/${gateway-Id}

AgentCore Gateway Service Quotas 801


The AgentCore service principal is: bedrock-agentcore.amazonaws.com

#### Service quotas.....................................................................................................................................

Amazon Bedrock AgentCore Gateway has the following service quotas. You can request increases
for some quotas using the Service Quotas console.

**Amazon Bedrock AgentCore Gateway service quotas**

Quota Default value Adjustable

Number of gateways per account 1000 Yes

Number of targets per gateway 100 Yes

Number of tools per target 1000 Yes

Timeout for a gateway invocation 5 minutes Yes

Maximum inline schema size 1 MB Yes

Maximum S3 payload schema size 10 MB Yes

Tool name character limit 256 characters Yes

CreateGateway API rate 5 transactions per second Yes

UpdateGateway API rate 5 transactions per second Yes

GetGateway API rate 10 transactions per second Yes

ListGateways API rate 10 transactions per second Yes

DeleteGateway API rate 5 transactions per second Yes

CreateGatewayTarget API rate 5 transactions per second Yes

UpdateGatewayTarget API rate 5 transactions per second Yes

GetGatewayTarget API rate 10 transactions per second Yes

ListGatewayTargets API rate 10 transactions per second Yes

Service quotas 802


Quota Default value Adjustable

DeleteGatewayTarget API rate 5 transactions per second Yes

Concurrent target operations (total of Create/
Update/DeleteTarget) on same gateway

5 Yes

tool-call/tool-list rate at gateway level 50 concurrent connections Yes

tool-call/tool-list rate at account level 50 concurrent connections Yes

Search-based tool-call rate 25 transactions per
minute

Yes

Maximum tool-call/tool-list/tool-search
payload size

6 MB Yes

For more information about service quotas and how to request increases, see Requesting a quota
increase in the _Service Quotas User Guide_.

### AgentCore Browser Service Quotas.....................................................................................................

The Browser tool has the following service quotas and considerations that apply to your account.

**Browser service quotas**

Quota Default Value Adjustable Notes

Concurrent active sessions per
account for browser and CI

1000 Yes Can be increased via
support ticket

Total Browser tool configura
tions per account

100 Yes Can be increased via
support ticket

Hardware configuration per
session

1vCPU/4GB No The maximum memory/
CPU usage and configura
tion per account

AgentCore Browser Service Quotas 803


#### Browser Invocation Limits.................................................................................................................

The following table describes the invocation limits for the Browser tool:

**Browser invocation limits**

Limit Value Adjustable Notes

Automation stream limit per
session

1 No Maximum number of
automation streams per
session

Live view stream limit per
session

1 No Maximum number of live
view streams per session

Asynchronous command max
duration

8 hrs No Maximum execution
time for asynchronous
commands

Disk size 10 GB No Maximum disk space
available per session

### AgentCore Code Interpreter Service Quotas......................................................................................

The Code Interpreter tool has the following service quotas and considerations that apply to your
account.

**Code Interpreter service quotas**

Quota Default Value Adjustable Notes

Concurrent active sessions per
account

500 Yes Can be increased via
support ticket

Total Code Interpreter tool
configurations per account

100 Yes Can be increased via
support ticket

Browser Invocation Limits 804


Quota Default Value Adjustable Notes

Hardware configuration per
session

2vCPU/8GB No The maximum memory/
CPU usage and configura
tion per account

#### Code Interpreter Invocation Limits.................................................................................................

The following table describes the invocation limits for the Code Interpreter tool:

**Code Interpreter invocation limits**

Limit Value Adjustable Notes

Request timeout 15 mins No Maximum time for
synchronous requests

Max payload size 100 MB No Maximum size for
request/response
payloads

Invocations per second 3 No Rate limit for API calls
per session

Asynchronous command max
duration

8 hrs No Maximum execution
time for asynchronous
commands

Disk size 10 GB No Maximum disk space
available per session

Code Interpreter Invocation Limits 805


## Document history for the AgentCore User Guide

The following table describes the documentation releases for Amazon Bedrock AgentCore.

Change Description Date

Runtime identity service-l
inked role

Added documentation for the
new runtime identity service-
linked role that manages
workload identity access
tokens and OAuth credentials.
Updated BedrockAgentCoreFu
llAccess policy to include
permission for creating the
Amazon Bedrock AgentCore
runtime identity service-l
inked role.

October 13, 2025

General release Amazon Bedrock AgentCore is
now generally available.

October 13, 2025

Model Context Protocol (MCP)
servers as Gateway targets

Added documentation for the
Model Context Protocol (MCP)
servers as Gateway targets
and using synchronization
operations.

October 10, 2025

Model Context Protocol (MCP)
server support

Added documentation for
the Model Context Protocol
(MCP) server that helps you
transform, deploy, and test
AgentCore-compatible agents
directly from your developme
nt environment. The MCP
server works with popular
MCP clients including Kiro,

October 2, 2025

806


Cursor, Claude Code, and
Amazon Q CLI.

Managed policy updates Updated managed policy
documentation. Added
documentation for the
BedrockAgentCoreNe
tworkServiceRolePolicy
managed policy. Updated
BedrockAgentCoreFullAccess
policy to include permissio
n for creating the Amazon
Bedrock AgentCore network
service-linked role.

September 19, 2025

Initial release (preview) Initial release of the Amazon
Bedrock AgentCore Developer
Guide

July 16, 2025

807

